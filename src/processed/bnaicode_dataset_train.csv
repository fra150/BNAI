problem,question_code,solution,solution_code,tags,type,url,metadata
"Make condition inside `codegen_addop_load_const` a macro

# Bug report

### Bug description:

We need to reuse this condition: https://github.com/python/cpython/blob/71ae93374defd192e5e88fe0912eff4f8e56f286/Python/codegen.c#L287
in CFG. FTR: https://github.com/python/cpython/pull/129568#discussion_r1938565018.


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-129553
<!-- /gh-linked-prs -->
",[],"@picnixz , can you edit bug label, since this issue has changed?",[],['python'],github,https://github.com/python/cpython/issues/129552,{'repo': 'python/cpython'}
"Dependency Conflict (when installing Kernel)

# Crash report

### What happened?

I was trying to connect my Python kernel to Jupyter notebook, and it asked me to run `pip install ipykernel` and upon running the same I was continuously getting the following **Error** which I don't get when switched to 3.13.2 (Latest Stable):
```
To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip to attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts
```

### CPython versions tested on:

3.14

### Operating systems tested on:

Windows

### Output from running 'python -VV' on the command line:

3.14.0a5","[""To fix this you could try to:\n1. loosen the range of package versions you've specified\n2. remove package versions to allow pip to attempt to solve the dependency conflict\n\nERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts""]","Hi, this is the issue tracker for CPython upstream; you'll want to report this to [pip](https://github.com/pypa/pip). But, as the error says, you have a dependency conflict (unrelated to the Python version).

Imagine it like this:

- `A` is installed at version 1.0.0
- `B` requires `A` to be at that version
- But, `C` wants `A` to be at 2.0.0--it's not possible to have them both installed!

See the documentation page that pip linked: https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts",[],['python'],github,https://github.com/python/cpython/issues/130872,{'repo': 'python/cpython'}
"Confusing docs for turtle.colormode(cmode=None)

The documentation for the **Turtle** class attribute **colormode** below;

[turtle.colormode(cmode=None)](https://docs.python.org/3/library/turtle.html#turtle.colormode)

is incorrect.

The Turtle class does not have the attribute **colormode**.




",[],"That's referring to the module-level function `turtle.colormode()`, which is implemented by the `turtle.TurtleScreen.colormode` method.",[],['python'],github,https://github.com/python/cpython/issues/131100,{'repo': 'python/cpython'}
"Compilation of HACL fails under macOS Silicon for version 3.14

# Bug report

### Bug description:

Related issues: #123748, #130366, #129043

Problem:
In Python 3.14.0a5, when compiling on macOS Silicon without specifying the `--enable-universalsdk` parameter (as there is no need to compile a universal version for x86_64 & arm64), an error ""unknown type name 'Lib_IntVector_Intrinsics_vec256'"" occurs.

Compilation parameters:
```bash
./configure --prefix=/Applications/ServBay/package/python/3.14/3.14.0a5 --enable-ipv6 --enable-loadable-sqlite-extensions --with-openssl=/Applications/ServBay/package/common/openssl/3.2 --enable-optimizations --with-system-expat --with-system-libmpdec --with-readline=editline --with-lto --enable-framework=/Applications/ServBay/package/python/3.14/3.14.0a5
```

Problem analysis:
The Python team previously released a patch for this issue, but in the `configure` and `configure.ac` scripts, the patch uses the `$UNIVERSAL_ARCHS` parameter for condition checks. This fix does not completely resolve the issue because `$UNIVERSAL_ARCHS` depends on the `--enable-universalsdk` parameter being passed. Without this parameter, the initial value of `$UNIVERSAL_ARCHS` is `UNIVERSAL_ARCHS=""32-bit""`, leading to the condition `if test ""$UNIVERSAL_ARCHS"" != ""universal2""; then` not being effective.

Partial configure log:
```bash
Python 3.9+ detected
checking build system type... aarch64-apple-darwin23.5.0
checking host system type... aarch64-apple-darwin23.5.0
checking for Python interpreter freezing... ./_bootstrap_python
checking for python3.14... no
checking for python3.13... no
checking for python3.12... python3.12
checking Python for regen version... Python 3.12.5
checking pkg-config is at least version 0.9.0... yes
checking MACHDEP... ""darwin""
checking for --enable-universalsdk... no
checking for --with-universal-archs... no
checking for --with-app-store-compliance... not patching for app store compliance
checking for xcrun... yes
checking macOS SDKROOT... /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether the compiler supports GNU C... yes
checking whether gcc accepts -g... yes
checking for gcc option to enable C11 features... none needed
checking how to run the C preprocessor... gcc -E
checking for grep that handles long lines and -e... /usr/bin/grep
checking for a sed that does not truncate output... /usr/bin/sed
checking for egrep... /usr/bin/grep -E
checking for CC compiler name... clang

// blablabla
```

Repair solution:
In the `configure` and `configure.ac` scripts, it is necessary to use other conditions for checks instead of relying on `$UNIVERSAL_ARCHS`.
Attached is a quick fix patch based on `build_cpu` and `build_vendor`. However, this is not the most appropriate solution.
https://github.com/user-attachments/files/18921691/fixed-hacl-arm64.patch

### CPython versions tested on:

3.14

### Operating systems tested on:

macOS","['./configure --prefix=/Applications/ServBay/package/python/3.14/3.14.0a5 --enable-ipv6 --enable-loadable-sqlite-extensions --with-openssl=/Applications/ServBay/package/common/openssl/3.2 --enable-optimizations --with-system-expat --with-system-libmpdec --with-readline=editline --with-lto --enable-framework=/Applications/ServBay/package/python/3.14/3.14.0a5', 'Python 3.9+ detected\nchecking build system type... aarch64-apple-darwin23.5.0\nchecking host system type... aarch64-apple-darwin23.5.0\nchecking for Python interpreter freezing... ./_bootstrap_python\nchecking for python3.14... no\nchecking for python3.13... no\nchecking for python3.12... python3.12\nchecking Python for regen version... Python 3.12.5\nchecking pkg-config is at least version 0.9.0... yes\nchecking MACHDEP... ""darwin""\nchecking for --enable-universalsdk... no\nchecking for --with-universal-archs... no\nchecking for --with-app-store-compliance... not patching for app store compliance\nchecking for xcrun... yes\nchecking macOS SDKROOT... /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk\nchecking for gcc... gcc\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables...\nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether the compiler supports GNU C... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to enable C11 features... none needed\nchecking how to run the C preprocessor... gcc -E\nchecking for grep that handles long lines and -e... /usr/bin/grep\nchecking for a sed that does not truncate output... /usr/bin/sed\nchecking for egrep... /usr/bin/grep -E\nchecking for CC compiler name... clang\n\n// blablabla']",cc @msprotz @gpshead ,[],['python'],github,https://github.com/python/cpython/issues/130478,{'repo': 'python/cpython'}
"Use after free in `PyDict_Clear()` due to re-entrancy

# Crash report

The implementation of `PyDict_Clear()` isn't safe for dictionaries with values that are embedded in an object:

The calls to `Py_CLEAR(oldvalues->values[i])` can execute arbitrary code via object destructors. `oldvalues` may no longer be valid because the object its embedded in may be freed during the `Py_CLEAR()` call.

https://github.com/python/cpython/blob/0ef4ffeefd1737c18dc9326133c7894d58108c2e/Objects/dictobject.c#L2868-L2880


### Repro

```
./configure --with-address-sanitizer --with-pydebug --without-pymalloc
```

```python
class MyObj:
    pass

class DelXOnDelete:
    def __del__(self):
        global x
        del x

x = MyObj()
x.a = DelXOnDelete()

d = x.__dict__
d.clear()
```

```
==3794958==ERROR: AddressSanitizer: heap-use-after-free on address 0x513000022ec2 at pc 0x56320dddb439 bp 0x7fff8205bb90 sp 0x7fff8205bb88
READ of size 1 at 0x513000022ec2 thread T0
    #0 0x56320dddb438 in clear_lock_held /raid/sgross/cpython/Objects/dictobject.c:2872:24
    #1 0x56320dddb438 in PyDict_Clear /raid/sgross/cpython/Objects/dictobject.c:2889:5
    #2 0x56320ddf7e38 in dict_clear_impl /raid/sgross/cpython/Objects/dictobject.c:4452:5
    #3 0x56320ddf7e38 in dict_clear /raid/sgross/cpython/Objects/clinic/dictobject.c.h:157:12
...

freed by thread T0 here:
    #0 0x56320db400e6 in free (/raid/sgross/cpython/python+0x2fd0e6) (BuildId: f9a13329ff2de3d6fd6a01eae843cc226d0d8f7c)
    #1 0x56320de99e6a in subtype_dealloc /raid/sgross/cpython/Objects/typeobject.c:2611:5
    #2 0x56320de31448 in _Py_Dealloc /raid/sgross/cpython/Objects/object.c:3004:5
    #3 0x56320dddc0e6 in Py_DECREF /raid/sgross/cpython/./Include/refcount.h:393:9
    #4 0x56320dddc0e6 in _PyDict_Pop_KnownHash /raid/sgross/cpython/Objects/dictobject.c:3028:9
    #5 0x56320e064bd4 in _PyEval_EvalFrameDefault /raid/sgross/cpython/Python/generated_cases.c.h:5006:23
...
```

cc @DinoV @markshannon ","['./configure --with-address-sanitizer --with-pydebug --without-pymalloc', 'class MyObj:\n    pass\n\nclass DelXOnDelete:\n    def __del__(self):\n        global x\n        del x\n\nx = MyObj()\nx.a = DelXOnDelete()\n\nd = x.__dict__\nd.clear()', '==3794958==ERROR: AddressSanitizer: heap-use-after-free on address 0x513000022ec2 at pc 0x56320dddb439 bp 0x7fff8205bb90 sp 0x7fff8205bb88\nREAD of size 1 at 0x513000022ec2 thread T0\n    #0 0x56320dddb438 in clear_lock_held /raid/sgross/cpython/Objects/dictobject.c:2872:24\n    #1 0x56320dddb438 in PyDict_Clear /raid/sgross/cpython/Objects/dictobject.c:2889:5\n    #2 0x56320ddf7e38 in dict_clear_impl /raid/sgross/cpython/Objects/dictobject.c:4452:5\n    #3 0x56320ddf7e38 in dict_clear /raid/sgross/cpython/Objects/clinic/dictobject.c.h:157:12\n...\n\nfreed by thread T0 here:\n    #0 0x56320db400e6 in free (/raid/sgross/cpython/python+0x2fd0e6) (BuildId: f9a13329ff2de3d6fd6a01eae843cc226d0d8f7c)\n    #1 0x56320de99e6a in subtype_dealloc /raid/sgross/cpython/Objects/typeobject.c:2611:5\n    #2 0x56320de31448 in _Py_Dealloc /raid/sgross/cpython/Objects/object.c:3004:5\n    #3 0x56320dddc0e6 in Py_DECREF /raid/sgross/cpython/./Include/refcount.h:393:9\n    #4 0x56320dddc0e6 in _PyDict_Pop_KnownHash /raid/sgross/cpython/Objects/dictobject.c:3028:9\n    #5 0x56320e064bd4 in _PyEval_EvalFrameDefault /raid/sgross/cpython/Python/generated_cases.c.h:5006:23\n...']",I don't see a way to fix this without copying `oldvalues` to a temporary array.,[],['python'],github,https://github.com/python/cpython/issues/130555,{'repo': 'python/cpython'}
"Pickle exception handling could state object path

# Feature or enhancement

### Proposal:

Consider the case that you get some exception during unpickling. This could be anything, in maybe your custom object `__setstate__` or whatever else. For example, we got this crash:
```python
...
  File ""/u/dorian.koch/setups/2024-10-11--denoising-lm/recipe/returnn/returnn/util/multi_proc_non_daemonic_spawn.py"", line 156, in NonDaemonicSpawnProcess._reconstruct_with_pre_init_func
    line: reconstruct_func, reconstruct_args, reconstruct_state = pickle.load(buffer)
    locals:
      reconstruct_func = <not found>
      reconstruct_args = <not found>
      reconstruct_state = <not found>
      pickle = <global> <module 'pickle' from '/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/pickle.py'>
      pickle.load = <global> <built-in function load>
      buffer = <local> <_io.BytesIO object at 0x74bbaa61e610>
  File ""/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/synchronize.py"", line 110, in SemLock.__setstate__
    line: self._semlock = _multiprocessing.SemLock._rebuild(*state)
    locals:
      self = <local> <Lock(owner=unknown)>
      self._semlock = <local> !AttributeError: 'Lock' object has no attribute '_semlock'
      _multiprocessing = <global> <module '_multiprocessing' from '/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/lib-dynload/_multiprocessing.cpython-311-x86_64-linux-gnu.so'>
      _multiprocessing.SemLock = <global> <class '_multiprocessing.SemLock'>
      _multiprocessing.SemLock._rebuild = <global> <built-in method _rebuild of type object at 0x74bbb60322c0>
      state = <local> (132092164476928, 1, 1, '/mp-2wkdacg_')
FileNotFoundError: [Errno 2] No such file or directory
```
So, `SemLock.__setstate__` fails here for some reason. Maybe some race condition. But when I saw this crash, my first thought was, where actually do we have a `SemLock` inside the pickled object?

So, this is what I would like: In case of an exception during unpickling, it can show me the object path during the construction which lead to this object. (In case there are multiple references to the object, just show me the first.)

I'm not sure exactly how this should be done. It means some overhead. For every single object that pickle creates, we would need to store the creating parent object + name/index/whatever. So maybe this is a feature which should be optional. It would be fine for me if I run unpickling first without, and if I get some exception, I run unpickling again with this debug flag enabled. Maybe it's also fine if this is only in the pure Python implementation.

Maybe I can already do sth like this by checking the local `self` in the stack frame where the exception occured and then using `gc.get_referrers` to get back to the root?


### Links to previous discussion of this feature:

https://discuss.python.org/t/pickle-exception-handling-could-state-object-path/82395
","['...\n  File ""/u/dorian.koch/setups/2024-10-11--denoising-lm/recipe/returnn/returnn/util/multi_proc_non_daemonic_spawn.py"", line 156, in NonDaemonicSpawnProcess._reconstruct_with_pre_init_func\n    line: reconstruct_func, reconstruct_args, reconstruct_state = pickle.load(buffer)\n    locals:\n      reconstruct_func = <not found>\n      reconstruct_args = <not found>\n      reconstruct_state = <not found>\n      pickle = <global> <module \'pickle\' from \'/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/pickle.py\'>\n      pickle.load = <global> <built-in function load>\n      buffer = <local> <_io.BytesIO object at 0x74bbaa61e610>\n  File ""/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/synchronize.py"", line 110, in SemLock.__setstate__\n    line: self._semlock = _multiprocessing.SemLock._rebuild(*state)\n    locals:\n      self = <local> <Lock(owner=unknown)>\n      self._semlock = <local> !AttributeError: \'Lock\' object has no attribute \'_semlock\'\n      _multiprocessing = <global> <module \'_multiprocessing\' from \'/work/tools/users/zeyer/linuxbrew/opt/python@3.11/lib/python3.11/lib-dynload/_multiprocessing.cpython-311-x86_64-linux-gnu.so\'>\n      _multiprocessing.SemLock = <global> <class \'_multiprocessing.SemLock\'>\n      _multiprocessing.SemLock._rebuild = <global> <built-in method _rebuild of type object at 0x74bbb60322c0>\n      state = <local> (132092164476928, 1, 1, \'/mp-2wkdacg_\')\nFileNotFoundError: [Errno 2] No such file or directory']","> As noted on DPO, apparently this was [already implemented](https://github.com/python/cpython/issues/122213) back in July. Not sure whether it's right to close this as ""completed"" or not 😆

I just tried. This is about exceptions during pickling. However, I am asking here about exceptions during unpickling. So it's not what I want currently. Although, otherwise, this looks very similar to what I want.

So can we reopen this?
",[],['python'],github,https://github.com/python/cpython/issues/130621,{'repo': 'python/cpython'}
"Inconsistent error messages when returning the wrong type for the type-conversion magic methods

# Bug report

### Bug description:

I noticed the error messages between magic methods like `__int__` and `__float__` were inconsistent. This seems like slightly undesirable behavior to me. I used the following code to generate many of them.

```python
class Foo:
    def __int__(self):
        return None
    
    def __float__(self):
        return None
    
    def __bytes__(self):
        return None
    
    def __complex__(self):
        return None
    
    def __bool__(self):
        return None
    
    def __str__(self):
        return None

try:
    int(Foo())
except Exception as e:
    print(e)

try:
    float(Foo())
except Exception as e:
    print(e)

try:
    bytes(Foo())
except Exception as e:
    print(e)

try:
    complex(Foo())
except Exception as e:
    print(e)

try:
    bool(Foo())
except Exception as e:
    print(e)

try:
    str(Foo())
except Exception as e:
    print(e)
```

And the output is as follows:

```python
__int__ returned non-int (type NoneType)
Foo.__float__ returned non-float (type NoneType)
__bytes__ returned non-bytes (type NoneType)
__complex__ returned non-complex (type NoneType)
__bool__ should return bool, returned NoneType
__str__ returned non-string (type NoneType)
```
The first issue I've made, but seems like a reasonable bug. I'm not sure if there are other ""type-conversion"" magic methods out there that aren't consistent.

### CPython versions tested on:

3.13, 3.12

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130835
<!-- /gh-linked-prs -->
","['class Foo:\n    def __int__(self):\n        return None\n    \n    def __float__(self):\n        return None\n    \n    def __bytes__(self):\n        return None\n    \n    def __complex__(self):\n        return None\n    \n    def __bool__(self):\n        return None\n    \n    def __str__(self):\n        return None\n\ntry:\n    int(Foo())\nexcept Exception as e:\n    print(e)\n\ntry:\n    float(Foo())\nexcept Exception as e:\n    print(e)\n\ntry:\n    bytes(Foo())\nexcept Exception as e:\n    print(e)\n\ntry:\n    complex(Foo())\nexcept Exception as e:\n    print(e)\n\ntry:\n    bool(Foo())\nexcept Exception as e:\n    print(e)\n\ntry:\n    str(Foo())\nexcept Exception as e:\n    print(e)', '__int__ returned non-int (type NoneType)\nFoo.__float__ returned non-float (type NoneType)\n__bytes__ returned non-bytes (type NoneType)\n__complex__ returned non-complex (type NoneType)\n__bool__ should return bool, returned NoneType\n__str__ returned non-string (type NoneType)']","The difference is
https://github.com/python/cpython/blob/d780f0af2bd7b9ef8cf46d28c5d495d1c980b1f0/Objects/abstract.c#L1529-L1534
vs
https://github.com/python/cpython/blob/d780f0af2bd7b9ef8cf46d28c5d495d1c980b1f0/Objects/abstract.c#L1607-L1612

CC @serhiy-storchaka as author of 16931c35596.

I don't think that inconsistency is a real bug.  But that does make sense for me as a feature request: i.e. include type information to the exception message.",[],['python'],github,https://github.com/python/cpython/issues/130821,{'repo': 'python/cpython'}
"Inconsistent output for two string methods

# Bug report

### Bug description:

```python
# Add a code block here, if required
s = ''
s.islower()
Output: False
s.isascii()
Output: True
```
Output of these two mthods such as islower() and isascii() are inconsistent. 
```
s.isascii()
Output: True
```
Explanation for this output is ""an empty string passes the isascii() check because it does not contain any non-ASCII characters"". This same logic should be applied to islower() method as well or the vice versa.

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS","[""# Add a code block here, if required\ns = ''\ns.islower()\nOutput: False\ns.isascii()\nOutput: True"", 's.isascii()\nOutput: True']","Hello, this isn't a bug, `str.islower()` is documented as:

> Return `True` if all cased characters [[4]](https://docs.python.org/3/library/stdtypes.html#id15) in the string are lowercase and there is at least one cased character, False otherwise.

https://docs.python.org/3/library/stdtypes.html#str.islower

So an empty string gives `False`.

If we changed it, it would likely break a lot of existing code, and we'd need a very good reason to do so, beyond consistency.

If you'd like to propose the change, please open a discussion at https://discuss.python.org/c/ideas/6, but I don't think it's likely to happen.",[],['python'],github,https://github.com/python/cpython/issues/130910,{'repo': 'python/cpython'}
"ForwardRef: do not cache evaluated value

Currently, when a ForwardRef is successfully evaluated, we store the resulting value and on subsequent calls return it immediately, regardless of the arguments passed to ForwardRef.evaluate().

This is currently implemented here: https://github.com/python/cpython/blob/a4722449caccc42ad644611d02fbdb5005f601eb/Lib/annotationlib.py#L100

It matches previous behavior in 3.13: https://github.com/python/cpython/blob/8b4a0d641cde667f94ce49f5e64da6bd9d6fbd9c/Lib/typing.py#L1053

I think this is confusing: if you call evaluate() on a ForwardRef that was already evaluated, we ignore whatever globals/locals/type_params you pass in and return whatever the result of the previous evaluation was. It would make more sense to me for evaluate() to re-evaluate the ForwardRef every time it is called. Callers can add caching if they want to in a more intelligent way.

As for #129463, cc @agronholm @Viicos @leycec.",[],Duplicate of #128593.,[],['python'],github,https://github.com/python/cpython/issues/129464,{'repo': 'python/cpython'}
"NoneType is basically deprecated but None behaves differently

# Bug report

### Bug description:

python 3.13
```python
# Add a code block here, if required

>>> from types import NoneType
>>> None | int
None | int

>>> int | None
int | None

>>> None | int == int | None
True

>>> NoneType | int == None | int
True

>>> NoneType | NoneType
<class 'NoneType'>

>>> NoneType | NoneType == NoneType
True

>>> from typing import Union

>>> Union[None, None]
<class 'NoneType'>

>>> NoneType | None
<class 'NoneType'>

>>> None | NoneType
<class 'NoneType'>

>>> Union[None, NoneType]
<class 'NoneType'>

>>> None | None
Traceback (most recent call last):
  File ""<python-input-50>"", line 1, in <module>
    None | None
    ~~~~~^~~~~~
TypeError: unsupported operand type(s) for |: 'NoneType' and 'NoneType'
```


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['# Add a code block here, if required\n\n>>> from types import NoneType\n>>> None | int\nNone | int\n\n>>> int | None\nint | None\n\n>>> None | int == int | None\nTrue\n\n>>> NoneType | int == None | int\nTrue\n\n>>> NoneType | NoneType\n<class \'NoneType\'>\n\n>>> NoneType | NoneType == NoneType\nTrue\n\n>>> from typing import Union\n\n>>> Union[None, None]\n<class \'NoneType\'>\n\n>>> NoneType | None\n<class \'NoneType\'>\n\n>>> None | NoneType\n<class \'NoneType\'>\n\n>>> Union[None, NoneType]\n<class \'NoneType\'>\n\n>>> None | None\nTraceback (most recent call last):\n  File ""<python-input-50>"", line 1, in <module>\n    None | None\n    ~~~~~^~~~~~\nTypeError: unsupported operand type(s) for |: \'NoneType\' and \'NoneType\'']","> NoneType is basically deprecated 

That's not true. NoneType is not deprecated, as it can be used in some places (we even exposed it in 3.10!) where one needs type expressions.

As for why `None | None` does not work, this is the expected behaviour. We're not in a type context so we're using the `|` for instances, not for classes. Also, changing this would be a breaking change if, for instance, one tries `x | y` and both are None. We would like that to raise but not to silently convert it to `None`.

The `TYPE | None` and `None | TYPE` working is mostly synctactic sugar I think. 

cc @JelleZijlstra for more details / confirmation.",[],['python'],github,https://github.com/python/cpython/issues/129816,{'repo': 'python/cpython'}
"New REPL - readline module does not save history with write_history_file

# Bug report

### Bug description:

When using new REPL in Python 13, the readline module does not write history to the files correctly.
I have checked this issue on both my host system, as well as python:alpine container from docker.

Using PYTHON_BASIC_REPL=1 no longer causes this issue.

**Expected**
hist.txt file contains the saved commands.

**Actual**
hist.txt file is empty. Note that .python_history file does save and load history correctly.

```
/ # python -i
Python 3.13.2 (main, Feb 14 2025, 19:28:41) [GCC 14.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import readline
>>> print('abc')
abc
>>> readline.get_current_history_length()
0
>>> readline.set_history_length(100)
>>> readline.get_current_history_length()
0
>>> readline.write_history_file('hist.txt')
>>> 
/ # cat hist.txt 
/ # cat ~/.python_history 
import readline
print('abc')
readline.get_current_history_length()
readline.set_history_length(100)
readline.get_current_history_length()
readline.write_history_file('hist.txt')
/ # 
```


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['/ # python -i\nPython 3.13.2 (main, Feb 14 2025, 19:28:41) [GCC 14.2.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import readline\n>>> print(\'abc\')\nabc\n>>> readline.get_current_history_length()\n0\n>>> readline.set_history_length(100)\n>>> readline.get_current_history_length()\n0\n>>> readline.write_history_file(\'hist.txt\')\n>>> \n/ # cat hist.txt \n/ # cat ~/.python_history \nimport readline\nprint(\'abc\')\nreadline.get_current_history_length()\nreadline.set_history_length(100)\nreadline.get_current_history_length()\nreadline.write_history_file(\'hist.txt\')\n/ #']","```python
>>> readline.get_current_history_length()
0
>>> readline.set_history_length(100)
>>> readline.get_current_history_length()
0
```
`set_history_length` method sets the `_ReadlineWrapper.saved_history_length` attribute, which you can get by `get_history_length` not `get_current_history_length`

What is the readline version of your _runtime_? You can check by

```python
import readline
readline._READLINE_LIBRARY_VERSION

```","['>>> readline.get_current_history_length()\n0\n>>> readline.set_history_length(100)\n>>> readline.get_current_history_length()\n0', 'import readline\nreadline._READLINE_LIBRARY_VERSION']",['python'],github,https://github.com/python/cpython/issues/130938,{'repo': 'python/cpython'}
"urllib : systematic exception in ""quote"" if called by ""pathname2url"" and ""pathname"" is a bytes object

# Bug report

### Bug description:

Originally I found this bug when using ""livecd-creator"" (Fedora 41 version). It can be reproduce whith this minimal code.
```
from urllib import request
url = b""test""
pathname = request.pathname2url(url)
```


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129910
<!-- /gh-linked-prs -->
","['from urllib import request\nurl = b""test""\npathname = request.pathname2url(url)']","Full error message:
```
Traceback (most recent call last):
  File [35m""/usr/lib64/python3.13/idlelib/run.py""[0m, line [35m590[0m, in [35mruncode[0m
    [31mexec[0m[1;31m(code, self.locals)[0m
    [31m~~~~[0m[1;31m^^^^^^^^^^^^^^^^^^^[0m
  File [35m""<pyshell#2>""[0m, line [35m1[0m, in [35m<module>[0m
  File [35m""/usr/lib64/python3.13/urllib/request.py""[0m, line [35m1679[0m, in [35mpathname2url[0m
    return quote(pathname, encoding=encoding, errors=errors)
  File [35m""/usr/lib64/python3.13/urllib/parse.py""[0m, line [35m908[0m, in [35mquote[0m
    raise TypeError(""quote() doesn't support 'encoding' for bytes"")
[1;35mTypeError[0m: [35mquote() doesn't support 'encoding' for bytes[0m
```","['Traceback (most recent call last):\n  File \x1b[35m""/usr/lib64/python3.13/idlelib/run.py""\x1b[0m, line \x1b[35m590\x1b[0m, in \x1b[35mruncode\x1b[0m\n    \x1b[31mexec\x1b[0m\x1b[1;31m(code, self.locals)\x1b[0m\n    \x1b[31m~~~~\x1b[0m\x1b[1;31m^^^^^^^^^^^^^^^^^^^\x1b[0m\n  File \x1b[35m""<pyshell#2>""\x1b[0m, line \x1b[35m1\x1b[0m, in \x1b[35m<module>\x1b[0m\n  File \x1b[35m""/usr/lib64/python3.13/urllib/request.py""\x1b[0m, line \x1b[35m1679\x1b[0m, in \x1b[35mpathname2url\x1b[0m\n    return quote(pathname, encoding=encoding, errors=errors)\n  File \x1b[35m""/usr/lib64/python3.13/urllib/parse.py""\x1b[0m, line \x1b[35m908\x1b[0m, in \x1b[35mquote\x1b[0m\n    raise TypeError(""quote() doesn\'t support \'encoding\' for bytes"")\n\x1b[1;35mTypeError\x1b[0m: \x1b[35mquote() doesn\'t support \'encoding\' for bytes\x1b[0m']",['python'],github,https://github.com/python/cpython/issues/129683,{'repo': 'python/cpython'}
"Active thread list may be inaccurate due to data type mismatch

# Bug report

### Bug description:

https://github.com/python/cpython/commit/0e9c364f4ac18a2237bdbac702b96bcf8ef9cb09 changed `thread_get_ident` to convert a `unsigned long long` vs the previous `unsigned long`.

```c
static PyObject *
thread_get_ident(PyObject *self, PyObject *Py_UNUSED(ignored))
{
    PyThread_ident_t ident = PyThread_get_thread_ident_ex();  // <-- ULL
    if (ident == PYTHREAD_INVALID_THREAD_ID) {
        PyErr_SetString(ThreadError, ""no current thread ident"");
        return NULL;
    }
    return PyLong_FromUnsignedLongLong(ident);
}

```

However, after https://github.com/python/cpython/pull/114839 commit https://github.com/python/cpython/pull/114839/commits/76bde036984431df51f2c432b4cd078e6a9ccc58

`MainThread` is now a special case because it doesn't use `self._set_ident()`:

```python
class _MainThread(Thread):

    def __init__(self):
        Thread.__init__(self, name=""MainThread"", daemon=False)
        self._started.set()
        self._ident = _get_main_thread_ident()
        self._handle = _make_thread_handle(self._ident)
        if _HAVE_THREAD_NATIVE_ID:
            self._set_native_id()
        with _active_limbo_lock:
            _active[self._ident] = self
```

It inserts an identifier from a special function which is always the clipped `unsigned long` from the runtime struct into the active thread list.

```c
static PyObject *
thread__get_main_thread_ident(PyObject *module, PyObject *Py_UNUSED(ignored))
{
    return PyLong_FromUnsignedLongLong(_PyRuntime.main_thread);
}
```
```c

    /* Platform-specific identifier and PyThreadState, respectively, for the
       main thread in the main interpreter. */
    unsigned long main_thread;
```
```c
    // Set it to the ID of the main thread of the main interpreter.
    runtime->main_thread = PyThread_get_thread_ident();
```

Because of this, on some platforms/libc implementations, we can observe a failure to look up the current thread because of the mismatch between clipped UL value vs the expected ULL value:


```
>>> import threading
>>> ct = threading.current_thread()
>>> ct
<_DummyThread(Dummy-1, started daemon 18446744072483979068)>
>>> hex(ct.ident)
'0xffffffffb6f33f3c'
>>> main = threading.main_thread()
>>> hex(main.ident)
'0xb6f33f3c'
>>> main._set_ident()
>>> hex(main.ident)
'0xffffffffb6f33f3c'

```

```
def current_thread():
    """"""Return the current Thread object, corresponding to the caller's thread of control.

    If the caller's thread of control was not created through the threading
    module, a dummy thread object with limited functionality is returned.

    """"""
    try:
        return _active[get_ident()]
    except KeyError:
        return _DummyThread()
```

Should `main_thread` to be a `PyThread_ident_t` ?  or should `MainThread` continue to call `_set_ident()`?

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130391
<!-- /gh-linked-prs -->
","['static PyObject *\nthread_get_ident(PyObject *self, PyObject *Py_UNUSED(ignored))\n{\n    PyThread_ident_t ident = PyThread_get_thread_ident_ex();  // <-- ULL\n    if (ident == PYTHREAD_INVALID_THREAD_ID) {\n        PyErr_SetString(ThreadError, ""no current thread ident"");\n        return NULL;\n    }\n    return PyLong_FromUnsignedLongLong(ident);\n}', 'class _MainThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=""MainThread"", daemon=False)\n        self._started.set()\n        self._ident = _get_main_thread_ident()\n        self._handle = _make_thread_handle(self._ident)\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self', 'static PyObject *\nthread__get_main_thread_ident(PyObject *module, PyObject *Py_UNUSED(ignored))\n{\n    return PyLong_FromUnsignedLongLong(_PyRuntime.main_thread);\n}', '/* Platform-specific identifier and PyThreadState, respectively, for the\n       main thread in the main interpreter. */\n    unsigned long main_thread;', '// Set it to the ID of the main thread of the main interpreter.\n    runtime->main_thread = PyThread_get_thread_ident();', "">>> import threading\n>>> ct = threading.current_thread()\n>>> ct\n<_DummyThread(Dummy-1, started daemon 18446744072483979068)>\n>>> hex(ct.ident)\n'0xffffffffb6f33f3c'\n>>> main = threading.main_thread()\n>>> hex(main.ident)\n'0xb6f33f3c'\n>>> main._set_ident()\n>>> hex(main.ident)\n'0xffffffffb6f33f3c'"", 'def current_thread():\n    """"""Return the current Thread object, corresponding to the caller\'s thread of control.\n\n    If the caller\'s thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    """"""\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()']","> I also wasn't sure if there was an explicit reason to avoid the default _set_ident call, I'm sure there is a story there but I didn't get very far before leaving work for vacation.

That would set the identity to the identity of the thread that imported the threading module. Most of the time that's the main thread of the main interpreter, but in rare cases (e.g. if it was imported by a thread started using the `_thread` module)  it might not be.",[],['python'],github,https://github.com/python/cpython/issues/130115,{'repo': 'python/cpython'}
"re.sub doesn't work when re.X is specify

# Bug report

### Bug description:

```python
# Add a code block here, if required

import re, sys
print(sys.version)

extended = ""z ""
short = ""z""

print(""extended"")
print(re.match(extended, ""z"", re.X))
# expected output: 'XXXX', actual output: 'z'
print(re.sub(extended, ""XXXX"", ""z"", re.X)) 

print(""short"")
print(re.match(short, ""z"", re.X))
# expected output: 'XXXX', actual output: 'XXXX'
print(re.sub(short, ""XXXX"", ""z"", re.X)) 
```

So I expect the output to be XXXX in the extended example from re.sub. And re.match seems to work fine.  

### CPython versions tested on:

3.11, 3.12

### Operating systems tested on:

Windows, Linux","['# Add a code block here, if required\n\nimport re, sys\nprint(sys.version)\n\nextended = ""z ""\nshort = ""z""\n\nprint(""extended"")\nprint(re.match(extended, ""z"", re.X))\n# expected output: \'XXXX\', actual output: \'z\'\nprint(re.sub(extended, ""XXXX"", ""z"", re.X)) \n\nprint(""short"")\nprint(re.match(short, ""z"", re.X))\n# expected output: \'XXXX\', actual output: \'XXXX\'\nprint(re.sub(short, ""XXXX"", ""z"", re.X))']","This happens because in [`re.sub`](https://docs.python.org/3/library/re.html#re.sub) the fourth argument is `count` not `flags`. When you write:

```python
print(re.sub(extended, ""XXXX"", ""z"", re.X))
```

the VERBOSE flag isn’t applied, so the pattern remains `""z ""` (notice the white space) and doesn’t match `""z""`. Changing it to:

```python
print(re.sub(extended, ""XXXX"", ""z"", flags=re.X))
```

applies the VERBOSE flag and produces the expected result.

","['print(re.sub(extended, ""XXXX"", ""z"", re.X))', 'print(re.sub(extended, ""XXXX"", ""z"", flags=re.X))']",['python'],github,https://github.com/python/cpython/issues/131070,{'repo': 'python/cpython'}
"adding the get method for lists

Hi! The topic of creating a secure get method for lists has been discussed several times in the community. I suggest the following implementation

### Proposal:

```С
static PyObject *
list_get(PyListObject *self, PyObject *args) {
    Py_ssize_t index;
    PyObject *default_value = Py_None;

    if (!PyArg_ParseTuple(args, ""n|O:get"", &index, &default_value)) {
        return NULL;
    }

    if (index < 0 || index >= Py_SIZE(self)) {
        Py_INCREF(default_value);
        return default_value;
    }

    Py_INCREF(self->ob_item[index]);
    return self->ob_item[index];
}
```
implementation in python:

>>> l = [1, 2, 3]
>>> l.get(0)
1
>>> print(type(p))
<class 'NoneType'>
>>> l.get(4, 'False')
'False'
>>> l.get(4, False)
False

### Has this already been discussed elsewhere?

Discussed on the python forum

### Links to previous discussion of this feature:

[previous discussion](https://discuss.python.org/t/add-safe-get-method-to-list/32555)","['static PyObject *\nlist_get(PyListObject *self, PyObject *args) {\n    Py_ssize_t index;\n    PyObject *default_value = Py_None;\n\n    if (!PyArg_ParseTuple(args, ""n|O:get"", &index, &default_value)) {\n        return NULL;\n    }\n\n    if (index < 0 || index >= Py_SIZE(self)) {\n        Py_INCREF(default_value);\n        return default_value;\n    }\n\n    Py_INCREF(self->ob_item[index]);\n    return self->ob_item[index];\n}']","TOP IDEA
This man really knows his business...",[],['python'],github,https://github.com/python/cpython/issues/131077,{'repo': 'python/cpython'}
"Not accurate when outputting an error during byte formatting for the 'i' flag, the 'd' flag is output, which can be misleading

# Bug report

### Bug description:

Code for demonstration:
```python
>>> b""%i"" % ""str""
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    b""%i"" % ""str""
    ~~~~~~^~~~~~~
TypeError: %d format: a real number is required, not str
```
Expected error message text:
```python
TypeError: %i format: a real number is required, not str
```

Also for strings this message is output correctly:
```python
>>> ""%i"" % ""str""
Traceback (most recent call last):
  File ""<python-input-1>"", line 1, in <module>
    ""%i"" % ""str""
    ~~~~~^~~~~~~
TypeError: %i format: a real number is required, not str
```
I would like to send a PR to fix this.


### CPython versions tested on:

3.12, 3.13, 3.14, CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130967
<!-- /gh-linked-prs -->
","['>>> b""%i"" % ""str""\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    b""%i"" % ""str""\n    ~~~~~~^~~~~~~\nTypeError: %d format: a real number is required, not str', 'TypeError: %i format: a real number is required, not str', '>>> ""%i"" % ""str""\nTraceback (most recent call last):\n  File ""<python-input-1>"", line 1, in <module>\n    ""%i"" % ""str""\n    ~~~~~^~~~~~~\nTypeError: %i format: a real number is required, not str']","I think that the error message can be improved, yes, thank you for noticing!",[],['python'],github,https://github.com/python/cpython/issues/130928,{'repo': 'python/cpython'}
"poplib.py: Missing integer parsing validation causes client crash on invalid server response

# Crash report

### What happened?

In [poplib.py at line 229](https://github.com/python/cpython/blob/8ba0d7bbc295781bf27902380521db97a272c442/Lib/poplib.py#L229) the code attempts to convert a server response to an integer without first verifying that the response is numeric. If the server returns a non-numeric response, the int() conversion fails causing the client to crash.

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130646
* gh-130763
* gh-130764
<!-- /gh-linked-prs -->
",[],"This is a wrong exception (`ValueError`), not a hard crash, right?",[],['python'],github,https://github.com/python/cpython/issues/130637,{'repo': 'python/cpython'}
"token module documentation is incomplete

# Documentation

The [`token` docs](https://docs.python.org/3/library/token.html) use a generated list of tokens, with short blurbs for the OP tokens but nothing for the other (more interesting) ones.
Some tokens (`COMMENT`, `NL`, etc.) have secondary, hand-written definitions. However, these are excluded from the index; [links](https://docs.python.org/3/library/token.html#token.COMMENT) go to the empty entries.

I propose adding hand-written prose for the non-OP tokens, and changing the automation to *check* the entries rather than generate them.
For the OP tokens, generating the docs is the correct thing to do, but the list can be more compact since they're all the same.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130588
<!-- /gh-linked-prs -->
",[],"Also another issue in the file:

![Image](https://github.com/user-attachments/assets/5cb2db70-661a-446a-ba1e-ee7994e3d6fd)

The '/' are not escaped.",[],['python'],github,https://github.com/python/cpython/issues/130587,{'repo': 'python/cpython'}
"`sys.exit()` does not align with document described behavior since 3.13

# Bug report

### Bug description:

Passing any non-zero integer to `sys.exit()` causes Python to exit with exit code 1, regardless of the actual value of passed integer. This is inconsistent with the online documentation description, which does not describe or imply this behavior:

> The optional argument arg can be an integer giving the exit status (defaulting to zero), or another type of object. If it is an integer, zero is considered “successful termination” and any nonzero value is considered “abnormal termination” by shells and the like.

Reproduced on Python 3.13.1 (provided by Arch Linux), Python [3.13.2](https://github.com/astral-sh/python-build-standalone/releases/download/20250205/cpython-3.13.2+20250205-x86_64_v3-unknown-linux-gnu-pgo+lto-full.tar.zst) and [3.14.0a4](https://github.com/astral-sh/python-build-standalone/releases/download/20250205/cpython-3.14.0a4+20250205-x86_64_v3-unknown-linux-gnu-pgo+lto-full.tar.zst) (both provided by astral-sh/python-build-standalone). Python 3.12 and lower has not affected.

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux",[],"Cannot reproduce with Python 3.13.2 and Python 3.14.0a4 on macOS, installed using the official installer:

```console
❯ python3.13 --version
Python 3.13.2

❯ python3.13 -c ""import sys; sys.exit(123)""

❯ echo $?
123

❯ python3.14 --version
Python 3.14.0a4

❯ python3.14 -c ""import sys; sys.exit(123)""

❯ echo $?
123
```


Nor with 3.13.0-3.13.2 using `uv run 1.py` when changing the version in:

```python
# /// script
# requires-python = ""==3.13.0""
# ///

import sys
print(sys.version)
sys.exit(123)
```

Nor with the same script with Ubuntu (via Docker) with 3.13.0-3.13.2 and 3.14.0a4.
","['❯ python3.13 --version\nPython 3.13.2\n\n❯ python3.13 -c ""import sys; sys.exit(123)""\n\n❯ echo $?\n123\n\n❯ python3.14 --version\nPython 3.14.0a4\n\n❯ python3.14 -c ""import sys; sys.exit(123)""\n\n❯ echo $?\n123', '# /// script\n# requires-python = ""==3.13.0""\n# ///\n\nimport sys\nprint(sys.version)\nsys.exit(123)']",['python'],github,https://github.com/python/cpython/issues/129936,{'repo': 'python/cpython'}
"Ubuntu / build and test (ubuntu-24.04-arm) fails on Removing Auth

[Example of this.](https://github.com/python/cpython/actions/runs/13140437345/job/36666129118?pr=129591#logs)

There is no error output and it simply stops after ~7 seconds. All other non-ubuntu (as remainder are cancelled) tests pass.",[],"It's most likely an issue with the `ubuntu-24.04-arm` image. @diegorusso filed a support ticket with GitHub.

Diego, here are two more failures ^",[],['python'],github,https://github.com/python/cpython/issues/129664,{'repo': 'python/cpython'}
"Improve docs of `math.isclose(0, x)` when `x = 0`

# Documentation

In the documentation of math.isclose it states 

> When comparing x to 0.0, isclose(x, 0) is computed as abs(x) <= rel_tol  * abs(x), which is False for any x and rel_tol less than 1.0.

The statement isn't correct since x = 0 will give True

<!-- gh-linked-prs -->
### Linked PRs
* gh-131138
* gh-131139
<!-- /gh-linked-prs -->
",[],"Seems the correction is to add a single word:

> When comparing x to 0.0, isclose(x, 0) is computed as abs(x) <= rel_tol  * abs(x), which is False for any **nonzero** x and rel_tol less than 1.0.

Would you mind making a PR?",[],['python'],github,https://github.com/python/cpython/issues/131094,{'repo': 'python/cpython'}
"Data race on `block->next` in `mi_block_set_nextx`

# Bug report

I've seen this in *non-debug* TSan builds. The TSAN report looks like:

```
  Write of size 8 at 0x7fffc4043690 by thread T2692:
    #0 mi_block_set_nextx /raid/sgross/cpython/./Include/internal/mimalloc/mimalloc/internal.h:652:15 (python+0x2ce71e) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
    #1 _mi_free_block_mt /raid/sgross/cpython/Objects/mimalloc/alloc.c:467:9 (python+0x2ce71e)
    #2 _mi_free_block /raid/sgross/cpython/Objects/mimalloc/alloc.c:506:5 (python+0x2a8b9a) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
    #3 _mi_free_generic /raid/sgross/cpython/Objects/mimalloc/alloc.c:524:3 (python+0x2a8b9a)
    #4 mi_free /raid/sgross/cpython/Objects/mimalloc/alloc.c (python+0x2c765b) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
    #5 _PyObject_MiFree /raid/sgross/cpython/Objects/obmalloc.c:284:5 (python+0x2c765b)
...

  Previous atomic read of size 8 at 0x7fffc4043690 by thread T2690:
    #0 _Py_atomic_load_uintptr_relaxed /raid/sgross/cpython/./Include/cpython/pyatomic_gcc.h:375:10 (python+0x4d0341) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
    #1 _Py_IsOwnedByCurrentThread /raid/sgross/cpython/./Include/object.h:252:12 (python+0x4d0341)
    #2 _Py_TryIncrefFast /raid/sgross/cpython/./Include/internal/pycore_object.h:560:9 (python+0x4d0341)
    #3 _Py_TryIncrefCompare /raid/sgross/cpython/./Include/internal/pycore_object.h:599:9 (python+0x4d0341)
    #4 PyMember_GetOne /raid/sgross/cpython/Python/structmember.c:99:18 (python+0x4d0054) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
    #5 member_get /raid/sgross/cpython/Objects/descrobject.c:179:12 (python+0x2056aa) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)
...

SUMMARY: ThreadSanitizer: data race /raid/sgross/cpython/./Include/internal/mimalloc/mimalloc/internal.h:652:15 in mi_block_set_nextx
```

This happens when we call `_Py_TryIncrefCompare()` or `_Py_TryXGetRef` or similar on an object that may be concurrently freed. Perhaps surprisingly, this is a supported operation. See https://peps.python.org/pep-0703/#mimalloc-changes-for-optimistic-list-and-dict-access.

The problem is `mi_block_set_nextx` doesn't use a relaxed store, so this is a data race because the [mimalloc freelist pointer](https://github.com/python/cpython/blob/0d68b14a0d8f493b2f403f64608bcfc055457053/Include/internal/mimalloc/mimalloc/types.h#L237-L239) may overlap the `ob_tid` field. The mimalloc freelist pointer is at the beginning of the freed memory block and `ob_tid` is the first field in `PyObject`.

You won't see this data race if:

* The object uses `Py_TPFLAGS_MANAGED_DICT`. In that case the beginning the managed dictionary pointer comes before `ob_tid`. That is fine because, unlike `ob_tid`, the managed dictionary pointer is never accessed concurrently with freeing the object.
* If CPython is built with `--with-pydebug`. The debug allocator sticks two extra words at the beginning of each allocation, so the freelist pointers will overlap with those (this is also fine).

Here are two options:

* Use relaxed stores in mimalloc, such as in `mi_block_set_nextx`. There's about six of these assignments -- not terrible to change -- but I don't love the idea of modifications to mimalloc that don't make sense to upstream, and these only make sense in the context of free threaded CPython.
* Reorder `PyObject` in the free threading build so that `ob_type` is the first field. This avoids any overlap with `ob_tid`. It's annoying to break ABI or change the PyObject header though.
 
cc @mpage @Yhg1s 
",['Write of size 8 at 0x7fffc4043690 by thread T2692:\n    #0 mi_block_set_nextx /raid/sgross/cpython/./Include/internal/mimalloc/mimalloc/internal.h:652:15 (python+0x2ce71e) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n    #1 _mi_free_block_mt /raid/sgross/cpython/Objects/mimalloc/alloc.c:467:9 (python+0x2ce71e)\n    #2 _mi_free_block /raid/sgross/cpython/Objects/mimalloc/alloc.c:506:5 (python+0x2a8b9a) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n    #3 _mi_free_generic /raid/sgross/cpython/Objects/mimalloc/alloc.c:524:3 (python+0x2a8b9a)\n    #4 mi_free /raid/sgross/cpython/Objects/mimalloc/alloc.c (python+0x2c765b) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n    #5 _PyObject_MiFree /raid/sgross/cpython/Objects/obmalloc.c:284:5 (python+0x2c765b)\n...\n\n  Previous atomic read of size 8 at 0x7fffc4043690 by thread T2690:\n    #0 _Py_atomic_load_uintptr_relaxed /raid/sgross/cpython/./Include/cpython/pyatomic_gcc.h:375:10 (python+0x4d0341) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n    #1 _Py_IsOwnedByCurrentThread /raid/sgross/cpython/./Include/object.h:252:12 (python+0x4d0341)\n    #2 _Py_TryIncrefFast /raid/sgross/cpython/./Include/internal/pycore_object.h:560:9 (python+0x4d0341)\n    #3 _Py_TryIncrefCompare /raid/sgross/cpython/./Include/internal/pycore_object.h:599:9 (python+0x4d0341)\n    #4 PyMember_GetOne /raid/sgross/cpython/Python/structmember.c:99:18 (python+0x4d0054) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n    #5 member_get /raid/sgross/cpython/Objects/descrobject.c:179:12 (python+0x2056aa) (BuildId: 2d15b5a5260b454c4f23bd5e53d32d43bfb806c4)\n...\n\nSUMMARY: ThreadSanitizer: data race /raid/sgross/cpython/./Include/internal/mimalloc/mimalloc/internal.h:652:15 in mi_block_set_nextx'],I think we saw this one too: https://gist.github.com/hawkinsp/948bc90fe8942f69db78924ffbb8a4eb but never figured out how to trigger it.,[],['python'],github,https://github.com/python/cpython/issues/129748,{'repo': 'python/cpython'}
"Day of the week

# Bug report

### Bug description:

Hello I was writing out a date time program, I wanted to test if today was a week day. 0:Sunday 6:Saturday. For what ever reason it is reporting the **today.weekday()** as being 1 day behind. Today is Friday February 28th yet the results keep returning as 

_2025-02-28 09:59:50.472268
4
Thursday
Yes today is a weekday_

Here is my code:

```python
import datetime
import datetime as dt

dayDic = {0:""Sunday"", 1:""Monday"", 2:""Tuesday"", 3:""Wednesday"", 4:""Thursday"", 5:""Friday"", 6:""Saturday"" }

def CheckifWeekDay():
    global dayDic
    # Check to see if today is one of the business days of the week Monday tru Friday

    # Variables
    today = dt.datetime.today() # get the numerical value of the day of the week 0 = Sunday 6 = Saturday
    Days_MF = [1,2,3,4,5] # List of days of the week 1=Monday 5=Friday
    isMyDay = False # Use this to return values as true of False (default False) it is not a weekday

    # Run through the length of the list days of the weeks and compares it to the current day.
    for i in range(len(Days_MF)):
        if today.weekday() == Days_MF[i]:
            print(today)
            print(today.weekday())
            print(dayDic[today.weekday()])
            print(""Yes today is a weekday"")
            isMyDay = True # changes isMyDay to True
        else:
            pass
    return isMyDay # returns isMyDay
```

My IDE is PyCharm, my OS is windows 11. Thank you. 

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['import datetime\nimport datetime as dt\n\ndayDic = {0:""Sunday"", 1:""Monday"", 2:""Tuesday"", 3:""Wednesday"", 4:""Thursday"", 5:""Friday"", 6:""Saturday"" }\n\ndef CheckifWeekDay():\n    global dayDic\n    # Check to see if today is one of the business days of the week Monday tru Friday\n\n    # Variables\n    today = dt.datetime.today() # get the numerical value of the day of the week 0 = Sunday 6 = Saturday\n    Days_MF = [1,2,3,4,5] # List of days of the week 1=Monday 5=Friday\n    isMyDay = False # Use this to return values as true of False (default False) it is not a weekday\n\n    # Run through the length of the list days of the weeks and compares it to the current day.\n    for i in range(len(Days_MF)):\n        if today.weekday() == Days_MF[i]:\n            print(today)\n            print(today.weekday())\n            print(dayDic[today.weekday()])\n            print(""Yes today is a weekday"")\n            isMyDay = True # changes isMyDay to True\n        else:\n            pass\n    return isMyDay # returns isMyDay']","`weekday()` is shifted by 1, that's what the [docs](https://docs.python.org/3/library/datetime.html#datetime.date.weekday):

> Return the day of the week as an integer, where Monday is 0 and Sunday is 6.

What you're looking for is [`isoweekday()`](https://docs.python.org/3/library/datetime.html#datetime.date.isoweekday) where Sunday is 0 (well 7 technically) and not Monday: 

> Return the day of the week as an integer, where Monday is 1 and Sunday is 7",[],['python'],github,https://github.com/python/cpython/issues/130694,{'repo': 'python/cpython'}
"Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads

# Crash report

### What happened?

Python crashes at interpreter shutdown when running this script which starts a misconfigured SSL server:
```python
import ssl
import socket
import sys
import threading
import time

SERVER_ADDR = (""127.0.0.1"", 37017)
CA_FILE = ""test/certificates/ca.pem""
SERVER_CERT = ""test/certificates/server.pem""
CLIENT_CERT = ""test/certificates/client.pem""


def run_server():
    # Intentionally omit cafile/load_cert_chain causes CPython to crash
    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)#, cafile=CA_FILE)
    # context.load_cert_chain(SERVER_CERT)
    context.check_hostname = False
    context.verify_mode = ssl.CERT_NONE
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server = context.wrap_socket(server, server_side=True)
    server.bind(SERVER_ADDR)
    server.listen(0)

    while True:
        connection, client_address = server.accept()
        t = threading.Thread(target=handle_server_connection, args=(connection, client_address), daemon=True)
        t.start()


def handle_server_connection(connection, client_address):
    client_address = f""{client_address[0]}:{client_address[1]}""
    print(f""server opened connection from {client_address}"")
    while True:
        data = connection.recv(1024)
        if not data:
            print(f""server closed connection from {client_address}"")
            return
        print(f""server got data from {client_address}: {data}"")
        if data == b""CLOSE"":
            print(f""server closing {client_address}"")
            connection.close()
            return
        # Echo back
        connection.sendall(data)


def get_client():
    # Intentionally omit cafile/load_cert_chain causes CPython to crash
    context = ssl.create_default_context() #cafile=CA_FILE)
    # context.load_cert_chain(CLIENT_CERT)
    context.check_hostname = False
    context.verify_mode = ssl.CERT_NONE
    print(f""client connecting"")
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    sock.connect(SERVER_ADDR)
    sock = context.wrap_socket(sock)
    return sock


def main():
    print(f""{sys.version=}\n{ssl.OPENSSL_VERSION=}"")
    server = threading.Thread(target=run_server, daemon=True)
    server.start()
    time.sleep(1)
    client1 = get_client()


if __name__ == ""__main__"":
    main()
```

```python
$ python repro-ssl-crash-bug.py
sys.version='3.13.0 (v3.13.0:60403a5409f, Oct  7 2024, 00:37:40) [Clang 15.0.0 (clang-1500.3.9.4)]'
ssl.OPENSSL_VERSION='OpenSSL 3.0.15 3 Sep 2024'
client connecting
Exception in thread Thread-1 (run_server):
Traceback (most recent call last):
Traceback (most recent call last):
  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 71, in <module>
    main()
    ~~~~^^
  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 67, in main
    client1 = get_client()
  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 58, in get_client
    sock = context.wrap_socket(sock)
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        sock=sock,
        ^^^^^^^^^^
    ...<5 lines>...
        session=session
        ^^^^^^^^^^^^^^^
    )
    ^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 1041, in _bootstrap_inner
    self.run()
    ~~~~~~~~^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 992, in run
    self._target(*self._args, **self._kwargs)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1076, in _create
    self.do_handshake()
    ~~~~~~~~~~~~~~~~~^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1372, in do_handshake
    self._sslobj.do_handshake()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 26, in run_server
    connection, client_address = server.accept()
                                 ~~~~~~~~~~~~~^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1418, in accept
    newsock = self.context.wrap_socket(newsock,
                do_handshake_on_connect=self.do_handshake_on_connect,
                suppress_ragged_eofs=self.suppress_ragged_eofs,
                server_side=True)
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        sock=sock,
        ^^^^^^^^^^
    ...<5 lines>...
        session=session
        ^^^^^^^^^^^^^^^
    )
    ^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1076, in _create
    self.do_handshake()
    ~~~~~~~~~~~~~~~~~^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1372, in do_handshake
    self._sslobj.do_handshake()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1020)
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x00000001021ec560)

Current thread 0x0000000205de8f80 (most recent call first):
  <no Python frame>
[1]    45370 abort      python repro-pypy-ssl-bug.py
```


Here's some of the apple crash report:
```
Translated Report (Full Report Below)
-------------------------------------

Process:               Python [45370]
Path:                  /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python
Identifier:            org.python.python
Version:               3.13.0 (3.13.0)
Code Type:             ARM-64 (Native)
Parent Process:        zsh [45114]
Responsible:           pycharm [65042]
User ID:               502

Date/Time:             2025-01-31 16:19:54.0206 -0800
OS Version:            macOS 14.7.2 (23H311)
Report Version:        12

System Integrity Protection: enabled

Crashed Thread:        0  Dispatch queue: com.apple.main-thread

Exception Type:        EXC_CRASH (SIGABRT)
Exception Codes:       0x0000000000000000, 0x0000000000000000

Termination Reason:    Namespace SIGNAL, Code 6 Abort trap: 6
Terminating Process:   Python [45370]

Application Specific Information:
abort() called


Thread 0 Crashed::  Dispatch queue: com.apple.main-thread
0   libsystem_kernel.dylib        	       0x19df595d0 __pthread_kill + 8
1   libsystem_pthread.dylib       	       0x19df91c20 pthread_kill + 288
2   libsystem_c.dylib             	       0x19de9ea30 abort + 180
3   Python                        	       0x101f6e710 _Py_FatalErrorFormat + 40
4   Python                        	       0x101fd9418 _enter_buffered_busy + 288
5   Python                        	       0x101fdbd3c _io__Buffered_flush + 600
6   Python                        	       0x101d39f04 method_vectorcall_NOARGS + 120
7   Python                        	       0x101d298e4 PyObject_VectorcallMethod + 152
8   Python                        	       0x101fe1784 _io_TextIOWrapper_flush + 140
9   Python                        	       0x101d39f04 method_vectorcall_NOARGS + 120
10  Python                        	       0x101d298e4 PyObject_VectorcallMethod + 152
11  Python                        	       0x101f69e10 flush_std_files + 448
12  Python                        	       0x101f69724 fatal_error + 396
13  Python                        	       0x101f6e7cc _Py_FatalErrorFormat + 228
14  Python                        	       0x101fd9418 _enter_buffered_busy + 288
15  Python                        	       0x101fdb958 _io_BufferedWriter_write + 1240
16  Python                        	       0x101d3a14c method_vectorcall_O + 116
17  Python                        	       0x101d298e4 PyObject_VectorcallMethod + 152
18  Python                        	       0x101fe2a2c _textiowrapper_writeflush + 656
19  Python                        	       0x101fe1760 _io_TextIOWrapper_flush + 104
20  Python                        	       0x101d39f04 method_vectorcall_NOARGS + 120
21  Python                        	       0x101d298e4 PyObject_VectorcallMethod + 152
22  Python                        	       0x101f69e10 flush_std_files + 448
23  Python                        	       0x101f6a26c _Py_Finalize + 320
24  Python                        	       0x101fa0460 Py_RunMain + 620
25  Python                        	       0x101fa1dcc pymain_main + 500
26  Python                        	       0x101fa1f34 Py_BytesMain + 40
27  dyld                          	       0x19dc07154 start + 2476


Thread 0 crashed with ARM Thread State (64-bit):
    x0: 0x0000000000000000   x1: 0x0000000000000000   x2: 0x0000000000000000   x3: 0x0000000000000000
    x4: 0xfffffffffffb7d30   x5: 0x0000000000000020   x6: 0x000000000000003e   x7: 0x000000003b9ac618
    x8: 0x88027b3a413da6b8   x9: 0x88027b3844e32938  x10: 0x00000001022156f8  x11: 0x0000000000000000
   x12: 0x0000000000000000  x13: 0x0000000000000001  x14: 0x00000001021b0078  x15: 0x00000001021b0068
   x16: 0x0000000000000148  x17: 0x00000002104e6e40  x18: 0x0000000000000000  x19: 0x0000000000000006
   x20: 0x0000000205de8f80  x21: 0x0000000000000103  x22: 0x0000000205de9060  x23: 0x8000000000000001
   x24: 0x7fffffffffffffde  x25: 0x0000000100b9ec88  x26: 0x0000000000000000  x27: 0x0000000000000000
   x28: 0x0000000000000000   fp: 0x000000016f28a6e0   lr: 0x000000019df91c20
    sp: 0x000000016f28a6c0   pc: 0x000000019df595d0 cpsr: 0x40001000
   far: 0x0000000000000000  esr: 0x56000080  Address size fault

```

I also see the same crash on Python 3.9. Is this expected behavior?

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS

### Output from running 'python -VV' on the command line:

Python 3.13.0 (v3.13.0:60403a5409f, Oct  7 2024, 00:37:40) [Clang 15.0.0 (clang-1500.3.9.4)]","['import ssl\nimport socket\nimport sys\nimport threading\nimport time\n\nSERVER_ADDR = (""127.0.0.1"", 37017)\nCA_FILE = ""test/certificates/ca.pem""\nSERVER_CERT = ""test/certificates/server.pem""\nCLIENT_CERT = ""test/certificates/client.pem""\n\n\ndef run_server():\n    # Intentionally omit cafile/load_cert_chain causes CPython to crash\n    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)#, cafile=CA_FILE)\n    # context.load_cert_chain(SERVER_CERT)\n    context.check_hostname = False\n    context.verify_mode = ssl.CERT_NONE\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server = context.wrap_socket(server, server_side=True)\n    server.bind(SERVER_ADDR)\n    server.listen(0)\n\n    while True:\n        connection, client_address = server.accept()\n        t = threading.Thread(target=handle_server_connection, args=(connection, client_address), daemon=True)\n        t.start()\n\n\ndef handle_server_connection(connection, client_address):\n    client_address = f""{client_address[0]}:{client_address[1]}""\n    print(f""server opened connection from {client_address}"")\n    while True:\n        data = connection.recv(1024)\n        if not data:\n            print(f""server closed connection from {client_address}"")\n            return\n        print(f""server got data from {client_address}: {data}"")\n        if data == b""CLOSE"":\n            print(f""server closing {client_address}"")\n            connection.close()\n            return\n        # Echo back\n        connection.sendall(data)\n\n\ndef get_client():\n    # Intentionally omit cafile/load_cert_chain causes CPython to crash\n    context = ssl.create_default_context() #cafile=CA_FILE)\n    # context.load_cert_chain(CLIENT_CERT)\n    context.check_hostname = False\n    context.verify_mode = ssl.CERT_NONE\n    print(f""client connecting"")\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.connect(SERVER_ADDR)\n    sock = context.wrap_socket(sock)\n    return sock\n\n\ndef main():\n    print(f""{sys.version=}\\n{ssl.OPENSSL_VERSION=}"")\n    server = threading.Thread(target=run_server, daemon=True)\n    server.start()\n    time.sleep(1)\n    client1 = get_client()\n\n\nif __name__ == ""__main__"":\n    main()', '$ python repro-ssl-crash-bug.py\nsys.version=\'3.13.0 (v3.13.0:60403a5409f, Oct  7 2024, 00:37:40) [Clang 15.0.0 (clang-1500.3.9.4)]\'\nssl.OPENSSL_VERSION=\'OpenSSL 3.0.15 3 Sep 2024\'\nclient connecting\nException in thread Thread-1 (run_server):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 71, in <module>\n    main()\n    ~~~~^^\n  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 67, in main\n    client1 = get_client()\n  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 58, in get_client\n    sock = context.wrap_socket(sock)\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 455, in wrap_socket\n    return self.sslsocket_class._create(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        sock=sock,\n        ^^^^^^^^^^\n    ...<5 lines>...\n        session=session\n        ^^^^^^^^^^^^^^^\n    )\n    ^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 1041, in _bootstrap_inner\n    self.run()\n    ~~~~~~~~^^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 992, in run\n    self._target(*self._args, **self._kwargs)\n    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1076, in _create\n    self.do_handshake()\n    ~~~~~~~~~~~~~~~~~^^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1372, in do_handshake\n    self._sslobj.do_handshake()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File ""/Users/shane/git/mongo-python-driver/repro-pypy-ssl-bug.py"", line 26, in run_server\n    connection, client_address = server.accept()\n                                 ~~~~~~~~~~~~~^^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1418, in accept\n    newsock = self.context.wrap_socket(newsock,\n                do_handshake_on_connect=self.do_handshake_on_connect,\n                suppress_ragged_eofs=self.suppress_ragged_eofs,\n                server_side=True)\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 455, in wrap_socket\n    return self.sslsocket_class._create(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        sock=sock,\n        ^^^^^^^^^^\n    ...<5 lines>...\n        session=session\n        ^^^^^^^^^^^^^^^\n    )\n    ^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1076, in _create\n    self.do_handshake()\n    ~~~~~~~~~~~~~~~~~^^\n  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py"", line 1372, in do_handshake\n    self._sslobj.do_handshake()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^\nssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1020)\nFatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name=\'<stderr>\'> at interpreter shutdown, possibly due to daemon threads\nPython runtime state: finalizing (tstate=0x00000001021ec560)\n\nCurrent thread 0x0000000205de8f80 (most recent call first):\n  <no Python frame>\n[1]    45370 abort      python repro-pypy-ssl-bug.py', 'Translated Report (Full Report Below)\n-------------------------------------\n\nProcess:               Python [45370]\nPath:                  /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            org.python.python\nVersion:               3.13.0 (3.13.0)\nCode Type:             ARM-64 (Native)\nParent Process:        zsh [45114]\nResponsible:           pycharm [65042]\nUser ID:               502\n\nDate/Time:             2025-01-31 16:19:54.0206 -0800\nOS Version:            macOS 14.7.2 (23H311)\nReport Version:        12\n\nSystem Integrity Protection: enabled\n\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\n\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\n\nTermination Reason:    Namespace SIGNAL, Code 6 Abort trap: 6\nTerminating Process:   Python [45370]\n\nApplication Specific Information:\nabort() called\n\n\nThread 0 Crashed::  Dispatch queue: com.apple.main-thread\n0   libsystem_kernel.dylib        \t       0x19df595d0 __pthread_kill + 8\n1   libsystem_pthread.dylib       \t       0x19df91c20 pthread_kill + 288\n2   libsystem_c.dylib             \t       0x19de9ea30 abort + 180\n3   Python                        \t       0x101f6e710 _Py_FatalErrorFormat + 40\n4   Python                        \t       0x101fd9418 _enter_buffered_busy + 288\n5   Python                        \t       0x101fdbd3c _io__Buffered_flush + 600\n6   Python                        \t       0x101d39f04 method_vectorcall_NOARGS + 120\n7   Python                        \t       0x101d298e4 PyObject_VectorcallMethod + 152\n8   Python                        \t       0x101fe1784 _io_TextIOWrapper_flush + 140\n9   Python                        \t       0x101d39f04 method_vectorcall_NOARGS + 120\n10  Python                        \t       0x101d298e4 PyObject_VectorcallMethod + 152\n11  Python                        \t       0x101f69e10 flush_std_files + 448\n12  Python                        \t       0x101f69724 fatal_error + 396\n13  Python                        \t       0x101f6e7cc _Py_FatalErrorFormat + 228\n14  Python                        \t       0x101fd9418 _enter_buffered_busy + 288\n15  Python                        \t       0x101fdb958 _io_BufferedWriter_write + 1240\n16  Python                        \t       0x101d3a14c method_vectorcall_O + 116\n17  Python                        \t       0x101d298e4 PyObject_VectorcallMethod + 152\n18  Python                        \t       0x101fe2a2c _textiowrapper_writeflush + 656\n19  Python                        \t       0x101fe1760 _io_TextIOWrapper_flush + 104\n20  Python                        \t       0x101d39f04 method_vectorcall_NOARGS + 120\n21  Python                        \t       0x101d298e4 PyObject_VectorcallMethod + 152\n22  Python                        \t       0x101f69e10 flush_std_files + 448\n23  Python                        \t       0x101f6a26c _Py_Finalize + 320\n24  Python                        \t       0x101fa0460 Py_RunMain + 620\n25  Python                        \t       0x101fa1dcc pymain_main + 500\n26  Python                        \t       0x101fa1f34 Py_BytesMain + 40\n27  dyld                          \t       0x19dc07154 start + 2476\n\n\nThread 0 crashed with ARM Thread State (64-bit):\n    x0: 0x0000000000000000   x1: 0x0000000000000000   x2: 0x0000000000000000   x3: 0x0000000000000000\n    x4: 0xfffffffffffb7d30   x5: 0x0000000000000020   x6: 0x000000000000003e   x7: 0x000000003b9ac618\n    x8: 0x88027b3a413da6b8   x9: 0x88027b3844e32938  x10: 0x00000001022156f8  x11: 0x0000000000000000\n   x12: 0x0000000000000000  x13: 0x0000000000000001  x14: 0x00000001021b0078  x15: 0x00000001021b0068\n   x16: 0x0000000000000148  x17: 0x00000002104e6e40  x18: 0x0000000000000000  x19: 0x0000000000000006\n   x20: 0x0000000205de8f80  x21: 0x0000000000000103  x22: 0x0000000205de9060  x23: 0x8000000000000001\n   x24: 0x7fffffffffffffde  x25: 0x0000000100b9ec88  x26: 0x0000000000000000  x27: 0x0000000000000000\n   x28: 0x0000000000000000   fp: 0x000000016f28a6e0   lr: 0x000000019df91c20\n    sp: 0x000000016f28a6c0   pc: 0x000000019df595d0 cpsr: 0x40001000\n   far: 0x0000000000000000  esr: 0x56000080  Address size fault']","> So maybe we should check that we don't report SSL failures if we are finalizing as otherwise we'll need to acquire a lock on stderr (remember that the SSL path for creating exceptions is slow and that may also be the reason why the thread dies before we can create and report that exception).

That seems like a reasonable temporary fix.

IMO, avoiding locks isn't a great permanent solution. Really, we need a better way to shut down daemon threads, rather than just hanging the re-acquisition of thread states. The issue here isn't specific to IO, but to any lock. For example:

```c
Py_BEGIN_ALLOW_THREADS;
// tstate is detached
PyMutex_Lock(&whatever_lock); // or PyThread_acquire_lock
Py_END_ALLOW_THREADS; // Daemon thread gets hung with the lock held!
```

If the main thread tries to acquire that lock, deadlock ensues. Something akin to how stop-the-world works on free-threading would be better. Probably something like routine `PyThreadState_MustExit` checks by the eval loop rather than just disappearing at the nearest `_PyThreadState_Attach` would be significantly more robust.",['Py_BEGIN_ALLOW_THREADS;\n// tstate is detached\nPyMutex_Lock(&whatever_lock); // or PyThread_acquire_lock\nPy_END_ALLOW_THREADS; // Daemon thread gets hung with the lock held!'],['python'],github,https://github.com/python/cpython/issues/129536,{'repo': 'python/cpython'}
"Crash with `PYTHON_LLTRACE=4` due to presence of `PyDictKeysObject` on stack

# Bug report

### Bug description:

The `dump_stack()` function, used when tracing micro-op execution, crashes if a `PyDictKeysObject*`  pointer is on the stack.
Despite the name, `PyDictKeysObject` is not a `PyObject`.

Introduced in https://github.com/python/cpython/commit/f978fb4f8d6eac0585057e463bb1701dc04a9900

I think the best fix would be arrange the fields (at least in the debug build) of `PyDictKeysObject` such that the `dk_kind` field is placed in the least significant byte of the `ob_type` field of `PyObject` *and* change `DictKeysKind` so that none of its values have the low 2 bits set to 0.
Then `dump_stack` can check the low bits of the `ob_type` to see whether the ""object"" is a `PyObject` or a `PyDictKeysObject`.

Looking forward, we expect to have an unused value for the low bits in `PyStackRef`, so we could assign them the meaning ""not a Python object"".
This would add overhead when pushing and popping `PyDictKeysObject`s, but would make introspection a lot more robust.

@mpage 

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_",[],"Alternatively, since this only affects tracing of micro-ops, we could special case the few affected micro-ops in `dump_stack` rather than modifying `PyDictKeysObject`.

Also, I think the same issue should affect tracing of `_PUSH_FRAME`, which consumes a `_PyInterpreterFrame`, which is also not a `PyObject`, from the stack:
https://github.com/python/cpython/blob/99ed3025fe8fa9079b4c1eac01c5af62caa98c15/Python/bytecodes.c#L3784-L3788

Are you also seeing a crash when tracing those opcodes?",[],['python'],github,https://github.com/python/cpython/issues/129432,{'repo': 'python/cpython'}
"`zipfile.Path` has only partial compatibility `io.BytesIO`

### Bug description:

I encountered an edge-case while using `zipfile.Path` with in-memory data buffers. It seems like the filename of the root is set to `None`, which breaks anything that tries to join the zip-filename and its internal path (including `str()`, ``. 

I have two suggested fixes:

1. Update the initialization of the `zipfile.FastLookup`-class and set `self.filename` to `"":memory:""` if it is None, matching what you would write in e.g. sqlite to get an in-memory database.
2. Update all places where the code attempts do Path-operations on `self.root.filename` to notice if the filename is None and use ""`:memory:`"" instead.

The first is definitely the easiest fix, but the second would maybe be more backwards compatible in case someone uses `Path.root.filename` to notice that the `zipfile.Path`-object points to an in-memory zipfile. Though, I'm not sure how big of a problem that is.

I don't have any strong opinions of which to choose, and I would be happy to implement the fix.

##### Minimal reproducible example
```python
import io
import zipfile

# Create a dummy Zip file
data = io.BytesIO()
with zipfile.ZipFile(data, mode=""w"") as zf:
    zf.writestr(""hello.txt"", ""python\n"")

# Try to iterate over its content
data.seek(0)
p = zipfile.Path(data)
print(str(p))
print(list(p.iterdir()))
```
```raw
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[92], line 13
     11 p = zipfile.Path(data)
---> 12 print(str(p))

File /usr/lib/python3.12/zipfile/_path/__init__.py:391, in Path.__str__(self)
    390 def __str__(self):
--> 391     return posixpath.join(self.root.filename, self.at)

File <frozen posixpath>:76, in join(a, *p)

TypeError: expected str, bytes or os.PathLike object, not NoneType
```

##### Demonstration of fix
```python
import io
import zipfile

# Create a dummy Zip file
data = io.BytesIO()
with zipfile.ZipFile(data, mode=""w"") as zf:
    zf.writestr(""hello.txt"", ""python\n"")

# Try to iterate over its content
data.seek(0)
p = zipfile.Path(data)
p.root.filename = "":memory:""
print(str(p))
print(list(p.iterdir()))
```
```raw
:memory:/
[Path(':memory:', 'hello.txt')]
```

### CPython versions tested on:

3.12, 3.14

### Operating systems tested on:

Ubuntu 24.04 (WSL), Fedora (via the Python devcontainer on GitHub codespaces)

<!-- gh-linked-prs -->
### Linked PRs
* gh-130381
<!-- /gh-linked-prs -->
","['import io\nimport zipfile\n\n# Create a dummy Zip file\ndata = io.BytesIO()\nwith zipfile.ZipFile(data, mode=""w"") as zf:\n    zf.writestr(""hello.txt"", ""python\\n"")\n\n# Try to iterate over its content\ndata.seek(0)\np = zipfile.Path(data)\nprint(str(p))\nprint(list(p.iterdir()))', '---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[92], line 13\n     11 p = zipfile.Path(data)\n---> 12 print(str(p))\n\nFile /usr/lib/python3.12/zipfile/_path/__init__.py:391, in Path.__str__(self)\n    390 def __str__(self):\n--> 391     return posixpath.join(self.root.filename, self.at)\n\nFile <frozen posixpath>:76, in join(a, *p)\n\nTypeError: expected str, bytes or os.PathLike object, not NoneType', 'import io\nimport zipfile\n\n# Create a dummy Zip file\ndata = io.BytesIO()\nwith zipfile.ZipFile(data, mode=""w"") as zf:\n    zf.writestr(""hello.txt"", ""python\\n"")\n\n# Try to iterate over its content\ndata.seek(0)\np = zipfile.Path(data)\np.root.filename = "":memory:""\nprint(str(p))\nprint(list(p.iterdir()))', "":memory:/\n[Path(':memory:', 'hello.txt')]""]","I just realised that option 2. might be preferable, because we should probably overload the `parent` method to prevent it from resolving to `"".""` when the path is `"":memory:""` anyways?",[],['python'],github,https://github.com/python/cpython/issues/130120,{'repo': 'python/cpython'}
"Explore if the upcoming XCode 16.3 supports tail calling interpreters

# Feature or enhancement

### Proposal:

Xcode 16.3 seems to be getting a mixture of LLVM 17-19 features. It may be possible `preserve_none` ends up in there. If so, it would significantly boost interpreter performance if we can enable it.

https://developer.apple.com/documentation/xcode-release-notes/xcode-16_3-release-notes

We should play around with Xcode 16.3 and at least verify that it can/cannot support `[[clang::musttail]]` and `__attribute__((preserve_none))`.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_",[],Internal reports suggests this might be possible. Will let Ned know once Xcode 16.3 is released proper.,[],['python'],github,https://github.com/python/cpython/issues/130633,{'repo': 'python/cpython'}
"`exec(<string>, closure=<non-None>)` failed assertion

# Crash report

### What happened?

Minimal repro:

```python
print(""Reproducing!"")
exec("""", closure=object())
```

Fails with
```
Reproducing!
python: Python/ast.c:1047: _PyAST_Validate: Assertion `!PyErr_Occurred()' failed.
Aborted (core dumped)
```

Note the error occurs not because the passed `closure=` is incorrect (it should be a tuple of cell objects), but because `closure=` is not allowed when string is the source.

The reason for that to happen is a missing `goto error` jump:
https://github.com/python/cpython/blob/2a0256f588e5c8ea3892521009ae3834c407cd69/Python/bltinmodule.c#L1175-L1178

causing the rest of the code to execute and reach `_PyAST_Validate`.

In the PR, I included the missing test case.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.14.0a5+ (heads/main-dirty:f9a7d41bacb, Feb 13 2025, 04:52:15) [GCC 11.4.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-130071
<!-- /gh-linked-prs -->
","['print(""Reproducing!"")\nexec("""", closure=object())', ""Reproducing!\npython: Python/ast.c:1047: _PyAST_Validate: Assertion `!PyErr_Occurred()' failed.\nAborted (core dumped)""]",It crashes in debug builds.,[],['python'],github,https://github.com/python/cpython/issues/130070,{'repo': 'python/cpython'}
"`open()` built-in function: let it have `encoding=""utf-8""` and `newline=""\n""` by default

This is the signature of the `open()` built-in function:

```python
open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
```

### Proposal number 1

Since Python universally migrated to the UTF-8 character encoding a long time ago, set the `encoding` parameter of the `open()` built-in function to default to `encoding=""utf-8""`.

### Proposal number 2

Because the Windows operating system also handles `\n` as a newline character since practically forever, set `newline=""\n""` as a default parameter of the `open()` built-in function.

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_
","[""open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)""]","> ### Has this already been discussed elsewhere?
> This is a minor feature, which does not need previous discussion elsewhere

Thanks for the proposal, I think this is a good topic to discuss in the Ideas forum first, especially as it touches on backwards compatibility. 

Please could you open a thread at https://discuss.python.org/c/ideas/6 ? ",[],['python'],github,https://github.com/python/cpython/issues/129686,{'repo': 'python/cpython'}
"Add a new test resource to mark flaky tests

# Feature or enhancement

### Proposal:

Came up in this issue https://github.com/python/cpython/issues/130363 and this comment: https://github.com/python/cpython/issues/130363#issuecomment-2676349074

> How about a flaky resources. At least, we know which tests are meant to be flaky and which are not. And for the CI, we could ask the CI to rerun flaky tests on failures so that contributors don't need to wait for a triager/core dev to rerun a failed workflow when needed.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130489
<!-- /gh-linked-prs -->
",[],"I don't think we should have any tests that are meant to be flaky.
If it's OK to ignore a test, why not just delete it?",[],['python'],github,https://github.com/python/cpython/issues/130474,{'repo': 'python/cpython'}
"calendar displays month names in a genitive case for some locales

# Bug report

### Bug description:

A calendar module CLI displays month names in a Polish, and other Slavic languages using the genitive case, as it is used in a phrase ""in January"". However, for standalone usage, month names should appear in the nominative case to be grammatically correct. For instance, in Polish, ""January"" should be written as ""styczeń"" instead of ""stycznia""; similarly, in Russian, it should be ""январь"" rather than ""января"". This issue likely affects Baltic languages and Greek as well.

Example command demonstrating the issue:
```
python3 -m calendar --locale pl_PL --encoding utf
```

This problem occurs because the calendar module uses the strftime `%B` format specifier, which returns month names suitable for complete date contexts (genitive case). Instead, a nominative form is required when months are mentioned independently:

https://github.com/python/cpython/blob/4dcbe06fd264b3f9c0b26831f19d211a48c52286/Lib/calendar.py#L138-L140

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-131147
<!-- /gh-linked-prs -->
",['python3 -m calendar --locale pl_PL --encoding utf'],"> This problem occurs because the calendar module uses the strftime %B format specifier, which returns month names suitable for complete date contexts (genitive case). Instead, a nominative form is required when months are mentioned independently:

What would be the format specifier in this case? ",[],['python'],github,https://github.com/python/cpython/issues/131146,{'repo': 'python/cpython'}
"Remove references to Unicode objects being ready

We have some code referrencing readiness of Unicode objects but this property is deprecated (see https://github.com/python/cpython/issues/129894#issuecomment-2693828966). Following @encukou's advice, we should address each module with a separate PR so that experts can review them separately.

### `unicodedata.c`

https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Modules/unicodedata.c#L594-L596
https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Modules/unicodedata.c#L655-L661

### `_io/textio.c`

https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Modules/_io/textio.c#L357-L363
https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Modules/_io/textio.c#L1821-L1824

### `Parser` files

https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Parser/lexer/lexer.c#L311-L315
https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Parser/pegen.c#L505-L513

### `tracemalloc.c`

https://github.com/python/cpython/blob/a85eeb97710617404ba7a0fac3b264f586caf70c/Python/tracemalloc.c#L252-L259

This one seems to be dead code (cc @vstinner)

<!-- gh-linked-prs -->
### Linked PRs
* gh-130801
<!-- /gh-linked-prs -->
",[],"I was planning to do it tomorrow, but feel free to take it. It's just that I don't know if we need to split into multiple PRs or in one. I haven't looked at the code exactly to see whether we can safely remove the comment/code so there might be some conditions that still need to be checked.",[],['python'],github,https://github.com/python/cpython/issues/130790,{'repo': 'python/cpython'}
"_Py_TryIncrefCompareStackRef incorrectly listed as non-escaping in cases generator

# Bug report

### Bug description:

(This came up during the faster-cpython meeting, filing a bug so we don't forget.)

_Py_TryIncrefCompareStackRef and _Py_TryIncrefCompare are currently listed as non-escaping in the bytecode cases generator (https://github.com/python/cpython/blob/99ed3025fe8fa9079b4c1eac01c5af62caa98c15/Tools/cases_generator/analyzer.py#L635), but they can in fact escape (in the DECREF path when we're no longer sure the object we INCREF'ed is a correct object, since it may have been a pointer to a new object in re-used memory). _Py_TryIncrefCompare isn't currently used in bytecodes.c, but _Py_TryIncrefCompareStackRef  is used in LOAD_ATTR specializations, which are consequently incorrectly flagged as non-escaping (and also can also theoretically cause crashes because of the missing spilling).

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_",[],"There are a lot of functions and macros in that list that are actually escaping, including: `PyStackRef_CLEAR`, `PyStackRef_CLOSE`, `Py_CLEAR`, (and other related functions), and `_PyEval_FrameClearAndPop`.

The list needs a thorough audit. For free threading specific issues, we should look for:

* Lock / critical section acquisitions within the function (e.g., `PyException_GetTraceback`)
* `Py_DECREF` and equivalent within the function (e.g., `_Py_TryIncrefCompare`)",[],['python'],github,https://github.com/python/cpython/issues/129452,{'repo': 'python/cpython'}
"struct (un)packing of half-precision `nan` floats is non-invertible

# Bug report

### Bug description:

I noticed that chaining `struct.unpack()` and `struct.pack()` for IEEE 754 Half Precision floats (`e`) is non-invertible for `nan`. E.g.:

```python
import struct

original_bytes = b'\xff\xff'

unpacked_float = struct.unpack('e', original_bytes)[0]  # nan
repacked_bytes = struct.pack('e', unpacked_float)  # b'\x00\xfe'  != b'\xff\xff'
```

IEEE `nan`s aren't unique, so this isn't _that_ surprising... However I found it curious that the same behavior is not exhibited for `float` (`f`) or `double` (`d`) format, where every original bit pattern I tested could be recovered from the unpacked `nan` object. 

Is this by design?

Here's a quick `pytest` script that tests over a broad range of `nan`/`inf`/`-inf` cases for each encoding format.

```python
# /// script
# requires-python = "">=3.11""
# dependencies = [""pytest""]
# ///
import struct
import pytest


# Floating Point Encodings Based on IEEE 754 per https://en.wikipedia.org/wiki/IEEE_754#Basic_and_interchange_formats
# binary 16 (half precision) - 1 bit sign, 5 bit exponent, 11 bit significand
# binary 32 (single precision) - 1 bit sign, 8 bit exponent, 23 bit significand
# binary 64 (double precision) - 1 bit sign, 11 bit exponent, 52 bit significand


MAX_TEST_CASES = 100000  # limit number of bit patterns being sampled so we aren't waiting too long


@pytest.mark.parametrize([""precision_format"", ""precision"", ""exponent_bits""], [(""f"", 32, 8), (""d"", 64, 11), (""e"", 16, 5)])
@pytest.mark.parametrize(""sign_bit"", [0, 1])
@pytest.mark.parametrize(""endianness"", [""little"", ""big""])
def test_struct_floats(precision_format: str, precision: int, exponent_bits: int, sign_bit: int, endianness: str):
    significand_bits = precision - exponent_bits - 1

    n_tests = min(MAX_TEST_CASES, 2**significand_bits)

    significand_patterns = [significand_bits * ""0"", significand_bits * ""1""] + [
        bin(i + 1)[2:] for i in range(1, 2**significand_bits, 2**significand_bits // n_tests)
    ]

    for i in range(n_tests):
        binary = str(sign_bit) + ""1"" * exponent_bits + significand_patterns[i]
        if endianness == ""big"":
            format = "">"" + precision_format
        elif endianness == ""little"":
            format = ""<"" + precision_format
        else:
            raise NotImplementedError()

        test_bytes = int(binary, base=2).to_bytes(precision // 8, endianness)

        unpacked = struct.unpack(format, test_bytes)
        assert len(unpacked) == 1

        repacked = struct.pack(format, unpacked[0])

        assert (
            repacked == test_bytes
        ), f""struct pack/unpack was not invertible for format {format} with raw value: {test_bytes} -> unpacks to {unpacked[0]}, repacks to {repacked}""

if __name__ == ""__main__"":
    pytest.main([__file__])
```

![Image](https://github.com/user-attachments/assets/539eaa87-44da-421d-9bc0-bee81dc110ed)

### CPython versions tested on:

3.13, 3.11, 3.12

### Operating systems tested on:

Linux, Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130452
<!-- /gh-linked-prs -->
","[""import struct\n\noriginal_bytes = b'\\xff\\xff'\n\nunpacked_float = struct.unpack('e', original_bytes)[0]  # nan\nrepacked_bytes = struct.pack('e', unpacked_float)  # b'\\x00\\xfe'  != b'\\xff\\xff'"", '# /// script\n# requires-python = "">=3.11""\n# dependencies = [""pytest""]\n# ///\nimport struct\nimport pytest\n\n\n# Floating Point Encodings Based on IEEE 754 per https://en.wikipedia.org/wiki/IEEE_754#Basic_and_interchange_formats\n# binary 16 (half precision) - 1 bit sign, 5 bit exponent, 11 bit significand\n# binary 32 (single precision) - 1 bit sign, 8 bit exponent, 23 bit significand\n# binary 64 (double precision) - 1 bit sign, 11 bit exponent, 52 bit significand\n\n\nMAX_TEST_CASES = 100000  # limit number of bit patterns being sampled so we aren\'t waiting too long\n\n\n@pytest.mark.parametrize([""precision_format"", ""precision"", ""exponent_bits""], [(""f"", 32, 8), (""d"", 64, 11), (""e"", 16, 5)])\n@pytest.mark.parametrize(""sign_bit"", [0, 1])\n@pytest.mark.parametrize(""endianness"", [""little"", ""big""])\ndef test_struct_floats(precision_format: str, precision: int, exponent_bits: int, sign_bit: int, endianness: str):\n    significand_bits = precision - exponent_bits - 1\n\n    n_tests = min(MAX_TEST_CASES, 2**significand_bits)\n\n    significand_patterns = [significand_bits * ""0"", significand_bits * ""1""] + [\n        bin(i + 1)[2:] for i in range(1, 2**significand_bits, 2**significand_bits // n_tests)\n    ]\n\n    for i in range(n_tests):\n        binary = str(sign_bit) + ""1"" * exponent_bits + significand_patterns[i]\n        if endianness == ""big"":\n            format = "">"" + precision_format\n        elif endianness == ""little"":\n            format = ""<"" + precision_format\n        else:\n            raise NotImplementedError()\n\n        test_bytes = int(binary, base=2).to_bytes(precision // 8, endianness)\n\n        unpacked = struct.unpack(format, test_bytes)\n        assert len(unpacked) == 1\n\n        repacked = struct.pack(format, unpacked[0])\n\n        assert (\n            repacked == test_bytes\n        ), f""struct pack/unpack was not invertible for format {format} with raw value: {test_bytes} -> unpacks to {unpacked[0]}, repacks to {repacked}""\n\nif __name__ == ""__main__"":\n    pytest.main([__file__])']","It seems you are on IEEE-platform, or unpacking special values will fail for float and double formats.  So for those formats, pack/unpack functions work by copying bits.

But not [PyFloat_Pack2()](https://github.com/python/cpython/blob/12e1d3011b0ff427b7be36d5f5d2d63014c6a54d/Objects/floatobject.c#L2030-L2133) and [PyFloat_Unpack2()](https://github.com/python/cpython/blob/12e1d3011b0ff427b7be36d5f5d2d63014c6a54d/Objects/floatobject.c#L2373-L2423).  E.g. the later just ignores all payload in the nan value and maps `data` to one or another quiet nan:
https://github.com/python/cpython/blob/12e1d3011b0ff427b7be36d5f5d2d63014c6a54d/Objects/floatobject.c#L2402-L2405
The PyFloat_Pack2() also ignores all payload from double nan:
https://github.com/python/cpython/blob/12e1d3011b0ff427b7be36d5f5d2d63014c6a54d/Objects/floatobject.c#L2050-L2059

> Is this by design?

Looks as a bug for me.

CC @mdickinson 

Edit: assuming doubles are binary64, following patch fix your tests:
```diff
diff --git a/Objects/floatobject.c b/Objects/floatobject.c
index 3b72a1e7c3..e473fb72fe 100644
--- a/Objects/floatobject.c
+++ b/Objects/floatobject.c
@@ -2048,14 +2048,16 @@ PyFloat_Pack2(double x, char *data, int le)
         bits = 0;
     }
     else if (isnan(x)) {
-        /* There are 2046 distinct half-precision NaNs (1022 signaling and
-           1024 quiet), but there are only two quiet NaNs that don't arise by
-           quieting a signaling NaN; we get those by setting the topmost bit
-           of the fraction field and clearing all other fraction bits. We
-           choose the one with the appropriate sign. */
         sign = (copysign(1.0, x) == -1.0);
         e = 0x1f;
-        bits = 512;
+
+        uint64_t v;
+
+        memcpy(&v, &x, sizeof(v));
+        bits = v & 0x1ff;
+        if (v & 0x800000000000) {
+            bits += 0x200;
+        }
     }
     else {
         sign = (x < 0.0);
@@ -2401,7 +2403,16 @@ PyFloat_Unpack2(const char *data, int le)
         }
         else {
             /* NaN */
-            return sign ? -fabs(Py_NAN) : fabs(Py_NAN);
+            uint64_t v = ((sign? 0xff00000000000000 : 0x7f00000000000000)
+                          + 0xf0000000000000);
+
+            if (f & 0x200) {
+                v += 0x800000000000;
+                f -= 0x200;
+            }
+            v += f;
+            memcpy(&x, &v, sizeof(v));
+            return x;
         }
     }
 
```
FYI: https://github.com/python/cpython/issues/55943.  Probably the reason why payload was ignored is that the patch was adapted from numpy sources.","[""diff --git a/Objects/floatobject.c b/Objects/floatobject.c\nindex 3b72a1e7c3..e473fb72fe 100644\n--- a/Objects/floatobject.c\n+++ b/Objects/floatobject.c\n@@ -2048,14 +2048,16 @@ PyFloat_Pack2(double x, char *data, int le)\n         bits = 0;\n     }\n     else if (isnan(x)) {\n-        /* There are 2046 distinct half-precision NaNs (1022 signaling and\n-           1024 quiet), but there are only two quiet NaNs that don't arise by\n-           quieting a signaling NaN; we get those by setting the topmost bit\n-           of the fraction field and clearing all other fraction bits. We\n-           choose the one with the appropriate sign. */\n         sign = (copysign(1.0, x) == -1.0);\n         e = 0x1f;\n-        bits = 512;\n+\n+        uint64_t v;\n+\n+        memcpy(&v, &x, sizeof(v));\n+        bits = v & 0x1ff;\n+        if (v & 0x800000000000) {\n+            bits += 0x200;\n+        }\n     }\n     else {\n         sign = (x < 0.0);\n@@ -2401,7 +2403,16 @@ PyFloat_Unpack2(const char *data, int le)\n         }\n         else {\n             /* NaN */\n-            return sign ? -fabs(Py_NAN) : fabs(Py_NAN);\n+            uint64_t v = ((sign? 0xff00000000000000 : 0x7f00000000000000)\n+                          + 0xf0000000000000);\n+\n+            if (f & 0x200) {\n+                v += 0x800000000000;\n+                f -= 0x200;\n+            }\n+            v += f;\n+            memcpy(&x, &v, sizeof(v));\n+            return x;\n         }\n     }""]",['python'],github,https://github.com/python/cpython/issues/130317,{'repo': 'python/cpython'}
"Tkinter appears not to pass file extension to file writing correctly

### Bug description:

Requirements: pandas

Testing this on Windows 11, Python 3.13, pandas 2.2.3
Also tested on Python 3.11.9

File selection dialog custom class has added method _get_file_type for tkinter's asksaveasfilename for diagnostic prints.

The tkinter file dialog class has an internal method  _fixresult-- this will call other methods and pass along the correct file ending, but somehow, my script will not append it.

If the user selects an existing file that has a file extension the ending is included in the file name, and the script correctly writes a file.
If the user manually adds a correct file extension from the list, then python treats that as the correct file extension and ignores the dropdown selection.

But if the user does not manually add a file ending by selection of an existing file, or entering data in the dialog box, no ending is passed to the function, and therefore the file fails to write.

Is this actually not an intended feature? My reading of the source code and documentation, along with some consulting of CoPilot, leads me to believe that the ending selected in the dropdown is intended to be appended to any filename that lacks an ending, but if I've misunderstood, then perhaps this should be reclassified as a new feature request. But my understanding is that it should do this. Help me out if you can. Thanks.

+-----------------------------+
| asksaveasfilename Function  |
|                                               |
| - Calls SaveAs.show()            |
+-------------+---------------+
              |
              v
+-------------+---------------+
| SaveAs Class                        |
|                                             |
| - Inherits from _Dialog        |
| - Uses _Dialog.show()          |
+-------------+---------------+
              |
              v
+-------------+---------------+
| _Dialog Class                        |
|                                              |
| - Defines show()                   |
| - Calls tk.call()                       |
| - Passes result to                  |
|   _fixresult()                           |
+-------------+---------------+
              |
              v
+-------------+---------------+
| tk.call Method                      |
|                                              |
| - Executes Tcl command      |
| - Returns selected file path  |
+-------------+---------------+
              |
              v
+-------------+---------------+
| _fixresult Method                 |
|                                              |
| - Processes result                 |
| - Ensures correct file path    |
|   and extension                    |
+-----------------------------+

CODE:
```
import tkinter as tk
from tkinter import filedialog
import os
import pandas as pd

class FileDialogTest:
    def __init__(self, file_extensions):
        self.file_extensions = file_extensions
        self.selected_file_type = None

    def _format_file_extensions(self):
        return [(f""{ext} files"", ext) for ext in self.file_extensions]

    def _get_file_type(self, file_path):
        _, ext = os.path.splitext(file_path)
        return ext

    def select_file_to_save(self, default_name=""testfile""):
        root = tk.Tk()
        root.withdraw()
        file_path = filedialog.asksaveasfilename(
            title=""Select a file to save"",
            filetypes=self._format_file_extensions(),
            initialfile=default_name
        )
        if not file_path:
            raise FileNotFoundError(""No file selected."")
        print(f""[After Selection] Selected file path: {file_path}"") # Print for identifying file extension issues
        self.selected_file_type = self._get_file_type(file_path)
        if not self.selected_file_type:
            # Append the default extension based on the selected file type
            self.selected_file_type = self.file_extensions[0]  # Default to the first extension if none is selected
            file_path += self.selected_file_type
        elif self.selected_file_type not in self.file_extensions:
            # Correct the file extension if it doesn't match the selected type
            file_path += self.file_extensions[self.file_extensions.index(self.selected_file_type)]
        print(f""[After Extension Check] Final file path: {file_path}"") # Print for identifying file extension issues
        print(f""[After Extension Check] Selected file type: {self.selected_file_type}"") # Print for identifying file extension issues
        return file_path, self.selected_file_type

# Define file extensions for testing
file_extensions = ['.txt', '.csv', '.parquet', '.xlsx']

# Initialize FileDialogTest with file extensions
file_dialog_test = FileDialogTest(file_extensions)

# Test select_file_to_save method
try:
    file_path, selected_file_type = file_dialog_test.select_file_to_save()
    print(f""[Main] Selected file path: {file_path}"")  # Print for identifying file extension issues
    print(f""[Main] Selected file type: {selected_file_type}"")  # Print for identifying file extension issues
    
    # Sample data to save as DataFrame
    sample_data = {
        ""Column1"": [""Value 1"", ""Value 2""],
        ""Column2"": [123, 456],
        ""Column3"": [""Another string"", ""Yet another string""],
        ""Column4"": [456.78, 789.01]
    }
    
    df = pd.DataFrame(sample_data)
    
    # Save the DataFrame to the selected file
    print(f""[Before Saving] Saving DataFrame to {file_path} as {selected_file_type}"") # Print for identifying file extension issues
    if selected_file_type == '.csv':
        df.to_csv(file_path, index=False)
    elif selected_file_type == '.txt':
        df.to_csv(file_path, sep='\t', index=False)
    elif selected_file_type == '.parquet':
        df.to_parquet(file_path, index=False)
    elif selected_file_type == '.xlsx':
        df.to_excel(file_path, index=False)
    print(f""[After Saving] Data saved to {file_path}"") # Print for identifying file extension issues
except FileNotFoundError as e:
    print(e)
```


### CPython versions tested on:

3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-129682
<!-- /gh-linked-prs -->
","['import tkinter as tk\nfrom tkinter import filedialog\nimport os\nimport pandas as pd\n\nclass FileDialogTest:\n    def __init__(self, file_extensions):\n        self.file_extensions = file_extensions\n        self.selected_file_type = None\n\n    def _format_file_extensions(self):\n        return [(f""{ext} files"", ext) for ext in self.file_extensions]\n\n    def _get_file_type(self, file_path):\n        _, ext = os.path.splitext(file_path)\n        return ext\n\n    def select_file_to_save(self, default_name=""testfile""):\n        root = tk.Tk()\n        root.withdraw()\n        file_path = filedialog.asksaveasfilename(\n            title=""Select a file to save"",\n            filetypes=self._format_file_extensions(),\n            initialfile=default_name\n        )\n        if not file_path:\n            raise FileNotFoundError(""No file selected."")\n        print(f""[After Selection] Selected file path: {file_path}"") # Print for identifying file extension issues\n        self.selected_file_type = self._get_file_type(file_path)\n        if not self.selected_file_type:\n            # Append the default extension based on the selected file type\n            self.selected_file_type = self.file_extensions[0]  # Default to the first extension if none is selected\n            file_path += self.selected_file_type\n        elif self.selected_file_type not in self.file_extensions:\n            # Correct the file extension if it doesn\'t match the selected type\n            file_path += self.file_extensions[self.file_extensions.index(self.selected_file_type)]\n        print(f""[After Extension Check] Final file path: {file_path}"") # Print for identifying file extension issues\n        print(f""[After Extension Check] Selected file type: {self.selected_file_type}"") # Print for identifying file extension issues\n        return file_path, self.selected_file_type\n\n# Define file extensions for testing\nfile_extensions = [\'.txt\', \'.csv\', \'.parquet\', \'.xlsx\']\n\n# Initialize FileDialogTest with file extensions\nfile_dialog_test = FileDialogTest(file_extensions)\n\n# Test select_file_to_save method\ntry:\n    file_path, selected_file_type = file_dialog_test.select_file_to_save()\n    print(f""[Main] Selected file path: {file_path}"")  # Print for identifying file extension issues\n    print(f""[Main] Selected file type: {selected_file_type}"")  # Print for identifying file extension issues\n    \n    # Sample data to save as DataFrame\n    sample_data = {\n        ""Column1"": [""Value 1"", ""Value 2""],\n        ""Column2"": [123, 456],\n        ""Column3"": [""Another string"", ""Yet another string""],\n        ""Column4"": [456.78, 789.01]\n    }\n    \n    df = pd.DataFrame(sample_data)\n    \n    # Save the DataFrame to the selected file\n    print(f""[Before Saving] Saving DataFrame to {file_path} as {selected_file_type}"") # Print for identifying file extension issues\n    if selected_file_type == \'.csv\':\n        df.to_csv(file_path, index=False)\n    elif selected_file_type == \'.txt\':\n        df.to_csv(file_path, sep=\'\\t\', index=False)\n    elif selected_file_type == \'.parquet\':\n        df.to_parquet(file_path, index=False)\n    elif selected_file_type == \'.xlsx\':\n        df.to_excel(file_path, index=False)\n    print(f""[After Saving] Data saved to {file_path}"") # Print for identifying file extension issues\nexcept FileNotFoundError as e:\n    print(e)']",This would be easier for someone to test and troubleshoot if you had a simpler example with no external dependencies.,[],['python'],github,https://github.com/python/cpython/issues/129534,{'repo': 'python/cpython'}
"Type hints for `pathlib.types`

# Feature or enhancement

The `pathlib.types` module is new in 3.14, and contains a single public class: [`pathlib.types.PathInfo`](https://docs.python.org/3.14/library/pathlib.html#pathlib.types.PathInfo).

This module also contains a few private classes: `_PathParser`, `_JoinablePath`, `_ReadablePath` and `_WritablePath`.

As the `pathlib.types` module is **not** imported by `pathlib`, I think we're free to add proper type annotations to the entire module, including the private classes. I think this will help clarify the interface.

I'd like these hints to be compatible with the oldest version of Python still receiving security updates (3.9 at time of writing) because I'm hoping to provide a PyPI package from this module.",[],"> As the pathlib.types module is not imported by pathlib

Since this is the case, I don't think we'll need to bother about import time then. Are you planning to have more protocol-like classes, namely something that evolves like `collections.abc`? (I think `pathlib.types` is something like `collections.abc` then; maybe we should name it `pathlib.abc` instead? idk).",[],['python'],github,https://github.com/python/cpython/issues/130798,{'repo': 'python/cpython'}
"Add colour to `argparse` help

# Feature or enhancement

In Python 3.13 we added colour output to the new REPL, `traceback` and `doctest`, and in 3.14 to `unittest`, `test.regrtest` and `calendar`, that can also be controlled with the `PYTHON_COLORS`, `NO_COLOR` and `FORCE_COLOR` environment variables:

* https://docs.python.org/3.14/whatsnew/3.14.html#unittest
* https://docs.python.org/3.14/using/cmdline.html#using-on-controlling-color

Let's add colour to `argparse` help output.

## Survey

First, here's a survey of some other CLIs that use colour:

<details>
<summary>Survey</summary>


<table>
<tr>
<th colspan=2>uv
<tr>
<td>
<img width=""868"" alt=""Image"" src=""https://github.com/user-attachments/assets/31869566-6580-4035-b1f4-d5695b77cfb1"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/eea6349f-9590-4d2e-8cbe-9c0f27784cac"" />

<tr>
<th colspan=2>cargo

<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/3b6834c1-ca9d-4c97-a8c5-e9af660a8144"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/b4722fca-1610-407e-8672-604e3de2baf5"" />

<tr>
<th colspan=2>composer

<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/ad691d30-918e-4f88-8ae0-ca5fc2bbd7d6"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/fcb522cc-b6a8-47c4-b784-d121b7acff3e"" />

<tr>
<th colspan=2>ruff

<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/42a962c3-33d9-4fa1-aa35-1ba5a55f650a"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/89f997ee-0a18-49f5-9039-1a5634503d90"" />

<tr>
<th colspan=2>lsd

<tr>
<td><img width=""868"" alt=""Image"" src=""https://github.com/user-attachments/assets/03ad0675-1845-43aa-8802-fb6f3edf6d99"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/96b8b582-d40d-4a4e-be51-a04abb15c357"" />

<tr>
<th colspan=2>fd

<tr>
<td><img width=""868"" alt=""Image"" src=""https://github.com/user-attachments/assets/cd5caa47-fbda-47f8-841b-c3386534e8e4"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/c4eac0cf-b46d-478f-8604-86d666109e17"" />

See also: bat, hyperfine, oxipng, zizmor

<tr>
<th colspan=2>gh

<tr>
<td><img width=""868"" alt=""Image"" src=""https://github.com/user-attachments/assets/10be9e0e-3712-4ae5-98c5-7b2dcfe91908"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/2ef5971b-c322-440c-8179-08cce3b78b76"" />

<tr>
<th colspan=2>rich-cli

<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/4e7dae32-2992-419f-9ddc-92ae735ec3b9"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/abd1bebe-2dcf-4299-9295-de8da11a2500"" />

<tr>
<th colspan=2>typer

<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/e32d0e16-8e2b-4597-97f2-43d9cdbd482f"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/135643a7-7a1a-4786-ab96-3a2d69393b27"" />

</table>


</details>

These fall into four groups:

* uv/cargo: green + cyan
* composer: yellow + green
* ruff/lsd/fd/gh: only bold
* typer/rich-cli: green + cyan + yellow

## Prototypes

I've made prototypes of two of these (uv/cargo style, typer/rich-cli style), and another with blue + magenta similar to the 3.13 REPL/traceback.

<details>
<summary>Prototypes</summary>


<table>
<tr>
<th colspan=2>main
<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/20be44cc-ae36-49d1-9911-3b4a0d6ddee6"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/35bfe5e9-5985-4db1-bfe4-a06f0bcf999e"" />


<tr>
<th colspan=2>uv/cargo style
<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/21e21ab2-3e22-46ae-a10a-dd3dcc6c194d"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/e896f6e0-7112-482a-adba-21f1fdaa6dc1"" />

<tr>
<th colspan=2>typer/rich-cli style
<tr>

<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/a43c721b-0ad0-4087-b241-14bf86c96c9e"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/da4408e4-76c2-42c3-8fff-f1270c701d10"" />

<tr>
<th colspan=2>REPL style
<tr>
<td><img width=""864"" alt=""Image"" src=""https://github.com/user-attachments/assets/3feb9a82-dfa8-4d29-8613-713db857bd00"" />
<td><img width=""871"" alt=""Image"" src=""https://github.com/user-attachments/assets/ab5cdf6a-47a3-413b-bdf1-2dc885dc4c9a"" />

</table>

</details>


I think I prefer the typer/rich-cli style: the extra colour makes it easier to pick out the (green) short options from the (cyan) long options, and from their (green) arguments. And it should also be somewhat familiar to Python users who have used typer-based CLIs.",[],"I'm +1 on this, if it's opt-in and ensures that we can ensure the startup time isn't impacted. In CLI tools that I've worked on in the past, we leaned heavily on the [ANSI defined color presets](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors) when trying to guarantee accessibility/sufficient contrast.",[],['python'],github,https://github.com/python/cpython/issues/130645,{'repo': 'python/cpython'}
"An object referenced only through it's own `__dict__` can get collected too early.

# Bug report

### Bug description:

After reusing one object's `__dict__` for another object, and adding a reference to the original object in a dictionary on the target object, the original object might get collected too early (and cause a whole other dictionary to get cleared). I hope the code below describes it better than my words.

I've bisected this problem to c32dc47aca6.

This is the smallest reproduction I've found so far:

```python
import gc
import sys

print(sys.version_info)

class A:
    def __del__(self):
        print(""del"", hex(id(self)))

a = A()
a.attr_a = ""test value""
b = A()
b.__dict__ = a.__dict__
b.other_attr = {""self reference"": a, ""other data"": 42}
del a
print(""before gc:"", b.__dict__)
gc.collect()

print(""after gc:"", b.__dict__)
```

Results on 3.13:
```
sys.version_info(major=3, minor=13, micro=0, releaselevel='alpha', serial=5)
before gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x76cc6317a900>, 'other data': 42}}
del 0x76cc6317a900
after gc: {'attr_a': 'test value', 'other_attr': {}}
del 0x76cc6256ccd0
```

Results on 3.12, and what I expected to see:
```
sys.version_info(major=3, minor=12, micro=7, releaselevel='final', serial=0)
before gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x77496b531130>, 'other data': 42}}
after gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x77496b531130>, 'other data': 42}}
del 0x77496b531160
del 0x77496b531130
```

I've noticed this change in behaviour while working with Locust.io, the original issue for reference: https://github.com/locustio/locust/issues/3050

### CPython versions tested on:

3.13, CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130469
<!-- /gh-linked-prs -->
","['import gc\nimport sys\n\nprint(sys.version_info)\n\nclass A:\n    def __del__(self):\n        print(""del"", hex(id(self)))\n\na = A()\na.attr_a = ""test value""\nb = A()\nb.__dict__ = a.__dict__\nb.other_attr = {""self reference"": a, ""other data"": 42}\ndel a\nprint(""before gc:"", b.__dict__)\ngc.collect()\n\nprint(""after gc:"", b.__dict__)', ""sys.version_info(major=3, minor=13, micro=0, releaselevel='alpha', serial=5)\nbefore gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x76cc6317a900>, 'other data': 42}}\ndel 0x76cc6317a900\nafter gc: {'attr_a': 'test value', 'other_attr': {}}\ndel 0x76cc6256ccd0"", ""sys.version_info(major=3, minor=12, micro=7, releaselevel='final', serial=0)\nbefore gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x77496b531130>, 'other data': 42}}\nafter gc: {'attr_a': 'test value', 'other_attr': {'self reference': <__main__.A object at 0x77496b531130>, 'other data': 42}}\ndel 0x77496b531160\ndel 0x77496b531130""]","> Out of curiosity--what happens if two objects share a reference to A, and both objects traverse A? Does the garbage collector require that the number of GC referrers is <= the object's reference count?

Yes, the GC requires that the number of referrers is <= the object's reference count. Otherwise, you may trigger an assert like ""[""refcount is too small""](https://github.com/python/cpython/blob/fa6a8140dd2a72da6df2a7dfafbf07045debf64d/Python/gc.c#L639).

The GC computes object's reference count minus the number of referrers as ""gc_refs"". If this values is >0, then the object has some external reference and is definitely reachable and shouldn't be collected. If ""gc_refs"" is zero, then it doesn't have external references, but it may still be reachable from some other live object considered by the GC. And if ""gc_refs"" is <0, then we trigger an assertion failure like the one above.

So if we have too many `Py_VISIT()` calls we may:
* incorrectly make ""gc_refs"" zero and call a `tp_clear()` hook on an object that shouldn't actually be cleared. 
* incorrectly make ""gc_refs"" negative and trigger an assertion failure
* or nothing may happen because ""gc_refs"" is still positive or the relevant object was otherwise still reachable.",[],['python'],github,https://github.com/python/cpython/issues/130327,{'repo': 'python/cpython'}
"CSV write has SEGV when trying to write data 2GB or larger

# Crash report

### What happened?

```python
import csv


bad_size = 2 * 1024 * 1024 * 1024 + 1
val = 'x' * bad_size


print(""Total size of data {}"".format(len(val)))
for size in [2147483647, 2147483648, 2147483649]:
    data = val[0:size]
    print(""Trying to write data of size {}"".format(len(data)))
    with open('dump.csv', 'w', newline='') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',',
                                quotechar='|', quoting=csv.QUOTE_MINIMAL)
        spamwriter.writerow([data])
```

```
 python dump2.py 
Total size of data 2147483649
Trying to write data of size 2147483647
Trying to write data of size 2147483648
Segmentation fault (core dumped)

```

This happens with both 3.10 and 3.12 

When I reproduce this with python-dbg inside of gdb I see the following:

```
#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=140737352495104) at ./nptl/pthread_kill.c:44
#1  __pthread_kill_internal (signo=6, threadid=140737352495104) at ./nptl/pthread_kill.c:78
#2  __GI___pthread_kill (threadid=140737352495104, signo=signo@entry=6) at ./nptl/pthread_kill.c:89
#3  0x00007ffff7c42476 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26
#4  0x00007ffff7c287f3 in __GI_abort () at ./stdlib/abort.c:79
#5  0x00007ffff7c2871b in __assert_fail_base (fmt=0x7ffff7ddd130 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", 
    assertion=0x814bed ""index >= 0"", file=0x7ee008 ""../Include/cpython/unicodeobject.h"", line=318, 
    function=<optimized out>) at ./assert/assert.c:92
#6  0x00007ffff7c39e96 in __GI___assert_fail (assertion=assertion@entry=0x814bed ""index >= 0"", 
    file=file@entry=0x7ee008 ""../Include/cpython/unicodeobject.h"", line=line@entry=318, 
    function=function@entry=0x97ae28 <__PRETTY_FUNCTION__.4.lto_priv.56> ""PyUnicode_READ"") at ./assert/assert.c:101
#7  0x00000000006d46c3 in PyUnicode_READ (index=-2147483648, data=0x7ffe772fd058, kind=1)
    at ../Include/cpython/unicodeobject.h:318
#8  join_append_data (self=self@entry=0x7ffff74a0050, field_kind=field_kind@entry=1, 
    field_data=field_data@entry=0x7ffe772fd058, field_len=field_len@entry=2147483648, quoted=quoted@entry=0x7fffffffd0ec, 
    copy_phase=copy_phase@entry=0) at ../Modules/_csv.c:1108
#9  0x00000000006d49ea in join_append (self=self@entry=0x7ffff74a0050, 
    field=field@entry='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', quoted=<optimized out>, quoted@entry=0) at ../Modules/_csv.c:1213
#10 0x00000000006d4c9a in csv_writerow (self=self@entry=0x7ffff74a0050, 
    seq=seq@entry=['xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx']) at ../Modules/_csv.c:1303
#11 0x000000000062b002 in _PyEval_EvalFrameDefault (tstate=0xcd8d80 <_PyRuntime+475008>, frame=0x7ffff7fb0020, throwflag=0)
    at Python/bytecodes.c:3094

```

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.12.8 (main, Dec  4 2024, 08:54:12) [GCC 11.4.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-129413
* gh-129436
* gh-129437
<!-- /gh-linked-prs -->
","['import csv\n\n\nbad_size = 2 * 1024 * 1024 * 1024 + 1\nval = \'x\' * bad_size\n\n\nprint(""Total size of data {}"".format(len(val)))\nfor size in [2147483647, 2147483648, 2147483649]:\n    data = val[0:size]\n    print(""Trying to write data of size {}"".format(len(data)))\n    with open(\'dump.csv\', \'w\', newline=\'\') as csvfile:\n        spamwriter = csv.writer(csvfile, delimiter=\',\',\n                                quotechar=\'|\', quoting=csv.QUOTE_MINIMAL)\n        spamwriter.writerow([data])', 'python dump2.py \nTotal size of data 2147483649\nTrying to write data of size 2147483647\nTrying to write data of size 2147483648\nSegmentation fault (core dumped)', '#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=140737352495104) at ./nptl/pthread_kill.c:44\n#1  __pthread_kill_internal (signo=6, threadid=140737352495104) at ./nptl/pthread_kill.c:78\n#2  __GI___pthread_kill (threadid=140737352495104, signo=signo@entry=6) at ./nptl/pthread_kill.c:89\n#3  0x00007ffff7c42476 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\n#4  0x00007ffff7c287f3 in __GI_abort () at ./stdlib/abort.c:79\n#5  0x00007ffff7c2871b in __assert_fail_base (fmt=0x7ffff7ddd130 ""%s%s%s:%u: %s%sAssertion `%s\' failed.\\n%n"", \n    assertion=0x814bed ""index >= 0"", file=0x7ee008 ""../Include/cpython/unicodeobject.h"", line=318, \n    function=<optimized out>) at ./assert/assert.c:92\n#6  0x00007ffff7c39e96 in __GI___assert_fail (assertion=assertion@entry=0x814bed ""index >= 0"", \n    file=file@entry=0x7ee008 ""../Include/cpython/unicodeobject.h"", line=line@entry=318, \n    function=function@entry=0x97ae28 <__PRETTY_FUNCTION__.4.lto_priv.56> ""PyUnicode_READ"") at ./assert/assert.c:101\n#7  0x00000000006d46c3 in PyUnicode_READ (index=-2147483648, data=0x7ffe772fd058, kind=1)\n    at ../Include/cpython/unicodeobject.h:318\n#8  join_append_data (self=self@entry=0x7ffff74a0050, field_kind=field_kind@entry=1, \n    field_data=field_data@entry=0x7ffe772fd058, field_len=field_len@entry=2147483648, quoted=quoted@entry=0x7fffffffd0ec, \n    copy_phase=copy_phase@entry=0) at ../Modules/_csv.c:1108\n#9  0x00000000006d49ea in join_append (self=self@entry=0x7ffff74a0050, \n    field=field@entry=\'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\', quoted=<optimized out>, quoted@entry=0) at ../Modules/_csv.c:1213\n#10 0x00000000006d4c9a in csv_writerow (self=self@entry=0x7ffff74a0050, \n    seq=seq@entry=[\'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\']) at ../Modules/_csv.c:1303\n#11 0x000000000062b002 in _PyEval_EvalFrameDefault (tstate=0xcd8d80 <_PyRuntime+475008>, frame=0x7ffff7fb0020, throwflag=0)\n    at Python/bytecodes.c:3094']","When I patched it locally and built from source it fixes the problem:

```
--- Modules/_csv.c	2024-02-06 15:19:44.000000000 -0500
+++ Modules/_csv.c.new	2025-01-28 11:39:16.165889509 -0500
@@ -1072,7 +1072,7 @@
                  int copy_phase)
 {
     DialectObj *dialect = self->dialect;
-    int i;
+    Py_ssize_t i;
     Py_ssize_t rec_len;
 
 #define INCLEN \
```

```
 python dump2.py 
Total size of data 2147483649
Trying to write data of size 2147483647
Trying to write data of size 2147483648
Trying to write data of size 2147483649

```","['--- Modules/_csv.c\t2024-02-06 15:19:44.000000000 -0500\n+++ Modules/_csv.c.new\t2025-01-28 11:39:16.165889509 -0500\n@@ -1072,7 +1072,7 @@\n                  int copy_phase)\n {\n     DialectObj *dialect = self->dialect;\n-    int i;\n+    Py_ssize_t i;\n     Py_ssize_t rec_len;\n \n #define INCLEN \\', 'python dump2.py \nTotal size of data 2147483649\nTrying to write data of size 2147483647\nTrying to write data of size 2147483648\nTrying to write data of size 2147483649']",['python'],github,https://github.com/python/cpython/issues/129409,{'repo': 'python/cpython'}
"Tkinter file selection dialog fails to pass selected file ending and append to file being saved

# Bug report

### Bug description:

```python
import tkinter as tk
from tkinter import filedialog
import os

class FileDialogTest:
    def __init__(self, file_extensions):
        self.file_extensions = file_extensions
        self.selected_file_type = None

    def _format_file_extensions(self):
        return [(f""{ext} files"", ext) for ext in self.file_extensions]

    def _get_file_type(self, file_path):
        _, ext = os.path.splitext(file_path)
        return ext

    def select_file_to_save(self, default_name=""testfile""):
        root = tk.Tk()
        root.withdraw()
        file_path = filedialog.asksaveasfilename(
            title=""Select a file to save"",
            filetypes=self._format_file_extensions(),
            initialfile=default_name
        )
        if not file_path:
            raise FileNotFoundError(""No file selected."")
        self.selected_file_type = self._get_file_type(file_path)
        if not self.selected_file_type:
            # Append the default extension based on the selected file type
            self.selected_file_type = self.file_extensions[0]  # Default to the first extension if none is selected
            file_path += self.selected_file_type
        return file_path, self.selected_file_type

# Define file extensions for testing
file_extensions = ['.txt', '.csv']

# Initialize FileDialogTest with file extensions
file_dialog_test = FileDialogTest(file_extensions)

# Test select_file_to_save method
try:
    file_path, selected_file_type = file_dialog_test.select_file_to_save()
    print(f""Selected file path: {file_path}"")
    print(f""Selected file type: {selected_file_type}"")
except FileNotFoundError as e:
    print(e)
```


### CPython versions tested on:

3.11

### Operating systems tested on:

Windows","['import tkinter as tk\nfrom tkinter import filedialog\nimport os\n\nclass FileDialogTest:\n    def __init__(self, file_extensions):\n        self.file_extensions = file_extensions\n        self.selected_file_type = None\n\n    def _format_file_extensions(self):\n        return [(f""{ext} files"", ext) for ext in self.file_extensions]\n\n    def _get_file_type(self, file_path):\n        _, ext = os.path.splitext(file_path)\n        return ext\n\n    def select_file_to_save(self, default_name=""testfile""):\n        root = tk.Tk()\n        root.withdraw()\n        file_path = filedialog.asksaveasfilename(\n            title=""Select a file to save"",\n            filetypes=self._format_file_extensions(),\n            initialfile=default_name\n        )\n        if not file_path:\n            raise FileNotFoundError(""No file selected."")\n        self.selected_file_type = self._get_file_type(file_path)\n        if not self.selected_file_type:\n            # Append the default extension based on the selected file type\n            self.selected_file_type = self.file_extensions[0]  # Default to the first extension if none is selected\n            file_path += self.selected_file_type\n        return file_path, self.selected_file_type\n\n# Define file extensions for testing\nfile_extensions = [\'.txt\', \'.csv\']\n\n# Initialize FileDialogTest with file extensions\nfile_dialog_test = FileDialogTest(file_extensions)\n\n# Test select_file_to_save method\ntry:\n    file_path, selected_file_type = file_dialog_test.select_file_to_save()\n    print(f""Selected file path: {file_path}"")\n    print(f""Selected file type: {selected_file_type}"")\nexcept FileNotFoundError as e:\n    print(e)']","What is the expected output here, and what are you seeing? 

On both Python 3.11 and 3.14 (main), when I run this script and hit Save with the default file name, I see something like:
```
Selected file path: /home/jglass/Documents/cpython/testfile.txt
Selected file type: .txt
```
This is on ubuntu 22.04, for what it's worth.",['Selected file path: /home/jglass/Documents/cpython/testfile.txt\nSelected file type: .txt'],['python'],github,https://github.com/python/cpython/issues/129460,{'repo': 'python/cpython'}
"`math.sumprod` equivalent code is more complicated than needed

# Documentation

Docs say that `math.sumprod(p, q)` is roughly equivalent to:

```
sum(itertools.starmap(operator.mul, zip(p, q, strict=True)))
```

This is not useful for people who don't already know about `itertools.starmap` and `operator.mul`. IMO that is a shame, because `math.sumprod` is not that complicated to understand. It would be better to describe it as:

```
sum(x*y for x, y in zip(p, q, strict=True))
```

<!-- gh-linked-prs -->
### Linked PRs
* gh-130206
<!-- /gh-linked-prs -->
","['sum(itertools.starmap(operator.mul, zip(p, q, strict=True)))', 'sum(x*y for x, y in zip(p, q, strict=True))']","It seems like this was already simplified in gh-126407. On the main branch, it is:

```python
sum(map(operator.mul, p, q, strict=True))
```

I still feel like plain old `*` would be better than `operator.mul`. I will make a PR.","['sum(map(operator.mul, p, q, strict=True))']",['python'],github,https://github.com/python/cpython/issues/130203,{'repo': 'python/cpython'}
"Add `close()` method to `asyncio.StreamReader`

# Feature or enhancement

### Proposal:

When creating a sub-process using `asyncio.create_subprocess_exec()`, it returns a `Process` instance that has a `stdout` property. This property is intended to be an asyncio version of the `stdout` property of the `Popen` instance from the `subprocess` module.

An important aspect of `Popen.stdout` property is that you can close it. This is a signal to the sub-process that is generating output that it should cleanly terminate. This is a common pattern in processes used in shell pipelines. Indeed, the object located at `Popen.stdout` has a `close()` method. This pattern is demonstrated below:

```python
import subprocess
proc = subprocess.Popen([""yes""], stdout=subprocess.PIPE) # start subprocess
data = proc.stdout.read(4096) # get data
proc.stdout.close() # signal to process to cleanly shutdown
proc.wait() # wait for shutdown
```

Unfortunately this pattern cannot be reproduced easily with the `stdout` property of the `Process` instance returned from `asyncio.create_subprocess_exec()` because `stdout` is an instance of `StreamReader` which does not have the `close()` method.

I propose adding a `close()` method to the `StreamReader` class so that asyncio version of the `subprocess` module may support this pattern of managing sub-processes. This change is consistent with the asyncio ecosystem as the companion `StreamWriter` class already has a `close()` method, along with other methods that expose its inner ""transport"" object. It's also trivial to implement, since it's essentially a wrapper method around the inner transport object's `close()` method.

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130929
<!-- /gh-linked-prs -->
","['import subprocess\nproc = subprocess.Popen([""yes""], stdout=subprocess.PIPE) # start subprocess\ndata = proc.stdout.read(4096) # get data\nproc.stdout.close() # signal to process to cleanly shutdown\nproc.wait() # wait for shutdown']","I did think about this ahead of time and my conclusion was that a `__del__` method that auto-closes is not right in this instance because the `StreamReader` is not the owner of its internal ""transport"" object and thus not responsible for closing it. In all current uses of `StreamReader`, other code is responsible for closing the transport object and indeed does so. I.e. it would not be an error to not to call `close()` on `StreamReader` references you may have.

This is just to allow code that **only** has a reference to the `StreamReader` and not the transport to **eagerly** close the transport for the sake of signaling. This is the norm when dealing with sub-processes in asyncio using the convenience interface. Eventually once the actual resource cleanup happens, the transport will be closed again but that is fine since `close()` is designed to be idempotent.",[],['python'],github,https://github.com/python/cpython/issues/130925,{'repo': 'python/cpython'}
"Append subprocess stderr in CalledProcessError.__str__()

# Feature or enhancement

### Proposal:

At the time only signal / exit code is visible in the string value of the exception.
It seems reasonable to also dump stderr (either entirely or partially) when writing the exception.

This should ease the debugging and speed up the development feedback loop.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130262
<!-- /gh-linked-prs -->
",[],"I'm not so sure this is a good idea.

- A lot of applications that run into this error will display stderr anyway, either because it's attached to the main process or because it was explicitly printed. (IIRC pip does one of these--now they'll have to try to suppress the error message to prevent the double-output.)
- Even if we truncate the output, there's still bound to be some newlines in there. I suspect that will screw up logs.
",[],['python'],github,https://github.com/python/cpython/issues/130261,{'repo': 'python/cpython'}
"iOS testbed doesn't reliably capture *all* log output

# Bug report

### Bug description:

The iOS testbed captures test output by streaming the system log. It does this by running a log stream in parallel to the process that is running the test suite.

However, it takes time for this log stream to start; if the test suite finishes *really* quickly, it's possible no output will be captured at all. The test status will be accurately reported, because that's based on the return code of the process and is handled by Xcode; but in the case of a test failure, there won't be any log output that reports *why* the test failed.

Alternatively, if the test machine is busy and is generating lots of other log content, it will occasionally drop lines of output, as `log stream` will prioritizes currency of the log over completeness. These can be seen in iOS buildbot logs:
```
=== Messages dropped during live streaming (use `log show` to see what they were)
```

Ideally, we wouldn't lose *any* log output; however, this may not be possible given the constraints of iOS stdout logging. 

As a workaround, it may be preferable to use `log show` *after* the completion of a test run to get a *complete* log. This will result in log output being output twice - an initial ""live"" log (which might contain dropped lines) to indicate test progress, and then a ""complete"" log that contains everything at the completion of the test run. This ""complete"" log can be generated with `log show`, which is guaranteed to produce a complete log. As the log is only truly useful in the case of a test failure, it might be desirable to only generate the complete log on test failure.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Other",['=== Messages dropped during live streaming (use `log show` to see what they were)'],It may be possible to address both of these problems by filtering by PID. See discussion in https://github.com/beeware/briefcase/issues/2086.,[],['python'],github,https://github.com/python/cpython/issues/130294,{'repo': 'python/cpython'}
"Update the locale alias mapping

`locale_alias` mapping in the `locale` module is manually generated from the `locale.aliases` file from X.org distribution and the supported locales list from glibc. As these files are changed, we need to update `locale_alias` from time to time. Last time it was updated in 3.8. There are not much changes since then, but they are.

Other issue is that ""univ"" and ""universal"" map to non-existing locale ""en_US.utf"" (should be ""en_US.UTF-8""), as was noticed in #122877. `locale.aliases` no longer contains such aliases, it only contains aliases ""univ.utf8"" and ""universal.utf8@ucs4"".

<!-- gh-linked-prs -->
### Linked PRs
* gh-129647
* gh-129658
<!-- /gh-linked-prs -->
",[],"I backported this to 3.13 which is still in early stage of its life, but I am not so sure about 3.12. Perhaps it is not worth a hassle.",[],['python'],github,https://github.com/python/cpython/issues/129646,{'repo': 'python/cpython'}
"Vulnerability Exposure of CVE-2024-3220

We have our IBM Traditional WebSphere Application Server using jython. The code of jython is taken from CPython. I would like to know regarding the vulnerability exposure of jython towards CVE-2024-3220. 

I found a Python CVE to assess to determine if the Jython we use in tWAS 855 and 9.0 is vulnerable or not. The description of the CVE is as follows:
A flaw was found in the mimetypes standard library module for Python. On Windows systems, the default list of known file locations is writable, meaning other users can create invalid files to cause MemoryError to be raised on Python runtime startup or have file extensions be interpreted as the incorrect file type. This defect is caused by the default locations of Linux and macOS platforms (such as /etc/mime.types) also being used on Windows, where they are user-writable locations (C:\etc\mime.types).
https://access.redhat.com/security/cve/CVE-2024-3220
https://nvd.nist.gov/vuln/detail/CVE-2024-3220

I could see a work around addressing this in NVD link. To work-around this issue a user can call mimetypes.init() with an empty list (“[]”) on Windows platforms to avoid using the default list of known file locations.

I suspect jython is vulnerable since we use python. Do anyone have assessed this vulnerability and the level of its exposure ? And are we planning for a fix for this? Or is there any existing fix ? 

Thanks in Advance",[],"This is the CPython project, please contact the Jython project directly to ask about their code: https://www.jython.org/

Their security policy can be found at:

https://github.com/jython/jython?tab=security-ov-file#readme
",[],['python'],github,https://github.com/python/cpython/issues/130514,{'repo': 'python/cpython'}
"Undeprecate typing.Callable and deprecate collections.abc.Callable

# Feature or enhancement

### Proposal:

`Callable` doesn't seem to have much ""idea overlap"" with `Collection` - `Callable`s don't deal with zero-or-more of a thing, or whether or not a thing appears among another population of things, or any of the other concerns that give conceptual coherence to `Collection` and the rest of the family (`Set`, `Mapping`, `Sequence` and so forth) in `collections.abc`.

Also [old-issue-tracker issue 27598](https://bugs.python.org/issue27598) seems to be the scope for [the change that introduced `Callable` to `collections.abc`](https://github.com/python/cpython/commit/f0666949fda1f418eb656b7503b4609e6bd58163), but it doesn't give any insight into why `Callable` was included.

What might I be overlooking that would motivate a reason for `Callable` to ""belong"" in `collections.abc`?

If there's no particular reason for `Callable` to be in `collections.abc`, might `typing.Callable` be un-deprecated? And might `collections.abc.Callable` be deprecated?

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_",[],"We're not going to remove typing.Callable. If it makes you happy, use it. ",[],['python'],github,https://github.com/python/cpython/issues/131040,{'repo': 'python/cpython'}
"Tail calling interpreter for Windows

# Feature or enhancement

### Proposal:

Add new build flag for it.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130040
<!-- /gh-linked-prs -->
",[],"This is done. More importantly, this will allow sanitizers for Windows now as well!",[],['python'],github,https://github.com/python/cpython/issues/130039,{'repo': 'python/cpython'}
"warnings.catch_warnings docs: dubious mention of sys.stdout

https://docs.python.org/3/library/warnings.html#warnings.catch_warnings reads:

> If *record* is `True`, a list is returned that is progressively populated with objects as seen by a custom `showwarning()` function (which also suppresses output to `sys.stdout`).

Was it meant to say `sys.stderr` instead?
Otherwise, I don't understand why it mentions `stdout` specifically. I don't see anything about `stdout` elsewhere in the module docs or in the implementation.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130768
<!-- /gh-linked-prs -->
",[],"> https://docs.python.org/3/library/warnings.html#warnings.catch_warnings reads:
> 
> > If _record_ is `True`, a list is returned that is progressively populated with objects as seen by a custom `showwarning()` function (which also suppresses output to `sys.stdout`).
> 
> Was it meant to say `sys.stderr` instead? Otherwise, I don't understand why it mentions `stdout` specifically. I don't see anything about `stdout` elsewhere in the module docs or in the implementation.


The mention of `sys.stdout` in the documentation is likely included to highlight that the warning output is suppressed entirely, including any potential redirection of `sys.stderr` to `sys.stdout`. But, it is true that warnings are typically written to `sys.stderr` by default, not `sys.stdout`. So it is good that we can change 

> If _record_ is `True`, a list is returned that is progressively populated with objects as seen by a custom `showwarning()` function (which also suppresses output to `sys.stdout`).

to 

> If _record_ is `True`, a list is returned that is progressively populated with objects as seen by a custom `showwarning()` function (which also suppresses output to `sys.stderr`).

to make it more specific and clear to understand.",[],['python'],github,https://github.com/python/cpython/issues/129846,{'repo': 'python/cpython'}
"gdb stack trace incomplete when enabling Perf support

# Bug report

### Bug description:

GDB stack trace is incomplete when enabling Perf support under specific optimization options on x86_64. It seems that through various changes the stack trace was broken and/or fixed. I've bisected the relevant commits.

Perf 6.13.4, GDB 16.2, GCC 14.2.1 on x86_64, Fedora 41.

### **With frame pointers using -X perf:**

`./configure --enable-shared --without-static-libpython   && CFLAGS=""-fno-omit-frame-pointer -mno-omit-leaf-frame-pointer -<optmization>"" make`

Run `LD_LIBRARY_PATH=$PWD  gdb -args ./python -X perf -m test -vv test_sys` and within the GDB shell `run`.

Press ctrl+c during execution and run `bt`. On specific configurations the stack trace is trimmed, usually right after the unknown frames.

**python3.12:**

- -O3, -O1, -O0, -Og:
    Complete gdb stack trace.
- -O2:
    Incomplete gdb stack trace (stops at the unknown frames). (Didn't work from the beginning, resolved in [3.13](https://github.com/python/cpython/commit/75b3db8445188c2ad38cabc0021af694df0829b8))


**python3.13:**
- -O3, -O2, -O0, -Og:
    Complete gdb stack trace.

- -O1:
    Incomplete gdb stack trace (stops at the unknown frames). (regressed on 3.13 [here](https://github.com/python/cpython/commit/16055c160412544e2a49794aaf3aa70c584f843a) and fixed again in 3.14 [here](https://github.com/python/cpython/commit/bb1d30336e83837d4191a016107fd501cd230328))

**python3.14:**
- -O3, -O2, -Og:
    Incomplete gdb stack trace (stops at the unknown frames). (-O3, -O2 regressed [here](https://github.com/python/cpython/commit/128cc47fbd44e3e09c50d9674fe4a4bba3be450c), -Og regressed [here](https://github.com/python/cpython/commit/bb1d30336e83837d4191a016107fd501cd230328))

- -O1, -O0:
    Complete gdb stack trace.


### Without frame pointers using -X perf_jit

`./configure --enable-shared --without-static-libpython   && CFLAGS=""-<optmization>"" make`

Run `LD_LIBRARY_PATH=$PWD  gdb -args ./python -X perf_jit -m test -vv test_sys` and within the GDB shell `run`.

Press ctrl+c during execution and run `bt`. On specific configurations the stack trace is trimmed, usually right after the unknown frames.

**python3.12:**
- Not supported

**python3.13:**

- -O3:
    Incomplete gdb stack trace (stops at the unknown frames). (Worked initially, regressed [here](https://github.com/python/cpython/commit/00b13ec050696f98da28db15987122d1f3bd5d39), fixed in [3.14](https://github.com/python/cpython/commit/d6f010dead1a0d4b8a9e51f0187617b0394c9c2a))

- -O2, -O1, -Og:
    Complete gdb stack trace.

- -O0:
    Complete gdb stack trace.
    Python functions are **not** visible in Perf output.

**python3.14:**

- -O3, -O2, -O1:
    Complete gdb stack trace.

- -Og:
    Incomplete gdb stack trace (stops at the unknown frames). (Regressed [here](https://github.com/python/cpython/commit/bb1d30336e83837d4191a016107fd501cd230328), same as with frame pointers)

- -O0:
    Complete gdb stack trace.
    Python functions are **not** visible in Perf output.


### CPython versions tested on:

CPython main branch, 3.14, 3.13, 3.12

### Operating systems tested on:

Linux",[],"I have been investigating this and it's a bit of a mess. Different versions of gdb can basically leverage different heuristics to recontruct the stack trace and the different changes to ceval after the optimization work make this not play well with the algorithms they use. It's basically an impossible battle. The only way is to add gdb support for jit compilers but that slows down Python **considerably** as gdb demands entire ELF files in memory to be created wich kind of defies the purpose of having a low performance profiler active :(

So I am afraid we need to close this as won't fix 😢 ",[],['python'],github,https://github.com/python/cpython/issues/130856,{'repo': 'python/cpython'}
"Make `os.scandir` retry on system calls failing with EINTR

# Bug report

### Bug description:

In a long-running script, I hit:

```
[…]
  File ""/Users/gsnedders/ct.py"", line 104, in worker
    with os.scandir(path) as it:
         ~~~~~~~~~~^^^^^^
InterruptedError: [Errno 4] Interrupted system call: '/Users/gsnedders/Library/Containers/com.apple.ScreenTimeWidgetApplication.ScreenTimeWidgetExtension/Data/Library/Application Scripts'
```

No repro case is provided, because that would require making syscalls fail with EINTR reliably somehow.

[PEP 475](https://peps.python.org/pep-0475/) (Retry system calls failing with EINTR) implies to me that `os.scandir` should be retrying, rather than just failing here.

It does appear that `os.scandir` doesn't always retry, looking at the source:

https://github.com/python/cpython/blob/ae3064608935367c860182dc1b364631082ecdff/Modules/posixmodule.c#L16489

The iterator itself also seems to not retry:

https://github.com/python/cpython/blob/ae3064608935367c860182dc1b364631082ecdff/Modules/posixmodule.c#L16290

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS","['[…]\n  File ""/Users/gsnedders/ct.py"", line 104, in worker\n    with os.scandir(path) as it:\n         ~~~~~~~~~~^^^^^^\nInterruptedError: [Errno 4] Interrupted system call: \'/Users/gsnedders/Library/Containers/com.apple.ScreenTimeWidgetApplication.ScreenTimeWidgetExtension/Data/Library/Application Scripts\'']","I'm not sure but could `os.scandir` also have the same weirdness as `os.close`?

> os.close, close() methods and os.dup2() are a special case: they will ignore EINTR instead of retrying. The reason is complex but involves behaviour under Linux and the fact that the file descriptor may really be closed even if EINTR is returned.

Anyway, I think we should treat it as a feature request.",[],['python'],github,https://github.com/python/cpython/issues/130209,{'repo': 'python/cpython'}
"PyQt6 uses PySequence_Fast() which was removed from the limited C API 3.14

# Bug report

### Bug description:

In the issue https://github.com/python/cpython/issues/91417 I removed PySequence_Fast(), commit 2ad069d906c6952250dabbffbcb882676011b310:

> Remove PySequence_Fast() from the limited C API. The function never worked with the limited C API. It was added by mistake.

Problem: PyQt6 uses the function! I propose to add back PySequence_Fast() to the limited C API.

PyQt6:

```
./qpy/QtOpenGL/qpyopengl_attribute_array.cpp:    values = PySequence_Fast(values, ""an attribute array must be a sequence"");
./qpy/QtOpenGL/qpyopengl_attribute_array.cpp:            itm = PySequence_Fast(itm,
./qpy/QtOpenGL/qpyopengl_uniform_value_array.cpp:    values = PySequence_Fast(values,
./qpy/QtOpenGL/qpyopengl_uniform_value_array.cpp:            itm = PySequence_Fast(itm,
./qpy/QtOpenGL/qpyopengl_value_array.cpp:    PyObject *seq = PySequence_Fast(values,
```

They reimplemented PySequence_Fast_GET_SIZE() and PySequence_Fast_GET_ITEM() macros which don't work with the limited C API:

```c
// Replacements for the corresponding Python macros that use the limited API.
#define Sequence_Fast_Size(o) \
    (PyList_Check(o) ? PyList_Size(o) : PyTuple_Size(o))
#define Sequence_Fast_GetItem(o, i)\
    (PyList_Check(o) ? PyList_GetItem(o, i) : PyTuple_GetItem(o, i))
```

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130948
<!-- /gh-linked-prs -->
","['./qpy/QtOpenGL/qpyopengl_attribute_array.cpp:    values = PySequence_Fast(values, ""an attribute array must be a sequence"");\n./qpy/QtOpenGL/qpyopengl_attribute_array.cpp:            itm = PySequence_Fast(itm,\n./qpy/QtOpenGL/qpyopengl_uniform_value_array.cpp:    values = PySequence_Fast(values,\n./qpy/QtOpenGL/qpyopengl_uniform_value_array.cpp:            itm = PySequence_Fast(itm,\n./qpy/QtOpenGL/qpyopengl_value_array.cpp:    PyObject *seq = PySequence_Fast(values,', '// Replacements for the corresponding Python macros that use the limited API.\n#define Sequence_Fast_Size(o) \\\n    (PyList_Check(o) ? PyList_Size(o) : PyTuple_Size(o))\n#define Sequence_Fast_GetItem(o, i)\\\n    (PyList_Check(o) ? PyList_GetItem(o, i) : PyTuple_GetItem(o, i))']",Fedora downstream issue: https://bugzilla.redhat.com/show_bug.cgi?id=2345504,[],['python'],github,https://github.com/python/cpython/issues/130947,{'repo': 'python/cpython'}
"Asyncio's  loop.create_unix_server makes blocking calls

# Bug report

### Bug description:

It seems `create_unix_server` makes some calls to blocking functions.

https://github.com/python/cpython/blob/4d56c40440c9fd4499d61d24977336d8cd8d8d83/Lib/asyncio/unix_events.py#L273

In particular:
* os.fspath
* os.stat
* os.remove
* socket.bind (similar issue in `trio`: https://github.com/python-trio/trio/issues/241)


### CPython versions tested on:

3.11

### Operating systems tested on:

_No response_",[],"The calls you mention are not worth making asynchronous -- we'd just be making a simple thing complicated for no reason.

- Modern filesystems use caching and filesystem operations are effectively synchronous. People have looked into making async versions of filesystem operations and IIRC the conclusion was that it wasn't worth the complexity -- no actual parallelism was gained.

- It's the same for bind() -- it does no actual I/O, it just copies some bytes from user space to kernel space.",[],['python'],github,https://github.com/python/cpython/issues/129807,{'repo': 'python/cpython'}
"Asyncio: fork() in coroutine causes bad file descriptor

# Bug report

### Bug description:

Here is a simple repro:
```python
import asyncio
import os

async def main():
    pid = os.fork()
    if pid:
        os.waitpid(pid, 0)

asyncio.run(main())
```

The traceback looks like:
```
Traceback (most recent call last):
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 641, in run_until_complete
    self.run_forever()
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 608, in run_forever
    self._run_once()
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 1898, in _run_once
    event_list = self._selector.select(timeout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py"", line 566, in select
    kev_list = self._selector.control(None, max_ev, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""~/forkasyncio.py"", line 9, in <module>
    asyncio.run(main())
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 189, in run
    with Runner(debug=debug) as runner:
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 63, in __exit__
    self.close()
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 72, in close
    loop.run_until_complete(loop.shutdown_asyncgens())
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 641, in run_until_complete
    self.run_forever()
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 608, in run_forever
    self._run_once()
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 1898, in _run_once
    event_list = self._selector.select(timeout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py"", line 566, in select
    kev_list = self._selector.control(None, max_ev, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor
sys:1: RuntimeWarning: coroutine 'BaseEventLoop.shutdown_asyncgens' was never awaited
```

I believe the traceback is produced by the child process.

I would not expect bad file descriptor in either the parent or the child because fork is supposed to copy the open file descriptors. I have even tried a custom fork module to ensure `os.fork` isn't closing the file descriptor.

The issue also happens if the child does `sys.exit()`. I find the best workaround is to have the child do `os._exit(0)`:

```python
import asyncio
import os
import sys

async def main():
    pid = os.fork()
    if pid:
        os.waitpid(pid, 0)
    else:
        sys.stdout.flush()
        sys.stderr.flush()
        os._exit(0)

asyncio.run(main())
```

This produces no traceback. I also avoid doing anything asyncio in the child.

I'm mainly curious about what file descriptor is bad; it doesn't seem possible.

It sounds like this issue could be fixed by https://github.com/python/cpython/pull/99539, but I still reproduce the issue in 3.12.7 and 3.13.0, though with a slightly different exception:
```
Traceback (most recent call last):
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 674, in run_until_complete
    self.run_forever()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever
    self._run_once()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 1948, in _run_once
    event_list = self._selector.select(timeout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 566, in select
    kev_list = self._selector.control(None, max_ev, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: I/O operation on closed kqueue object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 71, in close
    loop.run_until_complete(loop.shutdown_asyncgens())
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 674, in run_until_complete
    self.run_forever()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever
    self._run_once()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 1948, in _run_once
    event_list = self._selector.select(timeout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 566, in select
    kev_list = self._selector.control(None, max_ev, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: I/O operation on closed kqueue object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""~/forkasyncio.py"", line 10, in <module>
    asyncio.run(main())
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 193, in run
    with Runner(debug=debug, loop_factory=loop_factory) as runner:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 62, in __exit__
    self.close()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 77, in close
    loop.close()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/unix_events.py"", line 68, in close
    super().close()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 104, in close
    self._close_self_pipe()
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 111, in _close_self_pipe
    self._remove_reader(self._ssock.fileno())
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 305, in _remove_reader
    self._selector.unregister(fd)
  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 542, in unregister
    self._selector.control([kev], 0, 0)
ValueError: I/O operation on closed kqueue object
/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py:712: RuntimeWarning: coroutine 'BaseEventLoop.shutdown_asyncgens' was never awaited
```



### CPython versions tested on:

3.11

### Operating systems tested on:

macOS","['import asyncio\nimport os\n\nasync def main():\n    pid = os.fork()\n    if pid:\n        os.waitpid(pid, 0)\n\nasyncio.run(main())', 'Traceback (most recent call last):\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 641, in run_until_complete\n    self.run_forever()\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 608, in run_forever\n    self._run_once()\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 1898, in _run_once\n    event_list = self._selector.select(timeout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py"", line 566, in select\n    kev_list = self._selector.control(None, max_ev, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""~/forkasyncio.py"", line 9, in <module>\n    asyncio.run(main())\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 189, in run\n    with Runner(debug=debug) as runner:\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 63, in __exit__\n    self.close()\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py"", line 72, in close\n    loop.run_until_complete(loop.shutdown_asyncgens())\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 641, in run_until_complete\n    self.run_forever()\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 608, in run_forever\n    self._run_once()\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py"", line 1898, in _run_once\n    event_list = self._selector.select(timeout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py"", line 566, in select\n    kev_list = self._selector.control(None, max_ev, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 9] Bad file descriptor\nsys:1: RuntimeWarning: coroutine \'BaseEventLoop.shutdown_asyncgens\' was never awaited', 'import asyncio\nimport os\nimport sys\n\nasync def main():\n    pid = os.fork()\n    if pid:\n        os.waitpid(pid, 0)\n    else:\n        sys.stdout.flush()\n        sys.stderr.flush()\n        os._exit(0)\n\nasyncio.run(main())', 'Traceback (most recent call last):\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 194, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 674, in run_until_complete\n    self.run_forever()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever\n    self._run_once()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 1948, in _run_once\n    event_list = self._selector.select(timeout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 566, in select\n    kev_list = self._selector.control(None, max_ev, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: I/O operation on closed kqueue object\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 71, in close\n    loop.run_until_complete(loop.shutdown_asyncgens())\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 674, in run_until_complete\n    self.run_forever()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever\n    self._run_once()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py"", line 1948, in _run_once\n    event_list = self._selector.select(timeout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 566, in select\n    kev_list = self._selector.control(None, max_ev, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: I/O operation on closed kqueue object\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""~/forkasyncio.py"", line 10, in <module>\n    asyncio.run(main())\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 193, in run\n    with Runner(debug=debug, loop_factory=loop_factory) as runner:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 62, in __exit__\n    self.close()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py"", line 77, in close\n    loop.close()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/unix_events.py"", line 68, in close\n    super().close()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 104, in close\n    self._close_self_pipe()\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 111, in _close_self_pipe\n    self._remove_reader(self._ssock.fileno())\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/selector_events.py"", line 305, in _remove_reader\n    self._selector.unregister(fd)\n  File ""/Users/will/.pyenv/versions/3.12.7/lib/python3.12/selectors.py"", line 542, in unregister\n    self._selector.control([kev], 0, 0)\nValueError: I/O operation on closed kqueue object\n/Users/will/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py:712: RuntimeWarning: coroutine \'BaseEventLoop.shutdown_asyncgens\' was never awaited']","For various reasons, it's a **very bad idea** to fork while an event loop is running and then continue running the loop in both parent and child process, so in the child process the event loop is intentionally sabotaged (I forget by which mechanism). However, it would be nice to get a better error for this. You can't just warn about forking when an event loop is running: if you don't use the event loop in the child, you can do something else, notably `exec` another binary. (If the child exits normally, the end-of-process GC might wake up daemons.)

So I give this a low importance and low priority, but in principle it *is* a bug and worthy of being fixed -- after most other bugs have been fixed, though. :-)",[],['python'],github,https://github.com/python/cpython/issues/130442,{'repo': 'python/cpython'}
"traceback.print_last behaving differently across python versions

# Bug report

### Bug description:

`traceback.print_last()` correctly prints the latest traceback for python 3.10.16 and 3.11.9, but it prints `NoneType: None` for 3.12.9 and 3.13.2

See also https://github.com/ipython/ipython/issues/14744, I originally thought it was an ipython issue

```
Python 3.10.16 (main, Feb 13 2025, 14:32:36) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 1/0
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ZeroDivisionError: division by zero
>>> import traceback
>>> traceback.print_last()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ZeroDivisionError: division by zero
```

```
Python 3.11.9 (main, Feb 13 2025, 14:34:41) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 1/0
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ZeroDivisionError: division by zero
>>> import traceback
>>> traceback.print_last()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ZeroDivisionError: division by zero
```

```
Python 3.12.9 (main, Feb 13 2025, 13:23:03) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 1/0
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ZeroDivisionError: division by zero
>>> import traceback
>>> traceback.print_last()
NoneType: None
```

```
Python 3.13.2 (main, Feb 13 2025, 11:10:27) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 1/0
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    1/0
    ~^~
ZeroDivisionError: division by zero
>>> import traceback
>>> traceback.print_last()
NoneType: None
```


### CPython versions tested on:

3.10, 3.11, 3.12, 3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130318
* gh-130325
* gh-130326
* gh-130329
* gh-130330
* gh-130331
* gh-130342
* gh-130344
* gh-130345
<!-- /gh-linked-prs -->
","['Python 3.10.16 (main, Feb 13 2025, 14:32:36) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> 1/0\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nZeroDivisionError: division by zero\n>>> import traceback\n>>> traceback.print_last()\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nZeroDivisionError: division by zero', 'Python 3.11.9 (main, Feb 13 2025, 14:34:41) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> 1/0\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nZeroDivisionError: division by zero\n>>> import traceback\n>>> traceback.print_last()\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nZeroDivisionError: division by zero', 'Python 3.12.9 (main, Feb 13 2025, 13:23:03) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> 1/0\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nZeroDivisionError: division by zero\n>>> import traceback\n>>> traceback.print_last()\nNoneType: None', 'Python 3.13.2 (main, Feb 13 2025, 11:10:27) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> 1/0\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    1/0\n    ~^~\nZeroDivisionError: division by zero\n>>> import traceback\n>>> traceback.print_last()\nNoneType: None']","If you remove `sys.last_exc`, you will get the old behavior.
```pycon
>>> import sys
>>> sys.last_exc
ZeroDivisionError('division by zero')
>>> del sys.last_exc
>>> traceback.print_last()
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    1/0
    ~^~
ZeroDivisionError: division by zero
```

The regression was most likely introduced in #102778. cc @iritkatriel ","['>>> import sys\n>>> sys.last_exc\nZeroDivisionError(\'division by zero\')\n>>> del sys.last_exc\n>>> traceback.print_last()\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    1/0\n    ~^~\nZeroDivisionError: division by zero']",['python'],github,https://github.com/python/cpython/issues/130250,{'repo': 'python/cpython'}
"macOS combined architecture platform tags are undocumented, and inconsistent

# Bug report

### Bug description:

While formalising the definition of platform tags for iOS and Android in packaging.python.org/pull/1804, I notice that macOS combined architecture tags (e.g., `universal2`) aren't documented.

The canonical definition is here: https://github.com/python/cpython/blob/cdcacec79f7a216c3c988baa4dc31ce4e76c97ac/Lib/_osx_support.py#L546-L562 

However, these tags aren't documented as part of the [mac usage guide](https://docs.python.org/3/using/mac.html), beyond a passing reference to the default installers being ""universal2"". 

The [documentation of the `configure` options that enable these builds](https://docs.python.org/3/using/configure.html#cmdoption-with-universal-archs) add an extra layer of complexity, as they describe options that exist, but (a) the names don't match the values returned by `sysconfig.get_platform()`, and (b) any mapping between the two isn't documented. What architectures are built for a ""3-way"" build? What's the corresponding wheel platform tag? (i386, ppc and x86_64; and fat3, respectively)

These options are almost entirely anachronistic as Python isn't maintaining support for i386, ppc or ppc64. The ""fix"" here might be to remove support for all tags other than `universal2`.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130389
* gh-130449
* gh-130450
<!-- /gh-linked-prs -->
",[],"These have grown organically, and it shows.  We've been very conservative with removing support for old systems (one might say, too conservative) because some users actually do run python on ancient macOS systems.

That said, my personal opinion is that the only 3 tags that are useful on macOS are arm64, x86_64 and universal2.  Any system that needs one of the others is basically for a museum.

BTW The universal2 tag intentionally mirrors Apple's ""Universal 2"" description for fat binaries that support arm64 and x86_64. 

@ned-deily might disagree though.",[],['python'],github,https://github.com/python/cpython/issues/129712,{'repo': 'python/cpython'}
"Move reftracer call from `_Py_Dealloc` to non-inlined function call

Even with PGO and LTO, the reftracer call in `_Py_Dealloc` causes a bunch of extra register spills on x86-64, especially in the free threading build:

https://github.com/python/cpython/blob/b5454509612870dd0e09aaba4b79865a5faad284/Objects/object.c#L3003-L3004

The free threading build calls `_Py_MergeZeroLocalRefcount()`, which in turn inlines the call to `_Py_Dealloc`:

```asm
Dump of assembler code for function _Py_MergeZeroLocalRefcount:
   0x00000000001a8e50 <+0>:     push   r14
   0x00000000001a8e52 <+2>:     push   rbx
   0x00000000001a8e53 <+3>:     push   rax
   0x00000000001a8e54 <+4>:     mov    rcx,QWORD PTR [rdi+0x10]
   0x00000000001a8e58 <+8>:     test   rcx,rcx
   0x00000000001a8e5b <+11>:    jne    0x1a8e7a <_Py_MergeZeroLocalRefcount+42>
   0x00000000001a8e5d <+13>:    mov    rax,QWORD PTR [rdi+0x18]
   0x00000000001a8e61 <+17>:    mov    rcx,QWORD PTR [rax+0x40]
   0x00000000001a8e65 <+21>:    mov    rax,QWORD PTR [rip+0x476324]        # 0x61f190 <_PyRuntime+10384>
   0x00000000001a8e6c <+28>:    test   rax,rax
   0x00000000001a8e6f <+31>:    jne    0x1a8ead <_Py_MergeZeroLocalRefcount+93>
   0x00000000001a8e71 <+33>:    add    rsp,0x8
   0x00000000001a8e75 <+37>:    pop    rbx
   0x00000000001a8e76 <+38>:    pop    r14
   0x00000000001a8e78 <+40>:    jmp    rcx  # the fast path ends here with the jump to tp_dealloc
   0x00000000001a8e7a <+42>:    mov    QWORD PTR [rdi],0x0
   0x00000000001a8e81 <+49>:    mov    rdx,rcx
   0x00000000001a8e84 <+52>:    or     rdx,0x3
   0x00000000001a8e88 <+56>:    mov    rax,rcx
   0x00000000001a8e8b <+59>:    lock cmpxchg QWORD PTR [rdi+0x10],rdx
   0x00000000001a8e91 <+65>:    je     0x1a8e9f <_Py_MergeZeroLocalRefcount+79>
   0x00000000001a8e93 <+67>:    mov    rcx,rax
   0x00000000001a8e96 <+70>:    mov    rdx,rax
   0x00000000001a8e99 <+73>:    or     rdx,0x3
   0x00000000001a8e9d <+77>:    jmp    0x1a8e8b <_Py_MergeZeroLocalRefcount+59>
   0x00000000001a8e9f <+79>:    cmp    rcx,0x3
   0x00000000001a8ea3 <+83>:    jbe    0x1a8e5d <_Py_MergeZeroLocalRefcount+13>
   0x00000000001a8ea5 <+85>:    add    rsp,0x8
   0x00000000001a8ea9 <+89>:    pop    rbx
   0x00000000001a8eaa <+90>:    pop    r14
   0x00000000001a8eac <+92>:    ret
   0x00000000001a8ead <+93>:    mov    rdx,QWORD PTR [rip+0x4762e4]        # 0x61f198 <_PyRuntime+10392>
   0x00000000001a8eb4 <+100>:   mov    rbx,rdi
   0x00000000001a8eb7 <+103>:   mov    esi,0x1
   0x00000000001a8ebc <+108>:   mov    r14,rcx
   0x00000000001a8ebf <+111>:   call   rax
   0x00000000001a8ec1 <+113>:   mov    rcx,r14
   0x00000000001a8ec4 <+116>:   mov    rdi,rbx
   0x00000000001a8ec7 <+119>:   jmp    0x1a8e71 <_Py_MergeZeroLocalRefcount+33>
```

(This is with `./configure -C --with-tail-call-interp --enable-optimizations --disable-gil --with-lto=thin`)

Note the three registers pushed to the stack at entry.

A slight refactoring of `_Py_Dealloc` avoids three `push` and three `pop` instructions, where if reftracer is active, the code jumps the non-inlined function `dealloc_with_reftracer`.

```asm
Dump of assembler code for function _Py_MergeZeroLocalRefcount:
   0x00000000001a7ec0 <+0>:     mov    rcx,QWORD PTR [rdi+0x10]
   0x00000000001a7ec4 <+4>:     test   rcx,rcx
   0x00000000001a7ec7 <+7>:     jne    0x1a7ede <_Py_MergeZeroLocalRefcount+30>
   0x00000000001a7ec9 <+9>:     cmp    QWORD PTR [rip+0x46b2bf],0x0        # 0x613190 <_PyRuntime+10384>
   0x00000000001a7ed1 <+17>:    jne    0xa8ca0 <dealloc_with_reftracer>
   0x00000000001a7ed7 <+23>:    mov    rax,QWORD PTR [rdi+0x18]
   0x00000000001a7edb <+27>:    jmp    QWORD PTR [rax+0x40]  # The fast path ends here with the jump to `tp_dealloc()`
   0x00000000001a7ede <+30>:    mov    QWORD PTR [rdi],0x0
   0x00000000001a7ee5 <+37>:    mov    rdx,rcx
   0x00000000001a7ee8 <+40>:    or     rdx,0x3
   0x00000000001a7eec <+44>:    mov    rax,rcx
   0x00000000001a7eef <+47>:    lock cmpxchg QWORD PTR [rdi+0x10],rdx
   0x00000000001a7ef5 <+53>:    je     0x1a7f03 <_Py_MergeZeroLocalRefcount+67>
   0x00000000001a7ef7 <+55>:    mov    rcx,rax
   0x00000000001a7efa <+58>:    mov    rdx,rax
   0x00000000001a7efd <+61>:    or     rdx,0x3
   0x00000000001a7f01 <+65>:    jmp    0x1a7eef <_Py_MergeZeroLocalRefcount+47>
   0x00000000001a7f03 <+67>:    cmp    rcx,0x3
   0x00000000001a7f07 <+71>:    jbe    0x1a7f0a <_Py_MergeZeroLocalRefcount+74>
   0x00000000001a7f09 <+73>:    ret
   0x00000000001a7f0a <+74>:    cmp    QWORD PTR [rip+0x46b27e],0x0        # 0x613190 <_PyRuntime+10384>
   0x00000000001a7f12 <+82>:    jne    0xa8ca0 <dealloc_with_reftracer>
   0x00000000001a7f18 <+88>:    mov    rax,QWORD PTR [rdi+0x18]
   0x00000000001a7f1c <+92>:    jmp    QWORD PTR [rax+0x40]
```","['Dump of assembler code for function _Py_MergeZeroLocalRefcount:\n   0x00000000001a8e50 <+0>:     push   r14\n   0x00000000001a8e52 <+2>:     push   rbx\n   0x00000000001a8e53 <+3>:     push   rax\n   0x00000000001a8e54 <+4>:     mov    rcx,QWORD PTR [rdi+0x10]\n   0x00000000001a8e58 <+8>:     test   rcx,rcx\n   0x00000000001a8e5b <+11>:    jne    0x1a8e7a <_Py_MergeZeroLocalRefcount+42>\n   0x00000000001a8e5d <+13>:    mov    rax,QWORD PTR [rdi+0x18]\n   0x00000000001a8e61 <+17>:    mov    rcx,QWORD PTR [rax+0x40]\n   0x00000000001a8e65 <+21>:    mov    rax,QWORD PTR [rip+0x476324]        # 0x61f190 <_PyRuntime+10384>\n   0x00000000001a8e6c <+28>:    test   rax,rax\n   0x00000000001a8e6f <+31>:    jne    0x1a8ead <_Py_MergeZeroLocalRefcount+93>\n   0x00000000001a8e71 <+33>:    add    rsp,0x8\n   0x00000000001a8e75 <+37>:    pop    rbx\n   0x00000000001a8e76 <+38>:    pop    r14\n   0x00000000001a8e78 <+40>:    jmp    rcx  # the fast path ends here with the jump to tp_dealloc\n   0x00000000001a8e7a <+42>:    mov    QWORD PTR [rdi],0x0\n   0x00000000001a8e81 <+49>:    mov    rdx,rcx\n   0x00000000001a8e84 <+52>:    or     rdx,0x3\n   0x00000000001a8e88 <+56>:    mov    rax,rcx\n   0x00000000001a8e8b <+59>:    lock cmpxchg QWORD PTR [rdi+0x10],rdx\n   0x00000000001a8e91 <+65>:    je     0x1a8e9f <_Py_MergeZeroLocalRefcount+79>\n   0x00000000001a8e93 <+67>:    mov    rcx,rax\n   0x00000000001a8e96 <+70>:    mov    rdx,rax\n   0x00000000001a8e99 <+73>:    or     rdx,0x3\n   0x00000000001a8e9d <+77>:    jmp    0x1a8e8b <_Py_MergeZeroLocalRefcount+59>\n   0x00000000001a8e9f <+79>:    cmp    rcx,0x3\n   0x00000000001a8ea3 <+83>:    jbe    0x1a8e5d <_Py_MergeZeroLocalRefcount+13>\n   0x00000000001a8ea5 <+85>:    add    rsp,0x8\n   0x00000000001a8ea9 <+89>:    pop    rbx\n   0x00000000001a8eaa <+90>:    pop    r14\n   0x00000000001a8eac <+92>:    ret\n   0x00000000001a8ead <+93>:    mov    rdx,QWORD PTR [rip+0x4762e4]        # 0x61f198 <_PyRuntime+10392>\n   0x00000000001a8eb4 <+100>:   mov    rbx,rdi\n   0x00000000001a8eb7 <+103>:   mov    esi,0x1\n   0x00000000001a8ebc <+108>:   mov    r14,rcx\n   0x00000000001a8ebf <+111>:   call   rax\n   0x00000000001a8ec1 <+113>:   mov    rcx,r14\n   0x00000000001a8ec4 <+116>:   mov    rdi,rbx\n   0x00000000001a8ec7 <+119>:   jmp    0x1a8e71 <_Py_MergeZeroLocalRefcount+33>', 'Dump of assembler code for function _Py_MergeZeroLocalRefcount:\n   0x00000000001a7ec0 <+0>:     mov    rcx,QWORD PTR [rdi+0x10]\n   0x00000000001a7ec4 <+4>:     test   rcx,rcx\n   0x00000000001a7ec7 <+7>:     jne    0x1a7ede <_Py_MergeZeroLocalRefcount+30>\n   0x00000000001a7ec9 <+9>:     cmp    QWORD PTR [rip+0x46b2bf],0x0        # 0x613190 <_PyRuntime+10384>\n   0x00000000001a7ed1 <+17>:    jne    0xa8ca0 <dealloc_with_reftracer>\n   0x00000000001a7ed7 <+23>:    mov    rax,QWORD PTR [rdi+0x18]\n   0x00000000001a7edb <+27>:    jmp    QWORD PTR [rax+0x40]  # The fast path ends here with the jump to `tp_dealloc()`\n   0x00000000001a7ede <+30>:    mov    QWORD PTR [rdi],0x0\n   0x00000000001a7ee5 <+37>:    mov    rdx,rcx\n   0x00000000001a7ee8 <+40>:    or     rdx,0x3\n   0x00000000001a7eec <+44>:    mov    rax,rcx\n   0x00000000001a7eef <+47>:    lock cmpxchg QWORD PTR [rdi+0x10],rdx\n   0x00000000001a7ef5 <+53>:    je     0x1a7f03 <_Py_MergeZeroLocalRefcount+67>\n   0x00000000001a7ef7 <+55>:    mov    rcx,rax\n   0x00000000001a7efa <+58>:    mov    rdx,rax\n   0x00000000001a7efd <+61>:    or     rdx,0x3\n   0x00000000001a7f01 <+65>:    jmp    0x1a7eef <_Py_MergeZeroLocalRefcount+47>\n   0x00000000001a7f03 <+67>:    cmp    rcx,0x3\n   0x00000000001a7f07 <+71>:    jbe    0x1a7f0a <_Py_MergeZeroLocalRefcount+74>\n   0x00000000001a7f09 <+73>:    ret\n   0x00000000001a7f0a <+74>:    cmp    QWORD PTR [rip+0x46b27e],0x0        # 0x613190 <_PyRuntime+10384>\n   0x00000000001a7f12 <+82>:    jne    0xa8ca0 <dealloc_with_reftracer>\n   0x00000000001a7f18 <+88>:    mov    rax,QWORD PTR [rdi+0x18]\n   0x00000000001a7f1c <+92>:    jmp    QWORD PTR [rax+0x40]']",I'll see if I can make a pr fix,[],['python'],github,https://github.com/python/cpython/issues/130706,{'repo': 'python/cpython'}
"Missing references to cli flags for `pickletools`

# Documentation

While looking for more examples for issue #130160 i found that the `pickletools` CLI documentation doesn't cover all the flags. I know many CLI docs don't mention the `-h` flag but this one also doesn't mention the `-t` and `-v` flags

`./python -m pickletools -h` output:
```
usage: python -m pickletools [-h] [-o OUTPUT] [-m] [-l INDENTLEVEL] [-a] [-p PREAMBLE] [-t] [-v] [pickle_file ...]

disassemble one or more pickle files

positional arguments:
  pickle_file           the pickle file

options:
  -h, --help            show this help message and exit
  -o, --output OUTPUT   the file where the output should be written
  -m, --memo            preserve memo between disassemblies
  -l, --indentlevel INDENTLEVEL
                        the number of blanks by which to indent a new MARK level
  -a, --annotate        annotate each line with a short opcode description
  -p, --preamble PREAMBLE
                        if more than one pickle file is specified, print this before each disassembly
  -t, --test            run self-test suite
  -v                    run verbosely; only affects self-test run
```

**Link to current documentation:** https://docs.python.org/dev/library/pickletools.html

![Image](https://github.com/user-attachments/assets/4bfd0bd7-1737-4949-93c3-06e8710a63cf)

<!-- gh-linked-prs -->
### Linked PRs
* gh-130974
<!-- /gh-linked-prs -->
","['usage: python -m pickletools [-h] [-o OUTPUT] [-m] [-l INDENTLEVEL] [-a] [-p PREAMBLE] [-t] [-v] [pickle_file ...]\n\ndisassemble one or more pickle files\n\npositional arguments:\n  pickle_file           the pickle file\n\noptions:\n  -h, --help            show this help message and exit\n  -o, --output OUTPUT   the file where the output should be written\n  -m, --memo            preserve memo between disassemblies\n  -l, --indentlevel INDENTLEVEL\n                        the number of blanks by which to indent a new MARK level\n  -a, --annotate        annotate each line with a short opcode description\n  -p, --preamble PREAMBLE\n                        if more than one pickle file is specified, print this before each disassembly\n  -t, --test            run self-test suite\n  -v                    run verbosely; only affects self-test run']",The t flag is probably something internal that we don't want to expose and the v flag then becomes also internal as it only affects self-tests.,[],['python'],github,https://github.com/python/cpython/issues/130973,{'repo': 'python/cpython'}
"3.13: `test_perf_profiler` fails on aarch64 Fedora Stable Refleaks buildbot

# Bug report

Since about 4 days ago, `test_perf_profiler.test_python_calls_appear_in_the_stack_if_perf_activated` *usually* fails on refleaks buildbots with one of these (see [build 416](https://buildbot.python.org/#/builders/1512/builds/416) for both):

- `AssertionError: 'py::foo:/tmp/test_python_2wtkitdm/tmpv30razor/perftest.py' not found in` &lt;very long string containing frames with a different temp dir instead: `/tmp/test_python_ecqze28x/tmpz61vpvo4/perftest.py+0xb` here>
- unexpected stderr:
  ```
  Warning:
  Processed 688 events and lost 3 chunks!

  Check IO/CPU overload!
  ``` 
",['Warning:\n  Processed 688 events and lost 3 chunks!\n\n  Check IO/CPU overload!'],cc @pablogsal @stratakis ,[],['python'],github,https://github.com/python/cpython/issues/131038,{'repo': 'python/cpython'}
"Parametrize tests for `pathlib.Path.copy()`

We should be able to parametrize tests for pathlib's `ReadablePath.copy()`, e.g.:

- Copy from `Path` to `Path`
- Copy from `Path` to `WritableZipPath`
- Copy from `ReadableZipPath` to `Path`
- Copy from `ReadableZipPath` to `WritableZipPath`

Unfortunately this breaks some deep assumptions in the existing test classes, so I think we should create new suites somewhere in `test.test_pathlib`.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130648
* gh-130990
* gh-130991
* gh-130988
* gh-131016
* gh-131017
* gh-131018
* gh-131112
* gh-131168
<!-- /gh-linked-prs -->
",[],"I've already made a start on this, but I'll stop making changes and put a PR up so that others can contribute.",[],['python'],github,https://github.com/python/cpython/issues/130614,{'repo': 'python/cpython'}
"pygettext: Extend support for specifying custom keywords

# Feature or enhancement

### Proposal:

pygettext already allows specifying custom keywords in a limited fashion. For example, specifying `--keyword=foo` will
look for functions named `foo` in addition to the default keywords (`gettext`, etc..).

However, the CLI currently only allows specifying single-argument functions (i.e. `gettext('foo')`). It is not possible to add
keywords that take `msgid_plural` or `msgctxt` or both.

Both xgettext and babel support this with a [simple keywordspec syntax](https://www.gnu.org/software/gettext/manual/html_node/xgettext-Invocation.html) that defines the function name and argument positions of `msgid`, `msgid_plural` and `msgctxt`.

For example, `--keyword:foo:1c,2` defines a `pgettext`-like function where the `msgctxt` is the first argument and `msgid` is the second argument, e.g. `foo('context', 'message')`.

It is also possible to use `t` to only match functions with that exact number of arguments. For example, `foo:1,1t` only matches `foo('bar')` but not `foo('bar', 'baz')`.

I propose to support this in pygettext as well. For that we will need to:

- Support the keyword spec syntax when specifying keywords. I suggest skipping the `t` specifier  for now.
- Support specifying multiple `--keyword` arguments with the same function name (this will require some internal changes, as those are stored in a dictionary with the function name as the key).
- Support the `t` specifier.




### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130463
* gh-130709
<!-- /gh-linked-prs -->
",[],"The first PR (with the most changes) was merged, but there is more work needed. I'll reuse this issue for the followup PRs :)",[],['python'],github,https://github.com/python/cpython/issues/130453,{'repo': 'python/cpython'}
"3.10: GHA Docs builds of PRs fail because they use removed actions/upload-artifact: v3

3.10 & 3.9 PRs fail on documentation builds with:

>  Error: This request has been automatically failed because it uses a deprecated version of `actions/upload-artifact: v3`. Learn more: https://github.blog/changelog/2024-04-16-deprecation-notice-v3-of-the-artifact-actions/

For example: https://github.com/python/cpython/actions/runs/13077929192/job/36494533879?pr=129529

<!-- gh-linked-prs -->
### Linked PRs
* gh-129642
* gh-130114
<!-- /gh-linked-prs -->
",[],Thanks! I already had the 3.9 PR half-done when I saw your message.,[],['python'],github,https://github.com/python/cpython/issues/129641,{'repo': 'python/cpython'}
"AttributeError on `with super()`

# Bug report

### Bug description:

Writing `with super()` raises an AttributeError.  I ran into this implementing context managers inspired by `contextlib.contextmnager` but which had extra functionality. I can see no reason why `with super()` should be disallowed, and in fact, `super().__enter__()` and `super().__exit__()` work just fine.

Attempting to use an `ExitStack` as a work around was unsuccessful.

```python
import sys
from contextlib import ExitStack

class Base:
    def __enter__(self):
        print(""Entering base context manager"")

    def __exit__(self, type, value, traceback):
        print(""Exiting base context manager"")

def __derived_enter__(self):
    self.context = self.contextlib_style_context()
    next(self.context)
    return self.context

def __derived_exit__(self, type, value, traceback):
    try:
        next(self.context)
    except StopIteration:
        pass

class DerivedUsingEnterExit(Base):
    def contextlib_style_context(self):
        print(""Entering contextlib style context manager"")
        super().__enter__()
        try:
            yield
        finally:
            super().__exit__(*sys.exc_info())

        print(""Exiting contextlib style context manager"")

    __enter__ = __derived_enter__
    __exit__ = __derived_exit__

class DerivedUsingWith(Base):
    def contextlib_style_context(self):
        print(""Entering contextlib style context manager"")
        with super():
            yield

        print(""Exiting contextlib style context manager"")

    __enter__ = __derived_enter__
    __exit__ = __derived_exit__

class DerivedUsingExitStack(Base):
    def contextlib_style_context(self):
        print(""Entering contextlib style context manager"")

        with ExitStack() as stack:
            stack.enter_context(super())
            yield

        print(""Exiting contextlib style context manager"")

    __enter__ = __derived_enter__
    __exit__ = __derived_exit__

# Runs successfully
with DerivedUsingEnterExit() as d:
    pass

# Raises AttributeError
with DerivedUsingWith() as d:
    pass

# Raises AttributeError
with DerivedUsingExitStack() as d:
    pass
```


### CPython versions tested on:

3.13, 3.12

### Operating systems tested on:

Windows","['import sys\nfrom contextlib import ExitStack\n\nclass Base:\n    def __enter__(self):\n        print(""Entering base context manager"")\n\n    def __exit__(self, type, value, traceback):\n        print(""Exiting base context manager"")\n\ndef __derived_enter__(self):\n    self.context = self.contextlib_style_context()\n    next(self.context)\n    return self.context\n\ndef __derived_exit__(self, type, value, traceback):\n    try:\n        next(self.context)\n    except StopIteration:\n        pass\n\nclass DerivedUsingEnterExit(Base):\n    def contextlib_style_context(self):\n        print(""Entering contextlib style context manager"")\n        super().__enter__()\n        try:\n            yield\n        finally:\n            super().__exit__(*sys.exc_info())\n\n        print(""Exiting contextlib style context manager"")\n\n    __enter__ = __derived_enter__\n    __exit__ = __derived_exit__\n\nclass DerivedUsingWith(Base):\n    def contextlib_style_context(self):\n        print(""Entering contextlib style context manager"")\n        with super():\n            yield\n\n        print(""Exiting contextlib style context manager"")\n\n    __enter__ = __derived_enter__\n    __exit__ = __derived_exit__\n\nclass DerivedUsingExitStack(Base):\n    def contextlib_style_context(self):\n        print(""Entering contextlib style context manager"")\n\n        with ExitStack() as stack:\n            stack.enter_context(super())\n            yield\n\n        print(""Exiting contextlib style context manager"")\n\n    __enter__ = __derived_enter__\n    __exit__ = __derived_exit__\n\n# Runs successfully\nwith DerivedUsingEnterExit() as d:\n    pass\n\n# Raises AttributeError\nwith DerivedUsingWith() as d:\n    pass\n\n# Raises AttributeError\nwith DerivedUsingExitStack() as d:\n    pass']","I don't think this is really a typing question, just a language question. If we add the behavior to `super` that it supports the context manager protocol by looking up `__enter__` and `__exit__` from the MRO, type checkers will adapt to that change.

I don't have strong feelings either way about the change. My main hesitance would be that it's not clear where we should stop; should `super` objects also support `__getitem__`? `__eq__` and comparison methods? Many other special methods? It may be better to keep the clear line that `super` just supports attribute access, which is the only thing it needs to support in order to fulfill its core function.

The implementation might also get a little weird, in that I think the `__enter__` and `__exit__` methods of the `super` type would have to copy/emulate the normal runtime error messages that occur when an object doesn't support the context manager protocol, if it can't find `__enter__` and `__exit__` in the MRO.

There could also be strange/surprising behaviors if `super` finds `__enter__` and `__exit__` in different places in the MRO? Though this implies some type is defining one but not the other, which would be unusual.

I think it would be pretty easy to write a small library class that could wrap a `super` object (or, really, any object with `__enter__` and `__exit__` attributes) and implement the context manager protocol. It would do the same thing that this issue proposes `super` do: implement `__enter__` and `__exit__` methods that proxy to those methods on the wrapped object. Then the code above could just be changed to `with ProxyContext(super()):`. It seems to me that's not too onerous for an uncommon need, and may be a better solution than building this directly into `super`.",[],['python'],github,https://github.com/python/cpython/issues/129466,{'repo': 'python/cpython'}
"PidfdChildWatcher removed without deprecation

# Bug report

### Bug description:

hi

We got a bug report that our software isn't working with Python 3.14 prereleases: https://bugzilla.redhat.com/show_bug.cgi?id=2350287

That's caused by this issue removing a publicly documented API which (as per the current official documentation) was not deprecated or slated for removal:

https://github.com/python/cpython/pull/120893

https://docs.python.org/3/library/asyncio-policy.html#asyncio.PidfdChildWatcher

I kinda get the intent that the entire abstract child watcher approach was intended to be deprecated, but that's not how it was advertised in the official docs.  We went out of our way to try to use the new API if available and fall back to the old deprecated API only if the new one wasn't available.  Having both pulled out in the same release has just broken our code.

Please add this back.

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux",[],I am closing this as it is the intended behavior. ,[],['python'],github,https://github.com/python/cpython/issues/130915,{'repo': 'python/cpython'}
"`isinstance(obj, Hashable)` raises `TypeError` when both `obj` and `type(obj)` are unhashable

# Bug report

### Bug description:

Assumption: `isinstance(anything, any_type)` should never raise.

The problem appears to be in `_abc.c` function `_abc__abc_subclasscheck_impl` (known at runtime as `_abc._abc_subclasscheck()`), which [reads](https://github.com/python/cpython/blob/ae4788809d674f8e27faef2678953be8cf67d4a3/Modules/_abc.c#L723) (in part):
```
    /* 1. Check cache. */
    incache = _in_weak_set(impl->_abc_cache, subclass);
```
The implementation assumes `subclass` is hashable. That's almost always true of classes, but not guaranteed.

Reproduction case:
```python
from __future__ import annotations
from collections.abc import Hashable

class UnhashableMeta(type):
    def __eq__(self, other: object) -> bool:
        return super().__eq__(other)

class UnhashableClass(metaclass=UnhashableMeta):
    def __eq__(self, other: object) -> bool:
        return super().__eq__(other)

# any non-hashable instance of a non-hashable class
#         ┌────────┴────────┐
isinstance(UnhashableClass(), Hashable)
```

Traceback for (cpython) Python 3.13.1:
```
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File "".../bug.py"", line 14, in <module>
    isinstance(UnhashableClass(), Hashable)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen abc>"", line 119, in __instancecheck__
  File ""<frozen abc>"", line 123, in __subclasscheck__
TypeError: unhashable type: 'UnhashableMeta'
```

Tracebacks are nearly identical with Python 3.8, 3.9, 3.10, 3.11, and 3.12, as well as Python 3.14.0a4.



### CPython versions tested on:

3.13, 3.12, 3.11, 3.10, 3.9, 3.14

### Operating systems tested on:

macOS","['/* 1. Check cache. */\n    incache = _in_weak_set(impl->_abc_cache, subclass);', 'from __future__ import annotations\nfrom collections.abc import Hashable\n\nclass UnhashableMeta(type):\n    def __eq__(self, other: object) -> bool:\n        return super().__eq__(other)\n\nclass UnhashableClass(metaclass=UnhashableMeta):\n    def __eq__(self, other: object) -> bool:\n        return super().__eq__(other)\n\n# any non-hashable instance of a non-hashable class\n#         ┌────────┴────────┐\nisinstance(UnhashableClass(), Hashable)', 'Traceback (most recent call last):\n  File ""<frozen runpy>"", line 198, in _run_module_as_main\n  File ""<frozen runpy>"", line 88, in _run_code\n  File "".../bug.py"", line 14, in <module>\n    isinstance(UnhashableClass(), Hashable)\n    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""<frozen abc>"", line 119, in __instancecheck__\n  File ""<frozen abc>"", line 123, in __subclasscheck__\nTypeError: unhashable type: \'UnhashableMeta\'']","Hard to investigate the docs and specs on mobile so I'm deferring it to my fellow core developers. I don't know who to tag for this one but I guess @JelleZijlstra, @sobolevn or @AlexWaygood may have insights on this matter.

As for me, I guess we could check that subclass is hashable beforehand and return false if it's not? By the way, is this class with this custom metaclass a ""broken"" class or not? 

In addition, is

> Assumption: isinstance(anything, any_type) should never raise.

an assumption that we should make or that is being documented? for instance, issubclass fails if the first argument is not a type I think (or the second one, or both, I don't remember) so maybe isinstance should also behave like this for ""broken"" classes (again, that's assuming the class and metaclass in this reproducer are broken, if it's not considered as broken, then we might  indeed have a bug). 


",[],['python'],github,https://github.com/python/cpython/issues/129589,{'repo': 'python/cpython'}
"`SyntaxError: parameter without a default follows parameter with a default` is inaccurate

# Bug report

### Bug description:

#### The problem

Trying to define a function in which a positional parameter follows a parameter with a default value, we get a `SyntaxError` as expected:

```pycon
>>> def f(a=1, b):
  File ""<python-input-0>"", line 1
    def f(a=1, b):
               ^
SyntaxError: parameter without a default follows parameter with a default
```

But the message that comes with it is not as accurate as it could be, as we can easily construct a valid function signature in which a parameter without a default follows a parameter with a default so long as both are keyword-only parameters:

```pycon
>>> def f(*, a=1, b):
...     pass
...     
>>> 
```

(I didn't use `a=1, *, b` for this counterexample because then one could argue that, if ""follows"" is interpreted as ""follows _immediately_"", we did resolve the situation described in the error message, making it formally accurate, albeit confusing.)

#### Proposed fix

So, in my opinion, the message should be changed to something more like `positional parameter without a default follows parameter with a default`, reflecting the true nature of the problem.

#### Other benefits

It's not _just_ a matter of accuracy for accuracy's sake, however: This change would also hint to people who don't know or have forgotten about keyword-only parameters that there is another possibility of resolving the issue than the ones implied by the current message.

#### Additional context

- As a result of https://github.com/python/cpython/issues/91210, the error message was changed from `non-default argument follows default argument` to the one above starting in Python 3.12 (via https://github.com/python/cpython/pull/95933). So there is precedent for changing this message to make it more accurate.
- Keyword-only parameters were introduced in Python 3.0 with [PEP 3102](https://peps.python.org/pep-3102/), which makes me think I must be missing some obvious reason why their consequences can't be reflected in the error message.
- `dataclasses` has an exception message with the same issue, but as that one also still has the ""argument"" vs ""parameter"" issue mentioned above, it's probably appropriate to create a separate ticket for that.

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130937
<!-- /gh-linked-prs -->
","['>>> def f(a=1, b):\n  File ""<python-input-0>"", line 1\n    def f(a=1, b):\n               ^\nSyntaxError: parameter without a default follows parameter with a default', '>>> def f(*, a=1, b):\n...     pass\n...     \n>>>']","Finished the code and tested, will make a pr when I have time",[],['python'],github,https://github.com/python/cpython/issues/129545,{'repo': 'python/cpython'}
"Revert to default fullLTO on Clang

# Feature or enhancement

### Proposal:

Python 3.12 changed the default for Clang to ThinLTO. However, many people were unaware of this change and did not update their build scripts. This leaves a lot of perf on the table for macOS and possibly some other platforms.

1. CPython was bitten by this: https://github.com/python/cpython/issues/122580
2. Faster CPython was bitten by this: https://github.com/faster-cpython/bench_runner/issues/342
3. python-build-standalone (Astral) also seems to not have the fix: https://github.com/astral-sh/python-build-standalone/issues/528
4. msys2/mingw also seems to have not noticed: https://github.com/msys2/MINGW-packages/pull/23384

This seems to be confusing and tripping up a lot of people. I propose we change the `--with-lto` default back to full.

cc @brandtbucher @corona10 

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130049
* gh-130088
<!-- /gh-linked-prs -->
",[],"Heh, this was on my backlog of issues to open. I fully support this... to me, `--with-lto` has always meant ""take a long time to compile the fastest executable"".",[],['python'],github,https://github.com/python/cpython/issues/130048,{'repo': 'python/cpython'}
"Should we set default lineno on hand crafted ASTs?



```
>>> compile(ast.Module([ast.Expr(ast.Constant(value=(1,)))]), """", ""exec"")
Traceback (most recent call last):
  File ""<python-input-39>"", line 1, in <module>
    compile(ast.Module([ast.Expr(ast.Constant(value=(1,)))]), """", ""exec"")
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: required field ""lineno"" missing from stmt
```

The error is coming from the conversion of the AST to a C ast. Should we make the lineno default to something like, say, 1?
Or are we happy with this being an invalid AST?
","['>>> compile(ast.Module([ast.Expr(ast.Constant(value=(1,)))]), """", ""exec"")\nTraceback (most recent call last):\n  File ""<python-input-39>"", line 1, in <module>\n    compile(ast.Module([ast.Expr(ast.Constant(value=(1,)))]), """", ""exec"")\n    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: required field ""lineno"" missing from stmt']",CC @pablogsal @isidentical @lysnikolaou .,[],['python'],github,https://github.com/python/cpython/issues/130241,{'repo': 'python/cpython'}
"Crash in Python/assemble.c:301: write_location_info_entry: Assertion `column >= -1' failed.

# Crash report

### What happened?

## Bug Description

This is a bug that only affects DEBUG builds.

The reproducer is as follow:
```python
import ast

tree = ast.Module(body=[
    ast.Import(names=[ast.alias(name='traceback', lineno=0, col_offset=0)], lineno=0, col_offset=-2)
], type_ignores=[])

compile(tree, ""<string>"", ""exec"")
```

This code fails with:
```
python: ../Python/assemble.c:301: write_location_info_entry: Assertion `column >= -1' failed.
fish: Job 1, '/home/yijan/Tools/cpython/debug…' terminated by signal SIGABRT (Abort)
```

## backtrace
```
#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44
#1  __pthread_kill_internal (signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:78
#2  __GI___pthread_kill (threadid=<optimized out>, signo=signo@entry=6) at ./nptl/pthread_kill.c:89
#3  0x00007ffff6c4527e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26
#4  0x00007ffff6c288ff in __GI_abort () at ./stdlib/abort.c:79
#5  0x00007ffff6c2881b in __assert_fail_base (fmt=0x7ffff6dd01e8 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", assertion=assertion@entry=0x555557212940 ""column >= -1"", 
    file=file@entry=0x555557211f60 ""../Python/assemble.c"", line=line@entry=301, function=function@entry=0x555557213040 <__PRETTY_FUNCTION__.11> ""write_location_info_entry"") at ./assert/assert.c:96
#6  0x00007ffff6c3b517 in __assert_fail (assertion=assertion@entry=0x555557212940 ""column >= -1"", file=file@entry=0x555557211f60 ""../Python/assemble.c"", line=line@entry=301, 
    function=function@entry=0x555557213040 <__PRETTY_FUNCTION__.11> ""write_location_info_entry"") at ./assert/assert.c:105
#7  0x0000555556bc1760 in write_location_info_entry (a=a@entry=0x7ffff4727fb0, loc=..., isize=isize@entry=6) at ../Python/assemble.c:301
#8  0x0000555556bc1974 in assemble_emit_location (a=a@entry=0x7ffff4727fb0, loc=..., isize=isize@entry=6) at ../Python/assemble.c:336
#9  0x0000555556bc1d36 in assemble_location_info (a=a@entry=0x7ffff4727fb0, instrs=instrs@entry=0x7ffff48c3840, firstlineno=<optimized out>) at ../Python/assemble.c:355
#10 0x0000555556bc487b in assemble_emit (a=a@entry=0x7ffff4727fb0, instrs=instrs@entry=0x7ffff48c3840, first_lineno=<optimized out>, const_cache=const_cache@entry=0x50800009e040) at ../Python/assemble.c:433
#11 0x0000555556bc4cd9 in _PyAssemble_MakeCodeObject (umd=umd@entry=0x51900008e710, const_cache=const_cache@entry=0x50800009e040, consts=consts@entry=0x5070001d8d80, maxdepth=maxdepth@entry=2, 
    instrs=instrs@entry=0x7ffff48c3840, nlocalsplus=nlocalsplus@entry=0, code_flags=<optimized out>, filename=<optimized out>) at ../Python/assemble.c:752
#12 0x0000555556cf6ba8 in optimize_and_assemble_code_unit (u=u@entry=0x51900008e390, const_cache=const_cache@entry=0x50800009e040, code_flags=code_flags@entry=0, filename=filename@entry=0x50700011db30)
    at ../Python/compile.c:1341
#13 0x0000555556cfe374 in _PyCompile_OptimizeAndAssemble (c=c@entry=0x50b000075480, addNone=addNone@entry=1) at ../Python/compile.c:1369
#14 0x0000555556cfe44c in compiler_mod (c=c@entry=0x50b000075480, mod=mod@entry=0x5250000231e8) at ../Python/compile.c:825
--Type <RET> for more, q to quit, c to continue without paging--
#15 0x0000555556cfe4da in _PyAST_Compile (mod=mod@entry=0x5250000231e8, filename=filename@entry=0x50700011db30, pflags=pflags@entry=0x7ffff4727b40, optimize=optimize@entry=-1, arena=arena@entry=0x5080001299b0)
    at ../Python/compile.c:1382
#16 0x0000555556bf755c in builtin_compile_impl (module=module@entry=0x508000049f40, source=source@entry=0x5070001d8af0, filename=<optimized out>, mode=mode@entry=0x5070000459c8 ""exec"", flags=flags@entry=0, 
    dont_inherit=dont_inherit@entry=0, optimize=<optimized out>, feature_version=<optimized out>) at ../Python/bltinmodule.c:868
#17 0x0000555556bf7e98 in builtin_compile (module=<optimized out>, args=<optimized out>, args@entry=0x529000005280, nargs=nargs@entry=3, kwnames=kwnames@entry=0x0) at ../Python/clinic/bltinmodule.c.h:363
#18 0x000055555692f626 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=0x50800004a540, args=0x529000005280, nargsf=<optimized out>, kwnames=0x0) at ../Objects/methodobject.c:452
#19 0x00005555567fb2e6 in _PyObject_VectorcallTstate (tstate=0x55555867f8f8 <_PyRuntime+329752>, callable=callable@entry=0x50800004a540, args=args@entry=0x529000005280, nargsf=9223372036854775811, 
    kwnames=kwnames@entry=0x0) at ../Include/internal/pycore_call.h:167
#20 0x00005555567fb42f in PyObject_Vectorcall (callable=callable@entry=0x50800004a540, args=args@entry=0x529000005280, nargsf=<optimized out>, kwnames=kwnames@entry=0x0) at ../Objects/call.c:327
#21 0x0000555556c21af5 in _PyEval_EvalFrameDefault (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, frame=frame@entry=0x529000005220, throwflag=throwflag@entry=0) at ../Python/generated_cases.c.h:1023
#22 0x0000555556c9d225 in _PyEval_EvalFrame (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, frame=frame@entry=0x529000005220, throwflag=throwflag@entry=0) at ../Include/internal/pycore_ceval.h:116
#23 0x0000555556c9d743 in _PyEval_Vector (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, func=func@entry=0x51000003d560, locals=locals@entry=0x50800009c340, args=args@entry=0x0, 
    argcount=argcount@entry=0, kwnames=kwnames@entry=0x0) at ../Python/ceval.c:1921
#24 0x0000555556c9da3e in PyEval_EvalCode (co=co@entry=0x514000033450, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340) at ../Python/ceval.c:660
#25 0x0000555556e22f41 in run_eval_code_obj (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, co=co@entry=0x514000033450, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340)
    at ../Python/pythonrun.c:1338
#26 0x0000555556e23378 in run_mod (mod=mod@entry=0x5250000191e0, filename=filename@entry=0x50b000041080, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340, 
    flags=flags@entry=0x7ffff4927e30, arena=arena@entry=0x5080000c27b0, interactive_src=0x0, generate_new_source=0) at ../Python/pythonrun.c:1423
#27 0x0000555556e25e70 in pyrun_file (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, start=start@entry=257, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340, 
    closeit=closeit@entry=1, flags=0x7ffff4927e30) at ../Python/pythonrun.c:1256
#28 0x0000555556e27d8b in _PyRun_SimpleFileObject (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, closeit=closeit@entry=1, flags=flags@entry=0x7ffff4927e30) at ../Python/pythonrun.c:491
#29 0x0000555556e280de in _PyRun_AnyFileObject (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, closeit=closeit@entry=1, flags=flags@entry=0x7ffff4927e30) at ../Python/pythonrun.c:78
#30 0x0000555556eb16f3 in pymain_run_file_obj (program_name=program_name@entry=0x50b000041130, filename=filename@entry=0x50b000041080, skip_source_first_line=<optimized out>) at ../Modules/main.c:410
#31 0x0000555556eb19cd in pymain_run_file (config=config@entry=0x55555864aa88 <_PyRuntime+113064>) at ../Modules/main.c:429
#32 0x0000555556eb4731 in pymain_run_python (exitcode=exitcode@entry=0x7ffff4640760) at ../Modules/main.c:697
#33 0x0000555556eb48f8 in Py_RunMain () at ../Modules/main.c:776
#34 0x0000555556eb4b0d in pymain_main (args=args@entry=0x7ffff470a0a0) at ../Modules/main.c:806
#35 0x0000555556eb4e92 in Py_BytesMain (argc=2, argv=0x7fffffffda78) at ../Modules/main.c:830
#36 0x0000555556590ba6 in main (argc=<optimized out>, argv=<optimized out>) at ../Programs/python.c:15
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.14.0a4+ (heads/main-dirty:75f59bb6293, Jan 23 2025, 22:33:08) [GCC 13.3.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-130795
<!-- /gh-linked-prs -->
","['import ast\n\ntree = ast.Module(body=[\n    ast.Import(names=[ast.alias(name=\'traceback\', lineno=0, col_offset=0)], lineno=0, col_offset=-2)\n], type_ignores=[])\n\ncompile(tree, ""<string>"", ""exec"")', ""python: ../Python/assemble.c:301: write_location_info_entry: Assertion `column >= -1' failed.\nfish: Job 1, '/home/yijan/Tools/cpython/debug…' terminated by signal SIGABRT (Abort)"", '#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44\n#1  __pthread_kill_internal (signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:78\n#2  __GI___pthread_kill (threadid=<optimized out>, signo=signo@entry=6) at ./nptl/pthread_kill.c:89\n#3  0x00007ffff6c4527e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\n#4  0x00007ffff6c288ff in __GI_abort () at ./stdlib/abort.c:79\n#5  0x00007ffff6c2881b in __assert_fail_base (fmt=0x7ffff6dd01e8 ""%s%s%s:%u: %s%sAssertion `%s\' failed.\\n%n"", assertion=assertion@entry=0x555557212940 ""column >= -1"", \n    file=file@entry=0x555557211f60 ""../Python/assemble.c"", line=line@entry=301, function=function@entry=0x555557213040 <__PRETTY_FUNCTION__.11> ""write_location_info_entry"") at ./assert/assert.c:96\n#6  0x00007ffff6c3b517 in __assert_fail (assertion=assertion@entry=0x555557212940 ""column >= -1"", file=file@entry=0x555557211f60 ""../Python/assemble.c"", line=line@entry=301, \n    function=function@entry=0x555557213040 <__PRETTY_FUNCTION__.11> ""write_location_info_entry"") at ./assert/assert.c:105\n#7  0x0000555556bc1760 in write_location_info_entry (a=a@entry=0x7ffff4727fb0, loc=..., isize=isize@entry=6) at ../Python/assemble.c:301\n#8  0x0000555556bc1974 in assemble_emit_location (a=a@entry=0x7ffff4727fb0, loc=..., isize=isize@entry=6) at ../Python/assemble.c:336\n#9  0x0000555556bc1d36 in assemble_location_info (a=a@entry=0x7ffff4727fb0, instrs=instrs@entry=0x7ffff48c3840, firstlineno=<optimized out>) at ../Python/assemble.c:355\n#10 0x0000555556bc487b in assemble_emit (a=a@entry=0x7ffff4727fb0, instrs=instrs@entry=0x7ffff48c3840, first_lineno=<optimized out>, const_cache=const_cache@entry=0x50800009e040) at ../Python/assemble.c:433\n#11 0x0000555556bc4cd9 in _PyAssemble_MakeCodeObject (umd=umd@entry=0x51900008e710, const_cache=const_cache@entry=0x50800009e040, consts=consts@entry=0x5070001d8d80, maxdepth=maxdepth@entry=2, \n    instrs=instrs@entry=0x7ffff48c3840, nlocalsplus=nlocalsplus@entry=0, code_flags=<optimized out>, filename=<optimized out>) at ../Python/assemble.c:752\n#12 0x0000555556cf6ba8 in optimize_and_assemble_code_unit (u=u@entry=0x51900008e390, const_cache=const_cache@entry=0x50800009e040, code_flags=code_flags@entry=0, filename=filename@entry=0x50700011db30)\n    at ../Python/compile.c:1341\n#13 0x0000555556cfe374 in _PyCompile_OptimizeAndAssemble (c=c@entry=0x50b000075480, addNone=addNone@entry=1) at ../Python/compile.c:1369\n#14 0x0000555556cfe44c in compiler_mod (c=c@entry=0x50b000075480, mod=mod@entry=0x5250000231e8) at ../Python/compile.c:825\n--Type <RET> for more, q to quit, c to continue without paging--\n#15 0x0000555556cfe4da in _PyAST_Compile (mod=mod@entry=0x5250000231e8, filename=filename@entry=0x50700011db30, pflags=pflags@entry=0x7ffff4727b40, optimize=optimize@entry=-1, arena=arena@entry=0x5080001299b0)\n    at ../Python/compile.c:1382\n#16 0x0000555556bf755c in builtin_compile_impl (module=module@entry=0x508000049f40, source=source@entry=0x5070001d8af0, filename=<optimized out>, mode=mode@entry=0x5070000459c8 ""exec"", flags=flags@entry=0, \n    dont_inherit=dont_inherit@entry=0, optimize=<optimized out>, feature_version=<optimized out>) at ../Python/bltinmodule.c:868\n#17 0x0000555556bf7e98 in builtin_compile (module=<optimized out>, args=<optimized out>, args@entry=0x529000005280, nargs=nargs@entry=3, kwnames=kwnames@entry=0x0) at ../Python/clinic/bltinmodule.c.h:363\n#18 0x000055555692f626 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=0x50800004a540, args=0x529000005280, nargsf=<optimized out>, kwnames=0x0) at ../Objects/methodobject.c:452\n#19 0x00005555567fb2e6 in _PyObject_VectorcallTstate (tstate=0x55555867f8f8 <_PyRuntime+329752>, callable=callable@entry=0x50800004a540, args=args@entry=0x529000005280, nargsf=9223372036854775811, \n    kwnames=kwnames@entry=0x0) at ../Include/internal/pycore_call.h:167\n#20 0x00005555567fb42f in PyObject_Vectorcall (callable=callable@entry=0x50800004a540, args=args@entry=0x529000005280, nargsf=<optimized out>, kwnames=kwnames@entry=0x0) at ../Objects/call.c:327\n#21 0x0000555556c21af5 in _PyEval_EvalFrameDefault (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, frame=frame@entry=0x529000005220, throwflag=throwflag@entry=0) at ../Python/generated_cases.c.h:1023\n#22 0x0000555556c9d225 in _PyEval_EvalFrame (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, frame=frame@entry=0x529000005220, throwflag=throwflag@entry=0) at ../Include/internal/pycore_ceval.h:116\n#23 0x0000555556c9d743 in _PyEval_Vector (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, func=func@entry=0x51000003d560, locals=locals@entry=0x50800009c340, args=args@entry=0x0, \n    argcount=argcount@entry=0, kwnames=kwnames@entry=0x0) at ../Python/ceval.c:1921\n#24 0x0000555556c9da3e in PyEval_EvalCode (co=co@entry=0x514000033450, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340) at ../Python/ceval.c:660\n#25 0x0000555556e22f41 in run_eval_code_obj (tstate=tstate@entry=0x55555867f8f8 <_PyRuntime+329752>, co=co@entry=0x514000033450, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340)\n    at ../Python/pythonrun.c:1338\n#26 0x0000555556e23378 in run_mod (mod=mod@entry=0x5250000191e0, filename=filename@entry=0x50b000041080, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340, \n    flags=flags@entry=0x7ffff4927e30, arena=arena@entry=0x5080000c27b0, interactive_src=0x0, generate_new_source=0) at ../Python/pythonrun.c:1423\n#27 0x0000555556e25e70 in pyrun_file (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, start=start@entry=257, globals=globals@entry=0x50800009c340, locals=locals@entry=0x50800009c340, \n    closeit=closeit@entry=1, flags=0x7ffff4927e30) at ../Python/pythonrun.c:1256\n#28 0x0000555556e27d8b in _PyRun_SimpleFileObject (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, closeit=closeit@entry=1, flags=flags@entry=0x7ffff4927e30) at ../Python/pythonrun.c:491\n#29 0x0000555556e280de in _PyRun_AnyFileObject (fp=fp@entry=0x51500000fa80, filename=filename@entry=0x50b000041080, closeit=closeit@entry=1, flags=flags@entry=0x7ffff4927e30) at ../Python/pythonrun.c:78\n#30 0x0000555556eb16f3 in pymain_run_file_obj (program_name=program_name@entry=0x50b000041130, filename=filename@entry=0x50b000041080, skip_source_first_line=<optimized out>) at ../Modules/main.c:410\n#31 0x0000555556eb19cd in pymain_run_file (config=config@entry=0x55555864aa88 <_PyRuntime+113064>) at ../Modules/main.c:429\n#32 0x0000555556eb4731 in pymain_run_python (exitcode=exitcode@entry=0x7ffff4640760) at ../Modules/main.c:697\n#33 0x0000555556eb48f8 in Py_RunMain () at ../Modules/main.c:776\n#34 0x0000555556eb4b0d in pymain_main (args=args@entry=0x7ffff470a0a0) at ../Modules/main.c:806\n#35 0x0000555556eb4e92 in Py_BytesMain (argc=2, argv=0x7fffffffda78) at ../Modules/main.c:830\n#36 0x0000555556590ba6 in main (argc=<optimized out>, argv=<optimized out>) at ../Programs/python.c:15']","I'm tempted to raise when constructing artificial AST nodes, but I'm not sure I'm not sure whether it could break code. Maybe people are using fake AST nodes with bad location values just for their own needs, like for a sentinel value. OTOH, checking the consistency of all AST nodes in `compile` may seem an overkill. I don't have enough insight on that part of the codebase to know how to avoid that assertion.

@JelleZijlstra any recommendation here?",[],['python'],github,https://github.com/python/cpython/issues/130775,{'repo': 'python/cpython'}
"Crash when accessing the `asyncio` module state in task deallocation

# Crash report

### What happened?

Cross posting from https://github.com/agronholm/anyio/issues/870.

I noticed that with Python 3.14.0a5 (it doesn't happen in a4) anyio's tests for asyncio run successfully and only in the end the info about the core dumped is displayed.
You can see it by running the minimal reproducer (cut out from one of the tests) or in the interactive asyncio repl.
I suspect this is a regression in Python rather than an issue in anyio, but I couldn't figure out a reproducer without anyio code.

### How can we reproduce the bug?

- With Python 3.14.0a5 installed (in the snippet I use debug build of Python, but it will produce similar information when using the ordinary one)
run `python -m asyncio`
```pycon
>>> import asyncio
>>> from anyio import to_interpreter
>>> from functools import partial
>>> assert await to_interpreter.run_sync(partial(sorted, reverse=True), [""a"", ""b""]) == [""b"", ""a""]
>>> exit
```
result:
```
exiting asyncio REPL...
python3-debug: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/typeobject.c:5262: PyType_GetModuleByDef: Assertion `mro != NULL' failed.
```

The underlying function `to_thread.run_sync()` seems to trigger the issue.
Running this as `repr.py` produces the same outcome. I ran it in gdb with Python debuginfo data, I attach the result.

```python
import asyncio, io, anyio
 
async def repr():
    stream = io.BytesIO(b""data"")
    assert await anyio.to_thread.run_sync(stream.read) == b""data""

asyncio.run(repr())
```

<details><summary>gdb stack trace</summary>

```
Starting program: /usr/bin/python3-debug repr.py

This GDB supports auto-downloading debuginfo from the following URLs:
  <https://debuginfod.fedoraproject.org/>
Enable debuginfod for this session? (y or [n]) y
Debuginfod has been enabled.
To make this setting permanent, add 'set debuginfod enabled on' to .gdbinit.
Downloading separate debug info for system-supplied DSO at 0x7ffff7fc5000
[Thread debugging using libthread_db enabled]                                                                          
Using host libthread_db library ""/lib64/libthread_db.so.1"".
[New Thread 0x7ffff61ff6c0 (LWP 47)]
[Thread 0x7ffff61ff6c0 (LWP 47) exited]
python3-debug: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/typeobject.c:5262: PyType_GetModuleByDef: Assertion `mro != NULL' failed.

Thread 1 ""python3-debug"" received signal SIGABRT, Aborted.
Downloading source file /usr/src/debug/glibc-2.40.9000-37.fc43.x86_64/nptl/pthread_kill.c
__pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0)                   
    at pthread_kill.c:44
44            return INTERNAL_SYSCALL_ERROR_P (ret) ? INTERNAL_SYSCALL_ERRNO (ret) : 0;
(gdb) bt
#0  __pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0)
    at pthread_kill.c:44
#1  0x00007ffff7480343 in __pthread_kill_internal (threadid=<optimized out>, signo=6) at pthread_kill.c:89
#2  0x00007ffff7426cbe in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26
#3  0x00007ffff740e6d6 in __GI_abort () at abort.c:73
#4  0x00007ffff740e639 in __assert_fail_base (fmt=<optimized out>, assertion=<optimized out>, file=<optimized out>, 
    line=5262, function=<optimized out>) at assert.c:118
#5  0x00007ffff77a883a in PyType_GetModuleByDef (type=0x555555852ca0, def=0x7ffff6911000 <_asynciomodule>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/typeobject.c:5262
#6  0x00007ffff68fb050 in get_asyncio_state_by_def (self=<_asyncio.Task() at remote 0x7ffff624ce60>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/_asynciomodule.c:204
#7  0x00007ffff6903144 in TaskObj_dealloc (self=<_asyncio.Task() at remote 0x7ffff624ce60>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/_asynciomodule.c:3068
#8  0x00007ffff7760214 in _Py_Dealloc (op=<_asyncio.Task() at remote 0x7ffff624ce60>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009
#9  0x00007ffff7735568 in Py_DECREF (
    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", 
    lineno=502, op=<_asyncio.Task() at remote 0x7ffff624ce60>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393
#10 0x00007ffff77355bd in Py_XDECREF (op=<_asyncio.Task() at remote 0x7ffff624ce60>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502
#11 0x00007ffff77373b9 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x7ffff62353f0, 
    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:460
#12 0x00007ffff773db30 in dict_dealloc (
    self={'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:3266
#13 0x00007ffff7760214 in _Py_Dealloc (
    op={'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009
#14 0x00007ffff7735568 in Py_DECREF (
    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", 
    lineno=502, 
    op={'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393
#15 0x00007ffff77355bd in Py_XDECREF (
    op={'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502
#16 0x00007ffff7737441 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x7ffff626e2c0, 
    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:468
#17 0x00007ffff773db30 in dict_dealloc (
    self={<unknown at remote 0x7ffff6270360>: {'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:3266
#18 0x00007ffff7760214 in _Py_Dealloc (
    op={<unknown at remote 0x7ffff6270360>: {'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_avai--Type <RET> for more, q to quit, c to continue without paging--c
lable_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009
#19 0x00007ffff7735568 in Py_DECREF (
    filename=0x7ffff7c94de0 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/dictobject.c"", 
    lineno=7179, 
    op={<unknown at remote 0x7ffff6270360>: {'_default_interpreter_limiter': <unknown at remote 0x7ffff6274480>, '_available_workers': <collections.deque at remote 0x7ffff63c3250>, '_threadpool_idle_workers': <unknown at remote 0x7ffff63c3850>, '_threadpool_workers': <unknown at remote 0x7ffff6211a90>, '_root_task': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393
#20 0x00007ffff774551d in set_dict_inline_values (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>, new_dict=0x0)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7179
#21 0x00007ffff7745654 in set_or_clear_managed_dict (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>, 
    new_dict=0x0, clear=true) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7313
#22 0x00007ffff77457d4 in PyObject_ClearManagedDict (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7351
#23 0x00007ffff77a2339 in subtype_dealloc (self=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/typeobject.c:2557
#24 0x00007ffff7760214 in _Py_Dealloc (op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009
#25 0x00007ffff7735568 in Py_DECREF (
    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", 
    lineno=502, op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393
#26 0x00007ffff77355bd in Py_XDECREF (op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502
#27 0x00007ffff77373b9 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x5555557888a0, 
    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:460
#28 0x00007ffff773cb85 in clear_lock_held (op={})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:2865
#29 0x00007ffff773ccc4 in PyDict_Clear (op={})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:2889
#30 0x00007ffff7740ea9 in dict_tp_clear (op={})
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:4608
#31 0x00007ffff792e0e5 in delete_garbage (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, 
    gcstate=0x7ffff7e0e1f8 <_PyRuntime+112472>, collectable=0x7fffffffde80, old=0x7ffff7e0e228 <_PyRuntime+112520>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1130
#32 0x00007ffff792f8cd in gc_collect_region (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, 
    from=0x7ffff7e0e228 <_PyRuntime+112520>, to=0x7ffff7e0e228 <_PyRuntime+112520>, stats=0x7fffffffdf40)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1745
#33 0x00007ffff792f62d in gc_collect_full (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, stats=0x7fffffffdf40)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1665
#34 0x00007ffff79303fa in _PyGC_Collect (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, generation=2, 
    reason=_Py_GC_REASON_SHUTDOWN) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:2026
#35 0x00007ffff7930501 in _PyGC_CollectNoFail (tstate=0x7ffff7e432f0 <_PyRuntime+329808>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:2067
#36 0x00007ffff7a0e006 in finalize_modules (tstate=0x7ffff7e432f0 <_PyRuntime+329808>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:1747
#37 0x00007ffff7a0e644 in _Py_Finalize (runtime=0x7ffff7df2aa0 <_PyRuntime>)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:2078
#38 0x00007ffff7a0e706 in Py_FinalizeEx ()
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:2204
#39 0x00007ffff7a58351 in Py_RunMain () at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:768
#40 0x00007ffff7a58422 in pymain_main (args=0x7fffffffe0a0)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:796
#41 0x00007ffff7a584ea in Py_BytesMain (argc=2, argv=0x7fffffffe218)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:820
#42 0x00005555555544bd in main (argc=2, argv=0x7fffffffe218)
    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Programs/python.c:15
```

</details> 


### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130245
<!-- /gh-linked-prs -->
","['>>> import asyncio\n>>> from anyio import to_interpreter\n>>> from functools import partial\n>>> assert await to_interpreter.run_sync(partial(sorted, reverse=True), [""a"", ""b""]) == [""b"", ""a""]\n>>> exit', ""exiting asyncio REPL...\npython3-debug: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/typeobject.c:5262: PyType_GetModuleByDef: Assertion `mro != NULL' failed."", 'import asyncio, io, anyio\n \nasync def repr():\n    stream = io.BytesIO(b""data"")\n    assert await anyio.to_thread.run_sync(stream.read) == b""data""\n\nasyncio.run(repr())', 'Starting program: /usr/bin/python3-debug repr.py\n\nThis GDB supports auto-downloading debuginfo from the following URLs:\n  <https://debuginfod.fedoraproject.org/>\nEnable debuginfod for this session? (y or [n]) y\nDebuginfod has been enabled.\nTo make this setting permanent, add \'set debuginfod enabled on\' to .gdbinit.\nDownloading separate debug info for system-supplied DSO at 0x7ffff7fc5000\n[Thread debugging using libthread_db enabled]                                                                          \nUsing host libthread_db library ""/lib64/libthread_db.so.1"".\n[New Thread 0x7ffff61ff6c0 (LWP 47)]\n[Thread 0x7ffff61ff6c0 (LWP 47) exited]\npython3-debug: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/typeobject.c:5262: PyType_GetModuleByDef: Assertion `mro != NULL\' failed.\n\nThread 1 ""python3-debug"" received signal SIGABRT, Aborted.\nDownloading source file /usr/src/debug/glibc-2.40.9000-37.fc43.x86_64/nptl/pthread_kill.c\n__pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0)                   \n    at pthread_kill.c:44\n44            return INTERNAL_SYSCALL_ERROR_P (ret) ? INTERNAL_SYSCALL_ERRNO (ret) : 0;\n(gdb) bt\n#0  __pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0)\n    at pthread_kill.c:44\n#1  0x00007ffff7480343 in __pthread_kill_internal (threadid=<optimized out>, signo=6) at pthread_kill.c:89\n#2  0x00007ffff7426cbe in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\n#3  0x00007ffff740e6d6 in __GI_abort () at abort.c:73\n#4  0x00007ffff740e639 in __assert_fail_base (fmt=<optimized out>, assertion=<optimized out>, file=<optimized out>, \n    line=5262, function=<optimized out>) at assert.c:118\n#5  0x00007ffff77a883a in PyType_GetModuleByDef (type=0x555555852ca0, def=0x7ffff6911000 <_asynciomodule>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/typeobject.c:5262\n#6  0x00007ffff68fb050 in get_asyncio_state_by_def (self=<_asyncio.Task() at remote 0x7ffff624ce60>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/_asynciomodule.c:204\n#7  0x00007ffff6903144 in TaskObj_dealloc (self=<_asyncio.Task() at remote 0x7ffff624ce60>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/_asynciomodule.c:3068\n#8  0x00007ffff7760214 in _Py_Dealloc (op=<_asyncio.Task() at remote 0x7ffff624ce60>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009\n#9  0x00007ffff7735568 in Py_DECREF (\n    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", \n    lineno=502, op=<_asyncio.Task() at remote 0x7ffff624ce60>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393\n#10 0x00007ffff77355bd in Py_XDECREF (op=<_asyncio.Task() at remote 0x7ffff624ce60>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502\n#11 0x00007ffff77373b9 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x7ffff62353f0, \n    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:460\n#12 0x00007ffff773db30 in dict_dealloc (\n    self={\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:3266\n#13 0x00007ffff7760214 in _Py_Dealloc (\n    op={\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009\n#14 0x00007ffff7735568 in Py_DECREF (\n    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", \n    lineno=502, \n    op={\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393\n#15 0x00007ffff77355bd in Py_XDECREF (\n    op={\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502\n#16 0x00007ffff7737441 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x7ffff626e2c0, \n    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:468\n#17 0x00007ffff773db30 in dict_dealloc (\n    self={<unknown at remote 0x7ffff6270360>: {\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:3266\n#18 0x00007ffff7760214 in _Py_Dealloc (\n    op={<unknown at remote 0x7ffff6270360>: {\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_avai--Type <RET> for more, q to quit, c to continue without paging--c\nlable_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009\n#19 0x00007ffff7735568 in Py_DECREF (\n    filename=0x7ffff7c94de0 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/dictobject.c"", \n    lineno=7179, \n    op={<unknown at remote 0x7ffff6270360>: {\'_default_interpreter_limiter\': <unknown at remote 0x7ffff6274480>, \'_available_workers\': <collections.deque at remote 0x7ffff63c3250>, \'_threadpool_idle_workers\': <unknown at remote 0x7ffff63c3850>, \'_threadpool_workers\': <unknown at remote 0x7ffff6211a90>, \'_root_task\': <_asyncio.Task() at remote 0x7ffff624ce60>}}) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393\n#20 0x00007ffff774551d in set_dict_inline_values (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>, new_dict=0x0)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7179\n#21 0x00007ffff7745654 in set_or_clear_managed_dict (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>, \n    new_dict=0x0, clear=true) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7313\n#22 0x00007ffff77457d4 in PyObject_ClearManagedDict (obj=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:7351\n#23 0x00007ffff77a2339 in subtype_dealloc (self=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/typeobject.c:2557\n#24 0x00007ffff7760214 in _Py_Dealloc (op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/object.c:3009\n#25 0x00007ffff7735568 in Py_DECREF (\n    filename=0x7ffff7c7b688 ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Include/refcount.h"", \n    lineno=502, op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:393\n#26 0x00007ffff77355bd in Py_XDECREF (op=<WeakKeyDictionary() at remote 0x7ffff6db2b00>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Include/refcount.h:502\n#27 0x00007ffff77373b9 in dictkeys_decref (interp=0x7ffff7e0c510 <_PyRuntime+105072>, dk=0x5555557888a0, \n    use_qsbr=false) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:460\n#28 0x00007ffff773cb85 in clear_lock_held (op={})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:2865\n#29 0x00007ffff773ccc4 in PyDict_Clear (op={})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:2889\n#30 0x00007ffff7740ea9 in dict_tp_clear (op={})\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Objects/dictobject.c:4608\n#31 0x00007ffff792e0e5 in delete_garbage (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, \n    gcstate=0x7ffff7e0e1f8 <_PyRuntime+112472>, collectable=0x7fffffffde80, old=0x7ffff7e0e228 <_PyRuntime+112520>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1130\n#32 0x00007ffff792f8cd in gc_collect_region (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, \n    from=0x7ffff7e0e228 <_PyRuntime+112520>, to=0x7ffff7e0e228 <_PyRuntime+112520>, stats=0x7fffffffdf40)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1745\n#33 0x00007ffff792f62d in gc_collect_full (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, stats=0x7fffffffdf40)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:1665\n#34 0x00007ffff79303fa in _PyGC_Collect (tstate=0x7ffff7e432f0 <_PyRuntime+329808>, generation=2, \n    reason=_Py_GC_REASON_SHUTDOWN) at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:2026\n#35 0x00007ffff7930501 in _PyGC_CollectNoFail (tstate=0x7ffff7e432f0 <_PyRuntime+329808>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/gc.c:2067\n#36 0x00007ffff7a0e006 in finalize_modules (tstate=0x7ffff7e432f0 <_PyRuntime+329808>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:1747\n#37 0x00007ffff7a0e644 in _Py_Finalize (runtime=0x7ffff7df2aa0 <_PyRuntime>)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:2078\n#38 0x00007ffff7a0e706 in Py_FinalizeEx ()\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Python/pylifecycle.c:2204\n#39 0x00007ffff7a58351 in Py_RunMain () at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:768\n#40 0x00007ffff7a58422 in pymain_main (args=0x7fffffffe0a0)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:796\n#41 0x00007ffff7a584ea in Py_BytesMain (argc=2, argv=0x7fffffffe218)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Modules/main.c:820\n#42 0x00005555555544bd in main (argc=2, argv=0x7fffffffe218)\n    at /usr/src/debug/python3.14-3.14.0~a5-1.fc43.x86_64/Programs/python.c:15']","Yes, this fixes the issue I observed.",[],['python'],github,https://github.com/python/cpython/issues/130221,{'repo': 'python/cpython'}
"`math.sumprod` should support a `start` parameter like `sum` and `math.prod`

# Feature or enhancement

### Proposal:

`math.sumprod` should support a `start` parameter.

```py
# old
def sumprod(p, q, /)

# proposal
def sumprod(p, q, /, *, start=0)
```

### Reason:

```python
from __future__ import annotations

from typing import Any
from math import sumprod

class Foo:
    def __add__(self, other: Any) -> Foo:
        return Foo()

    def __mul__(self, other: Any) -> Foo:
        return Foo()

sumprod([Foo()], [Foo()])
# TypeError: unsupported operand type(s) for +: 'int' and 'Foo'
```

For now, `math.sumprod` starts its calculation from 0 by default, and there seems to be no way to customize this value.

I understand that alternatives like `itertools.starmap` or defining `def __radd__(self, o)` exist. But I believe `sumprod` should support a `start` parameter for consistency with `sum` and `math.prod`.
","['# old\ndef sumprod(p, q, /)\n\n# proposal\ndef sumprod(p, q, /, *, start=0)', ""from __future__ import annotations\n\nfrom typing import Any\nfrom math import sumprod\n\nclass Foo:\n    def __add__(self, other: Any) -> Foo:\n        return Foo()\n\n    def __mul__(self, other: Any) -> Foo:\n        return Foo()\n\nsumprod([Foo()], [Foo()])\n# TypeError: unsupported operand type(s) for +: 'int' and 'Foo'""]","Ahh, I made a mistake when creating this issue. It's not a bug—it should be labeled as `type-feature`",[],['python'],github,https://github.com/python/cpython/issues/130270,{'repo': 'python/cpython'}
"format(Fraction(1, 3), '.016f') raises ValueError

# Bug report

### Bug description:

c.f.
```python
>>> format(float(Fraction(1, 3)), '.016f')
'0.3333333333333333'
```

Looking on [docs](https://docs.python.org/3.14/library/string.html#format-specification-mini-language), I think that float formatting better conforms to the specification.

Similar issue is valid for the width:
```py
>>> format(float(Fraction(1, 3)), '0030.016f')
'0000000000000.3333333333333333'
>>> format(Fraction(1, 3), '0030.016f')
Traceback (most recent call last):
  File ""<python-input-3>"", line 1, in <module>
    format(Fraction(1, 3), '0030.016f')
    ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.13/fractions.py"", line 577, in __format__
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Invalid format specifier '0030.016f' for object of type 'Fraction'
```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130663
* gh-130717
<!-- /gh-linked-prs -->
","["">>> format(float(Fraction(1, 3)), '.016f')\n'0.3333333333333333'"", '>>> format(float(Fraction(1, 3)), \'0030.016f\')\n\'0000000000000.3333333333333333\'\n>>> format(Fraction(1, 3), \'0030.016f\')\nTraceback (most recent call last):\n  File ""<python-input-3>"", line 1, in <module>\n    format(Fraction(1, 3), \'0030.016f\')\n    ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/lib/python3.13/fractions.py"", line 577, in __format__\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Invalid format specifier \'0030.016f\' for object of type \'Fraction\'']","> I suspect that the pattern was just copied without further ado.

Just for the historical record, that's not what happened: the choice to exclude leading zeros for both the width and the precision was carefully considered and very much deliberate. That said, I'm happy to leave it to the active core devs to decide how to take this forward.",[],['python'],github,https://github.com/python/cpython/issues/130662,{'repo': 'python/cpython'}
"Dataclass inheritance breakes ForwardRef

# Bug report

### Bug description:

If we have two classes split into two files with ForwardRefs, then you cannot get hints on `__init__` method of child

`parent.py`:
```python
from __future__ import annotations  # <--- this triggers the problem

from dataclasses import dataclass


class LocalDep:
    pass


@dataclass
class Parent:
    dep1: LocalDep
```
`child.py`
```python
from dataclasses import dataclass
from typing import get_type_hints

from parent import Parent


@dataclass
class Child(Parent):
    pass

print(get_type_hints(Child))
print(get_type_hints(Child.__init__))
```

I've expected to have two last lines printing the same
Actually, first print gives a correct output, but the second call raises an error
```
Traceback (most recent call last):
  File ""/home/tishka17/src/dishka/tmp/dtc/child.py"", line 16, in <module>
    print(get_type_hints(Child.__init__))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/typing.py"", line 2414, in get_type_hints
    hints[name] = _eval_type(value, globalns, localns)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/typing.py"", line 395, in _eval_type
    return t._evaluate(globalns, localns, recursive_guard)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/typing.py"", line 905, in _evaluate
    eval(self.__forward_code__, globalns, localns),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<string>"", line 1, in <module>
NameError: name 'LocalDep' is not defined
``` 

As far as I udnerstood, we inside `dataclass` logic [it copies](https://github.com/python/cpython/blob/805839021ba7074423811ba07995ae57984a46d3/Lib/dataclasses.py#L962-L974) `__init__` method annotations and that leads to an error. We do not copy class attrs (fields), so hints are retrieved from parent class directly (`get_type_hints` knows about MRO)

### CPython versions tested on:

3.11, 3.13, 3.14

### Operating systems tested on:

Linux","['from __future__ import annotations  # <--- this triggers the problem\n\nfrom dataclasses import dataclass\n\n\nclass LocalDep:\n    pass\n\n\n@dataclass\nclass Parent:\n    dep1: LocalDep', 'from dataclasses import dataclass\nfrom typing import get_type_hints\n\nfrom parent import Parent\n\n\n@dataclass\nclass Child(Parent):\n    pass\n\nprint(get_type_hints(Child))\nprint(get_type_hints(Child.__init__))', 'Traceback (most recent call last):\n  File ""/home/tishka17/src/dishka/tmp/dtc/child.py"", line 16, in <module>\n    print(get_type_hints(Child.__init__))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/lib/python3.11/typing.py"", line 2414, in get_type_hints\n    hints[name] = _eval_type(value, globalns, localns)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/lib/python3.11/typing.py"", line 395, in _eval_type\n    return t._evaluate(globalns, localns, recursive_guard)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/lib/python3.11/typing.py"", line 905, in _evaluate\n    eval(self.__forward_code__, globalns, localns),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""<string>"", line 1, in <module>\nNameError: name \'LocalDep\' is not defined']",Also https://github.com/python/cpython/issues/89687,[],['python'],github,https://github.com/python/cpython/issues/130506,{'repo': 'python/cpython'}
"`sqlite`: `timeout` doesn't seem to work

# Bug report

### Bug description:

Hey there.

(please read till the end... it **does work** with the `sqlite3` utility, but not with Python’s `sqlite`)

With 3.13.2 on Debian unstable, it seems that `sqlite.connect()`’s timeout doesn't work as it should.

I have a small demo program:
```
#!/usr/bin/python3

import sqlite3
import sys
import time

print(f""con tmout: "" + sys.argv[2])
con = sqlite3.connect(""locks.db"", autocommit=False, timeout=float(sys.argv[2]))
cur = con.cursor()

print(f""1st sleep: "" + sys.argv[3])
time.sleep(int(sys.argv[3]))

cur.execute(""CREATE TABLE IF NOT EXISTS locks (name TEXT PRIMARY KEY ON CONFLICT ROLLBACK) STRICT"")

x = cur.execute(""INSERT INTO locks (name) VALUES (?);"", (sys.argv[1],) )
print(x.fetchall())

print(f""2nd sleep: "" + sys.argv[4])
time.sleep(int(sys.argv[4]))

con.commit()

cur.close()
con.close()
```

- It uses `autocommit=False`, which uses `DEFERRED` transactions, which - AFAIU - means that the transaction only starts until the first, access, i.e. the `execute()` that would initially create the table and thus only **after** the first sleep.
- 4 args, first is the `name` value (which is a primary key and must be unique), second the `timeout=` of the connection, third is the sleep before the transaction starts, fourth the sleep right before the `commit()`, 

My assumption would be that while the DB is locked because of a write transaction, any concurrent write transaction waits `timeout=` before it aborts.

Now when I start the script twice (at the same time), first e.g. with:
```
$ ./lock.py 1st_a 5 0 10
```
second with:
```
$ ./lock.py 2nd_a 500 0 0
```
I'd expect the second to wait for 500s and as the first sleeps only 10s, it should succeed.
However it immediately aborts with:
```
sqlite3.OperationalError: database is locked
```


I've seen #124510, but the explanation there was about the case of **upgrading** read transactions to write transactions, so what’s written [here](https://www.sqlite.org/lang_transaction.html#read_transactions_versus_write_transactions) doesn't apply, and in fact it seems to just work as I expect with the `sqlite3` utility:<br>
First invocation:
```
$ sqlite3 locks.db
sqlite> BEGIN DEFERRED;
sqlite> INSERT INTO locks (name) VALUES ('1st_b');
```
Second invocation (note that `sqlite3`’s `.timeout` uses **milliseconds**):
```
$ sqlite3 locks.db
sqlite> .timeout 10000
sqlite> INSERT INTO locks (name) VALUES ('2nd_b');
```
Doing this, the second one will block, until either the 10s have passed, or I do a `COMMIT;` in the first.

Any ideas why that doesn't work in Python?

Thanks,
Chris.

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['#!/usr/bin/python3\n\nimport sqlite3\nimport sys\nimport time\n\nprint(f""con tmout: "" + sys.argv[2])\ncon = sqlite3.connect(""locks.db"", autocommit=False, timeout=float(sys.argv[2]))\ncur = con.cursor()\n\nprint(f""1st sleep: "" + sys.argv[3])\ntime.sleep(int(sys.argv[3]))\n\ncur.execute(""CREATE TABLE IF NOT EXISTS locks (name TEXT PRIMARY KEY ON CONFLICT ROLLBACK) STRICT"")\n\nx = cur.execute(""INSERT INTO locks (name) VALUES (?);"", (sys.argv[1],) )\nprint(x.fetchall())\n\nprint(f""2nd sleep: "" + sys.argv[4])\ntime.sleep(int(sys.argv[4]))\n\ncon.commit()\n\ncur.close()\ncon.close()', '$ ./lock.py 1st_a 5 0 10', '$ ./lock.py 2nd_a 500 0 0', 'sqlite3.OperationalError: database is locked', ""$ sqlite3 locks.db\nsqlite> BEGIN DEFERRED;\nsqlite> INSERT INTO locks (name) VALUES ('1st_b');"", ""$ sqlite3 locks.db\nsqlite> .timeout 10000\nsqlite> INSERT INTO locks (name) VALUES ('2nd_b');""]","It doesn't even work, when using `PRAGMA busy_timeout = milliseconds;`",[],['python'],github,https://github.com/python/cpython/issues/130971,{'repo': 'python/cpython'}
"Ensure `stdbool.h` is included after `Python.h`

# Bug report

Including `stdbool.h` before `Python.h` may cause build issues when using `zig cc`.

See https://github.com/python/cpython/pull/130641 and https://github.com/python/cpython/pull/130641#issuecomment-2692299464.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130738
* gh-130756
* gh-130757
<!-- /gh-linked-prs -->
",[],"Can this be closed, are there any cases of this left?

```bash
$ grep -RPzl '#include <stdbool.h>.*\n(?s:.*)#include <Python.h>' .
./configure
```

I presume we can ignore it.","[""$ grep -RPzl '#include <stdbool.h>.*\\n(?s:.*)#include <Python.h>' .\n./configure""]",['python'],github,https://github.com/python/cpython/issues/130740,{'repo': 'python/cpython'}
"graphlib.invert() and graphlib.transitive()

# Feature or enhancement

### Proposal:

I want to propose two utility functions to be added to the `graphlib` module.

First `invert()`:

```python
>>> graphlib.invert({""a"": [""b, ""c""]})
{""b"": {""a""}, ""c"": {""a""}}
```

Second `as_transitive()`:

```python
>>> graphlib.as_transitive({""a"": [""b""], ""b"": [""c""]})
{""a"": {""b"", ""c""}, ""b"": {""c""}}
```

Background: I've been working with `graphlib.TopologicalSorter` a lot, and found it to be extremely helpful working with task graphs both for static analysis and real-time processing.

`invert()` is a crucial step for processing a task graph backwards or for analysing dependents instead of dependencies. For example, if you *build* a set of components in topological order, you might *clean* them in inverse topological order (if a component can be used to clean the things that depend on it).

`as_transitive()` is valuable for static analysis. For example in a package dependency graph the transitive closure is what you must package in order to deploy a product. The inverse transitive dependency graph is what you must revalidate when changing a package.

These two operations would round out the basic capabilities needed for graph processing tasks (as opposed to the more mathematical analysis provided by a package like `NetworkX`).

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130875
<!-- /gh-linked-prs -->
","['>>> graphlib.invert({""a"": [""b, ""c""]})\n{""b"": {""a""}, ""c"": {""a""}}', '>>> graphlib.as_transitive({""a"": [""b""], ""b"": [""c""]})\n{""a"": {""b"", ""c""}, ""b"": {""c""}}']","> Should it be a method?

It is less useful as a method of `TopologicalSorter` because you cannot get the graph back out.

Also the transitive closure function is meaningless to be a method of topological sorter (it produces the same order).

Because `as_transitive(reverse(graph))` is useful I'd argue these should both be functions.

Maybe TopologicalSorter could have a `.reverse()` method as well, but I doubt that would drop out nicely, I'd have to look at the internals.",[],['python'],github,https://github.com/python/cpython/issues/129847,{'repo': 'python/cpython'}
"Taking a dictionary as an argument is the root of all evil

Both at my current company and in an open-source project I'm working on, I keep seeing the same heinous anti-pattern everywhere I look:  
```
def foo(params):
    why_wasnt_this_an_argument = params['why_wasnt_this_an_argument']
    # do something
    print('kill me')
```
Instead of taking specific/clear arguments, these functions take some mysterious `params` dictionary with lord knows what in it. It's like they didn't even know what the function was going to do while they were writing it. How am I supposed to know what this function is doing? How am I supposed to write tests for this function? I've spent tens of hours of my life figuring out what is supposed to be in `params`, so that I can use or test these god-forsaken functions.

This is a friendly reminder that other people will probably have to read your code. Never name anything `params`, and definitely never define functions with ill-defined dictionaries as arguments.","[""def foo(params):\n    why_wasnt_this_an_argument = params['why_wasnt_this_an_argument']\n    # do something\n    print('kill me')""]",See comments on Reddit,[],['Python'],reddit,https://www.reddit.com/r/Python/comments/jp0x4d/taking_a_dictionary_as_an_argument_is_the_root_of/,{'subreddit': 'Python'}
"Remove `_DYNAMIC_EXIT`

Looking at the latest benchmarking comparison for [JIT on vs. JIT off](https://github.com/faster-cpython/benchmarking-public/blob/main/results/bm-20250201-3.14.0a4%2B-cf4c4ec-JIT/bm-20250201-linux-x86_64-python-cf4c4ecc26c7e3b89f2e-3.14.0a4%2B-cf4c4ec-vs-base.svg), we currently have a number of benchmarks that are slowed down significantly, with 16 benchmarks slowing down over 5%, 3 slowing down over 15%, and one (`generators`) slowing down over 25%. Clearly, there are some code patterns that we just aren't handling well. If we want people to turn on the JIT, we need to minimize this potential downside.

It appears the culprit is, well, generators. In particular, `_DYNAMIC_EXIT`. Long story short, I think we should ditch `_DYNAMIC_EXIT`, at least for now. It was always a bit of a not-quite-complete solution to a hard tracing problem, and [getting rid of it is enough to cancel out the slowdown on all of our slowest benchmarks](https://github.com/faster-cpython/benchmarking-public/blob/main/results/bm-20250205-3.14.0a4%2B-06da973-JIT/bm-20250205-linux-x86_64-brandtbucher-no_dynamic_exit-3.14.0a4%2B-06da973-vs-base.svg) (only 10 benchmarks are slowed down more than 5%, and none slowed down more than 10%).

We use `_DYNAMIC_EXIT` for a couple of code patterns:
- Tracing into a generator, via `FOR_ITER_GEN` or `SEND_GEN`. This will no longer successfully project a trace.
- Tracing into a function, via `LOAD_ATTR_PROPERTY` or `BINARY_SUBSCR_GETITEM`. These caches actually have the necessary information to continue tracing, so `_DYNAMIC_EXIT` isn't really needed anymore.
- Tracing into a function that isn't in the reverse-lookup-by-version cache, which should be uncommon.

We may also want to fail to create traces that end in `YIELD_VALUE`, but that can be considered separately as a follow up.

Once this is done, we can work on a new solution for tracing generators that's more robust (perhaps by using normal side exits, and starting each trace with a guard on the instruction pointer). We should probably only merge a solution once it's proven to work in practice, since the JIT is beginning to mature and stabilize.

(Thanks @mdboom for the idea.)

<!-- gh-linked-prs -->
### Linked PRs
* gh-129716
* gh-130024
<!-- /gh-linked-prs -->
",[],"After talking with @markshannon about this, we've come up with the following path forward once `_DYNAMIC_EXIT` is out.

- [x] Don't project traces that end in underflow for now (this includes all `YIELD_VALUE`s).
- [ ] Update the tracing machinery to handle `LOAD_ATTR_PROPERTY` and `BINARY_SUBSCR_GETITEM`. which have all of the info we need to continue projecting in their caches.
- [ ] Update `FOR_ITER_GEN` and `SEND_GEN` to specialize for a specific code object and instruction pointer, and teach the tier two optimizer how to guard and trace through them (the code object guard can be replaced with a watcher, so we just do a single pointer comparison on the new instruction pointer as our only guard). If there are multiple yield points, they will chain the normal way. Also, un-skip `test_for_iter_gen`.
- [ ] Then, do the same thing for `YIELD_VALUE`.
- [ ] Then, do the same thing for `RETURN_VALUE` and `RETURN_GENERATOR` when they underflow.
- [ ] Then, try decreasing JIT thresholds again.",[],['python'],github,https://github.com/python/cpython/issues/129715,{'repo': 'python/cpython'}
"Python 3.14.0a5: `test_external_inspection` fails on freethreading-debug build on s390x Linux

# Bug report

### Bug description:


The failure happens only on s390x: `/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/call.c:342: _PyObject_Call: Assertion '!_PyErr_Occurred(tstate)' failed.`
Built as RPM on Fedora Linux 40-43, all occurrences have the same behavior.
The relevant log excerpt:

```
0:40:46 load avg: 3.05 [1/2/1] test_external_inspection worker non-zero exit code (Exit code -6 (SIGABRT))
Re-running test_external_inspection in verbose mode (matching: )
test_async_gather_remote_stack_trace (test.test_external_inspection.TestGetStackTrace.test_async_gather_remote_stack_trace) ... python: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/call.c:342: _PyObject_Call: Assertion `!_PyErr_Occurred(tstate)' failed.
Fatal Python error: Aborted
<Cannot show all threads while the GIL is disabled>
Stack (most recent call first):
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/test_external_inspection.py"", line 271 in test_async_gather_remote_stack_trace
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 606 in _callTestMethod
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 660 in run
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 716 in __call__
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 122 in run
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 84 in __call__
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 122 in run
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 84 in __call__
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/runner.py"", line 259 in run
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 84 in _run_suite
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 42 in run_unittest
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 162 in test_func
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 118 in regrtest_runner
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 165 in _load_run_test
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 210 in _runtest_env_changed_exc
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 319 in _runtest
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 348 in run_single_test
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 83 in worker_process
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 118 in main
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 122 in <module>
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/runpy.py"", line 88 in _run_code
  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/runpy.py"", line 198 in _run_module_as_main
Extension modules: _testinternalcapi, _testexternalinspection (total: 2)
```


### CPython versions tested on:

3.14

### Operating systems tested on:

Linux","['0:40:46 load avg: 3.05 [1/2/1] test_external_inspection worker non-zero exit code (Exit code -6 (SIGABRT))\nRe-running test_external_inspection in verbose mode (matching: )\ntest_async_gather_remote_stack_trace (test.test_external_inspection.TestGetStackTrace.test_async_gather_remote_stack_trace) ... python: /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Objects/call.c:342: _PyObject_Call: Assertion `!_PyErr_Occurred(tstate)\' failed.\nFatal Python error: Aborted\n<Cannot show all threads while the GIL is disabled>\nStack (most recent call first):\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/test_external_inspection.py"", line 271 in test_async_gather_remote_stack_trace\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 606 in _callTestMethod\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 660 in run\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/case.py"", line 716 in __call__\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 122 in run\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 84 in __call__\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 122 in run\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/suite.py"", line 84 in __call__\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/unittest/runner.py"", line 259 in run\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 84 in _run_suite\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 42 in run_unittest\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 162 in test_func\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 118 in regrtest_runner\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 165 in _load_run_test\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 210 in _runtest_env_changed_exc\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 319 in _runtest\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/single.py"", line 348 in run_single_test\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 83 in worker_process\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 118 in main\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/test/libregrtest/worker.py"", line 122 in <module>\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/runpy.py"", line 88 in _run_code\n  File ""/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/runpy.py"", line 198 in _run_module_as_main\nExtension modules: _testinternalcapi, _testexternalinspection (total: 2)']","> It seems like some of the error paths don't properly set a Python exception. Does s390x have `HAVE_PROCESS_VM_READV`?

🤔 It should otherwise the test should not even be attempted so whatever is going on is something else.",[],['python'],github,https://github.com/python/cpython/issues/130035,{'repo': 'python/cpython'}
"Data race in `intern_common` when interning str objects in the free threading build

# Bug report

When running `./python -m test test_exceptions --parallel-threads=10` in a TSAN build:

```
WARNING: ThreadSanitizer: data race (pid=763025)
  Atomic read of size 4 at 0x7fffbe0718cc by thread T190:
    #0 _Py_atomic_load_uint32_relaxed Include/cpython/pyatomic_gcc.h:367 (python+0x1d386e) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #1 Py_INCREF Include/refcount.h:261 (python+0x1d386e)
    #2 _Py_NewRef Include/refcount.h:518 (python+0x1d386e)
    #3 dict_setdefault_ref_lock_held Objects/dictobject.c:4386 (python+0x1e6817) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #4 PyDict_SetDefaultRef Objects/dictobject.c:4403 (python+0x1e6a37) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #5 intern_common Objects/unicodeobject.c:15820 (python+0x2a7a8d) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #6 _PyUnicode_InternImmortal Objects/unicodeobject.c:15874 (python+0x2e92d1) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #7 _PyPegen_new_identifier Parser/pegen.c:549 (python+0xad61f) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
....

  Previous write of size 4 at 0x7fffbe0718cc by thread T182:
    #0 Py_SET_REFCNT Include/refcount.h:176 (python+0x2a7c9a) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #1 Py_SET_REFCNT Include/refcount.h:145 (python+0x2a7c9a)
    #2 intern_common Objects/unicodeobject.c:15848 (python+0x2a7c9a)
    #3 _PyUnicode_InternImmortal Objects/unicodeobject.c:15874 (python+0x2e92d1) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
    #4 _PyPegen_new_identifier Parser/pegen.c:549 (python+0xad61f) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)
...
```

There are a few thread-safety issues with `intern_common`:

* It can return a string that's not marked as interned because we insert into `interned` before we mark the string as interned. This can be fixed with some additional locking.
* The `Py_SET_REFCNT(s, Py_REFCNT(s) - 2)` modification is not thread-safe with respect to other reference count modifications in the free threading build
* `_Py_SetImmortal` is not thread-safe in some circumstances (see https://github.com/python/cpython/issues/113956)

The `_Py_SetImmortal()` issue is tricky and I think it's unlikely to cause problems in practice, so I think we can defer dealing with that for now.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130089
<!-- /gh-linked-prs -->
",['WARNING: ThreadSanitizer: data race (pid=763025)\n  Atomic read of size 4 at 0x7fffbe0718cc by thread T190:\n    #0 _Py_atomic_load_uint32_relaxed Include/cpython/pyatomic_gcc.h:367 (python+0x1d386e) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #1 Py_INCREF Include/refcount.h:261 (python+0x1d386e)\n    #2 _Py_NewRef Include/refcount.h:518 (python+0x1d386e)\n    #3 dict_setdefault_ref_lock_held Objects/dictobject.c:4386 (python+0x1e6817) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #4 PyDict_SetDefaultRef Objects/dictobject.c:4403 (python+0x1e6a37) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #5 intern_common Objects/unicodeobject.c:15820 (python+0x2a7a8d) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #6 _PyUnicode_InternImmortal Objects/unicodeobject.c:15874 (python+0x2e92d1) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #7 _PyPegen_new_identifier Parser/pegen.c:549 (python+0xad61f) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n....\n\n  Previous write of size 4 at 0x7fffbe0718cc by thread T182:\n    #0 Py_SET_REFCNT Include/refcount.h:176 (python+0x2a7c9a) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #1 Py_SET_REFCNT Include/refcount.h:145 (python+0x2a7c9a)\n    #2 intern_common Objects/unicodeobject.c:15848 (python+0x2a7c9a)\n    #3 _PyUnicode_InternImmortal Objects/unicodeobject.c:15874 (python+0x2e92d1) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n    #4 _PyPegen_new_identifier Parser/pegen.c:549 (python+0xad61f) (BuildId: 5612db6eff0f51c7fd99ee4409b2ceafceea484c)\n...'],I hit this while testing PyYAML (though the TSAN stack trace was slightly different). Are you going to work on this @colesbury?,[],['python'],github,https://github.com/python/cpython/issues/129701,{'repo': 'python/cpython'}
"test_venv fails from within venv

# Bug report

### Bug description:

The test_venv tests were too strict about executable names, causing failures when running the test suite from within a virtual environment created from the built Python. Rather than enforcing specific executable names, it makes more sense to make the tests more flexible to support testing in both contexts - directly from build and from within a venv. What do you think about it?

```bash
# build
./configure && make -j

# create venv
./python.exe -m venv .venv
source .venv/bin/activate

# this will fail
python -m test test_venv
```

Also reproduced on Windows

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130487
<!-- /gh-linked-prs -->
",['# build\n./configure && make -j\n\n# create venv\n./python.exe -m venv .venv\nsource .venv/bin/activate\n\n# this will fail\npython -m test test_venv'],"My use-case to have `.venv` built with source `./python.exe` is that I use `pyperf` and other tools (`brurb`, `cherry-picker`) during development.

It would be nice if all tests can pass with this mode, in my opinion.
But, if this does not complicate tests for all other cases.",[],['python'],github,https://github.com/python/cpython/issues/130486,{'repo': 'python/cpython'}
"PyType_GenericAlloc doesn't initialize the content to NULL

# Bug report

### Bug description:

I spent a few hours yesterday debugging this, and thus thought I had to point it out.
Here's my simplified C++ code:
```c++
struct Example {
   // Lots of stuff, pointers, stuff like that
}

typedef struct {
  PyObject ob_base;
  struct A Example;
} ExampleObject;

static PyTypeObject ExampleType = {
  .ob_base = PyVarObject_HEAD_INIT(NULL, 0).tp_name = ""my_module.Example"",
  .tp_basicsize = sizeof(ExampleObject),
  .tp_flags = Py_TPFLAGS_DEFAULT,
  .tp_new = PyType_GenericNew,
};

static PyObject * foo(PyObject* self, PyObject * args) {
     auto* temp = PyObject_New(ExampleObject, &ExampleType);
    // The issue is here
}
```
The issues lies in the fact that, according to the documentation, the content of `temp` should be initialized at `NULL`, but that is clearly not the case here: I printed each byte of temp, and some of them clearly were not NULL.
This silent error caused me many a troubles. I fixed this by using `memset`, but I really shouldn't have to, so please fix this. 
Thanks !

![Image](https://github.com/user-attachments/assets/a6ef0c1b-1bd9-4680-b1ba-7a1057e8378b)

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['++\nstruct Example {\n   // Lots of stuff, pointers, stuff like that\n}\n\ntypedef struct {\n  PyObject ob_base;\n  struct A Example;\n} ExampleObject;\n\nstatic PyTypeObject ExampleType = {\n  .ob_base = PyVarObject_HEAD_INIT(NULL, 0).tp_name = ""my_module.Example"",\n  .tp_basicsize = sizeof(ExampleObject),\n  .tp_flags = Py_TPFLAGS_DEFAULT,\n  .tp_new = PyType_GenericNew,\n};\n\nstatic PyObject * foo(PyObject* self, PyObject * args) {\n     auto* temp = PyObject_New(ExampleObject, &ExampleType);\n    // The issue is here\n}']","I think you're saying that you expect `PyObject_New` to zero out the allocated memory (since you're referring to `temp`). But its documentation at https://docs.python.org/3.13/c-api/allocation.html#c.PyObject_New explicitly says ""Fields not defined by the Python object header are not initialized.""",[],['python'],github,https://github.com/python/cpython/issues/129508,{'repo': 'python/cpython'}
"As of 3.12 `_lsprof` no longer calls `_PyEval_SetProfile` making `sys.getprofile()` useless with `cProfile`

# Bug report

### Bug description:

Starting in 3.12 with the addition of `sys.monitoring`, `_lsprof`, specifically in `profiler_enable`, no longer calls `_PyEval_SetProfile`.

Very specifically, this impacts previous functionality where `python -m cProfile -m whatever` would result in `sys.setprofile()` being called, and subsequently the `whatever` module could access the profiler object via `sys.getprofile()`

To my knowledge this is now completely impossible as `sys.monitoring` provides no meaningful way to access the profiler object.

In my particular use case, profiling could be enabled within the application, or if `python -m cProfile` was used, the existing profiler could be used allowing profiling to happen earlier than the enablement point of `cProfile` within the application.

Something to the effect of:

```python
p = sys.getprofile()
if p is None:
    p = cProfile.Profile()
    p.enable()
```

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux",['p = sys.getprofile()\nif p is None:\n    p = cProfile.Profile()\n    p.enable()'],"This is not a bug. `sys.getprofile` gets the profile function from `sys.setprofile`, `cProfile` before 3.12 happened to use that specific utility for profiling. It switched to `sys.monitoring` mechanism after 3.12, so `sys.getprofile` won't get anything for `cProfile`. Yes they both have the word `profile` in it, but there's never a guarantee that they will always be related. `cProfile` documentation does not provide a way to get the profile object from CLI either. This is just something unsupported that happened to work before 3.12.

If you just want something equivalent to your current method (which is not 100% accurate, it's only guarantees that if `cProfile` is running, `sys.getprofile()` will be not `None`), you can do `sys.monitoring.get_tool(sys.monitoring.PROFILER_ID)` - that will return a string if cProfile is running.

Still, cProfile does not provide an official way to access it's profiler object in CLI mode, if you need that, that's a feature request.",[],['python'],github,https://github.com/python/cpython/issues/130377,{'repo': 'python/cpython'}
"Debug build assertion failure with native threads attempting to acquire GIL on termination

### Bug description:

I'm writing pyo3/pyo3#4874, which tries to avoid Rust crashing on Python interpreter termination when there are native threads attempting to acquire the GIL.

To test it, I created a test that constantly hammers the GIL on a daemon thread, and on debug builds, I get this assertion failure fairly reliably on Python 3.13:
```
Python/pystate.c:345: void unbind_gilstate_tstate(PyThreadState *): Assertion `tstate == tstate_tss_get(&(tstate->interp->runtime)->autoTSSkey)' failed
```

It looks like `zapthreads` is attempting to zap a native thread that does not currently hold the GIL.

Would it help if I'll reproduce this in a C example?

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","[""Python/pystate.c:345: void unbind_gilstate_tstate(PyThreadState *): Assertion `tstate == tstate_tss_get(&(tstate->interp->runtime)->autoTSSkey)' failed""]","So I think the GIL-hammering thread is adding itself to the list of threads after the call to `_PyThreadState_RemoveExcept`. I'll stand up an Ubuntu with `rr` to confirm.

[the test is not really simulating a production workload I have, it's just hammering the GIL to make sure that Python + Rust is stable in that case].",[],['python'],github,https://github.com/python/cpython/issues/131012,{'repo': 'python/cpython'}
"long_from_non_binary_base isn't thread-safe with free threading

# Bug report

The `long_from_non_binary_base` function in longobject.c isn't thread-safe with free threading or per-interpreter GIL due to the initialization of `log_base_BASE`, `convwidth_base`, and `convmultmax_base`:

https://github.com/python/cpython/blob/f963239ff1f986742d4c6bab2ab7b73f5a4047f6/Objects/longobject.c#L2835-L2856

There are a few ways we could make this thread-safe:

* Make the initialization thread-safe with something like [`_PyOnceFlag`](https://github.com/python/cpython/blob/5c8e8704c39110da15956b0678303aff7dffb3be/Include/internal/pycore_lock.h#L140-L145)
* Pre-compute the values and hardcode them.

Originally reported by @ngoldbaum in https://github.com/python/cpython/issues/130421

cc @tim-one 

<!-- gh-linked-prs -->
### Linked PRs
* gh-130600
* gh-130714
<!-- /gh-linked-prs -->
",[],"They are very fast to compute, takes less than 1 microsecond on my machine.  If we hard code the table, it perhaps needs entries for different values of `PyLong_BASE` (usually 15 or 30 but I think it was changed in the past).  So, I think the simple thing to do is compute them all at runtime init.  I'l make a patch that does that.",[],['python'],github,https://github.com/python/cpython/issues/130599,{'repo': 'python/cpython'}
"readline error when saving interactive command history when history file path is a symlink to a relative path

# Bug report

### Bug description:

## To reproduce the issue
1. Set up home directory like following:
```
$HOME/
  .python_history --> foo/history_file
  foo/
    history_file
```
2. Launch a Python interactive session with CWD different from `$HOME`
3. Execute the following
```python
import readline
import os
history_path=os.path.expanduser(""~/.python_history"")
assert os.path.exists(history_path)
readline.write_history_file(history_path)
```
4. Observe the following error
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
FileNotFoundError: [Errno 2] No such file or directory
```

## Possible cause
This is likely due to how GNU readline commits history information to file. As of GNU readline v8.2 (used in Python 3.10 and 3.12 among others), it creates a temporary file in the parent directory of the history file, write to that temporary file, and then rename the temporary file to the history file. See `history_tempfile` in `histfile.c` of GNU readline.

GNU readline determines the parent directory from the `readlink` output of the user-supplied history file path. In this case, since the history file is a symlink with a relative path, the parent directory is resolved to the relative path `foo/`. If `foo/` doesn't exist in the CWD, history saving fails.

### CPython versions tested on:

3.10, 3.12

### Operating systems tested on:

Linux","['$HOME/\n  .python_history --> foo/history_file\n  foo/\n    history_file', 'import readline\nimport os\nhistory_path=os.path.expanduser(""~/.python_history"")\nassert os.path.exists(history_path)\nreadline.write_history_file(history_path)', 'Traceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\nFileNotFoundError: [Errno 2] No such file or directory']",This looks like a problem in GNU upstream. Is there any conceivable workaround?,[],['python'],github,https://github.com/python/cpython/issues/129453,{'repo': 'python/cpython'}
"`PyGILState_Ensure` in one thread causes the thread-local storage of other threads to be GCed

# Bug report

### Bug description:

```sh
# Download https://gist.github.com/kevin85421/4616545d3bed2ebcfe5d0a01bdfde3ff
g++ example.cc -I/usr/include/python3.12 -lpython3.12 -lpthread -o example
./example
```

* The above script creates two C++ threads, `default_pool` and `custom_pool`, and calls Python code.
  * Phase 1 (`void init_python_thread`): Each thread
    * Calls `PyGILState_Ensure()`
    * Runs Python code that assigns the value 1 to the variable `a` and creates a thread-local state using `threading.local()`.
    * Calls `PyEval_SaveThread` to release GIL.
  * Phase 2 (`void release_gstate`): Each thread
    * Calls `PyEval_RestoreThread(*tstate)` to acquire GIL and restore thread state. 
    * Runs Python code to print `a`
    * Runs Python code to print thread-local state.
    * Calls `PyGILState_Release`

The thread who is the first thread to call `PyGILState_Ensure()` will fail to print thread-local state in step 2.

In the following example log,
* `default_pool` calls `PyGILState_Ensure()` and writes `a=1` and thread-local state.
* `custom_pool` calls `PyGILState_Ensure()` and writes `a=1` and thread-local state. => My current guess is that `PyGILState_Ensure()` here makes the thread-local state of `default_pool` be GCed.

```
[C++][08:21:37.740] Hello from the default_pool in init_python_thread
[C++][08:21:37.741] Hello from the custom_pool in init_python_thread
Hello from default_pool, a = 1!
[C++][08:21:37.744] Hello from the default_pool in release_gstate
Hello from custom_pool, a = 1!
a = 1 in release_gstate!
[C++][08:21:37.744] Hello from the custom_pool in release_gstate
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: '_thread._local' object has no attribute 'name'
a = 1 in release_gstate!
thread_local.name = custom_pool in release_gstate!
```


### CPython versions tested on:

3.12

### Operating systems tested on:

Linux","['# Download https://gist.github.com/kevin85421/4616545d3bed2ebcfe5d0a01bdfde3ff\ng++ example.cc -I/usr/include/python3.12 -lpython3.12 -lpthread -o example\n./example', '[C++][08:21:37.740] Hello from the default_pool in init_python_thread\n[C++][08:21:37.741] Hello from the custom_pool in init_python_thread\nHello from default_pool, a = 1!\n[C++][08:21:37.744] Hello from the default_pool in release_gstate\nHello from custom_pool, a = 1!\na = 1 in release_gstate!\n[C++][08:21:37.744] Hello from the custom_pool in release_gstate\nTraceback (most recent call last):\n  File ""<string>"", line 1, in <module>\nAttributeError: \'_thread._local\' object has no attribute \'name\'\na = 1 in release_gstate!\nthread_local.name = custom_pool in release_gstate!']","Hi! I'm not familiar with `boost::asio::post`, but your gist looks a little wrong. (Don't blame yourself, we've done a bad job of documenting how these functions work.)

This may seem a little counterintuitive, but the GIL can also be released randomly in-between execution of Python instructions, not just calls to `PyEval_SaveThread`. I'm seeing the following behavior based on the output:

- Thread 1 (`default_pool`) starts, and `thread_local` is assigned to a `threading.local()` and the `name` attribute is set. The GIL is then released explicitly by `PyEval_SaveThread`.
- Thread 2 (`custom_pool`) is now unblocked and takes the GIL, but completely *overwrites* the `thread_local` from before, losing the prior `name` attribute.
- At this point, Python decides another thread should execute (based on the [switch interval](https://docs.python.org/3/library/sys.html#sys.getswitchinterval)), and releases the GIL without having set the attribute yet.
- `release_gstate` for thread 1 is now unblocked and gets the GIL, but since `thread_local` was blown away before, it doesn't have the `name` anymore, resulting in an `AttributeError`.
- `init_python_thread` for thread 2 gets the GIL again and finishes up, then hands off the GIL to `release_gstate`.

That aside, I would suggest avoiding passing `PyGILState_STATE` and `PyThreadState` pointers up to the main function like you're currently doing. It's not wrong, but it's error-prone; if you accidentally use either of those in a different thread than where they were created, you'll get all sorts of hard-to-debug crashes.

---

I've seen several reports before due to `PyGILState_Ensure` inconsistencies. It would definitely be helpful to tell us where things need to be documented better, so we don't run into problems like these. Where were you reading, and what kind of information would be useful to you?",[],['python'],github,https://github.com/python/cpython/issues/130394,{'repo': 'python/cpython'}
"curses.panel misbehaves when drawing `wchar_t` characters

# Bug report

### Bug description:

```
import curses
import curses.panel as panels

def make_panel(y_mag, x_mag, yO, xO):
 win = curses.newwin(y_mag, x_mag, yO, xO)
 panel = panels.new_panel(win)
 return win, panel


def mainloop(stdscr):
    stdscr.clear()
    stdscr.nodelay(True)
    curses.curs_set(0)
    w1, p1 = make_panel(3, 20, 0, 0)
    w2, p2 = make_panel(3, 20, 0, 0)
    panels.update_panels()
    w1.addstr(0, 0, '-----------')
    # w2.addstr(0, 5, 'd')  # works
    w2.addstr(0, 5, '港d')  # works (kind of)
    # w2.addstr(0, 5, '港')  # fails to draw the contents of w1 to the right of the kanji character
    run = True
    while run:
        w1.refresh()
        w2.refresh()
        panels.update_panels()

        c = stdscr.getch()
        if c == 113:  # q
            run = False


if __name__ == '__main__':
    curses.wrapper(mainloop)
```
When using kanji charcters in panels, the content to the right of the character in the same row is not displayed. If the kanji is followed by a regular ascii character, everything displays as normal. The doc is a bit limited, so I'm not entirely clear if the panel should be showing anything at all from the panel below, but either way, this doesn't seem to be working as intended. Thanks for any insight :)

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS","[""import curses\nimport curses.panel as panels\n\ndef make_panel(y_mag, x_mag, yO, xO):\n win = curses.newwin(y_mag, x_mag, yO, xO)\n panel = panels.new_panel(win)\n return win, panel\n\n\ndef mainloop(stdscr):\n    stdscr.clear()\n    stdscr.nodelay(True)\n    curses.curs_set(0)\n    w1, p1 = make_panel(3, 20, 0, 0)\n    w2, p2 = make_panel(3, 20, 0, 0)\n    panels.update_panels()\n    w1.addstr(0, 0, '-----------')\n    # w2.addstr(0, 5, 'd')  # works\n    w2.addstr(0, 5, '港d')  # works (kind of)\n    # w2.addstr(0, 5, '港')  # fails to draw the contents of w1 to the right of the kanji character\n    run = True\n    while run:\n        w1.refresh()\n        w2.refresh()\n        panels.update_panels()\n\n        c = stdscr.getch()\n        if c == 113:  # q\n            run = False\n\n\nif __name__ == '__main__':\n    curses.wrapper(mainloop)""]","> I can reproduce this using the python.org installer. One thing I noticed: `HAVE_NCURSESW` is false for this build

(FTR, there is an issue with current 3.12 and 3.13 python.org installers for macOS that has caused them to inadvertently link with the system-supplied ncurses libraries. This problem has been corrected in the 3.14.0 alpha 5 preview with the upgrade to ncurses 6.5 which will also appear in the next releases of 3.12 (3.12.10) and 3.13 (3.13.3). But, as noted above, that doesn't seem to be a factor here.) ",[],['python'],github,https://github.com/python/cpython/issues/130161,{'repo': 'python/cpython'}
"Multithreaded, multiinterpreter software that worked fine with 3.12, but 3.13 it goes to a deadlock in PyImport_ImportModule()

# Bug report

### Bug description:

I used the following code successfully in 3.12 (cut down to the minimum to reproduce the bug):

```c
#include <thread>

#define PY_SSIZE_T_CLEAN
#include <Python.h>

PyThreadState *mPts;

void part2(int)
{
  PyThreadState_Swap(mPts);
  PyObject *pScript = PyImport_ImportModule(""r"");
  if (NULL == pScript)
  {
    PyErr_Print();
    exit(1);
  }
}

int main()
{
  setenv(""PYTHONPATH"", ""."", 1);
  Py_InitializeEx(0);
  PyInterpreterConfig config = {
    .use_main_obmalloc = 0,
    .allow_fork = 0,
    .allow_exec = 0,
    .allow_threads = 0,
    .allow_daemon_threads = 0,
    .check_multi_interp_extensions = 1,
    .gil = PyInterpreterConfig_OWN_GIL,
  };

  PyThreadState *mainpts = PyThreadState_Get();
  mPts = mainpts;
  PyStatus status = Py_NewInterpreterFromConfig(&mPts, &config);
  if (PyStatus_Exception(status)) {Py_ExitStatusException(status); exit(1);}
  PyThreadState_Swap(mainpts);
  std::thread mThread(part2, 0);
  mThread.join();
  return 0;
}
```
with ""r.py"":
```py
import random
print(""hello"")
```

It seems the import is important, if removed, the deadlock goes away.


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['#include <thread>\n\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n\nPyThreadState *mPts;\n\nvoid part2(int)\n{\n  PyThreadState_Swap(mPts);\n  PyObject *pScript = PyImport_ImportModule(""r"");\n  if (NULL == pScript)\n  {\n    PyErr_Print();\n    exit(1);\n  }\n}\n\nint main()\n{\n  setenv(""PYTHONPATH"", ""."", 1);\n  Py_InitializeEx(0);\n  PyInterpreterConfig config = {\n    .use_main_obmalloc = 0,\n    .allow_fork = 0,\n    .allow_exec = 0,\n    .allow_threads = 0,\n    .allow_daemon_threads = 0,\n    .check_multi_interp_extensions = 1,\n    .gil = PyInterpreterConfig_OWN_GIL,\n  };\n\n  PyThreadState *mainpts = PyThreadState_Get();\n  mPts = mainpts;\n  PyStatus status = Py_NewInterpreterFromConfig(&mPts, &config);\n  if (PyStatus_Exception(status)) {Py_ExitStatusException(status); exit(1);}\n  PyThreadState_Swap(mainpts);\n  std::thread mThread(part2, 0);\n  mThread.join();\n  return 0;\n}', 'import random\nprint(""hello"")']","call stack:
[gdb.txt](https://github.com/user-attachments/files/18941434/gdb.txt)",[],['python'],github,https://github.com/python/cpython/issues/130501,{'repo': 'python/cpython'}
"possible race-condition with python-doc

# Bug report

### Bug description:


While working on [reproducible builds](https://reproducible-builds.org/) for [openSUSE](https://en.opensuse.org/openSUSE:Reproducible_Builds), I found that our python314 (and python311) doc sub-packages produce different html on 1-core-VMs and 4-core-VMs. This suggests that there is some race going on about what the correct content should be.

https://rb.zq1.de/other/python314-doc-compare.out has a diff

The interesting bit of it is
```diff
-<p class=""audit-hook"" id=""audit_event_cpython_run_stdin_1"">
+<p class=""audit-hook"" id=""audit_event_cpython_run_stdin_2"">
```



### How to Reproduce

To test on openSUSE or Debian, use
```bash
osc checkout openSUSE:Factory/python314 && cd $_
for N in 1 14 ; do
    osc build -M=doc --noservice --clean --vm-type=kvm -j$N --release=1.1 --keep-pkg=RPMS.$N standard
    (cd RPMS.$N && unrpm python314-doc-3*.x86_64.rpm)
done
diff -ru RPMS.{1,14}/usr/
```

### Environment Information

```text
OS: openSUSE Tumbleweed 20250302
Sphinx-8.1.3
```

### Sphinx extensions

```python

```

### Additional context

This bug was found while working on [reproducible builds for openSUSE](https://en.opensuse.org/openSUSE:Reproducible_Builds).

This was originally filed in https://github.com/sphinx-doc/sphinx/issues/13419 but apparently the Sphinx people think this is an issue in cpython.

### CPython versions tested on:

3.11, 3.14, 3.13, 3.12

### Operating systems tested on:

Linux","['-<p class=""audit-hook"" id=""audit_event_cpython_run_stdin_1"">\n+<p class=""audit-hook"" id=""audit_event_cpython_run_stdin_2"">', 'osc checkout openSUSE:Factory/python314 && cd $_\nfor N in 1 14 ; do\n    osc build -M=doc --noservice --clean --vm-type=kvm -j$N --release=1.1 --keep-pkg=RPMS.$N standard\n    (cd RPMS.$N && unrpm python314-doc-3*.x86_64.rpm)\ndone\ndiff -ru RPMS.{1,14}/usr/', 'OS: openSUSE Tumbleweed 20250302\nSphinx-8.1.3']","I think Adam thinks its a CPython issue because it happens when building the docs of CPython. However it could also be a Sphinx issue (but first let's investigate if it's a CPython issue due to our CPython Sphinx extensions)

(btw, Adam and I are both Sphinx maintainers and CPython core devs so we would probably be responsible for solving the problem on either side)",[],['python'],github,https://github.com/python/cpython/issues/130979,{'repo': 'python/cpython'}
"Increase test coverage of `gettext.find` and `gettext._expand_lang`

The test coverage for these functions is low as there are no dedicated tests for them. I propose we add tests for these functions.
This will come in handy if/when we decide to fix https://github.com/python/cpython/issues/64243.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130656
* gh-130671
* gh-130672
* gh-130691
<!-- /gh-linked-prs -->
",[],I'll open a PR for find sometime tomorrow :-),[],['python'],github,https://github.com/python/cpython/issues/130655,{'repo': 'python/cpython'}
"warnings.catch_warnings docstring: obsolete compat note

The docstring for `warnings.catch_warnings.__init__` reads:

```
For compatibility with Python 3.0, please consider all arguments to be
keyword-only.
```

This makes little sense these days.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129845
<!-- /gh-linked-prs -->
","['For compatibility with Python 3.0, please consider all arguments to be\nkeyword-only.']","Please, feel free to send a PR with the fix. It is a good first issue :)",[],['python'],github,https://github.com/python/cpython/issues/129842,{'repo': 'python/cpython'}
"The doc for `-m` command doesn't completely state how the code is looked up

The current [python doc for `-m`](https://docs.python.org/3/using/cmdline.html#interface-options) option of python command states this 
> Search [sys.path](https://docs.python.org/3/library/sys.html#sys.path) for the named module and execute its contents as the [__main__](https://docs.python.org/3/library/__main__.html#module-__main__) module.

and this

> As with the [-c](https://docs.python.org/3/using/cmdline.html#cmdoption-c) option, the current directory will be added to the start of [sys.path](https://docs.python.org/3/library/sys.html#sys.path).

This would mean a file with any name, even if it matches with a builtin command would be run as long as we run the `python -m` command from the directory of the file. This is not completely true. 

If you name a file `os.py` (although no one would in reality, but the point is to just correct the doc) and run `python -m os` from the same directory, the custom file isn't run. It is because `os` is already imported when python is setting up, it is there in `sys.modules` even before the code is looked up. And the standard import process first looks at `sys.modules` and stops there.

So, the standard import process is used for looking up the code and not just the `sys.path`. It is clearly stated in the docs for [runpy.run_module](https://docs.python.org/3/library/runpy.html#runpy.run_module) which provides the same functionality as `-m`
> The module’s code is first located using the standard import mechanism ...

So, the doc for `-m` should state the same.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129861
* gh-129862
<!-- /gh-linked-prs -->
",[],"If allowed, I would like to contribute for the same.",[],['python'],github,https://github.com/python/cpython/issues/129851,{'repo': 'python/cpython'}
"JIT build crashes on Windows on Arm

# Crash report

### What happened?

The JIT on Windows on Arm (tested on Windows 11 Pro) is broken. It builds successfully but then the first test fails straightaway crashing the binary.

Also if I run the REPL and start typing commands, it stays alive for a few seconds and then dies.

When Python is built without the JIT, the test suite passes.

```
PS C:\Users\ent-user\cpython> .\PCbuild\build.bat -p ARM64 --experimental-jit
....
....
  Generating code
  Finished generating code
  python.vcxproj -> C:\Users\ent-user\cpython\PCbuild\arm64\python.exe
  Wrote C:\Users\ent-user\cpython\PCbuild\arm64\LICENSE.txt
  Generating code
  Finished generating code
  pythonw.vcxproj -> C:\Users\ent-user\cpython\PCbuild\arm64\pythonw.exeBuild succeeded.C:\Users\ent-user\cpython\Python\optimizer_symbols.c(487,20): warning C4244: 'return': conversion from 'Py_ssize_t' to
'int', possible loss of data [C:\Users\ent-user\cpython\PCbuild\pythoncore.vcxproj]
    1 Warning(s)
    0 Error(s)Time Elapsed 00:02:07.70


PS C:\Users\ent-user\cpython> .\python.bat -m test
Running Release|ARM64 interpreter...
== CPython 3.14.0a4+ (heads/main:d7672e5d5a, Feb 10 2025, 15:21:49) [MSC v.1940 64 bit (ARM64)]
== Windows-11-10.0.26100-SP0 little-endian
== Python build: release with_assert
== cwd: C:\Users\ent-user\cpython\build\test_python_worker_5516æ
== CPU count: 8
== encodings: locale=cp1252 FS=utf-8
== resources: all test resources are disabled, use -u option to unskip tests
Using random seed: 1919085789
0:00:00 Run 484 tests sequentially in a single process
0:00:00 [  1/484] test.test_asyncio.test_base_events
Windows fatal exception: access violation
Thread 0x0000093c (most recent call first):
  File ""C:\Users\ent-user\cpython\Lib\linecache.py"", line 75 in checkcache
  File ""C:\Users\ent-user\cpython\Lib\traceback.py"", line 487 in _extract_from_extended_frame_gen
  File ""C:\Users\ent-user\cpython\Lib\traceback.py"", line 445 in extract
  File ""C:\Users\ent-user\cpython\Lib\asyncio\format_helpers.py"", line 80 in extract_stack
  File ""C:\Users\ent-user\cpython\Lib\asyncio\events.py"", line 55 in __init__
  File ""C:\Users\ent-user\cpython\Lib\asyncio\events.py"", line 123 in __init__
  File ""__init__"", line ??? in __init__
  File ""C:\Users\ent-user\cpython\Lib\asyncio\base_events.py"", line 875 in call_soon_threadsafe
  File ""C:\Users\ent-user\cpython\Lib\asyncio\base_events.py"", line 2062 in set_debug
  File ""C:\Users\ent-user\cpython\Lib\test\test_asyncio\test_base_events.py"", line 310 in check_thread
  File ""C:\Users\ent-user\cpython\Lib\test\test_asyncio\test_base_events.py"", line 340 in check_in_thread
  File ""C:\Users\ent-user\cpython\Lib\threading.py"", line 996 in run
  File ""C:\Users\ent-user\cpython\Lib\threading.py"", line 1054 in _bootstrap_inner
  File ""C:\Users\ent-user\cpython\Lib\threading.py"", line 1016 in _bootstrap
Thread 0x00003824 (most recent call first):
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\win_utils.py"", line 47 in _update_load
Current thread 0x00001db8 (most recent call first):
  File ""C:\Users\ent-user\cpython\Lib\asyncio\base_events.py"", line 1965 in _run_once
  File ""C:\Users\ent-user\cpython\Lib\asyncio\base_events.py"", line 677 in run_forever
  File ""C:\Users\ent-user\cpython\Lib\asyncio\base_events.py"", line 706 in run_until_complete
  File ""C:\Users\ent-user\cpython\Lib\test\test_asyncio\test_base_events.py"", line 353 in test_thread
  File ""C:\Users\ent-user\cpython\Lib\test\test_asyncio\test_base_events.py"", line 360 in test_check_thread
  File ""C:\Users\ent-user\cpython\Lib\unittest\case.py"", line 606 in _callTestMethod
  File ""C:\Users\ent-user\cpython\Lib\unittest\case.py"", line 660 in run
  File ""C:\Users\ent-user\cpython\Lib\unittest\case.py"", line 716 in __call__
  File ""C:\Users\ent-user\cpython\Lib\unittest\suite.py"", line 122 in run
  File ""C:\Users\ent-user\cpython\Lib\unittest\suite.py"", line 84 in __call__
  File ""C:\Users\ent-user\cpython\Lib\unittest\suite.py"", line 122 in run
  File ""C:\Users\ent-user\cpython\Lib\unittest\suite.py"", line 84 in __call__
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\testresult.py"", line 148 in run
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 84 in _run_suite
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 42 in run_unittest
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 162 in test_func
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 118 in regrtest_runner
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 165 in _load_run_test
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 210 in _runtest_env_changed_exc
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 319 in _runtest
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\single.py"", line 348 in run_single_test
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 378 in run_test
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 412 in run_tests_sequentially
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 559 in _run_tests
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 594 in run_tests
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 766 in main
  File ""C:\Users\ent-user\cpython\Lib\test\libregrtest\main.py"", line 774 in main
  File ""C:\Users\ent-user\cpython\Lib\test\__main__.py"", line 2 in <module>
  File ""<frozen runpy>"", line 88 in _run_code
  File ""<frozen runpy>"", line 198 in _run_module_as_main
PS C:\Users\ent-user\cpython> 
```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Windows

### Output from running 'python -VV' on the command line:

.\python.bat -VV
Running Release|ARM64 interpreter...
Python 3.14.0a4+ (heads/main:d7672e5d5a, Feb 10 2025, 15:21:49) [MSC v.1940 64 bit (ARM64)]

<!-- gh-linked-prs -->
### Linked PRs
* gh-130882
<!-- /gh-linked-prs -->
","['PS C:\\Users\\ent-user\\cpython> .\\PCbuild\\build.bat -p ARM64 --experimental-jit\n....\n....\n  Generating code\n  Finished generating code\n  python.vcxproj -> C:\\Users\\ent-user\\cpython\\PCbuild\\arm64\\python.exe\n  Wrote C:\\Users\\ent-user\\cpython\\PCbuild\\arm64\\LICENSE.txt\n  Generating code\n  Finished generating code\n  pythonw.vcxproj -> C:\\Users\\ent-user\\cpython\\PCbuild\\arm64\\pythonw.exeBuild succeeded.C:\\Users\\ent-user\\cpython\\Python\\optimizer_symbols.c(487,20): warning C4244: \'return\': conversion from \'Py_ssize_t\' to\n\'int\', possible loss of data [C:\\Users\\ent-user\\cpython\\PCbuild\\pythoncore.vcxproj]\n    1 Warning(s)\n    0 Error(s)Time Elapsed 00:02:07.70\n\n\nPS C:\\Users\\ent-user\\cpython> .\\python.bat -m test\nRunning Release|ARM64 interpreter...\n== CPython 3.14.0a4+ (heads/main:d7672e5d5a, Feb 10 2025, 15:21:49) [MSC v.1940 64 bit (ARM64)]\n== Windows-11-10.0.26100-SP0 little-endian\n== Python build: release with_assert\n== cwd: C:\\Users\\ent-user\\cpython\\build\\test_python_worker_5516æ\n== CPU count: 8\n== encodings: locale=cp1252 FS=utf-8\n== resources: all test resources are disabled, use -u option to unskip tests\nUsing random seed: 1919085789\n0:00:00 Run 484 tests sequentially in a single process\n0:00:00 [  1/484] test.test_asyncio.test_base_events\nWindows fatal exception: access violation\nThread 0x0000093c (most recent call first):\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\linecache.py"", line 75 in checkcache\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\traceback.py"", line 487 in _extract_from_extended_frame_gen\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\traceback.py"", line 445 in extract\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\format_helpers.py"", line 80 in extract_stack\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\events.py"", line 55 in __init__\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\events.py"", line 123 in __init__\n  File ""__init__"", line ??? in __init__\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\base_events.py"", line 875 in call_soon_threadsafe\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\base_events.py"", line 2062 in set_debug\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\test_asyncio\\test_base_events.py"", line 310 in check_thread\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\test_asyncio\\test_base_events.py"", line 340 in check_in_thread\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\threading.py"", line 996 in run\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\threading.py"", line 1054 in _bootstrap_inner\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\threading.py"", line 1016 in _bootstrap\nThread 0x00003824 (most recent call first):\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\win_utils.py"", line 47 in _update_load\nCurrent thread 0x00001db8 (most recent call first):\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\base_events.py"", line 1965 in _run_once\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\base_events.py"", line 677 in run_forever\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\asyncio\\base_events.py"", line 706 in run_until_complete\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\test_asyncio\\test_base_events.py"", line 353 in test_thread\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\test_asyncio\\test_base_events.py"", line 360 in test_check_thread\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\case.py"", line 606 in _callTestMethod\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\case.py"", line 660 in run\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\case.py"", line 716 in __call__\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\suite.py"", line 122 in run\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\suite.py"", line 84 in __call__\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\suite.py"", line 122 in run\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\unittest\\suite.py"", line 84 in __call__\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\testresult.py"", line 148 in run\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 84 in _run_suite\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 42 in run_unittest\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 162 in test_func\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 118 in regrtest_runner\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 165 in _load_run_test\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 210 in _runtest_env_changed_exc\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 319 in _runtest\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\single.py"", line 348 in run_single_test\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 378 in run_test\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 412 in run_tests_sequentially\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 559 in _run_tests\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 594 in run_tests\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 766 in main\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\libregrtest\\main.py"", line 774 in main\n  File ""C:\\Users\\ent-user\\cpython\\Lib\\test\\__main__.py"", line 2 in <module>\n  File ""<frozen runpy>"", line 88 in _run_code\n  File ""<frozen runpy>"", line 198 in _run_module_as_main\nPS C:\\Users\\ent-user\\cpython>']","Yeah, this is one of the downsides of building, but not testing, this. Did you want to dig into it, or should I?

I'm guessing we're just relocating something wrong after both of our Clang upgrades. Hopefully something a manual review of the stencils can shake out.",[],['python'],github,https://github.com/python/cpython/issues/129964,{'repo': 'python/cpython'}
"`break` works after a sleep value below 1

# Bug report

### Bug description:

```python
# Add a code block here, if required
import time
input (""the ceiling says gullible on it!"")
while True:
        print (""you are an idiot!"")
        print (""hahahahahahahahah"")
        time.sleep(.5)
        if input(""IDIOT""):
         break

```
OS used: ubuntu 24.04.2
Found a bug in python3 where if the time.sleep is set to a value such as .5 then any break value may stop working in script (in the context of a loop).

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux","['# Add a code block here, if required\nimport time\ninput (""the ceiling says gullible on it!"")\nwhile True:\n        print (""you are an idiot!"")\n        print (""hahahahahahahahah"")\n        time.sleep(.5)\n        if input(""IDIOT""):\n         break']",I can't reproduce this.,[],['python'],github,https://github.com/python/cpython/issues/130166,{'repo': 'python/cpython'}
"IDLE submenu stays open if you switch windows

# Bug report

### Bug description:

The sub menu does not close automatically and when I switch windows with it open it stays on top of whatever window I've opened. The screenshot below shows the behavior.

![Image](https://github.com/user-attachments/assets/b130a176-4398-4425-a359-6ae4ff3122c3)

Occurs in both 3.13 and main branch. Running Fedora 41 GNOME

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux",[],"Everything between 'behavior.' and 'Occurs in' is the included image.  I don't see anything like this on Windows or macOS.  The menu goes away when focus goes away, so is gone when returning focus to IDLE.  So I am marking this as tkinter on Linux issue.",[],['python'],github,https://github.com/python/cpython/issues/130045,{'repo': 'python/cpython'}
"inspect.Signature documentation incorrect on ""parameters"" parameter

# Bug report

### Bug description:

[The documentation](https://docs.python.org/3/library/inspect.html#inspect.Signature.parameters) states:

>  **parameters**  
>    An ordered mapping of parameters’ names to the corresponding Parameter objects.

This is incorrect and it should actually be an iterable, as that is how the code treats it. If you pass it a mapping, the code will iterate over it, and only obtain the keys, and not the values.

```python
import inspect

def foo(arg):
    ...

sig = inspect.signature(foo)

print(repr(sig.parameters))
sig.replace(parameters=sig.parameters)
```

```
mappingproxy(OrderedDict({'arg': <Parameter ""arg"">}))
Traceback (most recent call last):
  File ""/tmp/test.py"", line 9, in <module>
    sig.replace(parameters=sig.parameters)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.13/inspect.py"", line 3094, in replace
    return type(self)(parameters,
           ~~~~~~~~~~^^^^^^^^^^^^
                      return_annotation=return_annotation)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.13/inspect.py"", line 3029, in __init__
    kind = param.kind
           ^^^^^^^^^^
AttributeError: 'str' object has no attribute 'kind'. Did you mean: 'find'?
```

Tested on 3.13.2

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['import inspect\n\ndef foo(arg):\n    ...\n\nsig = inspect.signature(foo)\n\nprint(repr(sig.parameters))\nsig.replace(parameters=sig.parameters)', 'mappingproxy(OrderedDict({\'arg\': <Parameter ""arg"">}))\nTraceback (most recent call last):\n  File ""/tmp/test.py"", line 9, in <module>\n    sig.replace(parameters=sig.parameters)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/lib/python3.13/inspect.py"", line 3094, in replace\n    return type(self)(parameters,\n           ~~~~~~~~~~^^^^^^^^^^^^\n                      return_annotation=return_annotation)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/local/lib/python3.13/inspect.py"", line 3029, in __init__\n    kind = param.kind\n           ^^^^^^^^^^\nAttributeError: \'str\' object has no attribute \'kind\'. Did you mean: \'find\'?']","The documentation is for the attribute, not the constructor parameter; the two have different types. Perhaps the docs could be rewritten to make this clearer.",[],['python'],github,https://github.com/python/cpython/issues/130818,{'repo': 'python/cpython'}
"nogil list `reverse` breaks atomicity

# Bug report

### Bug description:

Hi,

We're a research group focused on testing concurrent runtimes. Our work-in-progress prototype found a violation of atomicity on the current nogil build when using list `reverse` with other concurrent operations on the same list. The program below shows the wrong behavior for `reverse` and `__contains__`:

```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    s.reverse()

def t1(b1,s,res):
    b1.wait()
    res.append(s.__contains__(3))

def Test():
  l =  [1, 2, 3]
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, l,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, l,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] != True:
      print(""found bug: "" + str(res))

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```

Operation `__contains__` should always see element `3` in the list, either the original or reversed.  However, it can see a list without element `3` and return `False`, as shown in the sample output:

```
test begin...                                                                                                                                                                                                       
0                                                                                                         
found bug: [False]
found bug: [False]
1000
```

We observed the same behavior with operations `count` and `index` executing concurrently with `reverse` on the same list, I'll add a comment with those tests and sample outputs.

@flypoodles and @overlorde are part of the team, adding them so they get notified about further discussion.

We note that we observed these outputs in several x86_64 machines and one ARM machine.

### CPython versions tested on:

3.14, CPython main branch

### Operating systems tested on:

Linux","['import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    s.reverse()\n\ndef t1(b1,s,res):\n    b1.wait()\n    res.append(s.__contains__(3))\n\ndef Test():\n  l =  [1, 2, 3]\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, l,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, l,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] != True:\n      print(""found bug: "" + str(res))\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...                                                                                                                                                                                                       \n0                                                                                                         \nfound bug: [False]\nfound bug: [False]\n1000']","I don't think you need to attempt to reproduce the issue. It's clear to me from the implementation that this can happen: `list. __contains__` and `list.__getitem__` do not lock, so they can overlap with operations like `reverse`. `reverse` operates in-place, so you can see partial results.

I don't think we should change the implementation, but we will want to document the behavior.

Making reverse behave atomically would require either locking in all read operations or changing reverse to perform the operation out of place before swapping the `ob_item` pointers atomically. I don't think either option is worthwhile.

In general, we should not rush to make multi-element operations atomic.",[],['python'],github,https://github.com/python/cpython/issues/129619,{'repo': 'python/cpython'}
"`Lib/http/__init__.py` mentions RFF instead of RFC

# Documentation

Just a typo in 3.13, where http mentions `RFF` instead of `RFC`


<!-- gh-linked-prs -->
### Linked PRs
* gh-129411
* gh-129414
<!-- /gh-linked-prs -->
",[],"The bug was added to the class HTTPMethod docstring in 3.13 when a line was updated (and moved because of other additions).
```
(3.12 line 180)  * RFC 7231: Hypertext Transfer Protocol (HTTP/1.1), obsoletes 2616 
(3.13 line 193)  * RFF 9110: HTTP Semantics, obsoletes 7231, which obsoleted 2616
```

","['(3.12 line 180)  * RFC 7231: Hypertext Transfer Protocol (HTTP/1.1), obsoletes 2616 \n(3.13 line 193)  * RFF 9110: HTTP Semantics, obsoletes 7231, which obsoleted 2616']",['python'],github,https://github.com/python/cpython/issues/129408,{'repo': 'python/cpython'}
"Race between `dict_dealloc` and `split_keys_entry_added` under free threading

# Bug report

### Bug description:

In the following code it appears we race on the `dk_nentries` of a split keys dict.

```python
import concurrent.futures
import functools
import threading
import _testcapi

num_threads = 32

def closure(b, i):
  b.wait()
  h = _testcapi.HeapCTypeWithManagedDict()
  h.__dict__[f""asdf{i}""] = ""bar""

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
  for i in range(1000):
    b = threading.Barrier(num_threads)
    for i in range(num_threads):
      executor.submit(functools.partial(closure, b, i))
```


TSAN report:
```
WARNING: ThreadSanitizer: data race (pid=3466735)
  Read of size 8 at 0x7ffa06cba218 by thread T32:
    #0 dict_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:3170:42 (python3.13+0x26b02f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #1 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #2 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)
    #3 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x271cf7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #4 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x271cf7)
    #5 _PyObject_SetManagedDict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7151:13 (python3.13+0x271cf7)
    #6 PyObject_ClearManagedDict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7175:9 (python3.13+0x272317) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #7 heapmanaged_dealloc /usr/local/google/home/phawkins/p/cpython/./Modules/_testcapi/heaptype.c:822:5 (_testcapi.cpython-313t-x86_64-linux-gnu.so+0x21566) (BuildId: bcb92e2e6763ccff2c40c066ebaf418e7c3dee07)
    #8 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #9 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)
    #10 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x227b98) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #11 frame_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/frameobject.c:1728:13 (python3.13+0x227b98)
    #12 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #13 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)
    #14 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x4bde23) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #15 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x4bde23)
    #16 tb_dealloc /usr/local/google/home/phawkins/p/cpython/Python/traceback.c:188:5 (python3.13+0x4bde23)
    #17 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #18 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)
    #19 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x4bdda3) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #20 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x4bdda3)
    #21 tb_dealloc /usr/local/google/home/phawkins/p/cpython/Python/traceback.c:187:5 (python3.13+0x4bdda3)
    #22 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #23 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)
    #24 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x209a86) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #25 BaseException_clear /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:87:5 (python3.13+0x209a86)
    #26 NameError_clear /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:2228:12 (python3.13+0x210fac) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #27 NameError_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:2235:5 (python3.13+0x210fac)
    #28 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2904a5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #29 merge_queued_objects /usr/local/google/home/phawkins/p/cpython/Python/brc.c:110:13 (python3.13+0x3dca2a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #30 _Py_brc_merge_refcounts /usr/local/google/home/phawkins/p/cpython/Python/brc.c:131:5 (python3.13+0x3dca2a)
    #31 _Py_HandlePending /usr/local/google/home/phawkins/p/cpython/Python/ceval_gil.c:1289:9 (python3.13+0x45358e) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #32 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5160:17 (python3.13+0x3f2f00) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #33 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #34 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)
    #35 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #36 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef2d5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #37 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:62:18 (python3.13+0x1ef2d5)
    #38 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ead4a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #39 PyObject_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c:327:12 (python3.13+0x1ead4a)
    #40 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e264b) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #41 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #42 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)
    #43 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #44 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef38f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #45 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef38f)
    #46 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #47 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)
    #48 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #49 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x5649a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #50 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bdca7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)

  Previous atomic write of size 8 at 0x7ffa06cba218 by thread T2:
    #0 _Py_atomic_store_ssize_relaxed /usr/local/google/home/phawkins/p/cpython/./Include/cpython/pyatomic_gcc.h:481:3 (python3.13+0x273284) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #1 split_keys_entry_added /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:225:5 (python3.13+0x273284)
    #2 insert_split_key /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:1743:9 (python3.13+0x273284)
    #3 insertdict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:1796:25 (python3.13+0x263496) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #4 setitem_take2_lock_held /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2507:12 (python3.13+0x262996) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #5 _PyDict_SetItem_Take2 /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2515:11 (python3.13+0x262bcf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #6 PyDict_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2535:12 (python3.13+0x262bcf)
    #7 dict_ass_sub /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:3340:16 (python3.13+0x27557a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #8 PyObject_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/abstract.c:232:19 (python3.13+0x1b9488) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #9 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5777:27 (python3.13+0x3f5d0b) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #10 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #11 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)
    #12 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #13 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x5722c2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #14 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x5722c2)
    #15 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #16 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)
    #17 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #18 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e4832) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #19 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #20 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)
    #21 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #22 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef38f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #23 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef38f)
    #24 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #25 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)
    #26 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #27 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x5649a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
    #28 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bdca7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)
```

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130778
* gh-130833
<!-- /gh-linked-prs -->
","['import concurrent.futures\nimport functools\nimport threading\nimport _testcapi\n\nnum_threads = 32\n\ndef closure(b, i):\n  b.wait()\n  h = _testcapi.HeapCTypeWithManagedDict()\n  h.__dict__[f""asdf{i}""] = ""bar""\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n  for i in range(1000):\n    b = threading.Barrier(num_threads)\n    for i in range(num_threads):\n      executor.submit(functools.partial(closure, b, i))', 'WARNING: ThreadSanitizer: data race (pid=3466735)\n  Read of size 8 at 0x7ffa06cba218 by thread T32:\n    #0 dict_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:3170:42 (python3.13+0x26b02f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #1 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #2 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)\n    #3 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x271cf7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #4 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x271cf7)\n    #5 _PyObject_SetManagedDict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7151:13 (python3.13+0x271cf7)\n    #6 PyObject_ClearManagedDict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7175:9 (python3.13+0x272317) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #7 heapmanaged_dealloc /usr/local/google/home/phawkins/p/cpython/./Modules/_testcapi/heaptype.c:822:5 (_testcapi.cpython-313t-x86_64-linux-gnu.so+0x21566) (BuildId: bcb92e2e6763ccff2c40c066ebaf418e7c3dee07)\n    #8 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #9 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)\n    #10 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x227b98) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #11 frame_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/frameobject.c:1728:13 (python3.13+0x227b98)\n    #12 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #13 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)\n    #14 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x4bde23) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #15 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x4bde23)\n    #16 tb_dealloc /usr/local/google/home/phawkins/p/cpython/Python/traceback.c:188:5 (python3.13+0x4bde23)\n    #17 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #18 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)\n    #19 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x4bdda3) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #20 Py_XDECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:1042:9 (python3.13+0x4bdda3)\n    #21 tb_dealloc /usr/local/google/home/phawkins/p/cpython/Python/traceback.c:187:5 (python3.13+0x4bdda3)\n    #22 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2906a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #23 _Py_MergeZeroLocalRefcount /usr/local/google/home/phawkins/p/cpython/Objects/object.c (python3.13+0x2906a2)\n    #24 Py_DECREF /usr/local/google/home/phawkins/p/cpython/./Include/object.h:913:13 (python3.13+0x209a86) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #25 BaseException_clear /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:87:5 (python3.13+0x209a86)\n    #26 NameError_clear /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:2228:12 (python3.13+0x210fac) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #27 NameError_dealloc /usr/local/google/home/phawkins/p/cpython/Objects/exceptions.c:2235:5 (python3.13+0x210fac)\n    #28 _Py_Dealloc /usr/local/google/home/phawkins/p/cpython/Objects/object.c:2935:5 (python3.13+0x2904a5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #29 merge_queued_objects /usr/local/google/home/phawkins/p/cpython/Python/brc.c:110:13 (python3.13+0x3dca2a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #30 _Py_brc_merge_refcounts /usr/local/google/home/phawkins/p/cpython/Python/brc.c:131:5 (python3.13+0x3dca2a)\n    #31 _Py_HandlePending /usr/local/google/home/phawkins/p/cpython/Python/ceval_gil.c:1289:9 (python3.13+0x45358e) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #32 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5160:17 (python3.13+0x3f2f00) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #33 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #34 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)\n    #35 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #36 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef2d5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #37 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:62:18 (python3.13+0x1ef2d5)\n    #38 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ead4a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #39 PyObject_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c:327:12 (python3.13+0x1ead4a)\n    #40 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e264b) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #41 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #42 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)\n    #43 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #44 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef38f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #45 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef38f)\n    #46 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #47 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)\n    #48 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #49 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x5649a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #50 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bdca7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n\n  Previous atomic write of size 8 at 0x7ffa06cba218 by thread T2:\n    #0 _Py_atomic_store_ssize_relaxed /usr/local/google/home/phawkins/p/cpython/./Include/cpython/pyatomic_gcc.h:481:3 (python3.13+0x273284) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #1 split_keys_entry_added /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:225:5 (python3.13+0x273284)\n    #2 insert_split_key /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:1743:9 (python3.13+0x273284)\n    #3 insertdict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:1796:25 (python3.13+0x263496) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #4 setitem_take2_lock_held /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2507:12 (python3.13+0x262996) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #5 _PyDict_SetItem_Take2 /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2515:11 (python3.13+0x262bcf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #6 PyDict_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:2535:12 (python3.13+0x262bcf)\n    #7 dict_ass_sub /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:3340:16 (python3.13+0x27557a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #8 PyObject_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/abstract.c:232:19 (python3.13+0x1b9488) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #9 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5777:27 (python3.13+0x3f5d0b) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #10 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #11 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)\n    #12 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #13 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x5722c2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #14 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x5722c2)\n    #15 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #16 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)\n    #17 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #18 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e4832) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #19 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de77a) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #20 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1812:12 (python3.13+0x3de77a)\n    #21 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb3bf) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #22 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef38f) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #23 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef38f)\n    #24 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb033) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #25 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb033)\n    #26 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb0b5) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #27 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x5649a2) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)\n    #28 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bdca7) (BuildId: eba64ecb5d6238e288495b7377dad10e1b152da3)']",I will take a look :),[],['python'],github,https://github.com/python/cpython/issues/130547,{'repo': 'python/cpython'}
"Python documentation in Texinfo format: Problems with `dircategory` and `direntry` commands

# Documentation

The Python documentation could be downloaded in Texinfo and Info format.
Which is great, I'm very very thankful for it.

But their is multiple problems, in the `python.texi` file, with the `@dircategory` and `@direntry` commands.

The  `@dircategory` is now set to ""Miscellaneous"". It should be set to a more descriptive category. Like ""Programming"" or ""Programming language"" or ""Python"". A ""Python"" category could be re-used by other manuals related to Python. For example a manual for a Python framework or library.

In the `@direntry` command:
- The info file name, in parenthesis, should not include the `.info` extension [1]
- The menu entry description should be more descriptive than ""One line description of project""



[1] https://www.gnu.org/software/texinfo/manual/texinfo/texinfo.html#Listing-a-New-Info-File",[],"Looks like we need to add something like this to `conf.py` (this example taken from Sphinx itself):

```python
texinfo_documents = [
    (
        'index',
        'sphinx',
        'Sphinx Documentation',
        'the Sphinx developers',
        'Sphinx',
        'The Sphinx documentation builder.',
        'Documentation tools',
        True,
    ),
]
```

> This value determines how to group the document tree into Texinfo source files. It must be a list of tuples (startdocname, targetname, title, author, dir_entry, description, category, toctree_only), where the items are: ...

https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-texinfo-output","[""texinfo_documents = [\n    (\n        'index',\n        'sphinx',\n        'Sphinx Documentation',\n        'the Sphinx developers',\n        'Sphinx',\n        'The Sphinx documentation builder.',\n        'Documentation tools',\n        True,\n    ),\n]""]",['python'],github,https://github.com/python/cpython/issues/130517,{'repo': 'python/cpython'}
"Small typo in https://docs.python.org/3/library/unittest.mock.html#where-to-patch

https://docs.python.org/3/library/unittest.mock.html#where-to-patch has the text ""which we will have to do then it imports"" which should be ""which we will have to do when it imports"" (i.e. `s/then/when/`).

The source for this is 
https://github.com/python/cpython/blob/3bd3e09588bfde7edba78c55794a0e28e2d21ea5/Doc/library/unittest.mock.rst?plain=1#L2010-L2011

<!-- gh-linked-prs -->
### Linked PRs
* gh-130107
* gh-130143
* gh-130144
<!-- /gh-linked-prs -->
",[],"Dates back to at least 2014, so was backported.",[],['python'],github,https://github.com/python/cpython/issues/130106,{'repo': 'python/cpython'}
"Crash when concurrently writing with `print` and concurrently modifying `sys.stdout`

# Crash report

### What happened?

Playing with the code from #130148, I stumbled on a segfault in a free-threaded debug build with the following (seems to trigger faster/more consistently when pasted in the REPL):

```python
from contextlib import redirect_stdout
from io import StringIO
from threading import Thread
import time


def test_redirect():
    text = StringIO()
    with redirect_stdout(text):
        print(""hello1"", file=text)
        time.sleep(0.1)
        print(""hello2"", file=text)
    print(text.getvalue())
    assert text.getvalue() == ""hello1\nhello2\n""


for x in range(100):
    Thread(target=test_redirect, args=()).start()
```

~~I didn't have time to check whether JIT, debug or no-gil are strictly necessary for this to crash.~~ JIT is not needed for this to crash.


### Cause

The problem is that in the `print()` implementation, `_PySys_GetAttr` returns a borrowed reference. 

https://github.com/python/cpython/blob/655fc8a0fce3396fc1af3f7bc8f5c94ca8ec377d/Python/bltinmodule.c#L2173-L2175

So if `sys.stdout` changes concurrently with the `print()`, the program may crash because `file` will point to a deallocated Python object.

This affects the GIL-enabled build as well. See this reproducer: https://gist.github.com/colesbury/c48f50e95d5d68e24814a56e2664e587

### Suggested fix

Introduce a `_PySys_GetAttrRef` that returns a new reference instead of a borrowed reference. Use that instead.

We should audit all the uses of `_PySys_GetAttr` and `PySys_GetObject`. I expect most of them will need to be replaced with functions that return new references, but it doesn't all have to be in a single PR.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.14.0a5+ experimental free-threading build (heads/main:359c7dde3bb, Feb 15 2025, 17:54:11) [GCC 11.4.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-130282
* gh-130503
* gh-130556
* gh-130568
* gh-130576
<!-- /gh-linked-prs -->
","['from contextlib import redirect_stdout\nfrom io import StringIO\nfrom threading import Thread\nimport time\n\n\ndef test_redirect():\n    text = StringIO()\n    with redirect_stdout(text):\n        print(""hello1"", file=text)\n        time.sleep(0.1)\n        print(""hello2"", file=text)\n    print(text.getvalue())\n    assert text.getvalue() == ""hello1\\nhello2\\n""\n\n\nfor x in range(100):\n    Thread(target=test_redirect, args=()).start()']",And adding a critical section to `print` also doesn't help =/,[],['python'],github,https://github.com/python/cpython/issues/130163,{'repo': 'python/cpython'}
"Python 3.13.1 test_datetime failures

# Bug report

### Bug description:

Hi. I'm trying to build from source on a raspberry pi, on a fresh and fully updated debian bookworm install.

`test_datetime` was failing so I tried to get more information using `make test TESTOPTS=""-v test_datetime""` as suggested by the readme, but that just runs all tests again without additional output for test_datetime (see terminal output pastedbelow.

I hope that's enough information. I'll try to look a bit further, this is just where I got the feeling it might not be 100% my own fault anymore ;)

```System info:
karel@homeassistant:~/Python-3.13.0 $ lsb_release  -a
No LSB modules are available.
Distributor ID:	Debian
Description:	Debian GNU/Linux 12 (bookworm)
Release:	12
Codename:	bookworm
karel@homeassistant:~/Python-3.13.0 $ uname -a
Linux homeassistant 6.6.51+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.51-1+rpt3 (2024-10-08) aarch64 GNU/Linux
```

Test output

```
karel@homeassistant:~/Python-3.13.1 $ make test TESTOPTS=""-v test_datetime""
Running code to generate profile data (this can take a while):
# First, we need to create a clean build with profile generation
# enabled.
make profile-gen-stamp
make[1]: Entering directory '/home/karel/Python-3.13.1'
make[1]: 'profile-gen-stamp' is up to date.
make[1]: Leaving directory '/home/karel/Python-3.13.1'
# Next, run the profile task to generate the profile information.
./python -m test --pgo --timeout=
Using random seed: 1333715147
0:00:00 load avg: 0.33 Run 44 tests sequentially in a single process
0:00:00 load avg: 0.33 [ 1/44] test_array
0:00:02 load avg: 0.38 [ 2/44] test_base64
0:00:02 load avg: 0.38 [ 3/44] test_binascii
0:00:02 load avg: 0.38 [ 4/44] test_binop
0:00:02 load avg: 0.38 [ 5/44] test_bisect
0:00:03 load avg: 0.38 [ 6/44] test_bytes
0:00:08 load avg: 0.43 [ 7/44] test_bz2
0:00:09 load avg: 0.43 [ 8/44] test_cmath
0:00:10 load avg: 0.43 [ 9/44] test_codecs
0:00:11 load avg: 0.48 [10/44] test_collections
0:00:13 load avg: 0.48 [11/44] test_complex
0:00:14 load avg: 0.48 [12/44] test_dataclasses
0:00:15 load avg: 0.48 [13/44] test_datetime
test test_datetime failed
0:00:20 load avg: 0.52 [14/44] test_decimal -- test_datetime failed (4 failures)
0:00:26 load avg: 0.67 [15/44] test_difflib
0:00:27 load avg: 0.67 [16/44] test_embed
0:00:38 load avg: 0.72 [17/44] test_float
0:00:38 load avg: 0.72 [18/44] test_fstring
0:00:42 load avg: 0.74 [19/44] test_functools
0:00:43 load avg: 0.74 [20/44] test_generators
0:00:43 load avg: 0.74 [21/44] test_hashlib
0:00:44 load avg: 0.74 [22/44] test_heapq
0:00:45 load avg: 0.74 [23/44] test_int
0:00:46 load avg: 0.76 [24/44] test_itertools
0:00:53 load avg: 0.78 [25/44] test_json
... rest omitted...
```

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['info:\nkarel@homeassistant:~/Python-3.13.0 $ lsb_release  -a\nNo LSB modules are available.\nDistributor ID:\tDebian\nDescription:\tDebian GNU/Linux 12 (bookworm)\nRelease:\t12\nCodename:\tbookworm\nkarel@homeassistant:~/Python-3.13.0 $ uname -a\nLinux homeassistant 6.6.51+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.51-1+rpt3 (2024-10-08) aarch64 GNU/Linux', 'karel@homeassistant:~/Python-3.13.1 $ make test TESTOPTS=""-v test_datetime""\nRunning code to generate profile data (this can take a while):\n# First, we need to create a clean build with profile generation\n# enabled.\nmake profile-gen-stamp\nmake[1]: Entering directory \'/home/karel/Python-3.13.1\'\nmake[1]: \'profile-gen-stamp\' is up to date.\nmake[1]: Leaving directory \'/home/karel/Python-3.13.1\'\n# Next, run the profile task to generate the profile information.\n./python -m test --pgo --timeout=\nUsing random seed: 1333715147\n0:00:00 load avg: 0.33 Run 44 tests sequentially in a single process\n0:00:00 load avg: 0.33 [ 1/44] test_array\n0:00:02 load avg: 0.38 [ 2/44] test_base64\n0:00:02 load avg: 0.38 [ 3/44] test_binascii\n0:00:02 load avg: 0.38 [ 4/44] test_binop\n0:00:02 load avg: 0.38 [ 5/44] test_bisect\n0:00:03 load avg: 0.38 [ 6/44] test_bytes\n0:00:08 load avg: 0.43 [ 7/44] test_bz2\n0:00:09 load avg: 0.43 [ 8/44] test_cmath\n0:00:10 load avg: 0.43 [ 9/44] test_codecs\n0:00:11 load avg: 0.48 [10/44] test_collections\n0:00:13 load avg: 0.48 [11/44] test_complex\n0:00:14 load avg: 0.48 [12/44] test_dataclasses\n0:00:15 load avg: 0.48 [13/44] test_datetime\ntest test_datetime failed\n0:00:20 load avg: 0.52 [14/44] test_decimal -- test_datetime failed (4 failures)\n0:00:26 load avg: 0.67 [15/44] test_difflib\n0:00:27 load avg: 0.67 [16/44] test_embed\n0:00:38 load avg: 0.72 [17/44] test_float\n0:00:38 load avg: 0.72 [18/44] test_fstring\n0:00:42 load avg: 0.74 [19/44] test_functools\n0:00:43 load avg: 0.74 [20/44] test_generators\n0:00:43 load avg: 0.74 [21/44] test_hashlib\n0:00:44 load avg: 0.74 [22/44] test_heapq\n0:00:45 load avg: 0.74 [23/44] test_int\n0:00:46 load avg: 0.76 [24/44] test_itertools\n0:00:53 load avg: 0.78 [25/44] test_json\n... rest omitted...']","I ended up running ./python -mtest -v test_datetime and got the results listed below.
Looks like the test_vilnius_1949_* tests fail with something date formatting related. I suspect I have to configure a locale somewhere. I'll keep looking
```

======================================================================
FAIL: test_vilnius_1941_fromutc (test.datetimetester.TestLocalTimeDisambiguation_Pure.test_vilnius_1941_fromutc)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5808, in test_vilnius_1941_fromutc
    self.assertEqual(ldt.strftime(""%c %Z%z""),
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
                     'Mon Jun 23 23:59:59 1941 MSK+0300')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: 'Mon 23 Jun 1941 23:59:59 CET MSK+0300' != 'Mon Jun 23 23:59:59 1941 MSK+0300'
- Mon 23 Jun 1941 23:59:59 CET MSK+0300
?     ---    ^^^^          ^^^
+ Mon Jun 23 23:59:59 1941 MSK+0300
?         ^^          ^^^^


======================================================================
FAIL: test_vilnius_1941_toutc (test.datetimetester.TestLocalTimeDisambiguation_Pure.test_vilnius_1941_toutc)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5832, in test_vilnius_1941_toutc
    self.assertEqual(gdt.strftime(""%c %Z""),
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
                     'Mon Jun 23 19:59:59 1941 UTC')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: 'Mon 23 Jun 1941 19:59:59  UTC' != 'Mon Jun 23 19:59:59 1941 UTC'
- Mon 23 Jun 1941 19:59:59  UTC
?     ---    ^^^^
+ Mon Jun 23 19:59:59 1941 UTC
?         ^^          ++++


======================================================================
FAIL: test_vilnius_1941_fromutc (test.datetimetester.TestLocalTimeDisambiguation_Fast.test_vilnius_1941_fromutc)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5808, in test_vilnius_1941_fromutc
    self.assertEqual(ldt.strftime(""%c %Z%z""),
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
                     'Mon Jun 23 23:59:59 1941 MSK+0300')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: 'Mon 23 Jun 1941 23:59:59 CET MSK+0300' != 'Mon Jun 23 23:59:59 1941 MSK+0300'
- Mon 23 Jun 1941 23:59:59 CET MSK+0300
?     ---    ^^^^          ^^^
+ Mon Jun 23 23:59:59 1941 MSK+0300
?         ^^          ^^^^


======================================================================
FAIL: test_vilnius_1941_toutc (test.datetimetester.TestLocalTimeDisambiguation_Fast.test_vilnius_1941_toutc)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5832, in test_vilnius_1941_toutc
    self.assertEqual(gdt.strftime(""%c %Z""),
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
                     'Mon Jun 23 19:59:59 1941 UTC')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: 'Mon 23 Jun 1941 19:59:59  UTC' != 'Mon Jun 23 19:59:59 1941 UTC'
- Mon 23 Jun 1941 19:59:59  UTC
?     ---    ^^^^
+ Mon Jun 23 19:59:59 1941 UTC
?         ^^          ++++


----------------------------------------------------------------------
Ran 1036 tests in 4.967s

FAILED (failures=4, skipped=31)
test test_datetime failed
test_datetime failed (4 failures)

== Tests result: FAILURE ==

1 test failed:
    test_datetime

Total duration: 5.1 sec
Total tests: run=1,036 failures=4 skipped=31
Total test files: run=1/1 failed=1
Result: FAILURE
karel@homeassistant:~/Python-3.13.1 $ 
```","['======================================================================\nFAIL: test_vilnius_1941_fromutc (test.datetimetester.TestLocalTimeDisambiguation_Pure.test_vilnius_1941_fromutc)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5808, in test_vilnius_1941_fromutc\n    self.assertEqual(ldt.strftime(""%c %Z%z""),\n    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n                     \'Mon Jun 23 23:59:59 1941 MSK+0300\')\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: \'Mon 23 Jun 1941 23:59:59 CET MSK+0300\' != \'Mon Jun 23 23:59:59 1941 MSK+0300\'\n- Mon 23 Jun 1941 23:59:59 CET MSK+0300\n?     ---    ^^^^          ^^^\n+ Mon Jun 23 23:59:59 1941 MSK+0300\n?         ^^          ^^^^\n\n\n======================================================================\nFAIL: test_vilnius_1941_toutc (test.datetimetester.TestLocalTimeDisambiguation_Pure.test_vilnius_1941_toutc)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5832, in test_vilnius_1941_toutc\n    self.assertEqual(gdt.strftime(""%c %Z""),\n    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n                     \'Mon Jun 23 19:59:59 1941 UTC\')\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: \'Mon 23 Jun 1941 19:59:59  UTC\' != \'Mon Jun 23 19:59:59 1941 UTC\'\n- Mon 23 Jun 1941 19:59:59  UTC\n?     ---    ^^^^\n+ Mon Jun 23 19:59:59 1941 UTC\n?         ^^          ++++\n\n\n======================================================================\nFAIL: test_vilnius_1941_fromutc (test.datetimetester.TestLocalTimeDisambiguation_Fast.test_vilnius_1941_fromutc)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5808, in test_vilnius_1941_fromutc\n    self.assertEqual(ldt.strftime(""%c %Z%z""),\n    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n                     \'Mon Jun 23 23:59:59 1941 MSK+0300\')\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: \'Mon 23 Jun 1941 23:59:59 CET MSK+0300\' != \'Mon Jun 23 23:59:59 1941 MSK+0300\'\n- Mon 23 Jun 1941 23:59:59 CET MSK+0300\n?     ---    ^^^^          ^^^\n+ Mon Jun 23 23:59:59 1941 MSK+0300\n?         ^^          ^^^^\n\n\n======================================================================\nFAIL: test_vilnius_1941_toutc (test.datetimetester.TestLocalTimeDisambiguation_Fast.test_vilnius_1941_toutc)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/home/karel/Python-3.13.1/Lib/test/datetimetester.py"", line 5832, in test_vilnius_1941_toutc\n    self.assertEqual(gdt.strftime(""%c %Z""),\n    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n                     \'Mon Jun 23 19:59:59 1941 UTC\')\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: \'Mon 23 Jun 1941 19:59:59  UTC\' != \'Mon Jun 23 19:59:59 1941 UTC\'\n- Mon 23 Jun 1941 19:59:59  UTC\n?     ---    ^^^^\n+ Mon Jun 23 19:59:59 1941 UTC\n?         ^^          ++++\n\n\n----------------------------------------------------------------------\nRan 1036 tests in 4.967s\n\nFAILED (failures=4, skipped=31)\ntest test_datetime failed\ntest_datetime failed (4 failures)\n\n== Tests result: FAILURE ==\n\n1 test failed:\n    test_datetime\n\nTotal duration: 5.1 sec\nTotal tests: run=1,036 failures=4 skipped=31\nTotal test files: run=1/1 failed=1\nResult: FAILURE\nkarel@homeassistant:~/Python-3.13.1 $']",['python'],github,https://github.com/python/cpython/issues/129483,{'repo': 'python/cpython'}
"Missing error: ""parameter without a default follows parameter with a default"" with a function that uses `*args`

# Bug report

### Bug description:

Hey there,

I don't know if that's a bug or if that's expected behavior, but since it's weird I might as well get this checked out.
```python
>>> def f(*args, a = 0, b): pass
... 
>>> def f(a = 0, b): pass
  File ""<python-input-1>"", line 1
    def f(a = 0, b): pass
                 ^
SyntaxError: parameter without a default follows parameter with a default
```
I clearly understand the error here as it is not the first time I'm using Python, the thing that eludes me is: **why is there no error with the first function ?**

Thank you for your help !

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['>>> def f(*args, a = 0, b): pass\n... \n>>> def f(a = 0, b): pass\n  File ""<python-input-1>"", line 1\n    def f(a = 0, b): pass\n                 ^\nSyntaxError: parameter without a default follows parameter with a default']",">I don't know if that's a bug or if that's expected behavior,

Questions like this should go to https://discuss.python.org/c/help/7, where they are more likely to be found by others.",[],['python'],github,https://github.com/python/cpython/issues/129810,{'repo': 'python/cpython'}
"Unexpected sorted result

# Bug report

### Bug description:

Python 3.13 breaks the `sorted()` built-in using a custom class key. Here is some demo code to show it:
```python
class Within:
    def __init__(self, o):
        self.o = o
    def __lt__(self, other):
        print(""{}.issubset({}): {}"".format(self.o, other.o, self.o.issubset(other.o)))
        return self.o.issubset(other.o)

a = set([1])
b = set([1, 2])
c = set([1, 2, 3])
d = set([4])
actual = sorted([c, a, d, b, c], key=Within)
expected = [a, b, c, c, d]
print(""(actual == expected):"", actual == expected)
```
The `Within` class defines if a set is ""within"" another via [`issubset`](https://docs.python.org/3/library/stdtypes.html#frozenset.issubset) (or `<=` operator) method in `__lt__`, which also prints the comparison to show what the sort algorithm is comparing.

Testing with Python 3.3 to Python 3.12 via docker, the expected output is:
```
{1}.issubset({1, 2, 3}): True
{4}.issubset({1}): False
{4}.issubset({1, 2, 3}): False
{1, 2}.issubset({1, 2, 3}): True
{1, 2}.issubset({1}): False
{1, 2, 3}.issubset({1, 2, 3}): True
{1, 2, 3}.issubset({1, 2}): False
(actual == expected): True
```
But with Python 3.13.0 to 3.13.2 via docker, the output is unexpected:
```
{1}.issubset({1, 2, 3}): True
{4}.issubset({1}): False
{1}.issubset({4}): False
{1, 2}.issubset({4}): False
{4}.issubset({1, 2}): False
{1, 2, 3}.issubset({1, 2}): False
{1, 2}.issubset({1, 2, 3}): True
{1, 2, 3}.issubset({1, 2, 3}): True
{1, 2, 3}.issubset({1, 2}): False
{1, 2, 3}.issubset({1, 2, 3}): True
(actual == expected): False
```
The result (`[a, d, b, c, c]`) is incorrect and takes longer (more comparison combinations requested). Some of the comparisons are done more than once (e.g. `{1, 2, 3}.issubset({1, 2, 3})` and `{1, 2, 3}.issubset({1, 2})` each appear twice), but this is perhaps because `c` appears twice.

The background for this issue is that I discovered it while looking at upgrading doctesting for [this shapely manual](https://shapely.readthedocs.io/en/2.0.7/manual.html#object.within) using Python 3.13.1. The example make a custom class that uses a geospatial ""contains"" method for `__lt__`.

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['class Within:\n    def __init__(self, o):\n        self.o = o\n    def __lt__(self, other):\n        print(""{}.issubset({}): {}"".format(self.o, other.o, self.o.issubset(other.o)))\n        return self.o.issubset(other.o)\n\na = set([1])\nb = set([1, 2])\nc = set([1, 2, 3])\nd = set([4])\nactual = sorted([c, a, d, b, c], key=Within)\nexpected = [a, b, c, c, d]\nprint(""(actual == expected):"", actual == expected)', '{1}.issubset({1, 2, 3}): True\n{4}.issubset({1}): False\n{4}.issubset({1, 2, 3}): False\n{1, 2}.issubset({1, 2, 3}): True\n{1, 2}.issubset({1}): False\n{1, 2, 3}.issubset({1, 2, 3}): True\n{1, 2, 3}.issubset({1, 2}): False\n(actual == expected): True', '{1}.issubset({1, 2, 3}): True\n{4}.issubset({1}): False\n{1}.issubset({4}): False\n{1, 2}.issubset({4}): False\n{4}.issubset({1, 2}): False\n{1, 2, 3}.issubset({1, 2}): False\n{1, 2}.issubset({1, 2, 3}): True\n{1, 2, 3}.issubset({1, 2, 3}): True\n{1, 2, 3}.issubset({1, 2}): False\n{1, 2, 3}.issubset({1, 2, 3}): True\n(actual == expected): False']","`Within` is slightly buggy in implementing `<` as `<=`.  But this will not matter unless sort() calls `<` on equal objects, which it may not do.  The real bug, as Tomas said, is having an expectation on the 'sorted' position of the incomparable set {4}.  To me, the 3.13 result of sorting it 'small' is better that the earlier result of sorting it 'big'.  The Shapely User Manual has the same bug of expecting *any* particular result when comparing incomparable polygons.  (Why should the 'free-spirited point' be bigger than any polygon?)  Report that bug to the authors if you want.",[],['python'],github,https://github.com/python/cpython/issues/130823,{'repo': 'python/cpython'}
"🚨 Segmentation Fault in Python 3.10.12 when using OpenSSL (libcrypto.so.3)

# Crash report

### What happened?

[core_dump.tar.gz](https://github.com/user-attachments/files/18739749/core_dump.tar.gz)

## 🚨 Segmentation Fault in Python 3.10.12 when using OpenSSL (libcrypto.so.3)

### 🛠️ Operating System:
- **Python Version:** `Python 3.10.12`
- **OpenSSL Version:** `OpenSSL 3.0.2 15 Mar 2022`
- **Operating System:**  
  - Distributor ID: Ubuntu  
  - Description:    Ubuntu 22.04.5 LTS  
  - Release:        22.04  
  - Codename:       jammy  
  - Kernel:         5.15.0-117-generic x86_64

### 🔍 Stack Trace:
warning: core file may not match specified executable file.
[New LWP 1433243]
[New LWP 1433240]
[New LWP 1433235]
[New LWP 1433237]
[New LWP 1433244]
[New LWP 1514087]
[New LWP 1514116]
[New LWP 1433236]
[New LWP 1514707]
[New LWP 1514002]
[New LWP 1433234]
[New LWP 1433239]
[New LWP 1433241]
[New LWP 1433238]
[New LWP 1513877]
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
Core was generated by `python3 bot.py'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00001514dc039ce0 in ?? ()
[Current thread is 1 (Thread 0x15151113c640 (LWP 1433243))]
(gdb) bt full
#0  0x00001514dc039ce0 in ?? ()
No symbol table info available.
#1  0x0000151514d11ec3 in ?? () from /lib/x86_64-linux-gnu/libcrypto.so.3
No symbol table info available.
#2  0x0000151514d137e9 in ?? () from /lib/x86_64-linux-gnu/libcrypto.so.3
No symbol table info available.
#3  0x0000151514d13fd0 in EVP_PKEY_free () from /lib/x86_64-linux-gnu/libcrypto.so.3
No symbol table info available.
#4  0x00001515153d790d in ?? () from /lib/x86_64-linux-gnu/libssl.so.3
No symbol table info available.
#5  0x00001515153d79b0 in ?? () from /lib/x86_64-linux-gnu/libssl.so.3
No symbol table info available.
#6  0x00001515153e9ca1 in SSL_free () from /lib/x86_64-linux-gnu/libssl.so.3
No symbol table info available.
#7  0x000015151571ec12 in ?? () from /usr/lib/python3.10/lib-dynload/_ssl.cpython-310-x86_64-linux-gnu.so
No symbol table info available.
#8  0x00005602655a474f in ?? ()
No symbol table info available.
#9  0x00005602655a9ed0 in _PyObject_GenericSetAttrWithDict ()
No symbol table info available.
#10 0x00005602655a9c20 in PyObject_SetAttr ()
No symbol table info available.
#11 0x00005602655c01e7 in _PyEval_EvalFrameDefault ()
No symbol table info available.
#12 0x00005602655d759c in _PyFunction_Vectorcall ()
No symbol table info available.
#13 0x00005602655bf96e in _PyEval_EvalFrameDefault ()
No symbol table info available.
#14 0x00005602655d759c in _PyFunction_Vectorcall ()
No symbol table info available.
#15 0x00005602655bf96e in _PyEval_EvalFrameDefault ()
No symbol table info available.
#16 0x00005602655e5111 in ?? ()
No symbol table info available.
#17 0x00005602655c559a in _PyEval_EvalFrameDefault ()
No symbol table info available.
#18 0x00005602655d759c in _PyFunction_Vectorcall ()
No symbol table info available.
#19 0x00005602655bf96e in _PyEval_EvalFrameDefault ()
No symbol table info available.
#20 0x00005602655d759c in _PyFunction_Vectorcall ()
No symbol table info available.
#21 0x00005602655c1a9d in _PyEval_EvalFrameDefault ()
No symbol table info available.
#22 0x00005602655cc564 in _PyObject_FastCallDictTstate ()
No symbol table info available.
#23 0x00005602655e246c in _PyObject_Call_Prepend ()
No symbol table info available.
#24 0x00005602656fd180 in ?? ()
No symbol table info available.
#25 0x00005602655cd3cb in _PyObject_MakeTpCall ()
No symbol table info available.
#26 0x00005602655f35da in ?? ()
No symbol table info available.
#27 0x00005602655ef765 in ?? ()
--Type <RET> for more, q to quit, c to continue without paging--

### 📝 Additional Notes:
If needed, I can provide more debugging information.

### CPython versions tested on:

3.10

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

_No response_",[],"For this to be a valid bug report against CPython, you'll need to provide some Python code to reproduce the crash.  Also note that Python 3.10.12 is well out of date (3.10.16 is the latest release of 3.10) and OpenSSL 3.0.2 is even further out of date (3.0.15 is current).",[],['python'],github,https://github.com/python/cpython/issues/129974,{'repo': 'python/cpython'}
"Cython cannot use ""pycore_frame.h"" in Py3.14a4

# Bug report

### Bug description:

It's this time of the year again. As discussed before (e.g. https://github.com/python/cpython/issues/123747), Cython `#include`s CPython's `pycore_frame.h` to get access to certain frame features, e.g. their integration into tracebacks.

I noticed that Cython generated code doesn't compile in CPython 3.14 alpha with the following kind of errors:
```
…\Python\3.14.0-alpha.4\x64\include\internal\pycore_stackref.h(278): error C7555: use of designated initializers requires at least '/std:c++20'
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(196): error C7555: use of designated initializers requires at least '/std:c++20'
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(196): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(378): error C7555: use of designated initializers requires at least '/std:c++20'
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(378): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(379): error C7555: use of designated initializers requires at least '/std:c++20'
…\Python\3.14.0-alpha.4\x64\include\internal/pycore_frame.h(379): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax
```
This is from one of our Windows CI runs. Py3.14a4 seems to be what Github Actions currently provides. Cython code expects C99 and something close to (but not necessarily as complete as) C++11 as compiler standards. It targets both C and C++, depending on user needs.

The dependency on `pycore_stackref.h` was apparently added in https://github.com/python/cpython/pull/118450:
```diff
22b0de2755e [2024-06-27 03:10:43 +0800] GitHub | gh-117139: Convert the evaluation stack to stack refs (#118450)

diff --git a/Include/internal/pycore_frame.h b/Include/internal/pycore_frame.h
index bab92c771a7..1e0368faa5b 100644
--- a/Include/internal/pycore_frame.h
+++ b/Include/internal/pycore_frame.h
@@ -11,6 +11,7 @@ extern ""C"" {
 #include <stdbool.h>
 #include <stddef.h>               // offsetof()
 #include ""pycore_code.h""          // STATS
+#include ""pycore_stackref.h""      // _PyStackRef
 
 /* See Objects/frame_layout.md for an explanation of the frame stack
  * including explanation of the PyFrameObject and _PyInterpreterFrame
@@ -67,7 +68,7 @@ typedef struct _PyInterpreterFrame {
     uint16_t return_offset;  /* Only relevant during a function call */
     char owner;
     /* Locals and stack */
-    PyObject *localsplus[1];
+    _PyStackRef localsplus[1];
 } _PyInterpreterFrame;
 
 #define _PyInterpreterFrame_LASTI(IF) \
```
What can we do to resolve this?

### CPython versions tested on:

3.14

### Operating systems tested on:

Windows","[""…\\Python\\3.14.0-alpha.4\\x64\\include\\internal\\pycore_stackref.h(278): error C7555: use of designated initializers requires at least '/std:c++20'\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(196): error C7555: use of designated initializers requires at least '/std:c++20'\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(196): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(378): error C7555: use of designated initializers requires at least '/std:c++20'\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(378): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(379): error C7555: use of designated initializers requires at least '/std:c++20'\n…\\Python\\3.14.0-alpha.4\\x64\\include\\internal/pycore_frame.h(379): error C4576: a parenthesized type followed by an initializer list is a non-standard explicit type conversion syntax"", '22b0de2755e [2024-06-27 03:10:43 +0800] GitHub | gh-117139: Convert the evaluation stack to stack refs (#118450)\n\ndiff --git a/Include/internal/pycore_frame.h b/Include/internal/pycore_frame.h\nindex bab92c771a7..1e0368faa5b 100644\n--- a/Include/internal/pycore_frame.h\n+++ b/Include/internal/pycore_frame.h\n@@ -11,6 +11,7 @@ extern ""C"" {\n #include <stdbool.h>\n #include <stddef.h>               // offsetof()\n #include ""pycore_code.h""          // STATS\n+#include ""pycore_stackref.h""      // _PyStackRef\n \n /* See Objects/frame_layout.md for an explanation of the frame stack\n  * including explanation of the PyFrameObject and _PyInterpreterFrame\n@@ -67,7 +68,7 @@ typedef struct _PyInterpreterFrame {\n     uint16_t return_offset;  /* Only relevant during a function call */\n     char owner;\n     /* Locals and stack */\n-    PyObject *localsplus[1];\n+    _PyStackRef localsplus[1];\n } _PyInterpreterFrame;\n \n #define _PyInterpreterFrame_LASTI(IF) \\']","> What kind of public/unstable API would Cython need so it could avoid the internal headers?

Cython directly accesses frames in three places:
- profiling/tracing
- exceptions/tracebacks
- coroutines

We already got rid of direct frame usage for tracing in Py3.13+ by migrating to the new monitoring C-API. Sadly, that currently excludes coverage reporting since `coverage.py` cannot use it with plugins yet (such as the Cython coverage plugin). That'll eventually come, I hope, but it's not a CPython issue. It just means that you cannot currently use coverage reporting of Cython code in Python 3.14, as long as `coverage.py` needs this (old, pre-monitoring) code that requires `pycore_frame.h` (which doesn't currently compile in C++11):

https://github.com/cython/cython/blob/f193ba860b94a7139cffd8b0d11b7ef977aa10d3/Cython/Utility/Profile.c#L629-L639

For exceptions, all we'd need (AFAICT) is a `PyFrame_SetLineNumber(frame, lineno)`. This has been mentioned before in https://github.com/python/cpython/issues/118720 but was never implemented.

The coroutine support then needs to inject frames into the current stack. For this, we currently read and write `f_back`:

https://github.com/cython/cython/blob/f193ba860b94a7139cffd8b0d11b7ef977aa10d3/Cython/Utility/Coroutine.c#L784-L831

https://github.com/cython/cython/blob/f193ba860b94a7139cffd8b0d11b7ef977aa10d3/Cython/Utility/Coroutine.c#L870-L897

There was a Cython ticket about this created by @markshannon a while ago that also never got anywhere.
https://github.com/cython/cython/issues/4484
",[],['python'],github,https://github.com/python/cpython/issues/130931,{'repo': 'python/cpython'}
"`gzip.GzipFile` creates reference cycle that requires a deep garbage collection cycle to cleanup.

# Bug report

### Bug description:

 During debugging memory buildup, I've noticed `gzip.GzipFile` holds a reference to itself (Cycle: `GzipFile._buffer`->`BufferedWriter._raw`->`_WriteBufferStream.gzip_file`-> `GzipFile`). This cycle prevents memory from being freed until the garbage collector runs a deep cleanup cycle (generation=2). 

## Steps to reproduce 
1. Disable garbage collection temporarily to make sure we are the ones who catch it
2. Set the garbage collector's debug level to DEBUG_LEAK
3. Open GzipFile. 
4. Force garbage collection and look at its output

```python
import gc
import gzip
import io

gc.collect()
gc.disable()
gc.set_debug(gc.DEBUG_LEAK)

with io.BytesIO() as buffer:
    with gzip.GzipFile(mode=""wb"", fileobj=buffer):
        pass

gc.collect()
gc.set_debug(0)
```

## Potential solution
```python
class _WriteBufferStream(io.RawIOBase):
    ...

    def __del__(self):
        del self.gzip_file
```


### CPython versions tested on:

3.12

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130916
<!-- /gh-linked-prs -->
","['import gc\nimport gzip\nimport io\n\ngc.collect()\ngc.disable()\ngc.set_debug(gc.DEBUG_LEAK)\n\nwith io.BytesIO() as buffer:\n    with gzip.GzipFile(mode=""wb"", fileobj=buffer):\n        pass\n\ngc.collect()\ngc.set_debug(0)', 'class _WriteBufferStream(io.RawIOBase):\n    ...\n\n    def __del__(self):\n        del self.gzip_file']","I think this is the equivalent to gh-129726? (Hadn't seen this issue until just now). If so, has a fix which has been backported to 3.12. Similar concept, but broke refloop by adding a weakref (PR: https://github.com/python/cpython/pull/130055)",[],['python'],github,https://github.com/python/cpython/issues/129640,{'repo': 'python/cpython'}
"[Project] carefree-learn: Tabular Datasets ❤️ PyTorch

&gt; [GitHub](https://github.com/carefree0910/carefree-learn)
&gt; 
&gt; [Documentation](https://carefree0910.me/carefree-learn-doc/)
&gt; 
&gt; [PyTorch Official Medium Post](https://medium.com/pytorch/carefree-learn-tabular-datasets-%EF%B8%8F-pytorch-e329b2f008f2)

You like PyTorch? You like scikit-learn? Then you'll like carefree-learn!

Enjoy training neural networks on tabular datasets with one line of code:

```python
import cflearn

m = cflearn.make().fit(x, y)
```","['import cflearn\n\nm = cflearn.make().fit(x, y)']",See comments on Reddit,[],['Python'],reddit,https://www.reddit.com/r/Python/comments/kfwx2l/project_carefreelearn_tabular_datasets_pytorch/,{'subreddit': 'Python'}
"Inconsisted behavior of ternary pow() for Python classes and C extension types

# Bug report

### Bug description:

Consider an example:
```pycon
Python 3.13.1 (tags/v3.13.1:0671451779, Dec  4 2024, 07:55:26) [GCC 12.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import example
>>> pow(42, example.xxx(), example.xxx())  # (1)
called power
123
>>> pow(42, example.xxx())
called power
123
>>> class A:
...     def __pow__(self, other, mod=None):
...         print(""__pow__"")
...         return 123
...     def __rpow__(self, other, mod=None):
...         print(""__rpow__"")
...         return 321
...         
>>> pow(42, A(), A())  # (2)
Traceback (most recent call last):
  File ""<python-input-4>"", line 1, in <module>
    pow(42, A(), A())
    ~~~^^^^^^^^^^^^^^
TypeError: unsupported operand type(s) for ** or pow(): 'int', 'A', 'A'
>>> pow(42, A())
__rpow__
321
```
In presence of the mod argument, C extension type (1) behave differently than the pure-Python analog (2).  That looks as a bug.  There is no documentation anywhere that explains how any of this is supposed to work so it’s hard to say that an alternative Python implementation like PyPy is doing anything incorrect or not.

Third-party extensions (like gmpy2) already uses (1) to do things like `pow(int, gmpy2.mpz, gmpy2.mpz)` - work.  Unfortunately, it's not possible to implement a pure-Python class like gmpy2.mpz, that able to do this.  

<details>

<summary>example.c</summary>

```c
/* example.c */

#define PY_SSIZE_T_CLEAN
#include <Python.h>

PyTypeObject XXX_Type;

static PyObject *
new(PyTypeObject *type, PyObject *args, PyObject *keywds)
{
    return PyObject_New(PyObject, &XXX_Type);
}

static PyObject *
power(PyObject *self, PyObject *other, PyObject *module)
{
    printf(""called power\n"");
    return PyLong_FromLong(123);
}

static PyNumberMethods xxx_as_number = {
    .nb_power = power,
};

PyTypeObject XXX_Type = {
    PyVarObject_HEAD_INIT(NULL, 0)
    .tp_name = ""xxx"",
    .tp_new = new,
    .tp_as_number = &xxx_as_number,
};

static struct PyModuleDef ex_module = {
    PyModuleDef_HEAD_INIT,
    ""example"",
    ""Test module."",
    -1,
    NULL,
};

PyMODINIT_FUNC
PyInit_example(void)
{
    PyObject *m = PyModule_Create(&ex_module);
    if (PyModule_AddType(m, &XXX_Type) < 0) {
        return -1;
    }
    return m;
}
```

</details>

PS: This was discussed before in https://discuss.python.org/t/35185.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130251
<!-- /gh-linked-prs -->
","['Python 3.13.1 (tags/v3.13.1:0671451779, Dec  4 2024, 07:55:26) [GCC 12.2.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import example\n>>> pow(42, example.xxx(), example.xxx())  # (1)\ncalled power\n123\n>>> pow(42, example.xxx())\ncalled power\n123\n>>> class A:\n...     def __pow__(self, other, mod=None):\n...         print(""__pow__"")\n...         return 123\n...     def __rpow__(self, other, mod=None):\n...         print(""__rpow__"")\n...         return 321\n...         \n>>> pow(42, A(), A())  # (2)\nTraceback (most recent call last):\n  File ""<python-input-4>"", line 1, in <module>\n    pow(42, A(), A())\n    ~~~^^^^^^^^^^^^^^\nTypeError: unsupported operand type(s) for ** or pow(): \'int\', \'A\', \'A\'\n>>> pow(42, A())\n__rpow__\n321', '/* example.c */\n\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n\nPyTypeObject XXX_Type;\n\nstatic PyObject *\nnew(PyTypeObject *type, PyObject *args, PyObject *keywds)\n{\n    return PyObject_New(PyObject, &XXX_Type);\n}\n\nstatic PyObject *\npower(PyObject *self, PyObject *other, PyObject *module)\n{\n    printf(""called power\\n"");\n    return PyLong_FromLong(123);\n}\n\nstatic PyNumberMethods xxx_as_number = {\n    .nb_power = power,\n};\n\nPyTypeObject XXX_Type = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    .tp_name = ""xxx"",\n    .tp_new = new,\n    .tp_as_number = &xxx_as_number,\n};\n\nstatic struct PyModuleDef ex_module = {\n    PyModuleDef_HEAD_INIT,\n    ""example"",\n    ""Test module."",\n    -1,\n    NULL,\n};\n\nPyMODINIT_FUNC\nPyInit_example(void)\n{\n    PyObject *m = PyModule_Create(&ex_module);\n    if (PyModule_AddType(m, &XXX_Type) < 0) {\n        return -1;\n    }\n    return m;\n}']","This allows dispatching on the second argument of ternary power:
```diff
diff --git a/Objects/typeobject.c b/Objects/typeobject.c
index 1484d9b334..a4902d2680 100644
--- a/Objects/typeobject.c
+++ b/Objects/typeobject.c
@@ -9810,13 +9810,40 @@ slot_nb_power(PyObject *self, PyObject *other, PyObject *modulus)
 {
     if (modulus == Py_None)
         return slot_nb_power_binary(self, other);
-    /* Three-arg power doesn't use __rpow__.  But ternary_op
-       can call this when the second argument's type uses
-       slot_nb_power, so check before calling self.__pow__. */
+    PyObject* stack[3] = {self, other, modulus};
+    int do_other = !Py_IS_TYPE(self, Py_TYPE(other)) &&
+        Py_TYPE(other)->tp_as_number != NULL &&
+        Py_TYPE(other)->tp_as_number->nb_power == slot_nb_power;
     if (Py_TYPE(self)->tp_as_number != NULL &&
         Py_TYPE(self)->tp_as_number->nb_power == slot_nb_power) {
-        PyObject* stack[3] = {self, other, modulus};
-        return vectorcall_method(&_Py_ID(__pow__), stack, 3);
+        PyObject *r;
+        if (do_other && PyType_IsSubtype(Py_TYPE(other), Py_TYPE(self))) {
+            int ok = method_is_overloaded(self, other, &_Py_ID(__rpow__));
+            if (ok < 0) {
+                return NULL;
+            }
+            if (ok) {
+                stack[0] = other;
+                stack[1] = self;
+                r = vectorcall_method(&_Py_ID(__rpow__), stack, 3);
+                if (r != Py_NotImplemented)
+                    return r;
+                Py_DECREF(r);
+                do_other = 0;
+            }
+        }
+        stack[0] = self;
+        stack[1] = other;
+        r = vectorcall_method(&_Py_ID(__pow__), stack, 3);
+        if (r != Py_NotImplemented ||
+            Py_IS_TYPE(other, Py_TYPE(self)))
+            return r;
+        Py_DECREF(r);
+    }
+    if (do_other) {
+        stack[0] = other;
+        stack[1] = self;
+        return vectorcall_method(&_Py_ID(__rpow__), stack, 3);
     }
     Py_RETURN_NOTIMPLEMENTED;
 }
```
But for third argument, probably there should be a dedicated dunder method.","[""diff --git a/Objects/typeobject.c b/Objects/typeobject.c\nindex 1484d9b334..a4902d2680 100644\n--- a/Objects/typeobject.c\n+++ b/Objects/typeobject.c\n@@ -9810,13 +9810,40 @@ slot_nb_power(PyObject *self, PyObject *other, PyObject *modulus)\n {\n     if (modulus == Py_None)\n         return slot_nb_power_binary(self, other);\n-    /* Three-arg power doesn't use __rpow__.  But ternary_op\n-       can call this when the second argument's type uses\n-       slot_nb_power, so check before calling self.__pow__. */\n+    PyObject* stack[3] = {self, other, modulus};\n+    int do_other = !Py_IS_TYPE(self, Py_TYPE(other)) &&\n+        Py_TYPE(other)->tp_as_number != NULL &&\n+        Py_TYPE(other)->tp_as_number->nb_power == slot_nb_power;\n     if (Py_TYPE(self)->tp_as_number != NULL &&\n         Py_TYPE(self)->tp_as_number->nb_power == slot_nb_power) {\n-        PyObject* stack[3] = {self, other, modulus};\n-        return vectorcall_method(&_Py_ID(__pow__), stack, 3);\n+        PyObject *r;\n+        if (do_other && PyType_IsSubtype(Py_TYPE(other), Py_TYPE(self))) {\n+            int ok = method_is_overloaded(self, other, &_Py_ID(__rpow__));\n+            if (ok < 0) {\n+                return NULL;\n+            }\n+            if (ok) {\n+                stack[0] = other;\n+                stack[1] = self;\n+                r = vectorcall_method(&_Py_ID(__rpow__), stack, 3);\n+                if (r != Py_NotImplemented)\n+                    return r;\n+                Py_DECREF(r);\n+                do_other = 0;\n+            }\n+        }\n+        stack[0] = self;\n+        stack[1] = other;\n+        r = vectorcall_method(&_Py_ID(__pow__), stack, 3);\n+        if (r != Py_NotImplemented ||\n+            Py_IS_TYPE(other, Py_TYPE(self)))\n+            return r;\n+        Py_DECREF(r);\n+    }\n+    if (do_other) {\n+        stack[0] = other;\n+        stack[1] = self;\n+        return vectorcall_method(&_Py_ID(__rpow__), stack, 3);\n     }\n     Py_RETURN_NOTIMPLEMENTED;\n }""]",['python'],github,https://github.com/python/cpython/issues/130104,{'repo': 'python/cpython'}
"Removing inconsistency in number formatting.

There is a discrepancy between the default float formatting achieved in different ways, see the source code snippet. It would be appropriate if using :f would by default give the same effect to a float as printing that number without using :f. Currently this is not the case, using :f unexpectedly changes the number of digits printed after the decimal point. Unexpectedly, because it changes one default setting to a completely different default setting.


```
value = 1.123456789

print(value)                # print result is 1.123456789
print(f""{value}"")           # print result is 1.123456789
print(f""{float(value)}"")    # print result is 1.123456789
print(f""{value:f}"")         # print result is 1.123457
print(f""{float(value):f}"")  # print result is 1.123457

# However,
#
# ""[...] With no precision given, uses a precision of 6 digits
#  after the decimal point for float [...]""
#
# https://docs.python.org/pl/3/library/string.html#formatstrings
```","['value = 1.123456789\n\nprint(value)                # print result is 1.123456789\nprint(f""{value}"")           # print result is 1.123456789\nprint(f""{float(value)}"")    # print result is 1.123456789\nprint(f""{value:f}"")         # print result is 1.123457\nprint(f""{float(value):f}"")  # print result is 1.123457\n\n# However,\n#\n# ""[...] With no precision given, uses a precision of 6 digits\n#  after the decimal point for float [...]""\n#\n# https://docs.python.org/pl/3/library/string.html#formatstrings']","> It would be appropriate if using :f would by default give the same effect to a float as printing that number without using :f. Currently this is not the case, using :f unexpectedly changes the number of digits printed after the decimal point. Unexpectedly, because it changes one default setting to a completely different default setting.

I don't think it's ""unexpected"", [docs says](https://docs.python.org/3.13/library/string.html#formatstrings): Fixed-point notation. For a given precision p, formats the number as a decimal number with exactly p digits following the decimal point. With no precision given, uses a precision of 6 digits after the decimal point for [float](https://docs.python.org/3/library/functions.html#float), and uses a precision large enough to show all coefficient digits for [Decimal](https://docs.python.org/3/library/decimal.html#decimal.Decimal). If p=0, the decimal point is omitted unless the # option is used.

That's true on your case:
```python
>>> f""{1.123456789:f}""
'1.123457'
>>> len(_.split(""."")[1])
6
```

The default (no formatting type) is well documented too: ""For [float](https://docs.python.org/3/library/functions.html#float) this is like the 'g' type, except that when fixed-point notation is used to format the result, it always includes at least one digit past the decimal point, and switches to the scientific notation when exp >= p - 1. When the precision is not specified, the latter will be as large as needed to represent the given value faithfully.

For [Decimal](https://docs.python.org/3/library/decimal.html#decimal.Decimal), this is the same as either 'g' or 'G' depending on the value of context.capitals for the current decimal context.

The overall effect is to match the output of [str()](https://docs.python.org/3/library/stdtypes.html#str) as altered by the other format modifiers.""

Changing this to `f` format will be a huge compatibility break.  You should open a thread on https://discuss.python.org/c/ideas/6 do discuss such change, if you invent good arguments for this.","['>>> f""{1.123456789:f}""\n\'1.123457\'\n>>> len(_.split(""."")[1])\n6']",['python'],github,https://github.com/python/cpython/issues/129503,{'repo': 'python/cpython'}
"`test_concurrent_futures`: `test_free_reference` is flaky

# Bug report

Seen in https://buildbot.python.org/#/builders/1368/builds/2775/steps/6/logs/stdio

The test attempts to ensure that the executor doesn't hold on to the result object, but the executor necessarily holds onto it for a brief period from when it sets the result in in the future until the variable goes out of scope.

We should use `support.sleeping_retry` to check if the weakref eventually (ideally quickly) becomes dead.

```
======================================================================
FAIL: test_free_reference (test.test_concurrent_futures.test_thread_pool.ThreadPoolExecutorTest.test_free_reference)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/ec2-user/buildbot/buildarea/3.x.itamaro-macos-arm64-aws.macos-with-brew.refleak.nogil/build/Lib/test/test_concurrent_futures/executor.py"", line 132, in test_free_reference
    self.assertIsNone(wr())
    ~~~~~~~~~~~~~~~~~^^^^^^
AssertionError: <test.test_concurrent_futures.executor.MyObject object at 0x200041b0100> is not None

----------------------------------------------------------------------
```

https://github.com/python/cpython/blob/12db45211d411583cbe272c7ba6811a811b721ca/Lib/test/test_concurrent_futures/executor.py#L125-L132

https://github.com/python/cpython/blob/12db45211d411583cbe272c7ba6811a811b721ca/Lib/concurrent/futures/thread.py#L85-L92

<!-- gh-linked-prs -->
### Linked PRs
* gh-130958
* gh-131091
* gh-131092
<!-- /gh-linked-prs -->
","['======================================================================\nFAIL: test_free_reference (test.test_concurrent_futures.test_thread_pool.ThreadPoolExecutorTest.test_free_reference)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/Users/ec2-user/buildbot/buildarea/3.x.itamaro-macos-arm64-aws.macos-with-brew.refleak.nogil/build/Lib/test/test_concurrent_futures/executor.py"", line 132, in test_free_reference\n    self.assertIsNone(wr())\n    ~~~~~~~~~~~~~~~~~^^^^^^\nAssertionError: <test.test_concurrent_futures.executor.MyObject object at 0x200041b0100> is not None\n\n----------------------------------------------------------------------']","You can more easily reproduce this failure by adding a `time.sleep()`:

```patch
diff --git a/Lib/concurrent/futures/thread.py b/Lib/concurrent/futures/thread.py
index 909359b6487..73cce87b5dd 100644
--- a/Lib/concurrent/futures/thread.py
+++ b/Lib/concurrent/futures/thread.py
@@ -90,6 +90,7 @@ def run(self, ctx):
             self = None
         else:
             self.future.set_result(result)
+            time.sleep(1)

     __class_getitem__ = classmethod(types.GenericAlias)
```","['diff --git a/Lib/concurrent/futures/thread.py b/Lib/concurrent/futures/thread.py\nindex 909359b6487..73cce87b5dd 100644\n--- a/Lib/concurrent/futures/thread.py\n+++ b/Lib/concurrent/futures/thread.py\n@@ -90,6 +90,7 @@ def run(self, ctx):\n             self = None\n         else:\n             self.future.set_result(result)\n+            time.sleep(1)\n\n     __class_getitem__ = classmethod(types.GenericAlias)']",['python'],github,https://github.com/python/cpython/issues/130957,{'repo': 'python/cpython'}
"Implement stack overflow protection for linux based on actual stack depth

Linux doesn't offer an API for determining the current stack bounds, at least not that I am aware of.

This means we will need to probe the stack using a SIGSEGV handler and longjmp/setjump.
It is somewhat ugly but should work.

Actually, it looks like `pthread_get_stackaddr_np` might work, and avoid all the complexity of the signal handler. In theory, it should work for MacOS as well.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130398
* gh-130550
* gh-130552
* gh-130554
* gh-130572
* gh-130573
* gh-130593
* gh-130966
* gh-131088
<!-- /gh-linked-prs -->
",[],"This broke two buildbots (both can be seen in the [pre-merge run](https://buildbot.python.org/all/#/grid?branch=refs%2Fpull%2F130398%2Fmerge)):
- [AMD64 Windows Server 2022 NoGIL](https://buildbot.python.org/#/builders/1241/builds/4706) (tier 1): `test_trashcan_python_class1` loops with endless repetition of `Exception ignored in audit hook:` `RecursionError: Stack overflow (used 11729 kB)`
- [AMD64 Fedora Stable Clang 3.x](https://buildbot.python.org/#/builders/441/builds/7400) (tier 2): several `test_gdb` failures. 

Do you have any leads on these issues?",[],['python'],github,https://github.com/python/cpython/issues/130396,{'repo': 'python/cpython'}
"nogil `__len__` and `__eq__` break atomicity on sets and dicts

# Bug report

### Bug description:

Hi,

We're a research group focused on testing concurrent runtimes. Our work-in-progress prototype found a violation of atomicity on the current nogil build when using set `__len__` or `__eq__` with other concurrent operations on the same set/dict. The program below shows the wrong behavior for `__len__` and `__ixor__`:

```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    res.append(s.__len__())

def t1(b1,s,res):
    b1.wait()
    s.__ixor__({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 'a'})

def Test():
  s =  {17, 'a', 'b', 18, 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] not in { 7 , 32 }:
      print(""found bug: "" + str(res[0]))

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```

Operation `__len__` should see the initial set and return `7` or the set after the `__ixor__` completes and return `32`.  However, it can see internal changes made by `__ixor__` and return different numbers.  Here's an example execution:

```
test begin...
0
found bug: 9
found bug: 17
found bug: 22
found bug: 30
found bug: 9
found bug: 9
found bug: 9
found bug: 9
found bug: 9
```

We have observed the same problem when `__len__` runs concurrently with other operations: `symmetric_difference_update`, `__isub__`, and `update`.  We'll share these test below in a comment.

We observed the same problem when dict's `__len__` runs concurrently with `__ior__`:

```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    res.append(s.__len__())
​
def t1(b1,s,res):
    b1.wait()
    s.__ior__({0: 0, 1: 1, 2: 2, 3: 3, 4: 4})
​
def Test():
  d =  {'k1': 'v1', 'k2': 'v2', 'k3': 3, 10: 10}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, d,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, d,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] not in { 4, 9 }:
      print(""found bug: "" + str(res[0]))
​
print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```

Again, the length of the dict should be either 4 or 9, depending on whether `__ior__` took place.  However, `__len__` can see internal changes from `__ior__` as shown by the output:

```
test begin...
0
found bug: 5
found bug: 6
found bug: 5
found bug: 5
found bug: 8
found bug: 7
```

Finally, we observed set's `__eq__` to be able to access intermediate results of `__isub__`, as shown by the program below:
```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    s.__isub__({1, 'b', 'd', 17})

def t1(b1,s,res):
    b1.wait()
    res.append(s.__eq__({'a', 'b', 18, 'c', 'd', 'e'}))

def Test():
  s =  {'a', 17, 'b', 18, 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] != False:
      print(""found bug: "" + str(res[0]))

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```

The original and resulting sets are never equal to the argument passed to `__eq__`, however the operation can see internal changes from `__isub__` as shown by the ouput:

```
test begin...
0
found bug: True
found bug: True
found bug: True
found bug: True
found bug: True
found bug: True
```

@flypoodles and @overlorde are part of the team, adding them so they get notified about further discussion.

We note that we observed these outputs in several x86_64 machines and one ARM machine.

### CPython versions tested on:

CPython main branch, 3.14

### Operating systems tested on:

Linux","['import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    res.append(s.__len__())\n\ndef t1(b1,s,res):\n    b1.wait()\n    s.__ixor__({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \'a\'})\n\ndef Test():\n  s =  {17, \'a\', \'b\', 18, \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] not in { 7 , 32 }:\n      print(""found bug: "" + str(res[0]))\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: 9\nfound bug: 17\nfound bug: 22\nfound bug: 30\nfound bug: 9\nfound bug: 9\nfound bug: 9\nfound bug: 9\nfound bug: 9', 'import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    res.append(s.__len__())\n\u200b\ndef t1(b1,s,res):\n    b1.wait()\n    s.__ior__({0: 0, 1: 1, 2: 2, 3: 3, 4: 4})\n\u200b\ndef Test():\n  d =  {\'k1\': \'v1\', \'k2\': \'v2\', \'k3\': 3, 10: 10}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, d,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, d,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] not in { 4, 9 }:\n      print(""found bug: "" + str(res[0]))\n\u200b\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: 5\nfound bug: 6\nfound bug: 5\nfound bug: 5\nfound bug: 8\nfound bug: 7', 'import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    s.__isub__({1, \'b\', \'d\', 17})\n\ndef t1(b1,s,res):\n    b1.wait()\n    res.append(s.__eq__({\'a\', \'b\', 18, \'c\', \'d\', \'e\'}))\n\ndef Test():\n  s =  {\'a\', 17, \'b\', 18, \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] != False:\n      print(""found bug: "" + str(res[0]))\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: True\nfound bug: True\nfound bug: True\nfound bug: True\nfound bug: True\nfound bug: True']","Adding the tests mentioned in the main issue here, with sample outputs.
---
`__len__` and `symmetric_difference_update`:
```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    res.append(s.__len__())

def t1(b1,s,res):
    b1.wait()
    s.symmetric_difference_update({3, 4, 'b', 'e', 'f'})

def Test():
  s =  {1, 2, 'a', 'b', 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] not in { 7, 8 }:
      print(""found bug: "" + str(res))

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```

Output:
```
test begin...
0
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
found bug: [9]
```

---
`__len__` and `__isub__` (this one is rare, you may have to run it for a while to observe the behavior we mention; ARM hardware seems to observe it more often):
```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    s.__isub__({1, 'b', 17, 'd'})
​
def t1(b1,s,res):
    b1.wait()
    res.append(s.__len__())
​
def Test():
  s =  {'a', 17, 18, 'b', 'c', 'd', 'f'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] not in { 4, 7 }:
      print(""found bug: "" + str(res[0]))
​
print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```
Output:
```
test begin...
0
1000
2000
3000
found bug: 5
4000
found bug: 5
```
---
`__len__` and `update`:
```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    res.append(s.__len__())

def t1(b1,s,res):
    b1.wait()
    s.update({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 'a'})

def Test():
  s =  {17, 18, 'a', 'b', 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] not in { 7, 35 }:
      print(""found bug: "" + str(res[0]))

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```
Output:
```
test begin...
0
found bug: 24
found bug: 24
found bug: 21
found bug: 24
found bug: 32
found bug: 25
found bug: 28
```","['import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    res.append(s.__len__())\n\ndef t1(b1,s,res):\n    b1.wait()\n    s.symmetric_difference_update({3, 4, \'b\', \'e\', \'f\'})\n\ndef Test():\n  s =  {1, 2, \'a\', \'b\', \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] not in { 7, 8 }:\n      print(""found bug: "" + str(res))\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]\nfound bug: [9]', 'import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    s.__isub__({1, \'b\', 17, \'d\'})\n\u200b\ndef t1(b1,s,res):\n    b1.wait()\n    res.append(s.__len__())\n\u200b\ndef Test():\n  s =  {\'a\', 17, 18, \'b\', \'c\', \'d\', \'f\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] not in { 4, 7 }:\n      print(""found bug: "" + str(res[0]))\n\u200b\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\n1000\n2000\n3000\nfound bug: 5\n4000\nfound bug: 5', 'import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    res.append(s.__len__())\n\ndef t1(b1,s,res):\n    b1.wait()\n    s.update({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \'a\'})\n\ndef Test():\n  s =  {17, 18, \'a\', \'b\', \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] not in { 7, 35 }:\n      print(""found bug: "" + str(res[0]))\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: 24\nfound bug: 24\nfound bug: 21\nfound bug: 24\nfound bug: 32\nfound bug: 25\nfound bug: 28']",['python'],github,https://github.com/python/cpython/issues/129519,{'repo': 'python/cpython'}
"Test_sqlite3 failing with SQLite 3.49.0

# Bug report

### Bug description:

test_sqlite3/test_dump.py relies on fts4 for `test_dump_virtual_tables`. However, SQLite 3.49.0 apparently no longer builds  with`ENABLE_FTS4` by default, presumably because it was superseded by FTS5. This causes this unit test to fail.



### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129913
* gh-129918
<!-- /gh-linked-prs -->
",[],"> `sqlite3` was added from pysqlite in 2006

Yep, I'm that old. In fact, I am an old enough Python user that I was one of the people who voted to establish the [comp.lang.python Usenet newsgroup back in 1994](https://legacy.python.org/search/hypermail/python-1994q1/0488.html)

",[],['python'],github,https://github.com/python/cpython/issues/129870,{'repo': 'python/cpython'}
"`typing.TypeVar` doesn't distinguish between `(bound=None)` and not providing a `bound` argument

# Bug report

### Bug description:

I was trying to reconstruct typing interfaces in a `.pyi` stub file by using runtime symbols. When trying to extract the value of the `bound=` argument to `typing.TypeVar`, I came across this result (which to be fair is [documented in the signature](https://docs.python.org/3.14/library/typing.html#typing.TypeVar)):

```pycon
>>> from typing import TypeVar
>>>
>>> T = TypeVar(""T"")
>>> print(T.__bound__ is None)
True
```

In static type checkers, an omitted `bound=` is equivalent to `bound=builtins.object`. The inconsistency with the runtime default value is problematic, because explicitly specifying `bound=None` also has a well-defined meaning to static type checkers (even if such a specification is rare):

([mypy Playground](https://mypy-play.net/?mypy=latest&python=3.13&flags=implicit-optional%2Cstrict&gist=32dd7543c70e61117041142876dc1fad), [pyright Playground](https://pyright-play.net/?pythonVersion=3.13&strict=true&reportMissingModuleSource=true&enableExperimentalFeatures=true&code=GYJw9gtgBALgngBwJYDsDmUkQWEMoAqiApgGoCGIAUFQVALyEkUgAUARAewDRQBGYAK4oAJvQByYFMQCUNEcWBRgrAG7kANgC5CvAPQyoAWgB8hLVShWoIYjEEgUUdRporJ0w1ADEUAPIA0lQqAIxevvAIxEYAxgAWxDEA1sQgUKngIEA))

```python
from typing import TypeVar

T = TypeVar(""T"", bound=None)

def f(val: T, /) -> T:
    return val

f(None)  # OK
f(1)  # type-checker error
```

Not sure what the best course of action is here as any change to this will have backwards-compatibility concerns, but I think it's clear that static typing will not change an omitted `bound=` argument's interpretation to `bound=None`, as that would break most existing typed code.

### CPython versions tested on:

3.9, 3.14

### Operating systems tested on:

_No response_","['>>> from typing import TypeVar\n>>>\n>>> T = TypeVar(""T"")\n>>> print(T.__bound__ is None)\nTrue', 'from typing import TypeVar\n\nT = TypeVar(""T"", bound=None)\n\ndef f(val: T, /) -> T:\n    return val\n\nf(None)  # OK\nf(1)  # type-checker error']","I don't think that it ever makes sense to create a `TypeVar` with `bound=None`. I initially thought that maybe `int | None` can fit `bound=None`, but no: https://mypy-play.net/?mypy=latest&python=3.12&gist=aa9303391066fae2e35eb2b73f14adf5",[],['python'],github,https://github.com/python/cpython/issues/129543,{'repo': 'python/cpython'}
"Special syntax error for `elif` after `else`

# Feature or enhancement

### Proposal:

I've implemented a special syntax error in the case that an `elif` follows an `else`. See [here](https://github.com/swfarnsworth/cpython/commit/883ada95e129bec660f55da7b1422deec3871979).

```python
if i % 3 == 0:
    print(""divisible by 3"")
else:
    print(""not divisible by 3"")
elif i % 2 == 0:
    print(""divisible by 2"")
# SyntaxError: elif not allowed after else
```

This is currently the extent of the new behavior. If possible, I would be interested to implement behavior like this:

```python
if isinstance(i, int):
    if i % 3 == 0:
        print(""divisible by 3"")
    else:
        print(""not divisible by 3"")
    elif isinstance(i, str):
        print(""i is a string"")
# SyntaxError: elif not allowed after else. Perhaps the elif is at the wrong indentation level?
```

This would be even more informative for beginners, but I'm not sure if the parser supports that level of state. In particular, we wouldn't want the latter syntax error (the one that suggests that the indentation level is wrong) to be raised if the invalid elif were within a for block.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-129902
<!-- /gh-linked-prs -->
","['if i % 3 == 0:\n    print(""divisible by 3"")\nelse:\n    print(""not divisible by 3"")\nelif i % 2 == 0:\n    print(""divisible by 2"")\n# SyntaxError: elif not allowed after else', 'if isinstance(i, int):\n    if i % 3 == 0:\n        print(""divisible by 3"")\n    else:\n        print(""not divisible by 3"")\n    elif isinstance(i, str):\n        print(""i is a string"")\n# SyntaxError: elif not allowed after else. Perhaps the elif is at the wrong indentation level?']","I like the new error message! But, looks like `Perhaps the elif is at the wrong indentation level?` part would be really hard to generate, if even possible.

Please, send a PR with the first message for now :)",[],['python'],github,https://github.com/python/cpython/issues/129858,{'repo': 'python/cpython'}
"Unexpected behaviour in test (if) on list when list index out of range

# Bug report

### Bug description:

Have a look at the minimal example below. Running this example, I would expect the following error: ""IndexError: list index out of range"" but it carries on, as if L[30] was a boolean (""False"" or ""True""). Is it the expected behaviour? 
I'm using python 3.10.12

```python
L=[0,1,2,3]
if True or L[30]: 
    print(""That's OK despite the fact that I used an out of range index value of 30 for my test."")
```

But, if I use and ""AND"" instead of the ""OR"":
```python
L=[0,1,2,3]
if True and L[30]:
    print(""That's OK despite the fact that I used an out of range index value of 30 for my test."")
```
Then it throws the expected error: ""IndexError: list index out of range""
### CPython versions tested on:

3.10

### Operating systems tested on:

Linux","['L=[0,1,2,3]\nif True or L[30]: \n    print(""That\'s OK despite the fact that I used an out of range index value of 30 for my test."")', 'L=[0,1,2,3]\nif True and L[30]:\n    print(""That\'s OK despite the fact that I used an out of range index value of 30 for my test."")']","Thank you for using the Python bug tracker! The behavior you observe is not a bug -- it's by design that the `or` operator doesn't evaluate its second operand if the first is truthy. This is how boolean operations work in most languages -- e.g. `&&` and `||` work this way in C, C++, Java, JavaScript, and many other languages. (In fact I have to go as far back as Pascal for a language I know that doesn't do this.)

PS. The same behavior works for and if you write `if False and L[30]`.",[],['python'],github,https://github.com/python/cpython/issues/130426,{'repo': 'python/cpython'}
"Having type hints changes inheritance on dataclass

# Bug report

### Bug description:

When declaring a subclass for a `dataclass`, including/omitting type hints change the behavior of inherited attributes. It seems that if the parent class has a type hint but the child class does not, the child class will not override the parent's attribute value.

# Example for reproducing issue  

```python
from dataclasses import dataclass

@dataclass
class Field:
    name: str
    d_type: str = 'CustomType'

@dataclass
class FieldStr(Field):
    d_type: str = 'string'

@dataclass
class FieldStrNoHint(Field):
    d_type = 'string'

my_field = FieldStr('FieldWithString')
print(my_field.d_type) # expected: 'string', actual: 'string'

my_field = FieldStrNoHint('FieldWithStrNoHint')
print(my_field.d_type) # expected: 'string', actual: 'CustomType'
```

# Expected Behavior  

In both cases (`FieldStr` and `FieldStrNoHint`), the `d_type` attribute should return `'string'`.

# Actual Behavior  

The child class **with** a type hint (`FieldStr`) correctly returns the value.

The child class **without** a type hint (`FieldStrNoHint`) returns the parent's value instead.

In this table, the result should always be the child's value, but if the parent has a hint and the child does not, the parent's value is used instead. The hint type doesn't matter (e.g., `d_type: int` on the parent still returns the same result).

| Parent has hint | Child has hint | Result |
| --- | --- | --- |
| Yes | Yes | Child's value |
| Yes | No | Parent's value |
| No | Yes | Child's value |
| No | No | Child's value |

## Other observations

If I change the type hint on the `name` attribute in the parent class, the behavior changes more dramatically. The child class appears to set the `d_type` attribute instead of the `name` when instantiating the object.

```python
@dataclass
class Field:
    name = None # No hint on name
    d_type: str = 'CustomType'
# ... everything else is the same

my_field = FieldStr('FieldWithString')
print(my_field.d_type) # expected: 'string', actual: 'FieldWithString'

my_field = FieldStrNoHint('FieldWithStrNoHint')
print(my_field.d_type) # expected: 'string', actual: 'FieldWithStrNoHint'
```

# Additional Information  

## Main environment  
- Windows 11, 24H2
- Python version: 3.12.4

## Replicated environment
- Google Colab
- Python version: 3.11.11



### CPython versions tested on:

3.11, 3.12

### Operating systems tested on:

Windows, Other","[""from dataclasses import dataclass\n\n@dataclass\nclass Field:\n    name: str\n    d_type: str = 'CustomType'\n\n@dataclass\nclass FieldStr(Field):\n    d_type: str = 'string'\n\n@dataclass\nclass FieldStrNoHint(Field):\n    d_type = 'string'\n\nmy_field = FieldStr('FieldWithString')\nprint(my_field.d_type) # expected: 'string', actual: 'string'\n\nmy_field = FieldStrNoHint('FieldWithStrNoHint')\nprint(my_field.d_type) # expected: 'string', actual: 'CustomType'"", ""@dataclass\nclass Field:\n    name = None # No hint on name\n    d_type: str = 'CustomType'\n# ... everything else is the same\n\nmy_field = FieldStr('FieldWithString')\nprint(my_field.d_type) # expected: 'string', actual: 'FieldWithString'\n\nmy_field = FieldStrNoHint('FieldWithStrNoHint')\nprint(my_field.d_type) # expected: 'string', actual: 'FieldWithStrNoHint'""]","@B-D-T : You didn't waste anyone's time! Thank you for taking the time and reporting what could have been a bug, I appreciate it.

I'll go ahead and close this.",[],['python'],github,https://github.com/python/cpython/issues/129832,{'repo': 'python/cpython'}
"Windows datetime.astimezone(tz=None) should return tzinfo with zone name that can be used by ZoneInfo

# Bug report

### Bug description:

I often use `datetime.astimezone()` to make my datetime objects tz-aware. Using `astimezone(tz=None)` is very convenient, but the tzinfo object that is returned has a `tzname()` that can't be passed to ZoneInfo:

```python
import datetime
from zoneinfo import ZoneInfo

dt=datetime.datetime.now().astimezone()
dt.tzname()
'Eastern Standard Time'
```

If I try 
```python
ZoneInfo(dt.tzname())
```
I get 
```ZoneInfoNotFoundError: 'No time zone found with key Eastern Standard Time'```

I understand why, and I almost submitted this issue for `zoneinfo`, but after looking at the docs, I thought it would be more appropriate for the `datetime` module. 

What I've done recently is to create a dictionary to map the timezones to something `ZoneInfo` has a key for:
```python
US_timezone_dict = {'eastern standard time':'US/Eastern',
                    'eastern daylight time':'US/Eastern',
                    'central standard time':'US/Central',
                    'central daylight time':'US/Central',
                    'mountain standard time':'US/Mountain',
                    'mountain daylight time':'US/Mountain',
                    'us mountain standard time':'US/Arizona',
                    'pacific standard time':'US/Pacific',
                    'pacific daylight time':'US/Pacific',
                    'alaska standard time':'US/Alaska',
                    'aleutian standard time':'US/Aleutian',
                    'hawaiian standard time':'US/Hawaii',
                    }
_timezone = dt.tzname()
if _timezone and _timezone.lower() in US_timezone_dict:
    _timezone = US_timezone_dict[_timezone.lower()]

```
Now this works for me, but it would be nice if `dt.astimezone() ` would return a `tzinfo` with a name that `ZoneInfo` knows about.

I can do 
```python
dt=datetime.datetime.now().astimezone(ZoneInfo('US/Eastern'))
dt.tzname()
Out[32]: 'EST'
```
but I don't always know which time zone I will be in when I run my code.
Thanks.


### CPython versions tested on:

3.11

### Operating systems tested on:

Windows","[""import datetime\nfrom zoneinfo import ZoneInfo\n\ndt=datetime.datetime.now().astimezone()\ndt.tzname()\n'Eastern Standard Time'"", 'ZoneInfo(dt.tzname())', "": 'No time zone found with key Eastern Standard Time'"", ""US_timezone_dict = {'eastern standard time':'US/Eastern',\n                    'eastern daylight time':'US/Eastern',\n                    'central standard time':'US/Central',\n                    'central daylight time':'US/Central',\n                    'mountain standard time':'US/Mountain',\n                    'mountain daylight time':'US/Mountain',\n                    'us mountain standard time':'US/Arizona',\n                    'pacific standard time':'US/Pacific',\n                    'pacific daylight time':'US/Pacific',\n                    'alaska standard time':'US/Alaska',\n                    'aleutian standard time':'US/Aleutian',\n                    'hawaiian standard time':'US/Hawaii',\n                    }\n_timezone = dt.tzname()\nif _timezone and _timezone.lower() in US_timezone_dict:\n    _timezone = US_timezone_dict[_timezone.lower()]"", ""dt=datetime.datetime.now().astimezone(ZoneInfo('US/Eastern'))\ndt.tzname()\nOut[32]: 'EST'""]","That is not really within the spec of what `.astimezone()` does. It's a bit weird that Windows has `tzname` set to ""Eastern Standard Time"" and not something like ""EST"" or ""EDT"", though ""EST"" and ""EDT"" should *also* not be used for this.

In any case, `.tzname()` is there to provide the human-readable name for a specific *offset*, not the name of the time zone. The proper thing to do here would be to expose something in `zoneinfo` that tries to figure out what tzdata identifier applies to the local machine, but for various reasons I'm not even convinced that that is usually the right thing to do (there's not really a correct thing to do here because of the way this ecosystem has naturally evolved, but I *usually* think that if you want to know the system time zone automatically you are probably using the wrong abstraction).

Surprisingly, I can't see any bug like, ""How do I get the local time zone ID"", otherwise I would say that that is the right place for the discussion. Surely this is just my inability to search, though, I'm sure I've had conversations like this.",[],['python'],github,https://github.com/python/cpython/issues/129670,{'repo': 'python/cpython'}
"Treat `KeyboardInterrupt` or `SystemExit` the same on program exit even if they are inside exception groups

# Feature or enhancement

### Proposal:

A `KeyboardInterrupt` or `SystemExit` inside a `BaseExceptionGroup` should be treated like a bare `KeyboardInterrupt` or `SystemExit`.

```powershell
PS C:\...> python x.py
  + Exception Group Traceback (most recent call last):
  |   File ""C:\...\x.py"", line 1, in <module>
  |     raise BaseExceptionGroup(""ki in an exception group"", [KeyboardInterrupt()])
  | BaseExceptionGroup: ki in an exception group (1 sub-exception)
  +-+---------------- 1 ----------------
    | KeyboardInterrupt
    +------------------------------------
PS C:\...> $LastExitCode
1


PS C:\...> python x.py
Traceback (most recent call last):
  File ""C:\...\x.py"", line 1, in <module>
    raise KeyboardInterrupt()
KeyboardInterrupt
PS C:\...> $LastExitCode
-1073741510
```

Looking at the CPython source code, I believe `_Py_HandleSystemExitAndKeyboardInterrupt` is the relevant function.

---

Points for it:
 - less pitfalls for a 3rd party using exception groups
 - see any other failures (as exceptions) upon shutdown (ATM the workaround requires discarding the other exceptions)

Points against:
 - `SystemExit` in an exception group prints out the stack trace, unlike when it's not in an exception group
   - we could make them consistent (filter out `SystemExit` and print the exception group then)

I volunteer to implement this if this is fine.

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

EDIT: I have now made a post. See https://discuss.python.org/t/keyboardinterrupt-and-systemexit-in-exception-groups-should-be-considered-for-pythons-exit-code/82816

### Links to previous discussion of this feature:

I have tried some basic keyword searches as well as some digging in blame, but I can't find any previous discussion.","['PS C:\\...> python x.py\r\n  + Exception Group Traceback (most recent call last):\r\n  |   File ""C:\\...\\x.py"", line 1, in <module>\r\n  |     raise BaseExceptionGroup(""ki in an exception group"", [KeyboardInterrupt()])\r\n  | BaseExceptionGroup: ki in an exception group (1 sub-exception)\r\n  +-+---------------- 1 ----------------\r\n    | KeyboardInterrupt\r\n    +------------------------------------\r\nPS C:\\...> $LastExitCode\r\n1\r\n\r\n\r\nPS C:\\...> python x.py\r\nTraceback (most recent call last):\r\n  File ""C:\\...\\x.py"", line 1, in <module>\r\n    raise KeyboardInterrupt()\r\nKeyboardInterrupt\r\nPS C:\\...> $LastExitCode\r\n-1073741510']",I'll do that and edit a link in -- should the pending tag be removed?,[],['python'],github,https://github.com/python/cpython/issues/130713,{'repo': 'python/cpython'}
"socket.create_server: dualstack_ipv6 and family

# Documentation

Calling `socket.create_server` with `dualstack_ipv6=True` expect `family=AF_INET`. For example:

```
socket.create_server(("""", 12345), family=socket.AF_INET, dualstack_ipv6=True)
```
raise `ValueError`.

There is nothing about it docs. We should add this constrain in docs.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129996
<!-- /gh-linked-prs -->
","['socket.create_server(("""", 12345), family=socket.AF_INET, dualstack_ipv6=True)']","I guess we can indeed mention that `dualstack_ipv6` requires `family=socket.AF_INET6`, although the example of https://docs.python.org/3/library/socket.html#socket.create_server is a bit implicit about that.",[],['python'],github,https://github.com/python/cpython/issues/129994,{'repo': 'python/cpython'}
"test_fstring.py:1655: SyntaxWarning: invalid escape sequence

# Bug report

### Bug description:

This is a failure during the set of tests performed during build of 3.13.2:

```
    default: 0:00:22 load avg: 1.70 [18/44] test_fstring
    default: /root/Python-3.13.2/Lib/test/test_fstring.py:1655: SyntaxWarning: invalid escape sequence '\N'
    default:   self.assertEqual(f'{b""\N{OX}""=}', 'b""\\N{OX}""=b\'\\\\N{OX}\'')
```

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129830
* gh-130068
<!-- /gh-linked-prs -->
","['default: 0:00:22 load avg: 1.70 [18/44] test_fstring\n    default: /root/Python-3.13.2/Lib/test/test_fstring.py:1655: SyntaxWarning: invalid escape sequence \'\\N\'\n    default:   self.assertEqual(f\'{b""\\N{OX}""=}\', \'b""\\\\N{OX}""=b\\\'\\\\\\\\N{OX}\\\'\')']",Added in https://github.com/python/cpython/pull/128399 (cc @pablogsal) We could simply suppress the warning for that line.,[],['python'],github,https://github.com/python/cpython/issues/129693,{'repo': 'python/cpython'}
"Documentation: Remove incorrect role directive in `graphlib.py`

# Documentation

Remove :exec: role directive from ValueError in TopologicalSorter.done() docstring since docstrings are not processed as reST contents.


<!-- gh-linked-prs -->
### Linked PRs
* gh-129896
* gh-129904
* gh-129905
<!-- /gh-linked-prs -->
",[],"Anyone is free to open a PR, but I would prefer that we just remove the role itself. We don't process docstrings as reST contents so this role is useless.",[],['python'],github,https://github.com/python/cpython/issues/129892,{'repo': 'python/cpython'}
"asyncio possible Improvement: Using `shutdown()` Before `close()` in `_close_self_pipe`

### Description

While reviewing the `_close_self_pipe` method in [`Lib/asyncio/selector_events.py`](https://github.com/python/cpython/blob/main/Lib/asyncio/selector_events.py#L112), I noticed that the sockets `_ssock` and `_csock` are directly closed using `close()`, without first calling `shutdown()`.

### Code Reference
```python
    def _close_self_pipe(self):
        self._remove_reader(self._ssock.fileno())
        self._ssock.close()
        self._ssock = None
        self._csock.close()
        self._csock = None
        self._internal_fds -= 1
```

### Question
Would there be any potential downsides or benefits to adding a shutdown(socket.SHUT_RDWR) call before closing these sockets?

### Possible Benefits
- Ensures that all pending data is properly discarded before closing, particularly in scenarios where data might still be buffered.
- Prevents potential issues with lingering resources in some edge cases.
Aligns with best practices for socket cleanup.

### Reference

The Python socket documentation states:

""close() releases the resource associated with a connection but does not necessarily close the connection immediately. If you want to close the connection in a timely fashion, call shutdown() before close()."" [link](https://docs.python.org/3/library/socket.html#socket.socket.close)

Looking forward to your thoughts!

Thanks!

<!-- gh-linked-prs -->
### Linked PRs
* gh-130862
<!-- /gh-linked-prs -->
",['def _close_self_pipe(self):\n        self._remove_reader(self._ssock.fileno())\n        self._ssock.close()\n        self._ssock = None\n        self._csock.close()\n        self._csock = None\n        self._internal_fds -= 1'],I'll post a pr when I fix all the issues,[],['python'],github,https://github.com/python/cpython/issues/130850,{'repo': 'python/cpython'}
"codecs module doesn't recognize new C++ 23 universal-character-name \u{xxx}.

# Bug report

### Bug description:

The C++ 23 Standard has a new syntax for universal character names, which `codecs.decode` does not recognize.  I ran this on Python 3.13, and the same occurs with earlier Python versions.

```python
Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)] on win32
>>> import codecs
>>> codecs.decode('\u41',encoding='unicode-escape')
'A'
>>> codecs.decode('\u{41}',encoding='unicode-escape')
  File ""<python-input-3>"", line 1
    codecs.decode('\u{41}',encoding='unicode-escape')
                  ^^^^^^^^^^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \uXXXX escape
```
The result should be `'A'`.


For reference, this is quoted from the C++ 23 Standard, Appendix A.3:
```
universal-character-name:
    ...
    \u{ simple-hexadecimal-digit-sequence }

simple-hexadecimal-digit-sequence:
    hexadecimal-digit
    simple-hexadecimal-digit-sequence hexadecimal-digit
```

## Please update `codecs` in Python 3.13, and all earlier Python versions that are still publishing bug fixes.


### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)] on win32\n>>> import codecs\n>>> codecs.decode(\'\\u41\',encoding=\'unicode-escape\')\n\'A\'\n>>> codecs.decode(\'\\u{41}\',encoding=\'unicode-escape\')\n  File ""<python-input-3>"", line 1\n    codecs.decode(\'\\u{41}\',encoding=\'unicode-escape\')\n                  ^^^^^^^^^^\nSyntaxError: (unicode error) \'unicodeescape\' codec can\'t decode bytes in position 0-1: truncated \\uXXXX escape', 'universal-character-name:\n    ...\n    \\u{ simple-hexadecimal-digit-sequence }\n\nsimple-hexadecimal-digit-sequence:\n    hexadecimal-digit\n    simple-hexadecimal-digit-sequence hexadecimal-digit']","If you care about the issue, please track it yourself. You can't just drop an idea and disappear -- that's inefficient use of the Python project's scarce resources.",[],['python'],github,https://github.com/python/cpython/issues/130475,{'repo': 'python/cpython'}
"print function with bad string content

# Bug report

### Bug description:

```python
# Add a code block here, if required
```
print(""hello world"", end=""-"")


### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['# Add a code block here, if required']","We hope the correct answer: ""hello world-"". But, we obtain: ""o world-"" ",[],['python'],github,https://github.com/python/cpython/issues/129960,{'repo': 'python/cpython'}
"asyncio.events.BaseDefaultEventLoopPolicy gone from Python 3.14 without prior deprecation

# Bug report

### Bug description:

```python
from asyncio.events import BaseDefaultEventLoopPolicy
```

This is from https://github.com/MagicStack/uvloop/blob/7bb12a174884b2ec8b3162a08564e5fb8a5c6b39/uvloop/__init__.py#L6 cc @fantix 

On Python 3.13, this works.
On Python 3.14 since https://github.com/python/cpython/pull/128216 this no longer works and raises `ImportError`. As far as I know, the class was not deprecated in 3.13 or 3.12.

```pycon
>>> from asyncio.events import BaseDefaultEventLoopPolicy
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    from asyncio.events import BaseDefaultEventLoopPolicy
ImportError: cannot import name 'BaseDefaultEventLoopPolicy' from 'asyncio.events' (/usr/lib64/python3.14/asyncio/events.py)
```

The commit message of https://github.com/python/cpython/pull/128216 does not mention any API removals at all. It has no NEWS either, so I assume this removal was accidental.

### CPython versions tested on:

3.14, CPython main branch

### Operating systems tested on:

Linux","['from asyncio.events import BaseDefaultEventLoopPolicy', '>>> from asyncio.events import BaseDefaultEventLoopPolicy\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    from asyncio.events import BaseDefaultEventLoopPolicy\nImportError: cannot import name \'BaseDefaultEventLoopPolicy\' from \'asyncio.events\' (/usr/lib64/python3.14/asyncio/events.py)']","I'm not sure this was meant to actually be publicly exposed. Policies were deprecated since 3.12 and `asyncio.events.BaseDefaultEventLoopPolicy` has probably not been intended to be public (I can't find it documented anywhere). cc @kumaraditya303 

Note that it's not really gone, just that it has been now named as really ""private"" (but maybe it should have been kept half-public?)",[],['python'],github,https://github.com/python/cpython/issues/131148,{'repo': 'python/cpython'}
"segmentfault when pip installing setuptools

# Crash report

### What happened?

```
(test) ➜  build git:(development) gdb --args /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target '' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- 'setuptools>=40.8.0'
GNU gdb (GDB) Red Hat Enterprise Linux 8.2-20.el8
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-redhat-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...

warning: /workspace/git/ezennin/peda/peda.py: No such file or directory
Reading symbols from /workspace/git/ezennin/mbedtls/build/test/bin/python3...done.
(gdb) r
Starting program: /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target '' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- setuptools\>=40.8.0
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib64/libthread_db.so.1"".
Using pip 25.0.1 from /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip (python 3.12)
[Detaching after vfork from child process 728053]
[Detaching after vfork from child process 728078]
[Detaching after vfork from child process 728079]
Looking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
Collecting setuptools>=40.8.0
  Using cached https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/69/8a/b9dc7678803429e4a3bc9ba462fa3dd9066824d3c607490235c6a796be5a/setuptools-75.8.0-py3-none-any.whl (1.2 MB)
Installing collected packages: setuptools

Program received signal SIGSEGV, Segmentation fault.
0x00007fffe4c0e70f in _getcode (self=0x0, 
    name=0x1484b58 ""SNOWMAN}\"",\n"", ' ' <repeats 16 times>, ""extras_require={\""voting\"": [\""beaglevote\""]},\n"", ' ' <repeats 12 times>, "")\n"", ' ' <repeats 12 times>, ""@A\254"", namelen=7, 
    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275
1275        v = code_hash[i];
Missing separate debuginfos, use: yum debuginfo-install bzip2-libs-1.0.6-27.el8_10.x86_64 glibc-2.28-251.el8_10.5.x86_64 libuuid-2.32.1-46.el8.x86_64 openssl-libs-1.1.1k-14.el8_6.x86_64 xz-libs-5.2.4-4.el8_6.x86_64
(gdb) bt
#0  0x00007fffe4c0e70f in _getcode (self=0x0, 
    name=0x1484b58 ""SNOWMAN}\"",\n"", ' ' <repeats 16 times>, ""extras_require={\""voting\"": [\""beaglevote\""]},\n"", ' ' <repeats 12 times>, "")\n"", ' ' <repeats 12 times>, ""@A\254"", namelen=7, 
    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275
#1  0x0000000000584e89 in _PyUnicode_DecodeUnicodeEscapeInternal (s=<optimized out>, size=<optimized out>, errors=errors@entry=0x0, consumed=consumed@entry=0x0, 
    first_invalid_escape=first_invalid_escape@entry=0x7fffffffa588) at Objects/unicodeobject.c:6239
#2  0x00000000005b9e6d in decode_unicode_with_escapes (parser=0x7fffe3add110, s=<optimized out>, len=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, t=0x7fffe389d970)
    at Parser/string_parser.c:146
#3  0x0000000000544f30 in _PyPegen_constant_from_string (p=p@entry=0x7fffe3add110, tok=0x7fffe389d970) at Parser/action_helpers.c:1331
#4  0x0000000000549faa in string_rule (p=0x7fffe3add110) at Parser/parser.c:16242
#5  _tmp_259_rule (p=0x7fffe3add110) at Parser/parser.c:40700
#6  _loop1_115_rule (p=0x7fffe3add110) at Parser/parser.c:32163
#7  strings_rule (p=0x7fffe3add110) at Parser/parser.c:16294
#8  0x0000000000549370 in atom_rule (p=0x7fffe3add110) at Parser/parser.c:14819
#9  0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327
#10 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#11 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#12 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#13 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#14 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#15 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#16 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#17 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#18 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
#19 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#20 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#21 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#22 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#23 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#24 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#25 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#26 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#27 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#28 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#29 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#30 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#31 0x000000000054b99e in _tmp_122_rule (p=0x7fffe3add110) at Parser/parser.c:32616
#32 genexp_rule (p=0x7fffe3add110) at Parser/parser.c:17168
#33 0x0000000000550ec6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14115
#34 0x0000000000550cd8 in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#35 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#36 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#37 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#38 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#39 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#40 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#41 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#42 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
--Type <RET> for more, q to quit, c to continue without paging--
#43 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#44 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#45 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#46 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#47 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#48 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#49 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#50 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#51 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#52 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#53 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#54 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#55 0x00000000005b601f in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16753
#56 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714
#57 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32352
#58 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641
#59 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561
#60 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838
#61 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772
#62 0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327
#63 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#64 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#65 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#66 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#67 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#68 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#69 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#70 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#71 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
#72 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#73 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#74 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#75 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#76 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#77 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#78 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#79 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#80 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#81 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#82 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#83 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#84 0x00000000005b60be in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:32277
#85 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714
#86 _loop0_118_rule (p=0x7fffe3add110) at Parser/parser.c:32287
#87 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32354
#88 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641
#89 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561
--Type <RET> for more, q to quit, c to continue without paging--
#90 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838
#91 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772
#92 0x0000000000548aa5 in t_primary_raw (p=0x7fffe3add110) at Parser/parser.c:18966
#93 0x000000000054afa7 in t_primary_rule (p=0x7fffe3add110) at Parser/parser.c:18757
#94 target_with_star_atom_rule (p=0x7fffe3add110) at Parser/parser.c:18257
#95 0x000000000054a541 in star_target_rule (p=0x7fffe3add110) at Parser/parser.c:18199
#96 star_targets_rule (p=0x7fffe3add110) at Parser/parser.c:17942
#97 0x00000000005478e9 in _tmp_250_rule (p=0x7fffe3add110) at Parser/parser.c:40231
#98 _loop1_14_rule (p=0x7fffe3add110) at Parser/parser.c:25810
#99 assignment_rule (p=0x7fffe3add110) at Parser/parser.c:2360
#100 simple_stmt_rule (p=0x7fffe3add110) at Parser/parser.c:1707
#101 0x0000000000546fa1 in simple_stmts_rule (p=0x7fffe3add110) at Parser/parser.c:1601
#102 0x00000000005b2722 in statement_rule (p=0x7fffe3add110) at Parser/parser.c:1426
#103 _loop1_3_rule (p=0x7fffe3add110) at Parser/parser.c:25157
#104 statements_rule (p=0x7fffe3add110) at Parser/parser.c:1360
#105 file_rule (p=0x7fffe3add110) at Parser/parser.c:1162
#106 _PyPegen_parse (p=p@entry=0x7fffe3add110) at Parser/parser.c:41920
#107 0x00000000005b142d in _PyPegen_run_parser (p=0x7fffe3add110) at Parser/pegen.c:926
#108 0x00000000005b1263 in _PyPegen_run_parser_from_string (
    str=str@entry=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., start_rule=start_rule@entry=257, filename_ob=filename_ob@entry=0x7fffe3c84c90, flags=flags@entry=0x7fffffffbab8, arena=0x7fffe3c26710, 
    arena@entry=0x5b1263 <_PyPegen_run_parser_from_string+147>) at Parser/pegen.c:1039
#109 0x00000000005b9f2a in _PyParser_ASTFromString (
    str=str@entry=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., filename=filename@entry=0x7fffe3c84c90, mode=mode@entry=257, flags=flags@entry=0x7fffffffbab8, arena=0x5b1263 <_PyPegen_run_parser_from_string+147>, 
    arena@entry=0x7fffe3c26710) at Parser/peg_api.c:14
#110 0x00000000005fcec4 in Py_CompileStringObject (
    str=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., filename=filename@entry=0x7fffe3c84c90, start=start@entry=257, flags=flags@entry=0x7fffffffbab8, optimize=optimize@entry=-1) at Python/pythonrun.c:1801
#111 0x00000000005e28e3 in builtin_compile_impl (module=<optimized out>, source=0x14925a0, filename=0x7fffe3c84c90, mode=0xace568 <const_str_exec+40> ""exec"", flags=0, dont_inherit=1, optimize=-1, 
    feature_version=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:831
#112 builtin_compile (module=<optimized out>, args=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargs=<optimized out>, kwnames=<optimized out>)
    at Python/clinic/bltinmodule.c.h:383
#113 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50
#114 0x00000000005bd795 in _PyVectorcall_Call (tstate=0xb53070 <_PyRuntime+458992>, func=0x56c220 <cfunction_vectorcall_FASTCALL_KEYWORDS>, callable=0x7ffff7f745e0, tuple=<optimized out>, 
    kwargs=<optimized out>) at Objects/call.c:283
#115 0x000000000059602a in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:3263
#116 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xc33ec0, globals=globals@entry=0x7fffe9fd0a00, locals=locals@entry=0x7fffe9fd0a00) at Python/ceval.c:578
#117 0x00000000005e2573 in builtin_exec_impl (module=<optimized out>, source=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, globals=0x7fffe9fd0a00, 
    locals=0x7fffe9fd0a00, closure=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:1096
#118 builtin_exec (module=<optimized out>, args=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Python/clinic/bltinmodule.c.h:586
#119 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50
#120 0x000000000055a0e4 in _PyObject_VectorcallTstate (tstate=0xb53070 <_PyRuntime+458992>, callable=0x7ffff7f74770, 
    callable@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, args=<optimized out>, 
    args@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargsf=<optimized out>, 
    nargsf@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, kwnames=<optimized out>, 
    kwnames@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at ./Include/internal/pycore_call.h:92
--Type <RET> for more, q to quit, c to continue without paging--
#121 PyObject_Vectorcall (callable=0x7ffff7f74770, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at Objects/call.c:325
#122 0x000000000058eca9 in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:2715
#123 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xbf72b0, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0) at Python/ceval.c:578
#124 0x00000000005fd0e7 in run_eval_code_obj (tstate=0xb53070 <_PyRuntime+458992>, co=0xbf72b0, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0) at Python/pythonrun.c:1722
#125 0x00000000005fd073 in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0, flags=<optimized out>, arena=<optimized out>) at Python/pythonrun.c:1743
#126 0x00000000005fd4e2 in pyrun_file (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, start=start@entry=257, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0, 
    closeit=closeit@entry=1, flags=0x7fffffffc208) at Python/pythonrun.c:1643
#127 0x00000000005fd395 in _PyRun_SimpleFileObject (fp=0xb96840, filename=0x7ffff7f30810, closeit=1, flags=0x7fffffffc208) at Python/pythonrun.c:433
#128 0x00000000005fd1ca in _PyRun_AnyFileObject (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, closeit=closeit@entry=1, flags=flags@entry=0x7fffffffc208) at Python/pythonrun.c:78
#129 0x0000000000602e41 in pymain_run_file_obj (program_name=0x7ffff7f07150, filename=0x7ffff7f30810, skip_source_first_line=0) at Modules/main.c:360
#130 pymain_run_file (config=0xaf5c50 <_PyRuntime+77008>) at Modules/main.c:379
#131 pymain_run_python (exitcode=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Modules/main.c:633
#132 Py_RunMain () at Modules/main.c:713
#133 0x0000000000602a95 in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at Modules/main.c:767
#134 0x00007ffff70877e5 in __libc_start_main () from /lib64/libc.so.6
#135 0x00000000005b102e in _start () at Modules/main.c:478
(gdb) 
(gdb) 
(gdb) p code_hash
value requires 262144 bytes, which is more than max-value-size
(gdb) info locals
h = 9443209
v = <optimized out>
i = 9496694
incr = <optimized out>
(gdb) 
```

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

_No response_","['(test) ➜  build git:(development) gdb --args /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target \'\' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- \'setuptools>=40.8.0\'\nGNU gdb (GDB) Red Hat Enterprise Linux 8.2-20.el8\nCopyright (C) 2018 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nType ""show copying"" and ""show warranty"" for details.\nThis GDB was configured as ""x86_64-redhat-linux-gnu"".\nType ""show configuration"" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n    <http://www.gnu.org/software/gdb/documentation/>.\n\nFor help, type ""help"".\nType ""apropos word"" to search for commands related to ""word""...\n\nwarning: /workspace/git/ezennin/peda/peda.py: No such file or directory\nReading symbols from /workspace/git/ezennin/mbedtls/build/test/bin/python3...done.\n(gdb) r\nStarting program: /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target \'\' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- setuptools\\>=40.8.0\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library ""/lib64/libthread_db.so.1"".\nUsing pip 25.0.1 from /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip (python 3.12)\n[Detaching after vfork from child process 728053]\n[Detaching after vfork from child process 728078]\n[Detaching after vfork from child process 728079]\nLooking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\nCollecting setuptools>=40.8.0\n  Using cached https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/69/8a/b9dc7678803429e4a3bc9ba462fa3dd9066824d3c607490235c6a796be5a/setuptools-75.8.0-py3-none-any.whl (1.2 MB)\nInstalling collected packages: setuptools\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007fffe4c0e70f in _getcode (self=0x0, \n    name=0x1484b58 ""SNOWMAN}\\"",\\n"", \' \' <repeats 16 times>, ""extras_require={\\""voting\\"": [\\""beaglevote\\""]},\\n"", \' \' <repeats 12 times>, "")\\n"", \' \' <repeats 12 times>, ""@A\\254"", namelen=7, \n    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275\n1275        v = code_hash[i];\nMissing separate debuginfos, use: yum debuginfo-install bzip2-libs-1.0.6-27.el8_10.x86_64 glibc-2.28-251.el8_10.5.x86_64 libuuid-2.32.1-46.el8.x86_64 openssl-libs-1.1.1k-14.el8_6.x86_64 xz-libs-5.2.4-4.el8_6.x86_64\n(gdb) bt\n#0  0x00007fffe4c0e70f in _getcode (self=0x0, \n    name=0x1484b58 ""SNOWMAN}\\"",\\n"", \' \' <repeats 16 times>, ""extras_require={\\""voting\\"": [\\""beaglevote\\""]},\\n"", \' \' <repeats 12 times>, "")\\n"", \' \' <repeats 12 times>, ""@A\\254"", namelen=7, \n    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275\n#1  0x0000000000584e89 in _PyUnicode_DecodeUnicodeEscapeInternal (s=<optimized out>, size=<optimized out>, errors=errors@entry=0x0, consumed=consumed@entry=0x0, \n    first_invalid_escape=first_invalid_escape@entry=0x7fffffffa588) at Objects/unicodeobject.c:6239\n#2  0x00000000005b9e6d in decode_unicode_with_escapes (parser=0x7fffe3add110, s=<optimized out>, len=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, t=0x7fffe389d970)\n    at Parser/string_parser.c:146\n#3  0x0000000000544f30 in _PyPegen_constant_from_string (p=p@entry=0x7fffe3add110, tok=0x7fffe389d970) at Parser/action_helpers.c:1331\n#4  0x0000000000549faa in string_rule (p=0x7fffe3add110) at Parser/parser.c:16242\n#5  _tmp_259_rule (p=0x7fffe3add110) at Parser/parser.c:40700\n#6  _loop1_115_rule (p=0x7fffe3add110) at Parser/parser.c:32163\n#7  strings_rule (p=0x7fffe3add110) at Parser/parser.c:16294\n#8  0x0000000000549370 in atom_rule (p=0x7fffe3add110) at Parser/parser.c:14819\n#9  0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327\n#10 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126\n#11 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079\n#12 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956\n#13 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906\n#14 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746\n#15 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509\n#16 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462\n#17 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342\n#18 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301\n#19 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181\n#20 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140\n#21 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059\n#22 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019\n#23 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937\n#24 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896\n#25 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815\n#26 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055\n#27 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006\n#28 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882\n#29 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794\n#30 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082\n#31 0x000000000054b99e in _tmp_122_rule (p=0x7fffe3add110) at Parser/parser.c:32616\n#32 genexp_rule (p=0x7fffe3add110) at Parser/parser.c:17168\n#33 0x0000000000550ec6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14115\n#34 0x0000000000550cd8 in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126\n#35 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079\n#36 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956\n#37 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906\n#38 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746\n#39 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509\n#40 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462\n#41 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342\n#42 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301\n--Type <RET> for more, q to quit, c to continue without paging--\n#43 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181\n#44 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140\n#45 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059\n#46 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019\n#47 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937\n#48 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896\n#49 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815\n#50 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055\n#51 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006\n#52 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882\n#53 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794\n#54 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082\n#55 0x00000000005b601f in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16753\n#56 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714\n#57 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32352\n#58 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641\n#59 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561\n#60 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838\n#61 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772\n#62 0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327\n#63 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126\n#64 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079\n#65 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956\n#66 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906\n#67 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746\n#68 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509\n#69 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462\n#70 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342\n#71 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301\n#72 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181\n#73 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140\n#74 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059\n#75 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019\n#76 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937\n#77 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896\n#78 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815\n#79 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055\n#80 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006\n#81 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882\n#82 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794\n#83 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082\n#84 0x00000000005b60be in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:32277\n#85 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714\n#86 _loop0_118_rule (p=0x7fffe3add110) at Parser/parser.c:32287\n#87 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32354\n#88 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641\n#89 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561\n--Type <RET> for more, q to quit, c to continue without paging--\n#90 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838\n#91 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772\n#92 0x0000000000548aa5 in t_primary_raw (p=0x7fffe3add110) at Parser/parser.c:18966\n#93 0x000000000054afa7 in t_primary_rule (p=0x7fffe3add110) at Parser/parser.c:18757\n#94 target_with_star_atom_rule (p=0x7fffe3add110) at Parser/parser.c:18257\n#95 0x000000000054a541 in star_target_rule (p=0x7fffe3add110) at Parser/parser.c:18199\n#96 star_targets_rule (p=0x7fffe3add110) at Parser/parser.c:17942\n#97 0x00000000005478e9 in _tmp_250_rule (p=0x7fffe3add110) at Parser/parser.c:40231\n#98 _loop1_14_rule (p=0x7fffe3add110) at Parser/parser.c:25810\n#99 assignment_rule (p=0x7fffe3add110) at Parser/parser.c:2360\n#100 simple_stmt_rule (p=0x7fffe3add110) at Parser/parser.c:1707\n#101 0x0000000000546fa1 in simple_stmts_rule (p=0x7fffe3add110) at Parser/parser.c:1601\n#102 0x00000000005b2722 in statement_rule (p=0x7fffe3add110) at Parser/parser.c:1426\n#103 _loop1_3_rule (p=0x7fffe3add110) at Parser/parser.c:25157\n#104 statements_rule (p=0x7fffe3add110) at Parser/parser.c:1360\n#105 file_rule (p=0x7fffe3add110) at Parser/parser.c:1162\n#106 _PyPegen_parse (p=p@entry=0x7fffe3add110) at Parser/parser.c:41920\n#107 0x00000000005b142d in _PyPegen_run_parser (p=0x7fffe3add110) at Parser/pegen.c:926\n#108 0x00000000005b1263 in _PyPegen_run_parser_from_string (\n    str=str@entry=0x14925c0 ""from __future__ import annotations\\n\\nimport builtins\\nimport importlib\\nimport os.path\\nimport platform\\nimport shutil\\nimport stat\\nimport struct\\nimport sys\\nimport sysconfig\\nfrom contextlib import suppress\\n""..., start_rule=start_rule@entry=257, filename_ob=filename_ob@entry=0x7fffe3c84c90, flags=flags@entry=0x7fffffffbab8, arena=0x7fffe3c26710, \n    arena@entry=0x5b1263 <_PyPegen_run_parser_from_string+147>) at Parser/pegen.c:1039\n#109 0x00000000005b9f2a in _PyParser_ASTFromString (\n    str=str@entry=0x14925c0 ""from __future__ import annotations\\n\\nimport builtins\\nimport importlib\\nimport os.path\\nimport platform\\nimport shutil\\nimport stat\\nimport struct\\nimport sys\\nimport sysconfig\\nfrom contextlib import suppress\\n""..., filename=filename@entry=0x7fffe3c84c90, mode=mode@entry=257, flags=flags@entry=0x7fffffffbab8, arena=0x5b1263 <_PyPegen_run_parser_from_string+147>, \n    arena@entry=0x7fffe3c26710) at Parser/peg_api.c:14\n#110 0x00000000005fcec4 in Py_CompileStringObject (\n    str=0x14925c0 ""from __future__ import annotations\\n\\nimport builtins\\nimport importlib\\nimport os.path\\nimport platform\\nimport shutil\\nimport stat\\nimport struct\\nimport sys\\nimport sysconfig\\nfrom contextlib import suppress\\n""..., filename=filename@entry=0x7fffe3c84c90, start=start@entry=257, flags=flags@entry=0x7fffffffbab8, optimize=optimize@entry=-1) at Python/pythonrun.c:1801\n#111 0x00000000005e28e3 in builtin_compile_impl (module=<optimized out>, source=0x14925a0, filename=0x7fffe3c84c90, mode=0xace568 <const_str_exec+40> ""exec"", flags=0, dont_inherit=1, optimize=-1, \n    feature_version=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:831\n#112 builtin_compile (module=<optimized out>, args=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargs=<optimized out>, kwnames=<optimized out>)\n    at Python/clinic/bltinmodule.c.h:383\n#113 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50\n#114 0x00000000005bd795 in _PyVectorcall_Call (tstate=0xb53070 <_PyRuntime+458992>, func=0x56c220 <cfunction_vectorcall_FASTCALL_KEYWORDS>, callable=0x7ffff7f745e0, tuple=<optimized out>, \n    kwargs=<optimized out>) at Objects/call.c:283\n#115 0x000000000059602a in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:3263\n#116 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xc33ec0, globals=globals@entry=0x7fffe9fd0a00, locals=locals@entry=0x7fffe9fd0a00) at Python/ceval.c:578\n#117 0x00000000005e2573 in builtin_exec_impl (module=<optimized out>, source=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, globals=0x7fffe9fd0a00, \n    locals=0x7fffe9fd0a00, closure=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:1096\n#118 builtin_exec (module=<optimized out>, args=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Python/clinic/bltinmodule.c.h:586\n#119 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50\n#120 0x000000000055a0e4 in _PyObject_VectorcallTstate (tstate=0xb53070 <_PyRuntime+458992>, callable=0x7ffff7f74770, \n    callable@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, args=<optimized out>, \n    args@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargsf=<optimized out>, \n    nargsf@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, kwnames=<optimized out>, \n    kwnames@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at ./Include/internal/pycore_call.h:92\n--Type <RET> for more, q to quit, c to continue without paging--\n#121 PyObject_Vectorcall (callable=0x7ffff7f74770, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at Objects/call.c:325\n#122 0x000000000058eca9 in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:2715\n#123 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xbf72b0, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0) at Python/ceval.c:578\n#124 0x00000000005fd0e7 in run_eval_code_obj (tstate=0xb53070 <_PyRuntime+458992>, co=0xbf72b0, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0) at Python/pythonrun.c:1722\n#125 0x00000000005fd073 in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0, flags=<optimized out>, arena=<optimized out>) at Python/pythonrun.c:1743\n#126 0x00000000005fd4e2 in pyrun_file (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, start=start@entry=257, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0, \n    closeit=closeit@entry=1, flags=0x7fffffffc208) at Python/pythonrun.c:1643\n#127 0x00000000005fd395 in _PyRun_SimpleFileObject (fp=0xb96840, filename=0x7ffff7f30810, closeit=1, flags=0x7fffffffc208) at Python/pythonrun.c:433\n#128 0x00000000005fd1ca in _PyRun_AnyFileObject (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, closeit=closeit@entry=1, flags=flags@entry=0x7fffffffc208) at Python/pythonrun.c:78\n#129 0x0000000000602e41 in pymain_run_file_obj (program_name=0x7ffff7f07150, filename=0x7ffff7f30810, skip_source_first_line=0) at Modules/main.c:360\n#130 pymain_run_file (config=0xaf5c50 <_PyRuntime+77008>) at Modules/main.c:379\n#131 pymain_run_python (exitcode=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Modules/main.c:633\n#132 Py_RunMain () at Modules/main.c:713\n#133 0x0000000000602a95 in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at Modules/main.c:767\n#134 0x00007ffff70877e5 in __libc_start_main () from /lib64/libc.so.6\n#135 0x00000000005b102e in _start () at Modules/main.c:478\n(gdb) \n(gdb) \n(gdb) p code_hash\nvalue requires 262144 bytes, which is more than max-value-size\n(gdb) info locals\nh = 9443209\nv = <optimized out>\ni = 9496694\nincr = <optimized out>\n(gdb)']","close duplicate one,see 129993 for detail",[],['python'],github,https://github.com/python/cpython/issues/129992,{'repo': 'python/cpython'}
"Make RotatingFileHandler pad numbers with leading zeros

# Feature or enhancement

### Proposal:

`logging.handlers.RotatingFileHandler` appends a number to a log file when performing the rotation. These numbers do not contain any leading zeros even if `RotatingFileHandler` is configured to create 10 or more backups, i.e. with `backupCount` set to 10 or bigger.

Hence, the log files are not properly ordered when listed. For example, a section of the list might look like:

```
log.18
log.19
log.2
log.20
log.21
```

or even worse:

```
log.1
log.10
log.100
log.11
log.12
```

It would be nice if `RotatingFileHandler` would pad the numbers with leading zeros up to the number of digits in the init argument `backupCount` in order to create a chronologically sorted list of log files, such that the latter example would look like:

```
log.001
log.002
...
log.010
log.011
log.012
...
log.100
```

This would help when analyzing the log files, particularly when you do a manual binary search for messages in a big number of rotated log files.


### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_","['log.18\nlog.19\nlog.2\nlog.20\nlog.21', 'log.1\nlog.10\nlog.100\nlog.11\nlog.12', 'log.001\nlog.002\n...\nlog.010\nlog.011\nlog.012\n...\nlog.100']",That's what [namer](https://docs.python.org/3/library/logging.handlers.html#logging.handlers.BaseRotatingHandler.namer) is for.,[],['python'],github,https://github.com/python/cpython/issues/130256,{'repo': 'python/cpython'}
"[sqlite3] Converter Not Called with Aggregate Functions

# Bug report

### Bug description:

The converter functions are correctly called when using the raw field name in a query, but when you use an aggregate function like `MIN(fieldname)` the value is returned as a string. 

## Minimal Example
```python
import sqlite3


sqlite3.register_converter('faketype', lambda s: int(s.rstrip(b';')))
con = sqlite3.connect(':memory:', detect_types=sqlite3.PARSE_DECLTYPES)
cur = con.execute('CREATE TABLE awesome(f faketype)')
cur.execute('INSERT INTO awesome(f) VALUES(""5;"")')

queries = ['SELECT f FROM awesome', 'SELECT MIN(f) FROM awesome']
for query in queries:
    cur.execute(query)
    result = cur.fetchone()[0]
    print(f'{query}\n{type(result)} {result}\n')
```

## Expected Output
```console
SELECT f FROM awesome
<class 'int'> 5

SELECT MIN(f) FROM awesome
<class 'int'> 5
```

Both queries return an integer


## Actual Output
```console
SELECT f FROM awesome
<class 'int'> 5

SELECT MIN(f) FROM awesome
<class 'str'> 5;
```

The query with just the fieldname `f` returns the proper type (int). The query using the aggregate function `MIN(f)` returns a string, indicating the converter function has not been called. 

## Additional information
A slightly expanded example is [available as gist](https://gist.github.com/DLu/19cb472d9864274931ada38c729fa686)

`Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0] on linux` / Ubuntu 24.04




### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-131006
<!-- /gh-linked-prs -->
","['import sqlite3\n\n\nsqlite3.register_converter(\'faketype\', lambda s: int(s.rstrip(b\';\')))\ncon = sqlite3.connect(\':memory:\', detect_types=sqlite3.PARSE_DECLTYPES)\ncur = con.execute(\'CREATE TABLE awesome(f faketype)\')\ncur.execute(\'INSERT INTO awesome(f) VALUES(""5;"")\')\n\nqueries = [\'SELECT f FROM awesome\', \'SELECT MIN(f) FROM awesome\']\nfor query in queries:\n    cur.execute(query)\n    result = cur.fetchone()[0]\n    print(f\'{query}\\n{type(result)} {result}\\n\')', ""SELECT f FROM awesome\n<class 'int'> 5\n\nSELECT MIN(f) FROM awesome\n<class 'int'> 5"", ""SELECT f FROM awesome\n<class 'int'> 5\n\nSELECT MIN(f) FROM awesome\n<class 'str'> 5;""]",Is this the same in pure sqlite3 or not? ,[],['python'],github,https://github.com/python/cpython/issues/131002,{'repo': 'python/cpython'}
"Value of ""tm_gmtoff"" is invalid when setting time far in the future on Windows

# Bug report

### Bug description:

Hi.

On Windows 11, when changing the system time to the year 2040 (through OS settings), the value of [`struct_time.tm_gmtoff`](https://docs.python.org/3.12/library/time.html#time.struct_time.tm_gmtoff) becomes unreliable.

The following code:

```python
from time import localtime
from datetime import datetime

now = datetime.now()
timestamp = now.timestamp()
local = localtime(timestamp)

print(f""tm_gmtoff: {local.tm_gmtoff}"")
```

Outputs on my computer:
```
tm_gmtoff: -4294963696
```

My real offset from UTC is +3600 seconds. It's worth noting that -2**32 + 3600 = -4294963696.

I noted the following code can be used as a workaround, producing the expected 3600 value despite the time shift:

```python
from datetime import datetime, timezone

timestamp = now = datetime.now().timestamp()
utc_naive = datetime.fromtimestamp(timestamp, tz=timezone.utc).replace(tzinfo=None)
offset = datetime.fromtimestamp(timestamp) - utc_naive
seconds = offset.total_seconds()

print(f""offset: {seconds}"")
```

As a more concrete real-world scenario, clock shifting can occur accidentally due to battery issues (as per the user who originally reported this bug to me).

I don't know if this should be considered a bug for CPython. If not, could we at least add a note about this edge case in the documentation?

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['from time import localtime\nfrom datetime import datetime\n\nnow = datetime.now()\ntimestamp = now.timestamp()\nlocal = localtime(timestamp)\n\nprint(f""tm_gmtoff: {local.tm_gmtoff}"")', 'tm_gmtoff: -4294963696', 'from datetime import datetime, timezone\n\ntimestamp = now = datetime.now().timestamp()\nutc_naive = datetime.fromtimestamp(timestamp, tz=timezone.utc).replace(tzinfo=None)\noffset = datetime.fromtimestamp(timestamp) - utc_naive\nseconds = offset.total_seconds()\n\nprint(f""offset: {seconds}"")']","Closing, sorry, it seems already documented. Year 2040 falls out of the range supported by [`localtime`](https://docs.python.org/3/library/time.html#time.localtime):

> [`localtime()`](https://docs.python.org/3/library/time.html#time.localtime) may raise [`OverflowError`](https://docs.python.org/3/library/exceptions.html#OverflowError), if the timestamp is outside the range of values supported by the platform C `localtime()` or `gmtime()` functions, and [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError) on `localtime()` or `gmtime()` failure. It’s common for this to be restricted to years between 1970 and 2038.",[],['python'],github,https://github.com/python/cpython/issues/130047,{'repo': 'python/cpython'}
"Support PGO for clang-cl

# Feature or enhancement

### Proposal:

Support PGO (profile guided optimization) for clang-cl on Windows using a similar approach as done in the Linux makefiles for clang.


### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

Discussion has started in the PR https://github.com/python/cpython/pull/129907 while being draft.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129907
* gh-131005
<!-- /gh-linked-prs -->

64bit pyperformance results on my Windows 10 PC (dusty i5-4570 CPU) run with `--fast --affinity 0` for commit https://github.com/python/cpython/pull/129907/commits/9db1a297d95574cc3114854c8c427736d9521917 with
- Microsoft Visual Studio 2022 17.13.0 Preview 5.0 which can do PGO again (https://github.com/python/cpython/issues/129244)
- which ships with clang-cl 19.1.1

| Benchmark                        | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9    | clang.pgo.9db1a297d9   |
|----------------------------------|-------------------------|--------------------------|------------------------|------------------------|
| Geometric mean                   | (ref)                   | 1.27x faster             | 1.28x faster           | 1.47x faster           |

| Benchmark                        | msvc.release.9db1a297d9 | clang.release.9db1a297d9 |
|----------------------------------|-------------------------|--------------------------|
| Geometric mean                   | (ref)                   | 1.27x faster             |

clang 18.1.8 is faster than 19.1.1, and 20.1.0.rc2 with tailcalling is the fastest:
| Benchmark       | msvc.pgo.9db1a297d9 | clang.pgo.18.1.8.9db1a297d9 | clang.pgo.9db1a297d9   | clang.pgo.tc.20.1.0.rc2.9db1a297d9 |
|-----------------|---------------------|-----------------------------|------------------------|------------------------------------|
| Geometric mean  | (ref)               | 1.19x faster                | 1.15x faster           | 1.25x faster                       |


<details><summary>Details</summary>
<p>
Benchmarks with tag 'apps':

| Benchmark      | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9    | clang.pgo.9db1a297d9   |
|----------------|-------------------------|--------------------------|------------------------|------------------------|
| 2to3           | 586 ms                  | 491 ms: 1.19x faster     | 462 ms: 1.27x faster   | 426 ms: 1.38x faster   |
| docutils       | 4.27 sec                | 3.75 sec: 1.14x faster   | 3.50 sec: 1.22x faster | 3.31 sec: 1.29x faster |
| html5lib       | 104 ms                  | 81.6 ms: 1.28x faster    | 77.9 ms: 1.34x faster  | 74.5 ms: 1.40x faster  |
| Geometric mean | (ref)                   | 1.20x faster             | 1.28x faster           | 1.35x faster           |

Benchmarks with tag 'asyncio':

| Benchmark                        | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9  | clang.pgo.9db1a297d9 |
|----------------------------------|-------------------------|--------------------------|----------------------|----------------------|
| async_tree_none                  | 511 ms                  | 383 ms: 1.33x faster     | 394 ms: 1.30x faster | 357 ms: 1.43x faster |
| async_tree_cpu_io_mixed          | 933 ms                  | 805 ms: 1.16x faster     | 749 ms: 1.25x faster | 697 ms: 1.34x faster |
| async_tree_cpu_io_mixed_tg       | 891 ms                  | 776 ms: 1.15x faster     | 716 ms: 1.24x faster | 665 ms: 1.34x faster |
| async_tree_eager                 | 209 ms                  | 153 ms: 1.37x faster     | 160 ms: 1.31x faster | 133 ms: 1.57x faster |
| async_tree_eager_cpu_io_mixed    | 656 ms                  | 630 ms: 1.04x faster     | 567 ms: 1.16x faster | 535 ms: 1.23x faster |
| async_tree_eager_cpu_io_mixed_tg | 830 ms                  | 741 ms: 1.12x faster     | 681 ms: 1.22x faster | 646 ms: 1.28x faster |
| async_tree_eager_io              | 1.12 sec                | 870 ms: 1.29x faster     | 874 ms: 1.28x faster | 817 ms: 1.37x faster |
| async_tree_eager_io_tg           | 1.12 sec                | 890 ms: 1.26x faster     | 898 ms: 1.25x faster | 840 ms: 1.33x faster |
| async_tree_eager_memoization     | 393 ms                  | 304 ms: 1.29x faster     | 304 ms: 1.29x faster | 281 ms: 1.40x faster |
| async_tree_eager_memoization_tg  | 546 ms                  | 420 ms: 1.30x faster     | 427 ms: 1.28x faster | 397 ms: 1.37x faster |
| async_tree_eager_tg              | 408 ms                  | 312 ms: 1.31x faster     | 321 ms: 1.27x faster | 297 ms: 1.38x faster |
| async_tree_io                    | 1.14 sec                | 868 ms: 1.31x faster     | 889 ms: 1.28x faster | 824 ms: 1.38x faster |
| async_tree_io_tg                 | 1.14 sec                | 871 ms: 1.31x faster     | 877 ms: 1.30x faster | 807 ms: 1.41x faster |
| async_tree_memoization           | 649 ms                  | 493 ms: 1.32x faster     | 509 ms: 1.28x faster | 458 ms: 1.42x faster |
| async_tree_memoization_tg        | 605 ms                  | 453 ms: 1.34x faster     | 462 ms: 1.31x faster | 425 ms: 1.42x faster |
| async_tree_none_tg               | 497 ms                  | 371 ms: 1.34x faster     | 382 ms: 1.30x faster | 352 ms: 1.41x faster |
| Geometric mean                   | (ref)                   | 1.26x faster             | 1.27x faster         | 1.38x faster         |

Benchmarks with tag 'math':

| Benchmark      | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9  | clang.pgo.9db1a297d9  |
|----------------|-------------------------|--------------------------|----------------------|-----------------------|
| float          | 145 ms                  | 108 ms: 1.35x faster     | 116 ms: 1.25x faster | 96.8 ms: 1.50x faster |
| nbody          | 203 ms                  | 155 ms: 1.31x faster     | 171 ms: 1.19x faster | 128 ms: 1.58x faster  |
| pidigits       | 245 ms                  | 250 ms: 1.02x slower     | 250 ms: 1.02x slower | 240 ms: 1.02x faster  |
| Geometric mean | (ref)                   | 1.20x faster             | 1.13x faster         | 1.34x faster          |

Benchmarks with tag 'regex':

| Benchmark      | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9   | clang.pgo.9db1a297d9  |
|----------------|-------------------------|--------------------------|-----------------------|-----------------------|
| regex_compile  | 237 ms                  | 180 ms: 1.31x faster     | 180 ms: 1.31x faster  | 157 ms: 1.51x faster  |
| regex_dna      | 226 ms                  | 256 ms: 1.14x slower     | 210 ms: 1.07x faster  | 211 ms: 1.07x faster  |
| regex_effbot   | 4.05 ms                 | not significant          | 3.66 ms: 1.11x faster | 3.39 ms: 1.20x faster |
| regex_v8       | 38.7 ms                 | 35.7 ms: 1.08x faster    | 33.7 ms: 1.15x faster | 29.8 ms: 1.30x faster |
| Geometric mean | (ref)                   | 1.06x faster             | 1.16x faster          | 1.26x faster          |

Benchmarks with tag 'serialize':

| Benchmark            | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9    | clang.pgo.9db1a297d9   |
|----------------------|-------------------------|--------------------------|------------------------|------------------------|
| json_dumps           | 19.6 ms                 | 16.9 ms: 1.16x faster    | 15.0 ms: 1.31x faster  | 12.9 ms: 1.52x faster  |
| json_loads           | 48.1 us                 | 46.7 us: 1.03x faster    | 36.8 us: 1.31x faster  | 32.7 us: 1.47x faster  |
| pickle               | 21.5 us                 | 17.9 us: 1.20x faster    | 19.1 us: 1.13x faster  | 15.0 us: 1.44x faster  |
| pickle_dict          | 46.0 us                 | 34.3 us: 1.34x faster    | 43.2 us: 1.07x faster  | 27.6 us: 1.67x faster  |
| pickle_list          | 8.16 us                 | 6.19 us: 1.32x faster    | 6.89 us: 1.18x faster  | 5.05 us: 1.62x faster  |
| pickle_pure_python   | 672 us                  | 455 us: 1.48x faster     | 463 us: 1.45x faster   | 378 us: 1.78x faster   |
| tomli_loads          | 3.84 sec                | 2.79 sec: 1.38x faster   | 2.88 sec: 1.33x faster | 2.38 sec: 1.61x faster |
| unpickle             | 26.2 us                 | 24.0 us: 1.09x faster    | 19.8 us: 1.32x faster  | 17.9 us: 1.46x faster  |
| unpickle_list        | 7.29 us                 | 6.03 us: 1.21x faster    | 6.87 us: 1.06x faster  | 5.38 us: 1.36x faster  |
| unpickle_pure_python | 505 us                  | 321 us: 1.57x faster     | 336 us: 1.50x faster   | 257 us: 1.96x faster   |
| xml_etree_parse      | 232 ms                  | 228 ms: 1.02x faster     | 200 ms: 1.16x faster   | 210 ms: 1.10x faster   |
| xml_etree_iterparse  | 185 ms                  | 160 ms: 1.16x faster     | 154 ms: 1.21x faster   | 145 ms: 1.27x faster   |
| xml_etree_generate   | 181 ms                  | 148 ms: 1.22x faster     | 135 ms: 1.35x faster   | 119 ms: 1.53x faster   |
| xml_etree_process    | 128 ms                  | 100 ms: 1.28x faster     | 94.4 ms: 1.36x faster  | 82.0 ms: 1.56x faster  |
| Geometric mean       | (ref)                   | 1.24x faster             | 1.26x faster           | 1.51x faster           |

Benchmarks with tag 'startup':

| Benchmark              | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9   | clang.pgo.9db1a297d9  |
|------------------------|-------------------------|--------------------------|-----------------------|-----------------------|
| python_startup         | 45.4 ms                 | not significant          | 43.1 ms: 1.05x faster | 43.7 ms: 1.04x faster |
| python_startup_no_site | 37.1 ms                 | not significant          | 35.4 ms: 1.05x faster | 35.9 ms: 1.03x faster |
| Geometric mean         | (ref)                   | 1.00x faster             | 1.05x faster          | 1.04x faster          |

Benchmarks with tag 'template':

| Benchmark       | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9   | clang.pgo.9db1a297d9  |
|-----------------|-------------------------|--------------------------|-----------------------|-----------------------|
| django_template | 75.6 ms                 | 55.6 ms: 1.36x faster    | 52.1 ms: 1.45x faster | 42.1 ms: 1.79x faster |
| genshi_text     | 44.5 ms                 | 31.4 ms: 1.42x faster    | 32.5 ms: 1.37x faster | 26.3 ms: 1.69x faster |
| genshi_xml      | 102 ms                  | 74.0 ms: 1.37x faster    | 74.6 ms: 1.36x faster | 63.1 ms: 1.61x faster |
| mako            | 23.3 ms                 | 17.7 ms: 1.31x faster    | 16.7 ms: 1.39x faster | 14.4 ms: 1.61x faster |
| Geometric mean  | (ref)                   | 1.36x faster             | 1.39x faster          | 1.67x faster          |

All benchmarks:

| Benchmark                        | msvc.release.9db1a297d9 | clang.release.9db1a297d9 | msvc.pgo.9db1a297d9    | clang.pgo.9db1a297d9   |
|----------------------------------|-------------------------|--------------------------|------------------------|------------------------|
| 2to3                             | 586 ms                  | 491 ms: 1.19x faster     | 462 ms: 1.27x faster   | 426 ms: 1.38x faster   |
| async_generators                 | 696 ms                  | 565 ms: 1.23x faster     | 577 ms: 1.21x faster   | 514 ms: 1.35x faster   |
| async_tree_none                  | 511 ms                  | 383 ms: 1.33x faster     | 394 ms: 1.30x faster   | 357 ms: 1.43x faster   |
| async_tree_cpu_io_mixed          | 933 ms                  | 805 ms: 1.16x faster     | 749 ms: 1.25x faster   | 697 ms: 1.34x faster   |
| async_tree_cpu_io_mixed_tg       | 891 ms                  | 776 ms: 1.15x faster     | 716 ms: 1.24x faster   | 665 ms: 1.34x faster   |
| async_tree_eager                 | 209 ms                  | 153 ms: 1.37x faster     | 160 ms: 1.31x faster   | 133 ms: 1.57x faster   |
| async_tree_eager_cpu_io_mixed    | 656 ms                  | 630 ms: 1.04x faster     | 567 ms: 1.16x faster   | 535 ms: 1.23x faster   |
| async_tree_eager_cpu_io_mixed_tg | 830 ms                  | 741 ms: 1.12x faster     | 681 ms: 1.22x faster   | 646 ms: 1.28x faster   |
| async_tree_eager_io              | 1.12 sec                | 870 ms: 1.29x faster     | 874 ms: 1.28x faster   | 817 ms: 1.37x faster   |
| async_tree_eager_io_tg           | 1.12 sec                | 890 ms: 1.26x faster     | 898 ms: 1.25x faster   | 840 ms: 1.33x faster   |
| async_tree_eager_memoization     | 393 ms                  | 304 ms: 1.29x faster     | 304 ms: 1.29x faster   | 281 ms: 1.40x faster   |
| async_tree_eager_memoization_tg  | 546 ms                  | 420 ms: 1.30x faster     | 427 ms: 1.28x faster   | 397 ms: 1.37x faster   |
| async_tree_eager_tg              | 408 ms                  | 312 ms: 1.31x faster     | 321 ms: 1.27x faster   | 297 ms: 1.38x faster   |
| async_tree_io                    | 1.14 sec                | 868 ms: 1.31x faster     | 889 ms: 1.28x faster   | 824 ms: 1.38x faster   |
| async_tree_io_tg                 | 1.14 sec                | 871 ms: 1.31x faster     | 877 ms: 1.30x faster   | 807 ms: 1.41x faster   |
| async_tree_memoization           | 649 ms                  | 493 ms: 1.32x faster     | 509 ms: 1.28x faster   | 458 ms: 1.42x faster   |
| async_tree_memoization_tg        | 605 ms                  | 453 ms: 1.34x faster     | 462 ms: 1.31x faster   | 425 ms: 1.42x faster   |
| async_tree_none_tg               | 497 ms                  | 371 ms: 1.34x faster     | 382 ms: 1.30x faster   | 352 ms: 1.41x faster   |
| asyncio_tcp                      | 1.64 sec                | 1.55 sec: 1.06x faster   | 1.48 sec: 1.11x faster | not significant        |
| asyncio_websockets               | 732 ms                  | 578 ms: 1.27x faster     | 758 ms: 1.04x slower   | not significant        |
| chaos                            | 132 ms                  | 88.6 ms: 1.48x faster    | 90.8 ms: 1.45x faster  | 74.3 ms: 1.77x faster  |
| comprehensions                   | 34.7 us                 | 24.5 us: 1.42x faster    | 25.2 us: 1.38x faster  | 19.2 us: 1.80x faster  |
| bench_mp_pool                    | 213 ms                  | 196 ms: 1.09x faster     | 177 ms: 1.20x faster   | 190 ms: 1.12x faster   |
| bench_thread_pool                | 1.95 ms                 | 1.74 ms: 1.12x faster    | 1.68 ms: 1.16x faster  | 1.63 ms: 1.19x faster  |
| coroutines                       | 45.3 ms                 | 33.9 ms: 1.34x faster    | 36.1 ms: 1.25x faster  | 26.9 ms: 1.68x faster  |
| coverage                         | 130 ms                  | 119 ms: 1.09x faster     | 120 ms: 1.09x faster   | 103 ms: 1.26x faster   |
| crypto_pyaes                     | 147 ms                  | 109 ms: 1.35x faster     | 109 ms: 1.35x faster   | 86.3 ms: 1.70x faster  |
| deepcopy                         | 516 us                  | 391 us: 1.32x faster     | 388 us: 1.33x faster   | 309 us: 1.67x faster   |
| deepcopy_reduce                  | 5.30 us                 | 4.19 us: 1.26x faster    | 3.95 us: 1.34x faster  | 3.23 us: 1.64x faster  |
| deepcopy_memo                    | 67.1 us                 | 41.6 us: 1.61x faster    | 46.8 us: 1.44x faster  | 34.8 us: 1.93x faster  |
| deltablue                        | 7.72 ms                 | 4.52 ms: 1.71x faster    | 4.92 ms: 1.57x faster  | 3.80 ms: 2.03x faster  |
| django_template                  | 75.6 ms                 | 55.6 ms: 1.36x faster    | 52.1 ms: 1.45x faster  | 42.1 ms: 1.79x faster  |
| docutils                         | 4.27 sec                | 3.75 sec: 1.14x faster   | 3.50 sec: 1.22x faster | 3.31 sec: 1.29x faster |
| dulwich_log                      | 156 ms                  | 141 ms: 1.11x faster     | 129 ms: 1.20x faster   | 131 ms: 1.19x faster   |
| fannkuch                         | 770 ms                  | 592 ms: 1.30x faster     | 637 ms: 1.21x faster   | 516 ms: 1.49x faster   |
| float                            | 145 ms                  | 108 ms: 1.35x faster     | 116 ms: 1.25x faster   | 96.8 ms: 1.50x faster  |
| create_gc_cycles                 | 1.62 ms                 | 1.71 ms: 1.05x slower    | not significant        | 1.71 ms: 1.05x slower  |
| gc_traversal                     | 5.03 ms                 | not significant          | 4.02 ms: 1.25x faster  | 5.71 ms: 1.13x slower  |
| generators                       | 65.1 ms                 | 40.4 ms: 1.61x faster    | 44.4 ms: 1.47x faster  | 36.0 ms: 1.81x faster  |
| genshi_text                      | 44.5 ms                 | 31.4 ms: 1.42x faster    | 32.5 ms: 1.37x faster  | 26.3 ms: 1.69x faster  |
| genshi_xml                       | 102 ms                  | 74.0 ms: 1.37x faster    | 74.6 ms: 1.36x faster  | 63.1 ms: 1.61x faster  |
| go                               | 255 ms                  | 147 ms: 1.73x faster     | 170 ms: 1.50x faster   | 132 ms: 1.94x faster   |
| hexiom                           | 13.4 ms                 | 8.49 ms: 1.58x faster    | 9.22 ms: 1.46x faster  | 7.11 ms: 1.89x faster  |
| html5lib                         | 104 ms                  | 81.6 ms: 1.28x faster    | 77.9 ms: 1.34x faster  | 74.5 ms: 1.40x faster  |
| json_dumps                       | 19.6 ms                 | 16.9 ms: 1.16x faster    | 15.0 ms: 1.31x faster  | 12.9 ms: 1.52x faster  |
| json_loads                       | 48.1 us                 | 46.7 us: 1.03x faster    | 36.8 us: 1.31x faster  | 32.7 us: 1.47x faster  |
| logging_format                   | 21.2 us                 | 16.4 us: 1.29x faster    | 14.7 us: 1.44x faster  | 13.6 us: 1.56x faster  |
| logging_silent                   | 213 ns                  | 143 ns: 1.49x faster     | 152 ns: 1.40x faster   | 109 ns: 1.95x faster   |
| logging_simple                   | 19.4 us                 | 14.6 us: 1.33x faster    | 13.5 us: 1.44x faster  | 12.2 us: 1.60x faster  |
| mako                             | 23.3 ms                 | 17.7 ms: 1.31x faster    | 16.7 ms: 1.39x faster  | 14.4 ms: 1.61x faster  |
| mdp                              | 3.99 sec                | 4.12 sec: 1.03x slower   | 3.76 sec: 1.06x faster | 3.37 sec: 1.18x faster |
| meteor_contest                   | 175 ms                  | 133 ms: 1.32x faster     | 139 ms: 1.26x faster   | 124 ms: 1.41x faster   |
| nbody                            | 203 ms                  | 155 ms: 1.31x faster     | 171 ms: 1.19x faster   | 128 ms: 1.58x faster   |
| nqueens                          | 179 ms                  | 129 ms: 1.38x faster     | 131 ms: 1.37x faster   | 103 ms: 1.73x faster   |
| pathlib                          | 278 ms                  | 266 ms: 1.04x faster     | 256 ms: 1.09x faster   | 262 ms: 1.06x faster   |
| pickle                           | 21.5 us                 | 17.9 us: 1.20x faster    | 19.1 us: 1.13x faster  | 15.0 us: 1.44x faster  |
| pickle_dict                      | 46.0 us                 | 34.3 us: 1.34x faster    | 43.2 us: 1.07x faster  | 27.6 us: 1.67x faster  |
| pickle_list                      | 8.16 us                 | 6.19 us: 1.32x faster    | 6.89 us: 1.18x faster  | 5.05 us: 1.62x faster  |
| pickle_pure_python               | 672 us                  | 455 us: 1.48x faster     | 463 us: 1.45x faster   | 378 us: 1.78x faster   |
| pidigits                         | 245 ms                  | 250 ms: 1.02x slower     | 250 ms: 1.02x slower   | 240 ms: 1.02x faster   |
| pprint_safe_repr                 | 1.46 sec                | 1.09 sec: 1.34x faster   | 1.09 sec: 1.34x faster | 934 ms: 1.57x faster   |
| pprint_pformat                   | 3.00 sec                | 2.22 sec: 1.35x faster   | 2.23 sec: 1.35x faster | 1.91 sec: 1.57x faster |
| pyflate                          | 875 ms                  | 626 ms: 1.40x faster     | 668 ms: 1.31x faster   | 537 ms: 1.63x faster   |
| python_startup                   | 45.4 ms                 | not significant          | 43.1 ms: 1.05x faster  | 43.7 ms: 1.04x faster  |
| python_startup_no_site           | 37.1 ms                 | not significant          | 35.4 ms: 1.05x faster  | 35.9 ms: 1.03x faster  |
| raytrace                         | 587 ms                  | 385 ms: 1.52x faster     | 414 ms: 1.42x faster   | 321 ms: 1.83x faster   |
| regex_compile                    | 237 ms                  | 180 ms: 1.31x faster     | 180 ms: 1.31x faster   | 157 ms: 1.51x faster   |
| regex_dna                        | 226 ms                  | 256 ms: 1.14x slower     | 210 ms: 1.07x faster   | 211 ms: 1.07x faster   |
| regex_effbot                     | 4.05 ms                 | not significant          | 3.66 ms: 1.11x faster  | 3.39 ms: 1.20x faster  |
| regex_v8                         | 38.7 ms                 | 35.7 ms: 1.08x faster    | 33.7 ms: 1.15x faster  | 29.8 ms: 1.30x faster  |
| richards                         | 102 ms                  | 65.3 ms: 1.56x faster    | 64.7 ms: 1.58x faster  | 49.7 ms: 2.05x faster  |
| richards_super                   | 116 ms                  | 74.3 ms: 1.57x faster    | 74.7 ms: 1.56x faster  | 56.2 ms: 2.07x faster  |
| scimark_fft                      | 664 ms                  | 485 ms: 1.37x faster     | 493 ms: 1.35x faster   | 358 ms: 1.85x faster   |
| scimark_lu                       | 227 ms                  | 159 ms: 1.43x faster     | 164 ms: 1.39x faster   | 132 ms: 1.72x faster   |
| scimark_monte_carlo              | 138 ms                  | 91.6 ms: 1.51x faster    | 101 ms: 1.37x faster   | 74.6 ms: 1.85x faster  |
| scimark_sor                      | 256 ms                  | 176 ms: 1.46x faster     | 195 ms: 1.31x faster   | 151 ms: 1.69x faster   |
| scimark_sparse_mat_mult          | 8.76 ms                 | 6.31 ms: 1.39x faster    | 6.06 ms: 1.45x faster  | 5.01 ms: 1.75x faster  |
| spectral_norm                    | 179 ms                  | 136 ms: 1.32x faster     | 151 ms: 1.19x faster   | 110 ms: 1.63x faster   |
| sqlglot_normalize                | 204 ms                  | 156 ms: 1.31x faster     | 151 ms: 1.35x faster   | 131 ms: 1.55x faster   |
| sqlglot_optimize                 | 97.0 ms                 | 77.7 ms: 1.25x faster    | 74.5 ms: 1.30x faster  | 66.2 ms: 1.47x faster  |
| sqlglot_parse                    | 2.52 ms                 | 1.72 ms: 1.46x faster    | 1.81 ms: 1.39x faster  | 1.51 ms: 1.66x faster  |
| sqlglot_transpile                | 3.02 ms                 | 2.15 ms: 1.41x faster    | 2.21 ms: 1.37x faster  | 1.85 ms: 1.63x faster  |
| sqlite_synth                     | 4.08 us                 | 3.81 us: 1.07x faster    | 3.75 us: 1.09x faster  | 3.44 us: 1.18x faster  |
| sympy_expand                     | 818 ms                  | 681 ms: 1.20x faster     | 640 ms: 1.28x faster   | 578 ms: 1.42x faster   |
| sympy_integrate                  | 33.5 ms                 | 28.2 ms: 1.19x faster    | 27.1 ms: 1.24x faster  | 24.2 ms: 1.38x faster  |
| sympy_sum                        | 258 ms                  | 222 ms: 1.16x faster     | 213 ms: 1.21x faster   | 199 ms: 1.29x faster   |
| sympy_str                        | 484 ms                  | 405 ms: 1.20x faster     | 383 ms: 1.26x faster   | 344 ms: 1.41x faster   |
| telco                            | 13.1 ms                 | 11.1 ms: 1.17x faster    | 10.7 ms: 1.22x faster  | 9.37 ms: 1.40x faster  |
| tomli_loads                      | 3.84 sec                | 2.79 sec: 1.38x faster   | 2.88 sec: 1.33x faster | 2.38 sec: 1.61x faster |
| typing_runtime_protocols         | 296 us                  | 239 us: 1.24x faster     | 223 us: 1.32x faster   | 193 us: 1.53x faster   |
| unpack_sequence                  | 152 ns                  | 58.2 ns: 2.61x faster    | 84.8 ns: 1.79x faster  | 59.3 ns: 2.56x faster  |
| unpickle                         | 26.2 us                 | 24.0 us: 1.09x faster    | 19.8 us: 1.32x faster  | 17.9 us: 1.46x faster  |
| unpickle_list                    | 7.29 us                 | 6.03 us: 1.21x faster    | 6.87 us: 1.06x faster  | 5.38 us: 1.36x faster  |
| unpickle_pure_python             | 505 us                  | 321 us: 1.57x faster     | 336 us: 1.50x faster   | 257 us: 1.96x faster   |
| xml_etree_parse                  | 232 ms                  | 228 ms: 1.02x faster     | 200 ms: 1.16x faster   | 210 ms: 1.10x faster   |
| xml_etree_iterparse              | 185 ms                  | 160 ms: 1.16x faster     | 154 ms: 1.21x faster   | 145 ms: 1.27x faster   |
| xml_etree_generate               | 181 ms                  | 148 ms: 1.22x faster     | 135 ms: 1.35x faster   | 119 ms: 1.53x faster   |
| xml_etree_process                | 128 ms                  | 100 ms: 1.28x faster     | 94.4 ms: 1.36x faster  | 82.0 ms: 1.56x faster  |
| Geometric mean                   | (ref)                   | 1.27x faster             | 1.28x faster           | 1.47x faster           |

Benchmark hidden because not significant (1): asyncio_tcp_ssl

</p>
</details> 

More benchmarks (including clang-cl 18.1.8,  20.1.0.rc2, `computed gotos` and `tailcall`) can be found in https://gist.github.com/chris-eibl/114a42f22563956fdb5cd0335b28c7ae.

Raw data is here https://gist.github.com/chris-eibl/c73b02762a7c467e9a410a0aa19c7701.",[],"This is now checked in, at least for 32-bit and 64-bit and natively-built ARM64 (cross-compiled ARM64 apparently needs some options that we don't know right now).

Thanks @chris-eibl!",[],['python'],github,https://github.com/python/cpython/issues/130090,{'repo': 'python/cpython'}
"Unify the handling of `KeyboardInterrupt` in new REPLs

# Feature or enhancement

### Proposal:

It's a little confusing now.

```pycon
❯ python -m asyncio
asyncio REPL 3.14.0a4+ (heads/main:7d275611f62, Jan 27 2025, 05:41:56) [GCC 11.4.0] on linux
Use ""await"" directly instead of ""asyncio.run()"".
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import asyncio
>>> raise KeyboardInterrupt

KeyboardInterrupt
>>> 
```

```pycon
❯ python
Python 3.14.0a4+ (heads/main:7d275611f62, Jan 27 2025, 05:41:56) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> raise KeyboardInterrupt
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    raise KeyboardInterrupt
KeyboardInterrupt
>>> 
```

Two options here:
1. Remove specialcasing of `KeyboardInterrupt` in the asyncio REPL
    https://github.com/python/cpython/blob/bb5c6875d6e84bf2b4e134ed482141a51d223f09/Lib/asyncio/__main__.py#L73-L77

2. Specialcase `KeyboardInterrupt` in the main REPL too, as is in the asyncio REPL

What would you opt for?

Me personally -- 1 (show traceback).

CC @ambv 

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-129636
<!-- /gh-linked-prs -->
","['❯ python -m asyncio\nasyncio REPL 3.14.0a4+ (heads/main:7d275611f62, Jan 27 2025, 05:41:56) [GCC 11.4.0] on linux\nUse ""await"" directly instead of ""asyncio.run()"".\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import asyncio\n>>> raise KeyboardInterrupt\n\nKeyboardInterrupt\n>>>', '❯ python\nPython 3.14.0a4+ (heads/main:7d275611f62, Jan 27 2025, 05:41:56) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> raise KeyboardInterrupt\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    raise KeyboardInterrupt\nKeyboardInterrupt\n>>>']","While developing asyncio REPL, it was noted that the Ctrl+C behaviour is different from standard REPL. https://github.com/python/cpython/pull/13472#issuecomment-495627909",[],['python'],github,https://github.com/python/cpython/issues/129628,{'repo': 'python/cpython'}
"Can't build 3.13.2 on macOS due to `#include <os/log.h>` in `Python/pylifecycle.c`

# Bug report

### Bug description:

I'm getting this error when trying to compile Python 3.13.2 via pyenv:

```
In file included from Python/pylifecycle.c:64:
/Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/usr/include/os/log.h:17:2: error: #error using os/log.h requires Xcode 8 or later
   17 | #error using os/log.h requires Xcode 8 or later
      |  ^~~~~
```

I found that `#include <os/log.h>` was added to `Python/pylifecycle.c` in 2041a95e68ebf6d13f867e214ada28affa830669, and then bbe0b33d2a6e73fb488a72a61329dafd974cbba6 supposedly excluded it on older macOS versions.

I'm on macOS ""Sequoia"" 15.3.1 and have Xcode 16.2 installed. I believe both of these are the latest versions. However, **I'm on an Intel Mac**, which I guess is becoming rare these days. So maybe this is only a problem on Intel Macs. I don't have an Apple Silicon Mac to test this on.

I found that the relevant lines in `os/log.h` on my computer look like this:

```
#if !__has_builtin(__builtin_os_log_format)
#error using os/log.h requires Xcode 8 or later
#endif
```

I don't know how or where `__builtin_os_log_format` is defined, but I guess I don't have it.

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS","['In file included from Python/pylifecycle.c:64:\n/Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/usr/include/os/log.h:17:2: error: #error using os/log.h requires Xcode 8 or later\n   17 | #error using os/log.h requires Xcode 8 or later\n      |  ^~~~~', '#if !__has_builtin(__builtin_os_log_format)\n#error using os/log.h requires Xcode 8 or later\n#endif']",I think I figured it out. It was because pyenv was using GCC installed via Homebrew. It works if I make it use `/usr/bin/cc`. I guess that makes sense. The `__builtin_os_log_format` thing is probably defined by the compiler.,[],['python'],github,https://github.com/python/cpython/issues/130210,{'repo': 'python/cpython'}
"`singledispatchmethod.register` fails with `typing.Self` annotation

# Bug report

### Bug description:

When using `singledispatchmethod`, the `register` decorator function raises an exception if `self` is annotated with `typing.Self`:
```
TypeError: Invalid annotation for 'self'. typing.Self is not a class.
```

Minimal example:
```python
from functools import singledispatchmethod
from typing import Self


class Foo:
    @singledispatchmethod
    def bar(self: Self, arg: int | str) -> int | str: ...

    @bar.register
    def _(self: Self, arg: int) -> int:
        return arg


foo = Foo()

print(foo.bar(1))
```

The workaround is to remove the `typing.Self` annotation for the `_` function.

(Same for `singledispatch` but that should not be used in that case anyway)

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130829
<!-- /gh-linked-prs -->
","[""TypeError: Invalid annotation for 'self'. typing.Self is not a class."", 'from functools import singledispatchmethod\nfrom typing import Self\n\n\nclass Foo:\n    @singledispatchmethod\n    def bar(self: Self, arg: int | str) -> int | str: ...\n\n    @bar.register\n    def _(self: Self, arg: int) -> int:\n        return arg\n\n\nfoo = Foo()\n\nprint(foo.bar(1))']","Presumably, we want to:

- Disallow `Self` on `singledispatch`.
- But allow it on `singledispatchmethod`.

That seems easy enough, but we'll probably need a new internal helper to hide any talking between `singledispatch` and `singledispatchmethod`. I'll submit a fix.",[],['python'],github,https://github.com/python/cpython/issues/130827,{'repo': 'python/cpython'}
"pygettext: Remove unused option `-a/--extract-all`

It has never been implemented. PR soon

@tomasr8 

<!-- gh-linked-prs -->
### Linked PRs
* gh-130196
* gh-130254
<!-- /gh-linked-prs -->
",[],"I'd be careful removing this flag. It could exist for ""compatibility"" with other tools that have a similar interface, and not supporting it might break people's scripts when they have flexibility in the tool used.

If it were me I'd just print a warning and continue to do nothing.",[],['python'],github,https://github.com/python/cpython/issues/130195,{'repo': 'python/cpython'}
"Segfault in GC at shutdown in 3.14-alpha.5

# Bug report

### Bug description:

While testing Tornado's test suite on 3.14-alpha.5, I found that after running certain (innocuous-looking) tests I would get a segfault in GC as the process shuts down. Unfortunately faulthandler doesn't give me any useful information:

```
(tornado) bdarnell@MacBookPro tornado % PYTHONFAULTHANDLER=1 uv run --no-project -p 3.14 python  -m tornado.test tornado.test.ioloop_test.TestPeriodicCallbackAsync.test_periodic_plain
.
----------------------------------------------------------------------
Ran 1 test in 0.031s

OK
Fatal Python error: Segmentation fault

Current thread 0x00000001f7ee4840 (most recent call first):
  Garbage-collecting
  <no Python frame>
```

I've narrowed the problem down to [two tests](https://github.com/tornadoweb/tornado/blob/master/tornado/test/ioloop_test.py#L711-L742) in `TestPeriodicCallbackAsync`, `test_periodic_plain` and `test_periodic_coro`. Curiously, the very similar `test_periodic_async` test in the same class does not trigger the segfault.  The GC failure appears to be deterministic when either of these tests are run and does not occur on any older version from 3.9-3.13. I've seen it on both macOS and linux (ubuntu 22.04 and 24.04). 

The tests themselves are small, although they pull in a non-trivial amount of machinery from Tornado and asyncio (note that this is all pure python on the Tornado side; the small amount of C code we use isn't imported in this test). I'll see if I can reduce the test case further to be more self-contained. Is there anything that can be done to get more information about the objects being GC'd in the failure?

The exact tornado commit I'm testing is https://github.com/tornadoweb/tornado/commit/5ae2fbbe2d1908e96cc4d4934625392cf46489ec. This includes some unmerged changes to adapt to new deprecation warnings. 

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux, macOS",['(tornado) bdarnell@MacBookPro tornado % PYTHONFAULTHANDLER=1 uv run --no-project -p 3.14 python  -m tornado.test tornado.test.ioloop_test.TestPeriodicCallbackAsync.test_periodic_plain\n.\n----------------------------------------------------------------------\nRan 1 test in 0.031s\n\nOK\nFatal Python error: Segmentation fault\n\nCurrent thread 0x00000001f7ee4840 (most recent call first):\n  Garbage-collecting\n  <no Python frame>'],"Stacktrace is the following, which makes me think this is the same bug as:

* https://github.com/python/cpython/issues/130221 (cc @kumaraditya303)

```
* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x10)
  * frame #0: 0x00000001014b4c58 libpython3.14.dylib`PyType_GetModuleByDef + 60
    frame #1: 0x0000000101d00d54 libpython3.14.dylib`TaskObj_dealloc + 48
    frame #2: 0x00000001015e0c94 libpython3.14.dylib`set_dealloc + 260
    frame #3: 0x000000010136c554 libpython3.14.dylib`dictkeys_decref.llvm.13609225281458662827 + 116
    frame #4: 0x00000001015e6b18 libpython3.14.dylib`type_clear + 52
    frame #5: 0x0000000101476ccc libpython3.14.dylib`gc_collect_region + 2596
    frame #6: 0x0000000101475aa4 libpython3.14.dylib`_PyGC_Collect + 3944
    frame #7: 0x00000001014b9c34 libpython3.14.dylib`finalize_modules + 5528
    frame #8: 0x00000001014e1644 libpython3.14.dylib`_Py_Finalize.llvm.18389874993806621089 + 344
    frame #9: 0x00000001014e03b8 libpython3.14.dylib`Py_RunMain + 268
    frame #10: 0x00000001014aba88 libpython3.14.dylib`pymain_main + 468
    frame #11: 0x00000001014ab8a8 libpython3.14.dylib`Py_BytesMain + 40
    frame #12: 0x0000000190860274 dyld`start + 2840
```

","[""* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x10)\n  * frame #0: 0x00000001014b4c58 libpython3.14.dylib`PyType_GetModuleByDef + 60\n    frame #1: 0x0000000101d00d54 libpython3.14.dylib`TaskObj_dealloc + 48\n    frame #2: 0x00000001015e0c94 libpython3.14.dylib`set_dealloc + 260\n    frame #3: 0x000000010136c554 libpython3.14.dylib`dictkeys_decref.llvm.13609225281458662827 + 116\n    frame #4: 0x00000001015e6b18 libpython3.14.dylib`type_clear + 52\n    frame #5: 0x0000000101476ccc libpython3.14.dylib`gc_collect_region + 2596\n    frame #6: 0x0000000101475aa4 libpython3.14.dylib`_PyGC_Collect + 3944\n    frame #7: 0x00000001014b9c34 libpython3.14.dylib`finalize_modules + 5528\n    frame #8: 0x00000001014e1644 libpython3.14.dylib`_Py_Finalize.llvm.18389874993806621089 + 344\n    frame #9: 0x00000001014e03b8 libpython3.14.dylib`Py_RunMain + 268\n    frame #10: 0x00000001014aba88 libpython3.14.dylib`pymain_main + 468\n    frame #11: 0x00000001014ab8a8 libpython3.14.dylib`Py_BytesMain + 40\n    frame #12: 0x0000000190860274 dyld`start + 2840""]",['python'],github,https://github.com/python/cpython/issues/130380,{'repo': 'python/cpython'}
"DOC: `urllib.parse.urlparse()` example doesn't parse the `params`

https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse

<blockquote>

```python
>>> urlparse(""scheme://netloc/path;parameters?query#fragment"")
ParseResult(scheme='scheme', netloc='netloc', path='/path;parameters', params='',
            query='query', fragment='fragment')
```

</blockquote>

I think the problem is here (for v3.13):

https://github.com/python/cpython/blob/78377c788e02e91bf43d290d69317198a2e563fd/Lib/urllib/parse.py#L401

I assume `scheme` isn't a scheme that `uses_params`, so the params don't get parsed out. On the other hand, `https` works as expected:

```python
>>> urlparse(""https://netloc/path;parameters?query#fragment"")
ParseResult(scheme='https', netloc='netloc', path='/path', params='parameters',
            query='query', fragment='fragment')
```

By the way, the documentation doesn't mention anything about `uses_params`. Is that an oversight? Should some mention be added?","['>>> urlparse(""scheme://netloc/path;parameters?query#fragment"")\nParseResult(scheme=\'scheme\', netloc=\'netloc\', path=\'/path;parameters\', params=\'\',\n            query=\'query\', fragment=\'fragment\')', '>>> urlparse(""https://netloc/path;parameters?query#fragment"")\nParseResult(scheme=\'https\', netloc=\'netloc\', path=\'/path\', params=\'parameters\',\n            query=\'query\', fragment=\'fragment\')']","A list of supported schemes is given in the second paragraph of the page. A scheme literally named “scheme:” is not listed, so is confusing as an example.

I think _uses_params_ is just an implementation detail (of the documented scheme list) that unfortunately has a public-looking name.",[],['python'],github,https://github.com/python/cpython/issues/129745,{'repo': 'python/cpython'}
"Load target address earlier for tail call interpreter

My working branch is here https://github.com/python/cpython/compare/main...aconz2:cpython:aconz2/early-tail-call-load

I saw the recent merge of the tail call interpreter (#128718), very nice! I have played with this style of interpreter before and one thing that comes up is when to calculate the target address. As it is, the current interpreter does it in `DISPATCH()` by doing

```c
DEF_TARGET(foo) {
    // ...
    TAIL return INSTRUCTION_TABLE[opcode](ARGS);
}
```

this results in assembly like:

```asm
0000000000289580 <_TAIL_CALL_GET_LEN>:
  289580: 50                           	push	rax
  289581: 89 fb                        	mov	ebx, edi
  289583: 4d 89 7c 24 38               	mov	qword ptr [r12 + 0x38], r15
  289588: 49 83 c7 02                  	add	r15, 0x2
  28958c: 49 8b 7d f8                  	mov	rdi, qword ptr [r13 - 0x8]
  289590: 4d 89 6c 24 40               	mov	qword ptr [r12 + 0x40], r13
  289595: e8 f6 fc ea ff               	call	0x139290 <PyObject_Size>
  28959a: 4d 8b 6c 24 40               	mov	r13, qword ptr [r12 + 0x40]
  28959f: 49 c7 44 24 40 00 00 00 00   	mov	qword ptr [r12 + 0x40], 0x0
  2895a8: 48 85 c0                     	test	rax, rax
  2895ab: 78 2b                        	js	0x2895d8 <_TAIL_CALL_GET_LEN+0x58>
  2895ad: 48 89 c7                     	mov	rdi, rax
  2895b0: e8 eb 54 ec ff               	call	0x14eaa0 <PyLong_FromSsize_t>
  2895b5: 48 85 c0                     	test	rax, rax
  2895b8: 74 1e                        	je	0x2895d8 <_TAIL_CALL_GET_LEN+0x58>
  2895ba: 49 89 45 00                  	mov	qword ptr [r13], rax
  2895be: 49 83 c5 08                  	add	r13, 0x8
  2895c2: 41 0f b7 3f                  	movzx	edi, word ptr [r15]  #<-- Load next_instr
  2895c6: 40 0f b6 c7                  	movzx	eax, dil             #<-- grab opcode
  2895ca: c1 ef 08                     	shr	edi, 0x8
  2895cd: 48 8d 0d 7c 50 1f 00         	lea	rcx, [rip + 0x1f507c]   # 0x47e650 <INSTRUCTION_TABLE>
  2895d4: 5a                           	pop	rdx
  2895d5: ff 24 c1                     	jmp	qword ptr [rcx + 8*rax] #<-- jmp with addr calculation
  2895d8: 89 df                        	mov	edi, ebx
  2895da: 58                           	pop	rax
  2895db: e9 30 dc ff ff               	jmp	0x287210 <_TAIL_CALL_error>
```

where we jmp to a computed adress which is dependent on the lea and a memory load a few instructions prior.

Another method looks like

```c
DEF_TARGET(foo) {
  // ...
  tail_funcptr next_f = INSTRUCTION_TABLE[next_opcode];
  // ...
  TAIL return next_f(ARGS);
}
```

where we try to get the compiler to compute the target earlier and then have a `jmp reg`. We have to pay special attention to places where `next_instr` is modified and reload the pointer (though hopefully the optimizer will just wait to do the calculation until the latest place).

In this early branch, I was able to get this working enough to see what asm it would generate. For `_TAIL_CALL_GET_LEN`, the sequence now looks like

```asm
00000000002896b0 <_TAIL_CALL_GET_LEN>:
  2896b0: 55                           	push	rbp
  2896b1: 89 fb                        	mov	ebx, edi
  2896b3: 4d 89 7c 24 38               	mov	qword ptr [r12 + 0x38], r15
  2896b8: 41 0f b6 47 02               	movzx	eax, byte ptr [r15 + 0x2]  #<-- Load next instr opcode
  2896bd: 49 83 c7 02                  	add	r15, 0x2
  2896c1: 48 8d 0d 88 5f 1f 00         	lea	rcx, [rip + 0x1f5f88]   # 0x47f650 <INSTRUCTION_TABLE>
  2896c8: 48 8b 2c c1                  	mov	rbp, qword ptr [rcx + 8*rax]  #<-- load next target addr
  2896cc: 49 8b 7d f8                  	mov	rdi, qword ptr [r13 - 0x8]
  2896d0: 4d 89 6c 24 40               	mov	qword ptr [r12 + 0x40], r13
  2896d5: e8 b6 fb ea ff               	call	0x139290 <PyObject_Size>
  2896da: 4d 8b 6c 24 40               	mov	r13, qword ptr [r12 + 0x40]
  2896df: 49 c7 44 24 40 00 00 00 00   	mov	qword ptr [r12 + 0x40], 0x0
  2896e8: 48 85 c0                     	test	rax, rax
  2896eb: 78 20                        	js	0x28970d <_TAIL_CALL_GET_LEN+0x5d>
  2896ed: 48 89 c7                     	mov	rdi, rax
  2896f0: e8 ab 53 ec ff               	call	0x14eaa0 <PyLong_FromSsize_t>
  2896f5: 48 85 c0                     	test	rax, rax
  2896f8: 74 13                        	je	0x28970d <_TAIL_CALL_GET_LEN+0x5d>
  2896fa: 49 89 45 00                  	mov	qword ptr [r13], rax
  2896fe: 49 83 c5 08                  	add	r13, 0x8
  289702: 41 0f b6 7f 01               	movzx	edi, byte ptr [r15 + 0x1]
  289707: 48 89 e8                     	mov	rax, rbp                  #<-- register rename
  28970a: 5d                           	pop	rbp
  28970b: ff e0                        	jmp	rax                       #<-- jmp to target addr
  28970d: 89 df                        	mov	edi, ebx
  28970f: 5d                           	pop	rbp
  289710: e9 fb da ff ff               	jmp	0x287210 <_TAIL_CALL_error>
  289715: 66 66 2e 0f 1f 84 00 00 00 00 00     	nop	word ptr cs:[rax + rax]
  2896c1: 48 8d 0d 88 5f 1f 00         	lea	rcx, [rip + 0x1f5f88]   # 0x47f650 <INSTRUCTION_TABLE>
  2896c8: 48 8b 2c c1                  	mov	rbp, qword ptr [rcx + 8*rax]
```

Specifically in this case, both PyObject_Size and PyLong_FromSsize_t don't touch rbp so there isn't any additional register pressure. But I haven't looked extensively so may not be universally true.

My theory is that this could be better for the CPU because in this example once it gets back from PyLong_FromSsize_t, the jump target is already in a register and could maybe prefetch better.

Have not benchmarked anything yet.

Looking at another example `_TAIL_CALL_BINARY_OP_SUBSCR_GETITEM`, this does a `LOAD_IP()` towards the end so we have to reload our target address. It does seem like the optimizer is smart enough to avoid double loading, but this just ends up with an almost identical ending:

```asm
# main
  28eba5: 41 0f b7 3f                   movzx   edi, word ptr [r15]
  28eba9: 40 0f b6 cf                   movzx   ecx, dil
  28ebad: c1 ef 08                      shr     edi, 0x8
  28ebb0: 48 8d 15 99 fa 1e 00          lea     rdx, [rip + 0x1efa99]   # 0x47e650 <INSTRUCTION_TABLE>
  28ebb7: 49 89 c4                      mov     r12, rax
  28ebba: ff 24 ca                      jmp     qword ptr [rdx + 8*rcx]

# this branch
  28f185: 41 0f b6 0f                   movzx   ecx, byte ptr [r15]
  28f189: 48 8d 15 c0 04 1f 00          lea     rdx, [rip + 0x1f04c0]   # 0x47f650 <INSTRUCTION_TABLE>
  28f190: 41 0f b6 7f 01                movzx   edi, byte ptr [r15 + 0x1]
  28f195: 49 89 c4                      mov     r12, rax
  28f198: ff 24 ca                      jmp     qword ptr [rdx + 8*rcx]
```

I did this a bit half-hazardly through a combination of modifying macros and manual changes to anything that assigns to `next_instr` and a few special cases like `exit_unwind` that didn't fit. Could clean up with some direction.

One super naive metric is

```
# should be a tab after jmp
llvm-objdump --x86-asm-syntax=intel -D python | grep 'jmp   r' | wc -l
```

which is 916 for this modification and 731 originally, so 185 more places where we jmp to a register instead of a computed address.
","['DEF_TARGET(foo) {\n    // ...\n    TAIL return INSTRUCTION_TABLE[opcode](ARGS);\n}', '0000000000289580 <_TAIL_CALL_GET_LEN>:\n  289580: 50                           \tpush\trax\n  289581: 89 fb                        \tmov\tebx, edi\n  289583: 4d 89 7c 24 38               \tmov\tqword ptr [r12 + 0x38], r15\n  289588: 49 83 c7 02                  \tadd\tr15, 0x2\n  28958c: 49 8b 7d f8                  \tmov\trdi, qword ptr [r13 - 0x8]\n  289590: 4d 89 6c 24 40               \tmov\tqword ptr [r12 + 0x40], r13\n  289595: e8 f6 fc ea ff               \tcall\t0x139290 <PyObject_Size>\n  28959a: 4d 8b 6c 24 40               \tmov\tr13, qword ptr [r12 + 0x40]\n  28959f: 49 c7 44 24 40 00 00 00 00   \tmov\tqword ptr [r12 + 0x40], 0x0\n  2895a8: 48 85 c0                     \ttest\trax, rax\n  2895ab: 78 2b                        \tjs\t0x2895d8 <_TAIL_CALL_GET_LEN+0x58>\n  2895ad: 48 89 c7                     \tmov\trdi, rax\n  2895b0: e8 eb 54 ec ff               \tcall\t0x14eaa0 <PyLong_FromSsize_t>\n  2895b5: 48 85 c0                     \ttest\trax, rax\n  2895b8: 74 1e                        \tje\t0x2895d8 <_TAIL_CALL_GET_LEN+0x58>\n  2895ba: 49 89 45 00                  \tmov\tqword ptr [r13], rax\n  2895be: 49 83 c5 08                  \tadd\tr13, 0x8\n  2895c2: 41 0f b7 3f                  \tmovzx\tedi, word ptr [r15]  #<-- Load next_instr\n  2895c6: 40 0f b6 c7                  \tmovzx\teax, dil             #<-- grab opcode\n  2895ca: c1 ef 08                     \tshr\tedi, 0x8\n  2895cd: 48 8d 0d 7c 50 1f 00         \tlea\trcx, [rip + 0x1f507c]   # 0x47e650 <INSTRUCTION_TABLE>\n  2895d4: 5a                           \tpop\trdx\n  2895d5: ff 24 c1                     \tjmp\tqword ptr [rcx + 8*rax] #<-- jmp with addr calculation\n  2895d8: 89 df                        \tmov\tedi, ebx\n  2895da: 58                           \tpop\trax\n  2895db: e9 30 dc ff ff               \tjmp\t0x287210 <_TAIL_CALL_error>', 'DEF_TARGET(foo) {\n  // ...\n  tail_funcptr next_f = INSTRUCTION_TABLE[next_opcode];\n  // ...\n  TAIL return next_f(ARGS);\n}', '00000000002896b0 <_TAIL_CALL_GET_LEN>:\n  2896b0: 55                           \tpush\trbp\n  2896b1: 89 fb                        \tmov\tebx, edi\n  2896b3: 4d 89 7c 24 38               \tmov\tqword ptr [r12 + 0x38], r15\n  2896b8: 41 0f b6 47 02               \tmovzx\teax, byte ptr [r15 + 0x2]  #<-- Load next instr opcode\n  2896bd: 49 83 c7 02                  \tadd\tr15, 0x2\n  2896c1: 48 8d 0d 88 5f 1f 00         \tlea\trcx, [rip + 0x1f5f88]   # 0x47f650 <INSTRUCTION_TABLE>\n  2896c8: 48 8b 2c c1                  \tmov\trbp, qword ptr [rcx + 8*rax]  #<-- load next target addr\n  2896cc: 49 8b 7d f8                  \tmov\trdi, qword ptr [r13 - 0x8]\n  2896d0: 4d 89 6c 24 40               \tmov\tqword ptr [r12 + 0x40], r13\n  2896d5: e8 b6 fb ea ff               \tcall\t0x139290 <PyObject_Size>\n  2896da: 4d 8b 6c 24 40               \tmov\tr13, qword ptr [r12 + 0x40]\n  2896df: 49 c7 44 24 40 00 00 00 00   \tmov\tqword ptr [r12 + 0x40], 0x0\n  2896e8: 48 85 c0                     \ttest\trax, rax\n  2896eb: 78 20                        \tjs\t0x28970d <_TAIL_CALL_GET_LEN+0x5d>\n  2896ed: 48 89 c7                     \tmov\trdi, rax\n  2896f0: e8 ab 53 ec ff               \tcall\t0x14eaa0 <PyLong_FromSsize_t>\n  2896f5: 48 85 c0                     \ttest\trax, rax\n  2896f8: 74 13                        \tje\t0x28970d <_TAIL_CALL_GET_LEN+0x5d>\n  2896fa: 49 89 45 00                  \tmov\tqword ptr [r13], rax\n  2896fe: 49 83 c5 08                  \tadd\tr13, 0x8\n  289702: 41 0f b6 7f 01               \tmovzx\tedi, byte ptr [r15 + 0x1]\n  289707: 48 89 e8                     \tmov\trax, rbp                  #<-- register rename\n  28970a: 5d                           \tpop\trbp\n  28970b: ff e0                        \tjmp\trax                       #<-- jmp to target addr\n  28970d: 89 df                        \tmov\tedi, ebx\n  28970f: 5d                           \tpop\trbp\n  289710: e9 fb da ff ff               \tjmp\t0x287210 <_TAIL_CALL_error>\n  289715: 66 66 2e 0f 1f 84 00 00 00 00 00     \tnop\tword ptr cs:[rax + rax]\n  2896c1: 48 8d 0d 88 5f 1f 00         \tlea\trcx, [rip + 0x1f5f88]   # 0x47f650 <INSTRUCTION_TABLE>\n  2896c8: 48 8b 2c c1                  \tmov\trbp, qword ptr [rcx + 8*rax]', '# main\n  28eba5: 41 0f b7 3f                   movzx   edi, word ptr [r15]\n  28eba9: 40 0f b6 cf                   movzx   ecx, dil\n  28ebad: c1 ef 08                      shr     edi, 0x8\n  28ebb0: 48 8d 15 99 fa 1e 00          lea     rdx, [rip + 0x1efa99]   # 0x47e650 <INSTRUCTION_TABLE>\n  28ebb7: 49 89 c4                      mov     r12, rax\n  28ebba: ff 24 ca                      jmp     qword ptr [rdx + 8*rcx]\n\n# this branch\n  28f185: 41 0f b6 0f                   movzx   ecx, byte ptr [r15]\n  28f189: 48 8d 15 c0 04 1f 00          lea     rdx, [rip + 0x1f04c0]   # 0x47f650 <INSTRUCTION_TABLE>\n  28f190: 41 0f b6 7f 01                movzx   edi, byte ptr [r15 + 0x1]\n  28f195: 49 89 c4                      mov     r12, rax\n  28f198: ff 24 ca                      jmp     qword ptr [rdx + 8*rcx]', ""# should be a tab after jmp\nllvm-objdump --x86-asm-syntax=intel -D python | grep 'jmp   r' | wc -l""]","Note that a 1% win is pretty significant. So great job! If we were to upstream this though, it would need to be less likely to trip up the cpython contributors, so let me think how to approach this in a less error-prone way using the code generator.",[],['python'],github,https://github.com/python/cpython/issues/129976,{'repo': 'python/cpython'}
"PEP 668: Moving a VENV breaks it as its path variable is hard coded and absolute.

# Documentation

```
error: externally-managed-environment

× This environment is externally managed
╰─> To install Python packages system-wide, try apt install
    python3-xyz, where xyz is the package you are trying to
    install.
    
    If you wish to install a non-Debian-packaged Python package,
    create a virtual environment using python3 -m venv path/to/venv.
    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
    sure you have python3-full installed.
    
    If you wish to install a non-Debian packaged Python application,
    it may be easiest to use pipx install xyz, which will manage a
    virtual environment for you. Make sure you have pipx installed.
    
    See /usr/share/doc/python3.12/README.venv for more information.

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.
```
This message is provided by my distro, Linux Mint. That's not your problem and that's reported here https://github.com/linuxmint/cinnamon/issues/12765 

When I went to your documentation, nothing included that this is usually caused by moving a venv file around.

Something like this could be added: ""this error can be caused by moving the venv file around as the PATH is looking for it in its old location. Please run ''echo $PATH`` and ``which pip`` to confirm. Here is how to fix this!""

Nothing in ``/usr/share/doc/python3.12/README.venv`` includes anything on this

# Additional Context

https://github.com/pypa/pip/issues/13259#event-16541069801
https://github.com/pypa/virtualenv/issues/2854","['error: externally-managed-environment\n\n× This environment is externally managed\n╰─> To install Python packages system-wide, try apt install\n    python3-xyz, where xyz is the package you are trying to\n    install.\n    \n    If you wish to install a non-Debian-packaged Python package,\n    create a virtual environment using python3 -m venv path/to/venv.\n    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n    sure you have python3-full installed.\n    \n    If you wish to install a non-Debian packaged Python application,\n    it may be easiest to use pipx install xyz, which will manage a\n    virtual environment for you. Make sure you have pipx installed.\n    \n    See /usr/share/doc/python3.12/README.venv for more information.\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification.']","You reported this to the distro here: https://github.com/linuxmint/cinnamon/issues/12765

That's where the message needs to be changed, so I'm not clear what you expect to happen here. As I said on the pip tracker, moving a virtual environment documented as something you shouldn't do, so ultimately your problem is user error. There's no documentation issue I can see, as ""don't move virtual environments"" is already documented.",[],['python'],github,https://github.com/python/cpython/issues/130810,{'repo': 'python/cpython'}
"`test_self_trace` times out on x86-64 MacOS Intel ASAN NoGIL

`test.test_external_inspection.TestGetStackTrace.test_self_trace` often times out on the macOS Intel ASAN NoGIL buildbot, e.g. here: https://buildbot.python.org/#/builders/1366/builds/3160/steps/6/logs/stdio

<!-- gh-linked-prs -->
### Linked PRs
* gh-129487
* gh-129494
<!-- /gh-linked-prs -->
",[],I have requested  to @itamaro to get access to the buildbot to investigate. I could not reproduce elsewhere and I am going to need a debugger to iterate.,[],['python'],github,https://github.com/python/cpython/issues/129430,{'repo': 'python/cpython'}
"computed-goto interpreter: Prevent the compiler from merging `DISPATCH` calls

- [Work-in-progress test branch here](https://github.com/python/cpython/compare/main...nelhage:cpython:computed-goto-nomerge)

As a reminder: when compiling the interpreter using computed gotos, we emit a separate copy of the ""dispatch"" jump (currently [`goto *opcode_targets[opcode]`](https://github.com/python/cpython/blob/1feaecc2bc42cb96f2d7bdc8d7083171bdcd0929/Python/ceval_macros.h#L98)) for each opcode implementation. The goal here -- as opposed to dispatching once at the top of the loop, and jumping to the top of the loop after each instruction -- is to expose more information to the hardware branch predictor (specifically, I believe, the branch **target** predictor, which tries to guess the destination of indirect branches).

However, the C compiler doesn't know that! It does, however, see that we've given it a C function containing a few hundred instances of identical `DISPATCH` code … and may choose to merge them together, replacing one or more instances with a jump into the tail end of a different opcode, thus undoing our careful work!

I suspect we can find a way to prevent the compiler from merging these branches, and thus restore similar branch-target-prediction behavior as in the tail-call interpreter.

The branch above attempts to prevent this merging by adding an empty `__asm__ volatile` ""optimization barrier"" to each call site, in the hopes that the compiler treats this as opaque and refuses to merge them. I'm far from certain this is the best approach, but in my testing it seems to be a speedup -- I see 1.03x [on `pyperformance` on my machine](https://gist.github.com/nelhage/bd99284233d3e5a56f177388e078bd9a) (`goto-mine` is the linked branch with the optimization barrier).

We can also observe the merging a bit more directly by counting the number of `DISPATCH` sites that remain after optimization, according to debug symbols:

## `main`
```
$ objdump -S --disassemble=_PyEval_EvalFrameDefault Python/ceval.o | grep -cF 'DISPATCH()'
47
```
## `nelhage/computed-goto-nomerge`
```
$ objdump -S --disassemble=_PyEval_EvalFrameDefault Python/ceval.o | grep -cF 'DISPATCH()'
306
```

For comparison, `generated_cases.c.h` contains 227 instances on the same commit.","[""$ objdump -S --disassemble=_PyEval_EvalFrameDefault Python/ceval.o | grep -cF 'DISPATCH()'\n47"", ""$ objdump -S --disassemble=_PyEval_EvalFrameDefault Python/ceval.o | grep -cF 'DISPATCH()'\n306""]","> I also think the commit message saying most of the gains from the tail-calling interpreter were from splitting up the jumps is potentially untrue. 

Yeah, that commit message was written in a fit of optimism before I'd run the full performance suite. I now agree that this explains **some** of the difference but no longer believe it's all or even a majority. I toned down my claims in the issue but didn't go back and update the branch.",[],['python'],github,https://github.com/python/cpython/issues/129987,{'repo': 'python/cpython'}
"ConfigParser: writing a config with an empty unnamed section adds an extra newline to the beginning of the file

# Bug report

### Bug description:

If you read a config with an empty unnamed section using ConfigParser with allow_unnamed_section set to True and write it back, the resulting file will contain an extra newline at the beginning:

```python
from configparser import ConfigParser
from io import StringIO
cfg = ConfigParser(allow_unnamed_section=True)
cfg.read_string('[sect]')
output = StringIO()
cfg.write(output)
print(repr(output.getvalue())) # '\n[sect]\n\n'
```



### CPython versions tested on:

3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-129679
<!-- /gh-linked-prs -->
","[""from configparser import ConfigParser\nfrom io import StringIO\ncfg = ConfigParser(allow_unnamed_section=True)\ncfg.read_string('[sect]')\noutput = StringIO()\ncfg.write(output)\nprint(repr(output.getvalue())) # '\\n[sect]\\n\\n'""]","Thank you! Merged to the 3.14 branch.
I don't think this is a *bug*, though.

To avoid a point release changing the output, I'll not backport to 3.13.",[],['python'],github,https://github.com/python/cpython/issues/129678,{'repo': 'python/cpython'}
"Remove unused imports - March 2025 Edition

# Feature or enhancement

### Proposal:

There are a bunch of unused imports in Python stdlib. I'm working on pull requests to remove them.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-131149
* gh-131153
* gh-131154
* gh-131155
* gh-131156
* gh-131169
<!-- /gh-linked-prs -->
",[],See also PR gh-131150.,[],['python'],github,https://github.com/python/cpython/issues/131152,{'repo': 'python/cpython'}
"json.dump(x,f) is much slower than f.write(json.dumps(x))

# Bug report

### Bug description:

Experimentally I measured a huge performance improvement when I switched my code from
```
json.dump(x, f, **)
```
to
```
f.write(json.dumps(x, **))
```

### Method
I essentially wrote the same contents to different files sequentially and measured the total amount of time taken. The json contents had 1, 300, and 400 entries per level, and 1, 5, and 6 levels of depth. There's quite a level of variance here but this wasn't what I was trying to measure in the first place. I discovered this by chance, so forgive the lack of precision. I also don't have the source code anymore because I wasn't originally planning to report this discovery.

### Results
| File Size | Consecutive Files |  dump µs | dumps µs |
|----------:|-----------------:|-------:|------------:|
|        74 |                1 |    508 |        581 |
|        74 |                2 |    520 |        541 |
|        74 |                4 |   1153 |        1151 |
|        74 |                8 |   1930 |        1750 |
|     39184 |                1 |   6363 |        1086 |
|     39184 |                2 |  11261 |        1821 |
|     39184 |                4 |  38126 |        3521 |
|     39184 |                8 |  80411 |       6466 |
|    468218 |                1 |  82821 |       11921 |
|    468218 |                2 | 150234 |       38017 |
|    468218 |                4 | 302357 |       42137 |
|    468218 |                8 | 573450 |       78545 |

### Conclusion
A cursory investigation into the cpython code suggests that the slow part is the sequential writing of the `iterencode` yield. The chunks are quite small.

### CPython versions tested on:

3.10

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130076
<!-- /gh-linked-prs -->
","['json.dump(x, f, **)', 'f.write(json.dumps(x, **))']","Demo with deep nesting:

```none
 37.3 ms  json.dump(x, f)
  0.3 ms  f.write(json.dumps(x))
 36.2 ms  json.dump(x, f)
  0.3 ms  f.write(json.dumps(x))
 36.2 ms  json.dump(x, f)
  0.3 ms  f.write(json.dumps(x))
```

```python
from timeit import timeit

setup = '''
import io, json
f = io.StringIO()
x = [0] * 1000
for i in range(900):
    x = [x]
'''

for code in [
    'json.dump(x, f)',
    'f.write(json.dumps(x))',
] * 3:
    t = timeit(code, setup, number=10) * 100
    print(f'{t:5.1f} ms  {code}')
```

[Attempt This Online!](https://ato.pxeger.com/run?1=PVC7TgMxEBStP4B6O9vInHxCSCFSPoCKgjJKAcRONpIf8u2JQ1G-JE2a8FF8DX4cbOeZ2dnxnL_jF-2Dv1yuI9n7xc_NrU3BAaEzSIAuhkTzi7HB0BhhBZxzNlMYFByG4JnNOIbulRL63fOLkGzKyFpv4A56rTWzIQECekhvfmfEk9ZyySBP1U0bVlyr6iNsTRGuK82LfbcdXRSTAiu5arDtPhOSEf_0ICZZ2HLxoVlTtm7hRTFVUH-gwI_u3aRVr2VLV8UxJydh-ZGWj11vT-AGgGPZO3HZ6plb-mvrFw)","['37.3 ms  json.dump(x, f)\n  0.3 ms  f.write(json.dumps(x))\n 36.2 ms  json.dump(x, f)\n  0.3 ms  f.write(json.dumps(x))\n 36.2 ms  json.dump(x, f)\n  0.3 ms  f.write(json.dumps(x))', ""from timeit import timeit\n\nsetup = '''\nimport io, json\nf = io.StringIO()\nx = [0] * 1000\nfor i in range(900):\n    x = [x]\n'''\n\nfor code in [\n    'json.dump(x, f)',\n    'f.write(json.dumps(x))',\n] * 3:\n    t = timeit(code, setup, number=10) * 100\n    print(f'{t:5.1f} ms  {code}')""]",['python'],github,https://github.com/python/cpython/issues/129711,{'repo': 'python/cpython'}
"Check EX_OK is defined before including sysexits.h means it is always redefined

# Bug report

### Bug description:

Minor nit, but there is a check for the definition of EX_OK before sysexits.h is included. Meaning it is always redefined when that header exists.

```
  In file included from ./Modules/posixmodule.c:295:
  /usr/include/sysexits.h:92:9: warning: ""EX_OK"" redefined
     92 | #define EX_OK           0       /* successful termination */
        |         ^~~~~ 
  ./Modules/posixmodule.c:56:11: note: this is the location of the previous definition
     56 | #  define EX_OK EXIT_SUCCESS
      |           ^~~~~ 
```

The C standard says redefinition's like this aren't allowed, but in practice I've only seen compilers warn about them.


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129540
* gh-129558
* gh-129590
* gh-129609
<!-- /gh-linked-prs -->
","['In file included from ./Modules/posixmodule.c:295:\n  /usr/include/sysexits.h:92:9: warning: ""EX_OK"" redefined\n     92 | #define EX_OK           0       /* successful termination */\n        |         ^~~~~ \n  ./Modules/posixmodule.c:56:11: note: this is the location of the previous definition\n     56 | #  define EX_OK EXIT_SUCCESS\n      |           ^~~~~']",Thanks for backporting it to 3.12 for me!,[],['python'],github,https://github.com/python/cpython/issues/129539,{'repo': 'python/cpython'}
"expression is not an integer constant expression and division by zero

# Bug report

### Bug description:

next_ticket.c:426:39: error: expression is not an integer constant expression
next_ticket.c:426:41: note: division by zero

```python
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
```


### CPython versions tested on:

3.14

### Operating systems tested on:

Windows",['enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };'],"Hi, this is a Cython issue I believe, which should be reported to https://github.com/cython/cython instead.",[],['python'],github,https://github.com/python/cpython/issues/130830,{'repo': 'python/cpython'}
"Reorganize `os.path` documentation

The `os.path` documentation is alphabetically sorted. That's great because it's easy to find a function. However, this also means that functions shouldn't reference other functions documented later as the reader may not have been aware of them before.

An alternative is to reorganize the documentation page so that we put at the top the most used functions such as `os.path.join`. The latter caused a bit of confusion in [gh-130527](https://github.com/python/cpython/issues/130527), where neither the OP nor me remembered that `os.path.join(""/a"", ""/b"") == ""/b""`.

If reorganizing the documentation is not preferred, we should at least add `.. seealso::` directives and clickable links so that any function mentioned but not yet documented at the time of reading can be easily looked up.

- [os.path.abspath](https://docs.python.org/3/library/os.path.html#os.path.abspath) contains a reference to `os.path.join` without a link.
- [os.path.isabs](https://docs.python.org/3/library/os.path.html#os.path.isabs) could backlink to `os.path.abspath`.
- [os.path.split](https://docs.python.org/3/library/os.path.html#os.path.split) mentions `os.path.join` but as it's far away, we could backlink it.
- [os.path.join](https://docs.python.org/3/library/os.path.html#os.path.join) mentions ""If a segment is an absolute path (which on Windows requires both a drive and a root), then all previous segments are ignored and joining continues from the absolute path segment."". We should add an example as it would be more explicit and teaching (e.g., `os.path.join(""/home/foo"", ""/home/bar"") == ""/home/bar""`.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130557
<!-- /gh-linked-prs -->
",[],"I think `seealso` is probably the least disruptive to start with?

A",[],['python'],github,https://github.com/python/cpython/issues/130536,{'repo': 'python/cpython'}
"pygettext: Clean up obsolete tests and improve test coverage

`ast.get_docstring` is now used making many tests obsolete.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130198
<!-- /gh-linked-prs -->
",[],"As I said on the PR, even if the tests may be redundant, they are still checking that running the tool with `--docstrings` option works well. So they are more than just one-shot tests, they can also be thought as E2E tests.",[],['python'],github,https://github.com/python/cpython/issues/130197,{'repo': 'python/cpython'}
"`_PyModule_IsPossiblyShadowing` can return `-1` without an exception set

# Bug report

### Bug description:

This can lead to an assertion failure:

```
#6  0x00007ffff7ca9e96 in __GI___assert_fail (assertion=0x555555a5e2da ""PyErr_Occurred()"", file=0x555555a6edcd ""Objects/object.c"", line=1253, function=0x555555a6f36e ""int _PyObject_SetAttributeErrorContext(PyObject *, PyObject *)"") at ./assert/assert.c:101
#7  0x00005555557273ac in _PyObject_SetAttributeErrorContext (v=<module at remote 0x200009a1a50>, name='getaliases') at Objects/object.c:1253
#8  0x0000555555726dde in PyObject_GetAttr (v=<module at remote 0x200009a1a50>, name='getaliases') at Objects/object.c:1306
#9  0x0000555555727de6 in _PyObject_GetMethod (obj=<module at remote 0x200009a1a50>, name='getaliases', method=0x7ffffffdb1b8) at Objects/object.c:1581
#10 0x000055555588456d in _PyEval_EvalFrameDefault (tstate=0x555555d16fb0 <_PyRuntime+360560>, frame=0x7ffff7f9cf20, throwflag=0) at Python/generated_cases.c.h:7682
```

`_Py_wgetcwd` does not set an exception on failure:

https://github.com/python/cpython/blob/a025f27d94afe732be2e9e6f05b9007d04f983a8/Objects/moduleobject.c#L923-L924

Likely related to https://github.com/python/cpython/issues/95754

cc @hauntsaninja 

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130934
* gh-130939
* gh-131037
* gh-131073
<!-- /gh-linked-prs -->
","['#6  0x00007ffff7ca9e96 in __GI___assert_fail (assertion=0x555555a5e2da ""PyErr_Occurred()"", file=0x555555a6edcd ""Objects/object.c"", line=1253, function=0x555555a6f36e ""int _PyObject_SetAttributeErrorContext(PyObject *, PyObject *)"") at ./assert/assert.c:101\n#7  0x00005555557273ac in _PyObject_SetAttributeErrorContext (v=<module at remote 0x200009a1a50>, name=\'getaliases\') at Objects/object.c:1253\n#8  0x0000555555726dde in PyObject_GetAttr (v=<module at remote 0x200009a1a50>, name=\'getaliases\') at Objects/object.c:1306\n#9  0x0000555555727de6 in _PyObject_GetMethod (obj=<module at remote 0x200009a1a50>, name=\'getaliases\', method=0x7ffffffdb1b8) at Objects/object.c:1581\n#10 0x000055555588456d in _PyEval_EvalFrameDefault (tstate=0x555555d16fb0 <_PyRuntime+360560>, frame=0x7ffff7f9cf20, throwflag=0) at Python/generated_cases.c.h:7682']",Thanks for spotting! Will put a PR...,[],['python'],github,https://github.com/python/cpython/issues/130932,{'repo': 'python/cpython'}
"`date.strftime` and `datetime.strftime` format dates wrong in some locales.

# Bug report

### Bug description:

`date.strftime` and `datetime.strftime` format dates wrong in some locales.  For example, when the locale is Bulgaria the '%A' format string returns an incorrect value.

```python
>>> locale.setlocale(locale.LC_TIME, 'bg')    # 'bg' is Bulgaria
>>> date_str = datetime.date(2025, 2, 25).strftime('%A') # %A is locale's day of the week
>>> date_str
'âòîðíèê'
>>> date_str.encode('cp1252').decode('cp1251')  # I think we're interpreting a cp1251 string as cp1252
'вторник'  # Google tells me this is Tuesday in Bulgarian
```
This also fails with the '%x' format string

I've only tested this on Windows.

My guess is that CPython is making a narrow character API call and using the wrong code page. It should be using the wide character call instead.


### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","["">>> locale.setlocale(locale.LC_TIME, 'bg')    # 'bg' is Bulgaria\n>>> date_str = datetime.date(2025, 2, 25).strftime('%A') # %A is locale's day of the week\n>>> date_str\n'âòîðíèê'\n>>> date_str.encode('cp1252').decode('cp1251')  # I think we're interpreting a cp1251 string as cp1252\n'вторник'  # Google tells me this is Tuesday in Bulgarian""]","~~Err, my question may be dumb, but aren't we Tuesday? Or do you mean that `date_str` is incorrectly rendered first?~~


EDIT: Oh ok, I missed the 1-off page example. I've read cp1251 twice so I wondered what was the issue.",[],['python'],github,https://github.com/python/cpython/issues/130528,{'repo': 'python/cpython'}
"Pylauncher does not correctly detect a BOM when searching for the shebang

# Bug report

### Bug description:

This is due to

https://github.com/python/cpython/blob/475f933ed8b1c9546f1b5497a2241140c7065b5f/PC/launcher2.c#L1080-L1081

for wich clang-cl creates the following warnings:

```
1>..\PC\launcher2.c(1080,29): warning : result of comparison of constant 239 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]
1>..\PC\launcher2.c(1081,34): warning : result of comparison of constant 191 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]
1>..\PC\launcher2.c(1081,18): warning : result of comparison of constant 187 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]
``` 

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-131021
* gh-131047
* gh-131048
<!-- /gh-linked-prs -->
","[""1>..\\PC\\launcher2.c(1080,29): warning : result of comparison of constant 239 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]\n1>..\\PC\\launcher2.c(1081,34): warning : result of comparison of constant 191 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]\n1>..\\PC\\launcher2.c(1081,18): warning : result of comparison of constant 187 with expression of type 'char' is always false [-Wtautological-constant-out-of-range-compare]""]",Duplicate: https://github.com/python/cpython/issues/99620,[],['python'],github,https://github.com/python/cpython/issues/131020,{'repo': 'python/cpython'}
"Data race in `compile_template` in `sre.c`

# Bug report

Concurrent accesses to `module_state->compile_template` in the free threaded build

https://github.com/python/cpython/blob/1feaecc2bc42cb96f2d7bdc8d7083171bdcd0929/Modules/_sre/sre.c#L1169-L1177

<!-- gh-linked-prs -->
### Linked PRs
* gh-130015
* gh-130038
<!-- /gh-linked-prs -->
",[],"I think the *much* simpler solution would be to initialize `compile_template` in module exec in this case `sre_exec`, then there will not be any thread safety issues as module exec is exclusively executed first before any code. ",[],['python'],github,https://github.com/python/cpython/issues/129983,{'repo': 'python/cpython'}
"`PyFrame_LocalsToFast` misbehaving when there is a comprehension with colliding local variable

# Bug report

### Bug description:

The following fails in Python 3.12 (but not 3.11 or 3.13):

```python
# Setup: in global scope, use a comprehension with colliding variable name
foo = None
[foo for foo in [0]]

# Repro: assigning to frame.f_locals and then merging to fast works only the first time
import inspect, ctypes
frame = inspect.currentframe()

frame.f_locals['a'] = 1
ctypes.pythonapi.PyFrame_LocalsToFast(ctypes.py_object(frame), ctypes.c_int(0))
print(a)  # 1

frame.f_locals['b'] = 2
ctypes.pythonapi.PyFrame_LocalsToFast(ctypes.py_object(frame), ctypes.c_int(0))
print(b)  # NameError: name 'b' is not defined
```

This impacts debuggers' ability to assign and evaluate local variables -- see microsoft/debugpy#1849 and microsoft/debugpy#1636.

Possibly related changes:
- #105715
- #109026

### CPython versions tested on:

3.12

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130816
<!-- /gh-linked-prs -->
","[""# Setup: in global scope, use a comprehension with colliding variable name\nfoo = None\n[foo for foo in [0]]\n\n# Repro: assigning to frame.f_locals and then merging to fast works only the first time\nimport inspect, ctypes\nframe = inspect.currentframe()\n\nframe.f_locals['a'] = 1\nctypes.pythonapi.PyFrame_LocalsToFast(ctypes.py_object(frame), ctypes.c_int(0))\nprint(a)  # 1\n\nframe.f_locals['b'] = 2\nctypes.pythonapi.PyFrame_LocalsToFast(ctypes.py_object(frame), ctypes.c_int(0))\nprint(b)  # NameError: name 'b' is not defined""]","`PyFrame_LocalsToFast` is an undocumented C API, and people using it should know well about how it works. For example, you are not supposed to call it twice in a frame. Actually, you are not supposed to call it at all, unless you really know what's going on. This is not a bug, the seemingly different behavior compared to 3.11 is due to PEP 709 - which could potentially introduce ""local"" variables in global scope. If you put the whole thing in local scope (in a function), the behavior would be consistent.",[],['python'],github,https://github.com/python/cpython/issues/130809,{'repo': 'python/cpython'}
"Py_DECREF() in interpreter doesn't call `_PyReftracerTrack(op, PyRefTracer_DESTROY)`

# Bug report

https://github.com/python/cpython/blob/6c450f44c283c61d0e1ada05ead9524a1fe97962/Python/ceval.c#L72-L85

Tracemalloc only handles `PyRefTracer_CREATE` events and we don't have any tests for `PyRefTracer_DESTROY` events.

**EDIT:** `_testcapimodule.c` tests `PyRefTracer_DESTROY` events, but only through the C API and not the Python interpreter.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130689
* gh-130700
<!-- /gh-linked-prs -->
",[],"There is a super-basic reftracer test in `_testcapimodule.c`, but no python interface that I can see, so added one to tracemalloc module to keep track of created and destroyed refs. Do you want this?

Example:
```py
import tracemalloc

tracemalloc.start()

refs = tracemalloc.get_traced_refs()
print(refs)

tracemalloc.reset_peak()
i = []
refs = tracemalloc.get_traced_refs()
print(refs)

tracemalloc.reset_peak()
j = [], []
del j
refs = tracemalloc.get_traced_refs()
print(refs)

import ssl
refs = tracemalloc.get_traced_refs()
print(refs)

tracemalloc.stop()
```
Run:
```
$ ./python reftrace.py
(0, 0)
(1, 0)
(3, 3)
(16722, 8671)
```","['import tracemalloc\n\ntracemalloc.start()\n\nrefs = tracemalloc.get_traced_refs()\nprint(refs)\n\ntracemalloc.reset_peak()\ni = []\nrefs = tracemalloc.get_traced_refs()\nprint(refs)\n\ntracemalloc.reset_peak()\nj = [], []\ndel j\nrefs = tracemalloc.get_traced_refs()\nprint(refs)\n\nimport ssl\nrefs = tracemalloc.get_traced_refs()\nprint(refs)\n\ntracemalloc.stop()', '$ ./python reftrace.py\n(0, 0)\n(1, 0)\n(3, 3)\n(16722, 8671)']",['python'],github,https://github.com/python/cpython/issues/130382,{'repo': 'python/cpython'}
"resurrected asyncio `_SelectorTransport` unregisters fds it doesn't own

# Bug report

### Bug description:

Short story:

1. Socket is closed in [`_SelectorTransport.__del__`](https://github.com/python/cpython/blob/4e38eea/Lib/asyncio/selector_events.py#L874), so it doesn't own the fd anymore.
2. Anything else in the process can create a new file descriptor at this point.
3. If the transport is gc-resurrected to call `close()`, it can then remove the reader/writer from `loop._selector` [here](https://github.com/python/cpython/blob/4e38eea/Lib/asyncio/selector_events.py#L865-L868) or [here](https://github.com/python/cpython/blob/4e38eea/Lib/asyncio/selector_events.py#L895-L900) for a fd it doesn't control anymore, causing access to that fd to hang.

Long story:

1. Introduce a GC cycle, such that an `asyncio.selector_events._SelectorTransport` and the object owning it are collected at the same time.
2. The transport `__del__` will be called, closing the socket, freeing its file descriptor, but not performing any other cleanup.
3. The owning object, being a good citizen, resurrects the transport during gc to have `close()` called on it properly. In the case of this issue, an asyncio task was created to close it later. (I definitely don't love seeing `asyncio.create_task` in a `__del__` method, but I expect that's not the only way to trigger this)
4. At this point, anything in your asyncio runloop can open a file descriptor. In my case, it was `asyncio.create_subprocess_exec` calling `os.pidfd_create()` in `PidfdChildWatcher.add_child_handler`. If you're lucky (or running a lot of tasks at once), the new fd will be the same as the resurrected socket's fd.
5. Now `transport.close()` can run any time later, which will call `loop._selector.remove_child_watcher(fd)`, despite not really owning the fd anymore.
6. Now the pidfd has been removed from `loop._selector`, so `await proc.wait()` will hang forever. Or whatever asyncio stream you were trying to use got removed from the selector and you won't be able to wait on it.

I definitely think the non-stdlib code in play here was unsound, but I don't think that should trigger such a cursed result in the stdlib, so I'd rather defend against this in asyncio.

I think this is the minimum patch to mitigate the issue, to prevent the `remove_child_reader` and `remove_child_writer` calls by breaking their pre-conditions. I'm not sure if it's worth trying to interact with the loop or selector from `__del__` to clean up the fd. (Selecting on a missing fd is probably handled somewhere else anyway?)

```diff
--- a/Lib/asyncio/selector_events.py
+++ b/Lib/asyncio/selector_events.py
@@ -871,6 +871,8 @@ def close(self):
     def __del__(self, _warn=warnings.warn):
         if self._sock is not None:
             _warn(f""unclosed transport {self!r}"", ResourceWarning, source=self)
+            self._closing = True
+            self._buffer.clear()
             self._sock.close()
             if self._server is not None:
                 self._server._detach(self)
```

Another consideration is that asyncio is using a cached `self._sock_fd` here without really knowing if the underlying socket was closed and fd was recycled or not. I think this isn't the first time the cached fd has caused a surprising behavior, see also https://github.com/python/cpython/issues/88968

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130142
<!-- /gh-linked-prs -->
","['--- a/Lib/asyncio/selector_events.py\n+++ b/Lib/asyncio/selector_events.py\n@@ -871,6 +871,8 @@ def close(self):\n     def __del__(self, _warn=warnings.warn):\n         if self._sock is not None:\n             _warn(f""unclosed transport {self!r}"", ResourceWarning, source=self)\n+            self._closing = True\n+            self._buffer.clear()\n             self._sock.close()\n             if self._server is not None:\n                 self._server._detach(self)']","This seems like a bigger problem especially wrt free-threading of reusing of sockets and file descriptors. 

cc @colesbury @gvanrossum ",[],['python'],github,https://github.com/python/cpython/issues/130141,{'repo': 'python/cpython'}
"email.policy.default mypy error

# Bug report

### Bug description:

i anticipated that this issue would be resolved in Python 3.13.2 because i thought i saw a pull request for it, but that did not happen. (i have had false memories before.) mypy 1.14.0 also reports an error, 1.13.0 does not.

```
from email import parser, policy

""""""
using Python 3.13.2, mypy 1.15.0 emits --
default_policy.py:10: error: Argument ""policy"" to ""Parser"" has incompatible type ""EmailPolicy[EmailMessage]""; expected ""Policy[Message[str, str]]""  [arg-type]
Found 1 error in 1 file (checked 1 source file)
""""""


parser.Parser(policy=policy.default)
```


### CPython versions tested on:

3.13

### Operating systems tested on:

macOS","['from email import parser, policy\n\n""""""\nusing Python 3.13.2, mypy 1.15.0 emits --\ndefault_policy.py:10: error: Argument ""policy"" to ""Parser"" has incompatible type ""EmailPolicy[EmailMessage]""; expected ""Policy[Message[str, str]]""  [arg-type]\nFound 1 error in 1 file (checked 1 source file)\n""""""\n\n\nparser.Parser(policy=policy.default)']","Is this a mypy or a CPython issue? if it's a mypy issue, please report it at https://github.com/python/mypy/issues instead (but it could also be a typeshed issue). What would be the non-typing issue? namely can it cause an issue at runtime?",[],['python'],github,https://github.com/python/cpython/issues/130412,{'repo': 'python/cpython'}
"Local annotation turns local variables in cells

# Bug report

### Bug description:

Compiling this function
```python
def f(x):
    a:x
    return x
```
Gives this bytecode:
```
  --           MAKE_CELL                0 (x)

   1           RESUME                   0

   3           LOAD_DEREF               0 (x)
               RETURN_VALUE
```
Local variable annotations are supposed to be ignored by Python (they are used by static type checkers only),
so the addition of the annotation should not change the generated code. 
The expected disassembly:
```
   1           RESUME                   0

   3           LOAD_LAST                0 (x)
               RETURN_VALUE
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_","['def f(x):\n    a:x\n    return x', '--           MAKE_CELL                0 (x)\n\n   1           RESUME                   0\n\n   3           LOAD_DEREF               0 (x)\n               RETURN_VALUE', '1           RESUME                   0\n\n   3           LOAD_LAST                0 (x)\n               RETURN_VALUE']","Yes, I already assigned it to myself to look into.

I think this is harmless in the sense that it doesn't change any behavior we should guarantee, but it's a pessimization.",[],['python'],github,https://github.com/python/cpython/issues/130924,{'repo': 'python/cpython'}
"Where is the _ environment variable documented?

When I run this script:
```
import os

for k,v in os.environ.items():
    print(f'key={k} val={v}')
```

it prints the environjment with an altered _ value.

The new _ value is:
> key=_ val=/usr/local/bin/python3.11

while the original value was:
> _=/usr/bin/env


Then this _ value alters the sys.path that Pyton uses in some way.

Is this behavior documented?

How to prevent _ from being altered when child Python processes are launched?

","[""import os\n\nfor k,v in os.environ.items():\n    print(f'key={k} val={v}')""]","For bash, the `_` environment variable is [documented](https://www.gnu.org/software/bash/manual/html_node/Bash-Variables.html) as follows:

> At shell startup, set to the absolute pathname used to invoke the shell or shell script being executed as passed in the environment or argument list. Subsequently, expands to the last argument to the previous command, after expansion. Also set to the full pathname used to invoke each command executed and placed in the environment exported to that command. When checking mail, this parameter holds the name of the mail file. 

It's not modified by Python but by the underlying shell. See https://askubuntu.com/questions/1198935/what-is-the-purpose-of-the-special-parameter-single-underscore-in-environm.

",[],['python'],github,https://github.com/python/cpython/issues/129982,{'repo': 'python/cpython'}
"unexpected behavior of `datetime.astimezone` method

# Bug report

### Bug description:

my system time zone is `UTC+04:00`
```python
>>> import datetime
>>> datetime.datetime(9999, 12, 31).astimezone() # same for .astimezone(datetime.UTC)
Traceback (most recent call last):
  File ""<python-input-46>"", line 1, in <module>
    datetime.datetime(9999, 12, 31).astimezone()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
ValueError: year must be in 1..9999, not 10000
>>> datetime.datetime(9999, 12, 31, tzinfo=datetime.UTC).astimezone()
datetime.datetime(9999, 12, 31, 4, 0, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400), '+04'))
```
same behavior for `_pydatetime` module, but I found that in version `3.11` the behavior is as next:
```python
>>> datetime.datetime(9999, 12, 31).astimezone()
datetime.datetime(9999, 12, 31, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400), '+04'))
```

EDIT: same behavior for `datetime(1, 1, 1)`:
```python
>>> datetime.datetime(1, 1, 1).astimezone()
Traceback (most recent call last):
  File ""<python-input-23>"", line 1, in <module>
    datetime.datetime(1, 1, 1).astimezone()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
ValueError: year must be in 1..9999, not 0
```

### CPython versions tested on:

CPython main branch, 3.13, 3.12

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130752
<!-- /gh-linked-prs -->
","['>>> import datetime\n>>> datetime.datetime(9999, 12, 31).astimezone() # same for .astimezone(datetime.UTC)\nTraceback (most recent call last):\n  File ""<python-input-46>"", line 1, in <module>\n    datetime.datetime(9999, 12, 31).astimezone()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\nValueError: year must be in 1..9999, not 10000\n>>> datetime.datetime(9999, 12, 31, tzinfo=datetime.UTC).astimezone()\ndatetime.datetime(9999, 12, 31, 4, 0, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400), \'+04\'))', "">>> datetime.datetime(9999, 12, 31).astimezone()\ndatetime.datetime(9999, 12, 31, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400), '+04'))"", '>>> datetime.datetime(1, 1, 1).astimezone()\nTraceback (most recent call last):\n  File ""<python-input-23>"", line 1, in <module>\n    datetime.datetime(1, 1, 1).astimezone()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\nValueError: year must be in 1..9999, not 0']","We might have some broader checks or maybe there's some rollover somewhere, or we somehow missed a bound check",[],['python'],github,https://github.com/python/cpython/issues/130718,{'repo': 'python/cpython'}
"docs: add an explicit `close()` call to `urlopen` examples without `with`

# Documentation

The [documentation](https://docs.python.org/3/library/urllib.request.html#examples) for `urllib.request` uses `urlopen()` 3 times without either `with` or manual closing. Although technically possible, this is not recommended.

> It is also possible to achieve the same result without using the [context manager](https://docs.python.org/3/glossary.html#term-context-manager) approach.
> ```
> >>> import urllib.request
> >>> f = urllib.request.urlopen('http://www.python.org/')
> >>> print(f.read(100).decode('utf-8'))
> ```
> ...
> Use of Basic HTTP Authentication:
> ```
> urllib.request.urlopen('http://www.example.com/login.html')
> ```
> ...
> Adding HTTP headers:
> ```
> r = urllib.request.urlopen(req)
> ```

This is a follow-up from [ruff #13683](https://github.com/astral-sh/ruff/issues/13683).

<!-- gh-linked-prs -->
### Linked PRs
* gh-130280
<!-- /gh-linked-prs -->
","[""> >>> import urllib.request\n> >>> f = urllib.request.urlopen('http://www.python.org/')\n> >>> print(f.read(100).decode('utf-8'))\n>"", ""> urllib.request.urlopen('http://www.example.com/login.html')\n>"", '> r = urllib.request.urlopen(req)\n>']","@Mr-Sunglasses @rruuaanng Proper closing should be added to all 3 quoted examples. As you may know, the audience includes learners and people from other fields than programming.",[],['python'],github,https://github.com/python/cpython/issues/130132,{'repo': 'python/cpython'}
"spam

# Documentation

(A clear and concise description of the issue.)
",[],"Dear @Satan19, please do not create spam issues (also https://github.com/python/cpython/issues/130944).",[],['python'],github,https://github.com/python/cpython/issues/130943,{'repo': 'python/cpython'}
"`PyList_SetItem` missing atomic store

# Bug report

`PyList_SetItem` currently uses `Py_XSETREF` to set the item and decref the old one, however the store is not atomic as such it can race with a concurrent read. The fix is to use a atomic store with release order to correctly set the new item and then decref the old object.

cc @colesbury @Yhg1s 

<!-- gh-linked-prs -->
### Linked PRs
* gh-129644
* gh-129677
* gh-129680
* gh-129725
<!-- /gh-linked-prs -->
",[],"There is a similar issue in the function `ins1`:

https://github.com/python/cpython/blob/979d76620990e6f8d68fa63e0ae0db1ec5b4d14c/Objects/listobject.c#L467-L470
",[],['python'],github,https://github.com/python/cpython/issues/129643,{'repo': 'python/cpython'}
"Python 3.14.0a5 i686 Linux freethreading-debug build fails: gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small

# Bug report

### Bug description:

I try to build freethreading-debug Python 3.14.0a5 for i686 Fedora Linux with a consistent failure: `/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small`. This happens when freezing `importlib._bootstrap_external`, `zipimport`, `importlib._bootstrap`.
The bigger log excerpt:

```
./Programs/_freeze_module getpath /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Modules/getpath.py Python/frozen_modules/getpath.h
./Programs/_freeze_module importlib._bootstrap_external /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/importlib/_bootstrap_external.py Python/frozen_modules/importlib._bootstrap_external.h
/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small
Enable tracemalloc to get the memory block allocation traceback
object address  : 0xefc48188
object refcount : 1
object type     : 0x56bef880
object type name: staticmethod
object repr     : <staticmethod(<built-in method maketrans of type object at 0x56be6ac0>)>
Fatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed
Python runtime state: core initialized
Stack (most recent call first):
  <no Python frame>
make: *** [Makefile:1772: Python/frozen_modules/importlib._bootstrap_external.h] Aborted (core dumped)
make: *** Waiting for unfinished jobs....
./Programs/_freeze_module zipimport /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/zipimport.py Python/frozen_modules/zipimport.h
/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small
Enable tracemalloc to get the memory block allocation traceback
object address  : 0xefc48188
object refcount : 1
object type     : 0x56be0880
object type name: staticmethod
object repr     : <staticmethod(<built-in method maketrans of type object at 0x56bd7ac0>)>
Fatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed
Python runtime state: core initialized
Stack (most recent call first):
  <no Python frame>
make: *** [Makefile:1775: Python/frozen_modules/zipimport.h] Aborted (core dumped)
./Programs/_freeze_module importlib._bootstrap /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/importlib/_bootstrap.py Python/frozen_modules/importlib._bootstrap.h
/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small
Enable tracemalloc to get the memory block allocation traceback
object address  : 0xefc48188
object refcount : 1
object type     : 0x56bb7880
object type name: staticmethod
object repr     : <staticmethod(<built-in method maketrans of type object at 0x56baeac0>)>
Fatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed
Python runtime state: core initialized
Stack (most recent call first):
  <no Python frame>
make: *** [Makefile:1769: Python/frozen_modules/importlib._bootstrap.h] Aborted (core dumped)
```


### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130043
<!-- /gh-linked-prs -->
","['./Programs/_freeze_module getpath /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Modules/getpath.py Python/frozen_modules/getpath.h\n./Programs/_freeze_module importlib._bootstrap_external /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/importlib/_bootstrap_external.py Python/frozen_modules/importlib._bootstrap_external.h\n/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small\nEnable tracemalloc to get the memory block allocation traceback\nobject address  : 0xefc48188\nobject refcount : 1\nobject type     : 0x56bef880\nobject type name: staticmethod\nobject repr     : <staticmethod(<built-in method maketrans of type object at 0x56be6ac0>)>\nFatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed\nPython runtime state: core initialized\nStack (most recent call first):\n  <no Python frame>\nmake: *** [Makefile:1772: Python/frozen_modules/importlib._bootstrap_external.h] Aborted (core dumped)\nmake: *** Waiting for unfinished jobs....\n./Programs/_freeze_module zipimport /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/zipimport.py Python/frozen_modules/zipimport.h\n/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small\nEnable tracemalloc to get the memory block allocation traceback\nobject address  : 0xefc48188\nobject refcount : 1\nobject type     : 0x56be0880\nobject type name: staticmethod\nobject repr     : <staticmethod(<built-in method maketrans of type object at 0x56bd7ac0>)>\nFatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed\nPython runtime state: core initialized\nStack (most recent call first):\n  <no Python frame>\nmake: *** [Makefile:1775: Python/frozen_modules/zipimport.h] Aborted (core dumped)\n./Programs/_freeze_module importlib._bootstrap /builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Lib/importlib/_bootstrap.py Python/frozen_modules/importlib._bootstrap.h\n/builddir/build/BUILD/python3.14-3.14.0_a5-build/Python-3.14.0a5/Python/gc_free_threading.c:1077: mark_heap_visitor: Assertion ""gc_get_refs(op) >= 0"" failed: refcount is too small\nEnable tracemalloc to get the memory block allocation traceback\nobject address  : 0xefc48188\nobject refcount : 1\nobject type     : 0x56bb7880\nobject type name: staticmethod\nobject repr     : <staticmethod(<built-in method maketrans of type object at 0x56baeac0>)>\nFatal Python error: _PyObject_AssertFailed: _PyObject_AssertFailed\nPython runtime state: core initialized\nStack (most recent call first):\n  <no Python frame>\nmake: *** [Makefile:1769: Python/frozen_modules/importlib._bootstrap.h] Aborted (core dumped)']","Thanks, I'm able to repro this and should have a fix soon.",[],['python'],github,https://github.com/python/cpython/issues/130030,{'repo': 'python/cpython'}
"email.utils.decode_params not supporting params that contain hyphens

# Bug report

### Bug description:

The decode_params function from email.utils is failing to combine the parameters from multiple lines if the name of the parameter includes a hyphen ""-"". Maybe it's this regex which is too strict: https://github.com/python/cpython/blob/9d1e668e6f40967dda5cbb1ce298bf0dff2d807c/Lib/email/utils.py#L392-L393

The decode_params function always ignores the first 2-tuple but the first parameter in a SMTP header can already be a multiline parameter. I don't see a reason why the first array element is skipped here:
https://github.com/python/cpython/blob/9d1e668e6f40967dda5cbb1ce298bf0dff2d807c/Lib/email/utils.py#L398-L405

my code to reproduce:
```python
from email.utils import decode_params

decode_params([('parameter-name*0*',""utf-8''start;""),(""parameter-name*1*"",""-middle-;""),(""parameter-name*2*"",""end;"")])
# parameter-name is not combined:
#  [('parameter-name*0*', ""utf-8''start;""), ('parameter-name*1*', '""-middle-;""'), ('parameter-name*2*', '""end;""')]

decode_params([('parametername*0*',""utf-8''start;""),(""parametername*1*"",""-middle-;""),(""parametername*2*"",""end;"")])
# parametername is combined but not the first 2-tuple:
# [('parametername*0*', ""utf-8''start;""), ('parametername', (None, None, '""-middle-;end;""'))]

decode_params([(""ignored"",""ignored""),('parametername*0*',""utf-8''start;""),(""parametername*1*"",""-middle-;""),(""parametername*2*"",""end;"")])
# parametername is now combined as expected, the additional entry can be ignored when processing the output
# [('ignored', 'ignored'), ('parametername', ('utf-8', '', '""start;-middle-;end;""'))]
```

Thank you
Michael

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux","['from email.utils import decode_params\n\ndecode_params([(\'parameter-name*0*\',""utf-8\'\'start;""),(""parameter-name*1*"",""-middle-;""),(""parameter-name*2*"",""end;"")])\n# parameter-name is not combined:\n#  [(\'parameter-name*0*\', ""utf-8\'\'start;""), (\'parameter-name*1*\', \'""-middle-;""\'), (\'parameter-name*2*\', \'""end;""\')]\n\ndecode_params([(\'parametername*0*\',""utf-8\'\'start;""),(""parametername*1*"",""-middle-;""),(""parametername*2*"",""end;"")])\n# parametername is combined but not the first 2-tuple:\n# [(\'parametername*0*\', ""utf-8\'\'start;""), (\'parametername\', (None, None, \'""-middle-;end;""\'))]\n\ndecode_params([(""ignored"",""ignored""),(\'parametername*0*\',""utf-8\'\'start;""),(""parametername*1*"",""-middle-;""),(""parametername*2*"",""end;"")])\n# parametername is now combined as expected, the additional entry can be ignored when processing the output\n# [(\'ignored\', \'ignored\'), (\'parametername\', (\'utf-8\', \'\', \'""start;-middle-;end;""\'))]']","As you observed, adding a first dummy parameter solves the issue. Now, why do we skip the first parameter? Actually, the reason is because we are always expecting a header to be found first 

https://github.com/python/cpython/blob/0f20281fa2f39673ec5d4a562e00d2f413890066/Lib/email/message.py#L664-L666

and then we parse that header. By default, I think the first element of the list being decoded is actually the `XXX` of `Content-Type: XXX` value where *no* multiline support is expected (or am I wrong here?) Then, what follows contains a list of possibly multi-line parameters.

The RFC says:

> A MIME disposition value may specify any number of associated parameters. 
> [...]
> These parameter names and values end up appearing in the content-type and content-disposition header fields in Internet email.  

For instance:

```
Content-Type: message/external-body; access-type=URL;
  URL*0=""ftp://"";
  URL*1=""cs.utk.edu/pub/moore/bulk-mailer/bulk-mailer.tar""
```

Consider https://www.ietf.org/rfc/rfc2045.html#section-5.1 vs https://datatracker.ietf.org/doc/html/rfc2231#section-7. I think we always have `HEADER_NAME: HEADER_VALUE[;ADDITIONAL_PARAMETERS]`. Observe that:

```py
>>> x = ""Content-Type: text/html; foo=one; bar=two; baz=three\n""
>>> msg = email.message_from_string(x)
>>> msg.get_params()
[('text/html', ''), ('foo', 'one'), ('bar', 'two'), ('baz', 'three')]
```

More precisely:

```py
>>> email.message._parseparam(x)
['Content-Type: text/html', 'foo=one', 'bar=two', 'baz=three']
```

We are actually parsing the entire header and not just its list of parameters. In particular, the ""first"" parameter is the header value and I suspect this is what RFC 2045 says. So the inputs to `decode_params` should not be manually specified but rather constructed in the same way (we still have a doc issue though IMO).

The reason why the content-type subtype is always present is because of RFC 2045 which states:

> Note also that a subtype specification is MANDATORY -- it may not be
omitted from a Content-Type header field.  As such, there are no
default subtypes.

EDIT: Note that the RFC only says something about the `Content-Type` header field. For *other* header fields without this, we may have some issues depending on how you actually specify a header without a value *but* with a parameter. If you add a `;` to separate the (empty) value from the list of parameters, it's fine. Otherwise, there will be parsing issues, though I don't think they are common because a header without a value is not common (is it even legal? I'm not sure that it is actually).

---

Now, let's move onto the second issue, namely the `-`. I *think* it's incorrect to reject them because neither RFC 2045 nor RFC 2231 say that the character is illegal. The ABNF is:

```
attribute := 1*attribute-char
attribute-char := <any (US-ASCII) CHAR except SPACE, CTLs,
                 ""*"", ""'"", ""%"", or tspecials>
```

and `-` is not part of `tspecials` which is (documented in RFC 2045)

```
tspecials :=  ""("" / "")"" / ""<"" / "">"" / ""@"" /
             "","" / "";"" / "":"" / ""\"" / <"">
             ""/"" / ""["" / ""]"" / ""?"" / ""=""
```

---

So, AFAICT, the title of the issue *is* correct, but there shouldn't be an issue with the implementation that skips the first parameter. There is *however* an issue with the documentation that should mention that the first element of the parameters list is skipped as the input should be parsed from a valid RFC 2045 header value.","['Content-Type: message/external-body; access-type=URL;\n  URL*0=""ftp://"";\n  URL*1=""cs.utk.edu/pub/moore/bulk-mailer/bulk-mailer.tar""', '>>> x = ""Content-Type: text/html; foo=one; bar=two; baz=three\\n""\n>>> msg = email.message_from_string(x)\n>>> msg.get_params()\n[(\'text/html\', \'\'), (\'foo\', \'one\'), (\'bar\', \'two\'), (\'baz\', \'three\')]', "">>> email.message._parseparam(x)\n['Content-Type: text/html', 'foo=one', 'bar=two', 'baz=three']"", 'attribute := 1*attribute-char\nattribute-char := <any (US-ASCII) CHAR except SPACE, CTLs,\n                 ""*"", ""\'"", ""%"", or tspecials>', 'tspecials :=  ""("" / "")"" / ""<"" / "">"" / ""@"" /\n             "","" / "";"" / "":"" / ""\\"" / <"">\n             ""/"" / ""["" / ""]"" / ""?"" / ""=""']",['python'],github,https://github.com/python/cpython/issues/130110,{'repo': 'python/cpython'}
"TSAN failures seen running PyO3 tests with the free-threaded build

I'm seeing TSAN warnings running the PyO3 tests using CPython commit 38642bf

I've done this on an M3 Macbook Pro running MacOS Sequoia as well as @nascheme's [cpython_sanity](https://github.com/nascheme/cpython_sanity) [docker image](https://github.com/nascheme/cpython_sanity/pkgs/container/cpython-tsan) which has LLVM 20 installed (as well as Python3.13 with TSAN and some packages, but I didn't use that). I *think* it's only possible to run TSAN on both the rust code and CPython using LLVM 20 and I can't easily install that on my Mac right now since it's not yet packaged on homebrew.

See [this comment](https://github.com/PyO3/pyo3/issues/4904#issuecomment-2675087546) in the PyO3 repo if you want to use the docker image, there are some small tweaks you need to do before it will work correctly.

On an ARM Mac, I installed llvm from homebrew and then did `CONFIGURE_OPTS=""--with-thread-sanitizer"" pyenv install 3.14t-dev` to get a TSAN CPython build. You'll also need to install a rust toolchain.

You'll also need a copy of PyO3 [checked out to this branch](https://github.com/ngoldbaum/pyo3/tree/3.14-testing).

Because homebrew doesn't have LLVM 19, I had to resort to just running the cargo tests as normal using a CPython with TSAN. I think this should still detect races happening inside CPython.

```
pyenv global 3.14t-dev
pip install nox
cd pyo3
nox -s test
```

Here is the full output from one invocation on my Mac: https://gist.github.com/ngoldbaum/e198d87149617ecdaf881f29a03b8126

Here are a sampling of the warning summaries:

```
data race pytime.c:1163 in py_get_monotonic_clock
data race typeobject.c:2235 in _PyType_AllocNoTrack
data race weakrefobject.c:413 in get_or_create_weakref
data race pytime.c:1180 in py_get_monotonic_clock
data race pytime.c:1162 in py_get_monotonic_clock
data race object.c:343 in _Py_IncRef
```

You can ignore all the `test_compiler_error` messages - nightly rust always has compiler error message failures.

Another way to trigger these failures is with `cargo stress`, which runs the tests in a loop to try to trigger safety issues like this. I have a hacked together version of `cargo stress` [on this branch](https://github.com/ngoldbaum/cargo-stress/tree/hacked-together-print-always) that makes it so that instead of crashing if a thread writes to stderr, it prints the stderr to the terminal and continues. If you run TSAN with `TSAN_OPTIONS=exit_code=0`, my version of `cargo stress` will happily continue running after the first TSAN warning. This is a good way to generate lots of warnings quickly without waiting to rerun the full test suite manually.

Here are some additional summaries that I see in a `cargo stress` run:

```
data race tupleobject.c:173 in PyTuple_Pack
data race typeobject.c:3368 in best_base
```

And here is the full terminal output (this ran for about 10 seconds before I killed it with ctrl-c): https://gist.github.com/ngoldbaum/1d1e29c8e10f0ac979ef27a95c73d39f


When I try to do the same tests in the docker container using a version of 3.14t-dev I built on the container, I don't see any of the TSAN reports seen above. Maybe they don't happen on x86_64?

Also note that there is a race inside PyO3 triggered by the PyO3 test`test_thread_safety_2`, you may see that if you are running the tests inside the docker container. There are also two test failures due to unexpected panics that I only see under TSAN in the docker container. I'm not sure what's happening with the failures yet.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130592
<!-- /gh-linked-prs -->
","['pyenv global 3.14t-dev\npip install nox\ncd pyo3\nnox -s test', 'data race pytime.c:1163 in py_get_monotonic_clock\ndata race typeobject.c:2235 in _PyType_AllocNoTrack\ndata race weakrefobject.c:413 in get_or_create_weakref\ndata race pytime.c:1180 in py_get_monotonic_clock\ndata race pytime.c:1162 in py_get_monotonic_clock\ndata race object.c:343 in _Py_IncRef', 'data race tupleobject.c:173 in PyTuple_Pack\ndata race typeobject.c:3368 in best_base']","For future reference:

### py_get_monotonic_clock (macOS only)

The initialization of the global `base` isn't thread-safe. My preference would be to try to initialize this during runtime initialization, before any other threads are created.

https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Python/pytime.c#L1160-L1166

### long_from_non_binary_base

Non thread-safe initialization of global state. Either initialize this during runtime initialization (if it's fast enough) or use `_PyOnceFlag`.

https://github.com/python/cpython/blob/f963239ff1f986742d4c6bab2ab7b73f5a4047f6/Objects/longobject.c#L2835-L2839

### _PyType_AllocNoTrack

`_PyType_PreHeaderSize()` reads `tp_flags` and `PyType_Ready()` modifies it. I think we should be ensuring that `PyType_Ready()` is called before any instances of objects are allocated, but:

* I'm not sure how this is happening in the PyO3 tests
* Python historically has been fairly forgiving for not calling `PyType_Ready()`

https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Objects/typeobject.c#L2237
https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Objects/typeobject.c#L8667

### get_or_create_weakref and PyType_FromMetaclass

Seems pretty similar to the `_PyType_AllocNoTrack` race above.  Again, I'm not sure how we are creating a weak reference to an object before we finish initializing that object's type.

https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Objects/weakrefobject.c#L413
https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Objects/typeobject.c#L5055

```
  Read of size 8 at 0x0003000600e0 by thread T725 (mutexes: write M0):
    #0 get_or_create_weakref weakrefobject.c:413 (libpython3.14t.dylib:arm64+0x200024)
    #1 PyWeakref_NewRef weakrefobject.c:921 (libpython3.14t.dylib:arm64+0x1fffc4)
    #2 pyo3::types::weakref::reference::PyWeakrefReference::new::h021cf5fda7b820b3 reference.rs:87 (pyo3-f6efbb17135478d3:arm64+0x10001e630)

  Previous write of size 8 at 0x0003000600e0 by thread T724 (mutexes: write M1):
    #0 PyType_FromMetaclass typeobject.c:5055 (libpython3.14t.dylib:arm64+0x176988)
    #1 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)
    #2 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h21354c33afccbc76 create_type_object.rs:493 (pyo3-f6efbb17135478d3:arm64+0x1000833ec)
```

### best_base / type_ready

Not sure, but seems related to the above two issues.

```
  Read of size 8 at 0x00010e0400b8 by thread T5 (mutexes: write M0):
    #0 best_base typeobject.c:3368 (libpython3.14t.dylib:arm64+0x176c60)
    #1 PyType_FromMetaclass typeobject.c:4893 (libpython3.14t.dylib:arm64+0x176284)
    #2 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)
    #3 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null>:140509280 (test_class_conversion-25e69c9142759d40:arm64+0x1000483d8)

  Previous write of size 8 at 0x00010e0400b8 by thread T3 (mutexes: write M1):
    #0 type_ready typeobject.c:8667 (libpython3.14t.dylib:arm64+0x183350)
    #1 PyType_Ready typeobject.c:8697 (libpython3.14t.dylib:arm64+0x1777f4)
    #2 PyType_FromMetaclass typeobject.c:5069 (libpython3.14t.dylib:arm64+0x1769bc)
    #3 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)
    #4 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null>:140509280 (test_class_conversion-25e69c9142759d40:arm64+0x1000483d8)
```

### _Py_IncRef and _PyObject_SetDeferredRefcount

`_PyObject_SetDeferredRefcount` modifies `ob_ref_shared` in a way that's not thread-safe if other threads may be modifying the reference count of that object. In general, we don't want to be calling `_PyObject_SetDeferredRefcount()` on objects that are accessible to other threads.

(We could also consider trying to make `_PyObject_SetDeferredRefcount` more thread-safe, but that would also make it more complicated and slower.)

The type shouldn't be exposed to other threads, but it might be getting accessed via a `gc.get_objects()` or `gc.get_referrers` call.

https://github.com/python/cpython/blob/38642bff139bde5c0118bc75fda25badc76b85fc/Objects/object.c#L2549

```
  Previous write of size 8 at 0x00010e040010 by thread T11 (mutexes: write M1):
    #0 _PyObject_SetDeferredRefcount object.c:2549 (libpython3.14t.dylib:arm64+0x127768)
    #1 _PyObject_AssignUniqueId uniqueid.c:96 (libpython3.14t.dylib:arm64+0x345a6c)
    #2 PyType_FromMetaclass typeobject.c:5060 (libpython3.14t.dylib:arm64+0x16ed24)
    #3 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x16fde0)
    #4 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null> (test_enum-eedee5d138326bdc:arm64+0x10007d098)
```

### PyTuple_Pack / mi_page_free_list_extend

Possible duplicate of:

* https://github.com/python/cpython/issues/129748

","['Read of size 8 at 0x0003000600e0 by thread T725 (mutexes: write M0):\n    #0 get_or_create_weakref weakrefobject.c:413 (libpython3.14t.dylib:arm64+0x200024)\n    #1 PyWeakref_NewRef weakrefobject.c:921 (libpython3.14t.dylib:arm64+0x1fffc4)\n    #2 pyo3::types::weakref::reference::PyWeakrefReference::new::h021cf5fda7b820b3 reference.rs:87 (pyo3-f6efbb17135478d3:arm64+0x10001e630)\n\n  Previous write of size 8 at 0x0003000600e0 by thread T724 (mutexes: write M1):\n    #0 PyType_FromMetaclass typeobject.c:5055 (libpython3.14t.dylib:arm64+0x176988)\n    #1 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)\n    #2 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h21354c33afccbc76 create_type_object.rs:493 (pyo3-f6efbb17135478d3:arm64+0x1000833ec)', 'Read of size 8 at 0x00010e0400b8 by thread T5 (mutexes: write M0):\n    #0 best_base typeobject.c:3368 (libpython3.14t.dylib:arm64+0x176c60)\n    #1 PyType_FromMetaclass typeobject.c:4893 (libpython3.14t.dylib:arm64+0x176284)\n    #2 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)\n    #3 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null>:140509280 (test_class_conversion-25e69c9142759d40:arm64+0x1000483d8)\n\n  Previous write of size 8 at 0x00010e0400b8 by thread T3 (mutexes: write M1):\n    #0 type_ready typeobject.c:8667 (libpython3.14t.dylib:arm64+0x183350)\n    #1 PyType_Ready typeobject.c:8697 (libpython3.14t.dylib:arm64+0x1777f4)\n    #2 PyType_FromMetaclass typeobject.c:5069 (libpython3.14t.dylib:arm64+0x1769bc)\n    #3 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x177b14)\n    #4 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null>:140509280 (test_class_conversion-25e69c9142759d40:arm64+0x1000483d8)', 'Previous write of size 8 at 0x00010e040010 by thread T11 (mutexes: write M1):\n    #0 _PyObject_SetDeferredRefcount object.c:2549 (libpython3.14t.dylib:arm64+0x127768)\n    #1 _PyObject_AssignUniqueId uniqueid.c:96 (libpython3.14t.dylib:arm64+0x345a6c)\n    #2 PyType_FromMetaclass typeobject.c:5060 (libpython3.14t.dylib:arm64+0x16ed24)\n    #3 PyType_FromSpec typeobject.c:5156 (libpython3.14t.dylib:arm64+0x16fde0)\n    #4 pyo3::pyclass::create_type_object::PyTypeBuilder::build::h4dc4cb20c59c0b38 <null> (test_enum-eedee5d138326bdc:arm64+0x10007d098)']",['python'],github,https://github.com/python/cpython/issues/130421,{'repo': 'python/cpython'}
"We need unambiguous, meaningful naming of stack reference operations dependent on how counting is done

https://github.com/faster-cpython/ideas/issues/700 describes three ways to count references:
* Virtual,
* Embedded, and
* Immediate

`Virtual` references are references that are know to exist to the relevant code generator, but are elided at runtime, so no API is needed for them.
`Embedded` references are marked by bit(s) in the reference and not in the `ob_refcount` field of the object.
`Immediate` references are counted in the  `ob_refcount` (or free-threading equivalent) field of the object.

To this we should add `uncounted` which are references to immortal objects (including `NULL`).
Note that it is possible to have embedded or immediate references to immortal objects if the object was mortal when the reference, or reference this reference was created from, was created.

### Why this matters

It is important that the use of references is understandable without referring to the implementation and we have multiple implementations of stackrefs, so the interface needs to be clear.

#### Multiple implementations

Even when we merge the free-threading and default implementations of stackrefs, we will still have the `Py_STACKREF_DEBUG` implementation which is very different and vital to finding reference errors.

### Examples:

When creating an embedded stackref from another stackref, we should use `PyStackRef_DUP_Embedded` which has the same semantics as `PyStackRef_DUP` but creates an embedded reference if the implementation supports it.

There are circumstance when a method of counting is not safe. E.g. using embedded references in the heap is not safe. For that we will want to physically transform a reference without a logic change in ownership.
E.g. `PyStackRef_ToNonEmbedded`. In terms of ownership, this a no-op, `PyStackRef_ToNonEmbedded(ref)` is equivalent `ref`, but ensures that any embedded count is turned into an immediate count.

We probably should only use `uncounted` when referring to references in docs and comments, as we already have `PyStackRef_FromPyObjectImmortal`, there is no need for `PyStackRef_FromPyObjectUncounted` as well.


",[],"We also need names for the use and lifetime of references. https://github.com/python/cpython/pull/130708 introduces the concept of references that depend, for correctness, on the lifetime of another reference outliving that reference.
The free-threading build allows deferred reclamation of some objects. For those reference counts, the immediate reference may reach zero when the object is still alive. Those objects are not reclaimed by `Py_Dealloc`, but by the cyclic GC when it can prove that there are no references (immediate or embedded) to the object.

With that in mind, we can use the term ""deferred"" for the embedded reference count when it relies on the GC to prevent premature reclamation, and ""scoped"" for the embedded reference count when it depends on the scope of the reference to prevent premature reclamation.
A reference with a scoped refcount can refer to any object. A reference with an embedded reference count can only refer to an object that supports deferred reclamation.

Note: there are no ""deferred references"", only deferred reference **counts**.

We should never use the term ""borrowed"", as that is used for `PyObject *` references, and is already ambiguous enough without adding yet another meaning.

The term ""scoped"" was suggested by @nascheme.",[],['python'],github,https://github.com/python/cpython/issues/130789,{'repo': 'python/cpython'}
"Clean up ""lltrace""

We should get rid of the `LLTRACE` macro, and just use `Py_DEBUG` instead (they're both used interchangeably anyways).

Also, we can check `PYTHON_LLTRACE` once at startup, instead of doing it constantly all over the place.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129764
<!-- /gh-linked-prs -->
",[],Agreed. Long ago it started as a special option that you could enable (only in debug mode IIRC) to make debug mode even slower. But that has fallen by the wayside and I imagine that on modern CPUs the speed loss is minimal. So go ahead!,[],['python'],github,https://github.com/python/cpython/issues/129763,{'repo': 'python/cpython'}
"Data race between _PyMonitoring_RegisterCallback and _Py_call_instrumentation_2args in instrumentation.c

# Bug report

### Bug description:

I built cpython 3.13 from source with TSAN and running the following code:

```python
import sys
import concurrent.futures
import threading


if __name__ == ""__main__"":
    num_workers = 20
    num_runs = 100

    barrier = threading.Barrier(num_workers)

    tool_id = 3
    event_id = sys.monitoring.events.CALL

    sys.monitoring.use_tool_id(tool_id, ""test_tool_1"")
    sys.monitoring.set_events(tool_id, event_id)


    def closure():
        barrier.wait()

        def my_callback(code, instruction_offset, callable, arg0):
            pass

        sys.monitoring.register_callback(tool_id, event_id, my_callback)

        def example_function():
            a = 1
            b = 2
            c = a + b

        for _ in range(num_runs):
            example_function()

    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for i in range(num_workers):
            futures.append(executor.submit(closure))
        assert len(list(f.result() for f in futures)) == num_workers
```

TSAN reports the following data race: https://gist.github.com/vfdev-5/e80f9b4528993eb1543e45a9216350e3#file-repro-log

cpython version:
```
Python 3.13.2+ experimental free-threading build (heads/3.13:9e0fce413a9, Mar 12 2025, 00:48:15) [Clang 18.1.3 (1ubuntu1)]
```

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-131142
* gh-131166
<!-- /gh-linked-prs -->
","['import sys\nimport concurrent.futures\nimport threading\n\n\nif __name__ == ""__main__"":\n    num_workers = 20\n    num_runs = 100\n\n    barrier = threading.Barrier(num_workers)\n\n    tool_id = 3\n    event_id = sys.monitoring.events.CALL\n\n    sys.monitoring.use_tool_id(tool_id, ""test_tool_1"")\n    sys.monitoring.set_events(tool_id, event_id)\n\n\n    def closure():\n        barrier.wait()\n\n        def my_callback(code, instruction_offset, callable, arg0):\n            pass\n\n        sys.monitoring.register_callback(tool_id, event_id, my_callback)\n\n        def example_function():\n            a = 1\n            b = 2\n            c = a + b\n\n        for _ in range(num_runs):\n            example_function()\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for i in range(num_workers):\n            futures.append(executor.submit(closure))\n        assert len(list(f.result() for f in futures)) == num_workers', 'Python 3.13.2+ experimental free-threading build (heads/3.13:9e0fce413a9, Mar 12 2025, 00:48:15) [Clang 18.1.3 (1ubuntu1)]']","On current main TSAN report: 
```console
==================
WARNING: ThreadSanitizer: data race (pid=76663)
  Atomic write of size 8 at 0x55dfbb90bfc0 by thread T1:
    #0 _Py_atomic_exchange_ptr Include/cpython/pyatomic_gcc.h:195 (python+0x3ea0d4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #1 exchange_callables Python/instrumentation.c:3014 (python+0x3ea0d4)
    #2 _PyMonitoring_RegisterCallback Python/instrumentation.c:3044 (python+0x3ef67d) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #3 monitoring_register_callback_impl Python/instrumentation.c:2289 (python+0x3efb95) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #4 monitoring_register_callback Python/clinic/instrumentation.c.h:152 (python+0x3efcbc) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #5 cfunction_vectorcall_FASTCALL Objects/methodobject.c:436 (python+0x1f7699) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #6 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x171175) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #7 PyObject_Vectorcall Objects/call.c:327 (python+0x1712be) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #8 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6141 (python+0x355edd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #9 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #10 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #11 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #12 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #13 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #14 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #15 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6302 (python+0x356fa8) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #16 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #17 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #18 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #19 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #20 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #21 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #22 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6302 (python+0x356fa8) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #23 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #24 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #25 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #26 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x1754c4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #27 method_vectorcall Objects/classobject.c:72 (python+0x1757e4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #28 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #29 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #30 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #31 thread_run Modules/_threadmodule.c:351 (python+0x4e448f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #32 pythread_wrapper Python/thread_pthread.h:242 (python+0x43ac31) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)

  Previous read of size 8 at 0x55dfbb90bfc0 by main thread:
    #0 call_one_instrument Python/instrumentation.c:977 (python+0x3e9036) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #1 call_instrumentation_vector Python/instrumentation.c:1171 (python+0x3ea8cc) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #2 _Py_call_instrumentation_2args Python/instrumentation.c:1226 (python+0x3eca2c) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #3 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6074 (python+0x355de0) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #4 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x19cd2a) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #5 gen_send_ex2 Objects/genobject.c:255 (python+0x19d307) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #6 gen_iternext Objects/genobject.c:629 (python+0x19f367) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #7 list_extend_iter_lock_held Objects/listobject.c:1230 (python+0x1c21fb) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #8 _list_extend Objects/listobject.c:1403 (python+0x1c2343) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #9 list___init___impl Objects/listobject.c:3448 (python+0x1c263c) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #10 list_vectorcall Objects/listobject.c:3472 (python+0x1c27db) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #11 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x171175) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #12 PyObject_Vectorcall Objects/call.c:327 (python+0x1712be) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #13 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6141 (python+0x355edd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #14 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #15 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #16 PyEval_EvalCode Python/ceval.c:771 (python+0x372d5b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #17 run_eval_code_obj Python/pythonrun.c:1362 (python+0x418fa0) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #18 run_mod Python/pythonrun.c:1433 (python+0x419217) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #19 pyrun_file Python/pythonrun.c:1290 (python+0x419c7a) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #20 _PyRun_SimpleFileObject Python/pythonrun.c:518 (python+0x41bbd4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #21 _PyRun_AnyFileObject Python/pythonrun.c:78 (python+0x41bdd4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #22 pymain_run_file_obj Modules/main.c:394 (python+0x45659b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #23 pymain_run_file Modules/main.c:413 (python+0x45670f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #24 pymain_run_python Modules/main.c:679 (python+0x45753f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #25 Py_RunMain Modules/main.c:760 (python+0x457899) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #26 pymain_main Modules/main.c:790 (python+0x457950) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #27 Py_BytesMain Modules/main.c:814 (python+0x457aaf) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)
    #28 main Programs/python.c:15 (python+0x85b3b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)

  Location is global '_PyRuntime' of size 377920 at 0x55dfbb8b4400 (python+0x7ebfc0)

```

The data race is because the callback is being read here without atomic whereas it was exchanged with atomics.
https://github.com/python/cpython/blob/e0637cebe5bf863897f2e89dfcb76be0015c1877/Python/instrumentation.c#L976","[""==================\nWARNING: ThreadSanitizer: data race (pid=76663)\n  Atomic write of size 8 at 0x55dfbb90bfc0 by thread T1:\n    #0 _Py_atomic_exchange_ptr Include/cpython/pyatomic_gcc.h:195 (python+0x3ea0d4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #1 exchange_callables Python/instrumentation.c:3014 (python+0x3ea0d4)\n    #2 _PyMonitoring_RegisterCallback Python/instrumentation.c:3044 (python+0x3ef67d) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #3 monitoring_register_callback_impl Python/instrumentation.c:2289 (python+0x3efb95) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #4 monitoring_register_callback Python/clinic/instrumentation.c.h:152 (python+0x3efcbc) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #5 cfunction_vectorcall_FASTCALL Objects/methodobject.c:436 (python+0x1f7699) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #6 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x171175) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #7 PyObject_Vectorcall Objects/call.c:327 (python+0x1712be) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #8 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6141 (python+0x355edd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #9 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #10 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #11 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #12 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #13 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #14 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #15 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6302 (python+0x356fa8) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #16 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #17 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #18 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #19 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #20 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #21 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #22 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6302 (python+0x356fa8) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #23 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #24 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #25 _PyFunction_Vectorcall Objects/call.c:413 (python+0x170d1f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #26 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x1754c4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #27 method_vectorcall Objects/classobject.c:72 (python+0x1757e4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #28 _PyVectorcall_Call Objects/call.c:273 (python+0x17312e) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #29 _PyObject_Call Objects/call.c:348 (python+0x173559) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #30 PyObject_Call Objects/call.c:373 (python+0x1735bd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #31 thread_run Modules/_threadmodule.c:351 (python+0x4e448f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #32 pythread_wrapper Python/thread_pthread.h:242 (python+0x43ac31) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n\n  Previous read of size 8 at 0x55dfbb90bfc0 by main thread:\n    #0 call_one_instrument Python/instrumentation.c:977 (python+0x3e9036) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #1 call_instrumentation_vector Python/instrumentation.c:1171 (python+0x3ea8cc) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #2 _Py_call_instrumentation_2args Python/instrumentation.c:1226 (python+0x3eca2c) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #3 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6074 (python+0x355de0) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #4 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x19cd2a) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #5 gen_send_ex2 Objects/genobject.c:255 (python+0x19d307) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #6 gen_iternext Objects/genobject.c:629 (python+0x19f367) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #7 list_extend_iter_lock_held Objects/listobject.c:1230 (python+0x1c21fb) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #8 _list_extend Objects/listobject.c:1403 (python+0x1c2343) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #9 list___init___impl Objects/listobject.c:3448 (python+0x1c263c) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #10 list_vectorcall Objects/listobject.c:3472 (python+0x1c27db) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #11 _PyObject_VectorcallTstate Include/internal/pycore_call.h:167 (python+0x171175) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #12 PyObject_Vectorcall Objects/call.c:327 (python+0x1712be) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #13 _PyEval_EvalFrameDefault Python/generated_cases.c.h:6141 (python+0x355edd) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #14 _PyEval_EvalFrame Include/internal/pycore_ceval.h:116 (python+0x372960) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #15 _PyEval_Vector Python/ceval.c:1843 (python+0x372be6) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #16 PyEval_EvalCode Python/ceval.c:771 (python+0x372d5b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #17 run_eval_code_obj Python/pythonrun.c:1362 (python+0x418fa0) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #18 run_mod Python/pythonrun.c:1433 (python+0x419217) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #19 pyrun_file Python/pythonrun.c:1290 (python+0x419c7a) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #20 _PyRun_SimpleFileObject Python/pythonrun.c:518 (python+0x41bbd4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #21 _PyRun_AnyFileObject Python/pythonrun.c:78 (python+0x41bdd4) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #22 pymain_run_file_obj Modules/main.c:394 (python+0x45659b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #23 pymain_run_file Modules/main.c:413 (python+0x45670f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #24 pymain_run_python Modules/main.c:679 (python+0x45753f) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #25 Py_RunMain Modules/main.c:760 (python+0x457899) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #26 pymain_main Modules/main.c:790 (python+0x457950) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #27 Py_BytesMain Modules/main.c:814 (python+0x457aaf) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n    #28 main Programs/python.c:15 (python+0x85b3b) (BuildId: 3cf7871e49ad73b7cfa6dc8c3d839e908ed6ea3c)\n\n  Location is global '_PyRuntime' of size 377920 at 0x55dfbb8b4400 (python+0x7ebfc0)""]",['python'],github,https://github.com/python/cpython/issues/131141,{'repo': 'python/cpython'}
"Clang Compilation Error on NetBSD Due to Incorrect Fallthrough Annotation

# Bug report

### Bug description:

**Configuration:**
[configure-output.txt](https://github.com/user-attachments/files/18790813/configure.txt)
```sh
./configure CC=clang LD=clang --disable-ipv6
```
**Build:**
```sh
make
```
Output:
```c
clang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/callproc.c -o Modules/_ctypes/callproc.o
--- Modules/socketmodule.o ---
./Modules/socketmodule.c:2262:13: error: fallthrough annotation does not directly precede switch label
 2262 |             _Py_FALLTHROUGH;
      |             ^
./Include/pyport.h:635:27: note: expanded from macro '_Py_FALLTHROUGH'
  635 | #  define _Py_FALLTHROUGH __attribute__((fallthrough))
      |                           ^
--- Modules/_ctypes/stgdict.o ---
clang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/stgdict.c -o Modules/_ctypes/stgdict.o
--- Modules/socketmodule.o ---
1 error generated.
--- Modules/_ctypes/cfield.o ---
clang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/cfield.c -o Modules/_ctypes/cfield.o
--- Modules/socketmodule.o ---
*** [Modules/socketmodule.o] Error code 1

make: stopped in /home/blue/cpython
1 error

make: stopped in /home/blue/cpython
```



### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Other

<!-- gh-linked-prs -->
### Linked PRs
* gh-130100
* gh-131026
<!-- /gh-linked-prs -->
","['./configure CC=clang LD=clang --disable-ipv6', 'make', ""clang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/callproc.c -o Modules/_ctypes/callproc.o\n--- Modules/socketmodule.o ---\n./Modules/socketmodule.c:2262:13: error: fallthrough annotation does not directly precede switch label\n 2262 |             _Py_FALLTHROUGH;\n      |             ^\n./Include/pyport.h:635:27: note: expanded from macro '_Py_FALLTHROUGH'\n  635 | #  define _Py_FALLTHROUGH __attribute__((fallthrough))\n      |                           ^\n--- Modules/_ctypes/stgdict.o ---\nclang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/stgdict.c -o Modules/_ctypes/stgdict.o\n--- Modules/socketmodule.o ---\n1 error generated.\n--- Modules/_ctypes/cfield.o ---\nclang -pthread -fno-strict-overflow -I/usr/pkg/include -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall  -O2  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ctypes/cfield.c -o Modules/_ctypes/cfield.o\n--- Modules/socketmodule.o ---\n*** [Modules/socketmodule.o] Error code 1\n\nmake: stopped in /home/blue/cpython\n1 error\n\nmake: stopped in /home/blue/cpython""]","The failing code is here:

https://github.com/python/cpython/blob/655fc8a0fce3396fc1af3f7bc8f5c94ca8ec377d/Modules/socketmodule.c#L2258-L2267

According to [NetBSD can.4](https://man.netbsd.org/NetBSD-9.0/can.4) NetBSD only supports ``CAN_RAW``, which means there is no fall-through here. That explains the error.

IMHO it would be wrong to unconditionally disable ``_Py_FALLTHROUGH`` on NetBSD because of this.  Switching the ``CAN_RAW`` and ``CAN_BCM`` should also fix the issue and result in equivalent code.",[],['python'],github,https://github.com/python/cpython/issues/130099,{'repo': 'python/cpython'}
"Add math.curt() function for cube root

# Feature or enhancement

### Proposal:

```python
import math
print(math.curt(27))  # Output: 3.0
print(math.curt(64))  # Output: 4.0
```
Python’s math module has math.sqrt() for square root, but no direct math.curt() for cube root. Adding math.curt(x) would make cube root calculations easier and more intuitive. Currently, users must use x ** (1/3), which can lead to precision issues. So, it is requested to add this feature in the upcoming release of Python.

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_",['import math\nprint(math.curt(27))  # Output: 3.0\nprint(math.curt(64))  # Output: 4.0'],"This is already available as `math.cbrt()` starting in Python 3.11: 

```pycon
Python 3.13.2 (v3.13.2:4f8bb3947cf, Feb  4 2025, 11:51:10) [Clang 15.0.0 (clang-1500.3.9.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import math
>>> math.cbrt(27)
3.0
>>> math.cbrt(64)
4.0
```

* https://docs.python.org/3/library/math.html#math.cbrt
* https://github.com/python/cpython/issues/88523
","['Python 3.13.2 (v3.13.2:4f8bb3947cf, Feb  4 2025, 11:51:10) [Clang 15.0.0 (clang-1500.3.9.4)] on darwin\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import math\n>>> math.cbrt(27)\n3.0\n>>> math.cbrt(64)\n4.0']",['python'],github,https://github.com/python/cpython/issues/130726,{'repo': 'python/cpython'}
"[Windows] New REPL doesn't allow to input non-ASCII Unicode characters

# Bug report

### Bug description:

I got following error when I tried to type Cyrillic characters (tried ч in this example) in the new repl:
```pytb
.\python.bat
Running Release|x64 interpreter...
Python 3.14.0a5+ (heads/main-dirty:d0eb01c9de9, Mar  3 2025, 23:39:38) [MSC v.1942 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> x
Traceback (most recent call last):
  File ""<python-input-0>"", line 1, in <module>
    x
NameError: name 'x' is not defined
>>> Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\__main__.py"", line 6, in <module>
    __pyrepl_interactive_console()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\main.py"", line 59, in interactive_console
    run_multiline_interactive_console(console)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\simple_interact.py"", line 143, in run_multiline_interactive_console
    statement = multiline_input(more_lines, ps1, ps2)
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\readline.py"", line 389, in multiline_input
    return reader.readline()
           ~~~~~~~~~~~~~~~^^
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\reader.py"", line 802, in readline
    self.handle1()
    ~~~~~~~~~~~~^^
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\reader.py"", line 758, in handle1
    event = self.console.get_event(block=False)
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\windows_console.py"", line 472, in get_event
    self.event_queue.push(rec.Event.KeyEvent.uChar.UnicodeChar)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Sources\_pythonish\cpython\Lib\_pyrepl\base_eventqueue.py"", line 77, in push
    char = bytes(bytearray((ord_char,)))
                 ~~~~~~~~~^^^^^^^^^^^^^
ValueError: byte must be in range(0, 256)
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130805
<!-- /gh-linked-prs -->
","['.\\python.bat\nRunning Release|x64 interpreter...\nPython 3.14.0a5+ (heads/main-dirty:d0eb01c9de9, Mar  3 2025, 23:39:38) [MSC v.1942 64 bit (AMD64)] on win32\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> x\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 1, in <module>\n    x\nNameError: name \'x\' is not defined\n>>> Traceback (most recent call last):\n  File ""<frozen runpy>"", line 198, in _run_module_as_main\n  File ""<frozen runpy>"", line 88, in _run_code\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\__main__.py"", line 6, in <module>\n    __pyrepl_interactive_console()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\main.py"", line 59, in interactive_console\n    run_multiline_interactive_console(console)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\simple_interact.py"", line 143, in run_multiline_interactive_console\n    statement = multiline_input(more_lines, ps1, ps2)\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\readline.py"", line 389, in multiline_input\n    return reader.readline()\n           ~~~~~~~~~~~~~~~^^\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\reader.py"", line 802, in readline\n    self.handle1()\n    ~~~~~~~~~~~~^^\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\reader.py"", line 758, in handle1\n    event = self.console.get_event(block=False)\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\windows_console.py"", line 472, in get_event\n    self.event_queue.push(rec.Event.KeyEvent.uChar.UnicodeChar)\n    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""D:\\Sources\\_pythonish\\cpython\\Lib\\_pyrepl\\base_eventqueue.py"", line 77, in push\n    char = bytes(bytearray((ord_char,)))\n                 ~~~~~~~~~^^^^^^^^^^^^^\nValueError: byte must be in range(0, 256)']",@StanFromIreland it seems a windows related.,[],['python'],github,https://github.com/python/cpython/issues/130804,{'repo': 'python/cpython'}
"Perf doesn't show the Python functions when using the -O0 compilation flag without frame pointers

# Bug report

### Bug description:

When compiling without frame pointers and the -O0 optimization flag, Perf cannot see the Python functions.

This is not the case when using -O3, -O2, -O1, -Og or when enabling frame pointers.

Tested on both x86_64 and aarch64.

Perf 6.13.4, GDB 16.2, GCC 14.2.1 on x86_64/aarch64, Fedora 41.

To reproduce:

`./configure --enable-shared --without-static-libpython   && CFLAGS=""-O0"" make`

`LD_LIBRARY_PATH=$PWD perf record -F 9999 -g -k 1 --call-graph dwarf -o perf.data ./python -Xperf_jit script_from_python_perf_docs.py`

`perf inject -i perf.data --jit --output perf.jit.data`

`perf report -g -i perf.jit.data`

### CPython versions tested on:

CPython main branch, 3.14, 3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-131098
<!-- /gh-linked-prs -->
",[],"I suppose that script_from_python_perf_docs.py is the following script from https://docs.python.org/dev/howto/perf_profiling.html:

```py
def foo(n):
    result = 0
    for _ in range(n):
        result += 1
    return result

def bar(n):
    foo(n)

def baz(n):
    bar(n)

if __name__ == ""__main__"":
    baz(1000000)
```","['def foo(n):\n    result = 0\n    for _ in range(n):\n        result += 1\n    return result\n\ndef bar(n):\n    foo(n)\n\ndef baz(n):\n    bar(n)\n\nif __name__ == ""__main__"":\n    baz(1000000)']",['python'],github,https://github.com/python/cpython/issues/130861,{'repo': 'python/cpython'}
"Disable recursive tracing of calls with sys.settrace

Similar to https://github.com/python/cpython/issues/56201 and https://github.com/python/cpython/issues/56201#issuecomment-1431286444, the problem is that returning None in a tracer function disables tracing of the lines of a given frame, but the function calls are still recursively traced, and there doesn't seem to be a way of avoiding this.  

My current use case is to trace some functions defined in my codebase, while avoiding recursively tracing functions defined outside. This is quite a problem for me, because the vast majority of function calls are for functions outside my codebase, so there is a very big and unnecessary overhead.",[],"This is the documented feature of `sys.settrace` and it's impossible to change that. We would break a lot of code out there. It's a guarantee that very function call will trigger `sys.settrace`, regardless of whether they are recursive. If you want something with better granularity, try `sys.monitoring`.",[],['python'],github,https://github.com/python/cpython/issues/131089,{'repo': 'python/cpython'}
"When Python is started on AIX in the IBM-943 (Japanese shift_jis) locale, it aborts.

# Crash report

### What happened?

Python aborts when it is started in the IBM-943 (Japanese shift_jis) locale.

I hope python will support IBM-943.
Even if that is not achieved, is it possible to have python change its behavior to fall back to LANG=C instead of aborting when it encounters a character locale that python does not recognize? (like perl)

```python
[root:/]# uname -a 
AIX testhost 2 7 00FA9C234B00
[root:/]# oslevel -s
7200-05-06-2320
[root:/]# echo $LANG
Ja_JP
[root:/]# locale
LANG=Ja_JP
LC_COLLATE=""Ja_JP""
LC_CTYPE=""Ja_JP""
LC_MONETARY=""Ja_JP""
LC_NUMERIC=""Ja_JP""
LC_TIME=""Ja_JP""
LC_MESSAGES=""Ja_JP""
LC_ALL=
[root:/]# which python3
/usr/bin/python3
[root:/]# /usr/bin/python3 -VV 
Python 3.9.6 (default, Sep 30 2021, 15:30:58) 
[GCC 8.3.0]
[root:/]# /usr/bin/python3 
Python path configuration:
  PYTHONHOME = (not set)
  PYTHONPATH = (not set)
  program name = '/usr/bin/python3'
  isolated = 0
  environment = 1
  user site = 1
  import site = 1
  sys._base_executable = '/usr/bin/python3'
  sys.base_prefix = '/opt/freeware'
  sys.base_exec_prefix = '/opt/freeware'
  sys.platlibdir = 'lib64'
  sys.executable = '/usr/bin/python3'
  sys.prefix = '/opt/freeware'
  sys.exec_prefix = '/opt/freeware'
  sys.path = [
    '/opt/freeware/lib64/python39.zip',
    '/opt/freeware/lib64/python3.9',
    '/opt/freeware/lib64/python3.9/lib-dynload',
  ]
Fatal Python error: init_fs_encoding: failed to get the Python codec of the filesystem encoding
Python runtime state: core initialized
LookupError: unknown encoding: IBM-943

Current thread 0x0000000000000001 (most recent call first):
<no Python frame>
[root:/]# 
[root:/]# /usr/bin/python3 -vvv 
import _frozen_importlib # frozen
import _imp # builtin
import '_thread' # <class '_frozen_importlib.BuiltinImporter'>
import '_warnings' # <class '_frozen_importlib.BuiltinImporter'>
import '_weakref' # <class '_frozen_importlib.BuiltinImporter'>
import '_io' # <class '_frozen_importlib.BuiltinImporter'>
import 'marshal' # <class '_frozen_importlib.BuiltinImporter'>
import 'posix' # <class '_frozen_importlib.BuiltinImporter'>
import '_frozen_importlib_external' # <class '_frozen_importlib.FrozenImporter'>
# installing zipimport hook
import 'time' # <class '_frozen_importlib.BuiltinImporter'>
import 'zipimport' # <class '_frozen_importlib.FrozenImporter'>
# installed zipimport hook
# /opt/freeware/lib64/python3.9/encodings/__pycache__/__init__.cpython-39.pyc matches /opt/freeware/lib64/python3.9/encodings/__init__.py
# code object from '/opt/freeware/lib64/python3.9/encodings/__pycache__/__init__.cpython-39.pyc'
# trying /opt/freeware/lib64/python3.9/codecs.cpython-39.so
# trying /opt/freeware/lib64/python3.9/codecs.abi3.so
# trying /opt/freeware/lib64/python3.9/codecs.so
# trying /opt/freeware/lib64/python3.9/codecs.py
# /opt/freeware/lib64/python3.9/__pycache__/codecs.cpython-39.pyc matches /opt/freeware/lib64/python3.9/codecs.py
# code object from '/opt/freeware/lib64/python3.9/__pycache__/codecs.cpython-39.pyc'
import '_codecs' # <class '_frozen_importlib.BuiltinImporter'>
import 'codecs' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000aff40>
# trying /opt/freeware/lib64/python3.9/encodings/aliases.cpython-39.so
# trying /opt/freeware/lib64/python3.9/encodings/aliases.abi3.so
# trying /opt/freeware/lib64/python3.9/encodings/aliases.so
# trying /opt/freeware/lib64/python3.9/encodings/aliases.py
# /opt/freeware/lib64/python3.9/encodings/__pycache__/aliases.cpython-39.pyc matches /opt/freeware/lib64/python3.9/encodings/aliases.py
# code object from '/opt/freeware/lib64/python3.9/encodings/__pycache__/aliases.cpython-39.pyc'
import 'encodings.aliases' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000d3610>
import 'encodings' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000afe50>
# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.cpython-39.so
# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.abi3.so
# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.so
# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.py
# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.pyc
Python path configuration:
  PYTHONHOME = (not set)
  PYTHONPATH = (not set)
  program name = '/usr/bin/python3'
  isolated = 0
  environment = 1
  user site = 1
  import site = 1
  sys._base_executable = '/usr/bin/python3'
  sys.base_prefix = '/opt/freeware'
  sys.base_exec_prefix = '/opt/freeware'
  sys.platlibdir = 'lib64'
  sys.executable = '/usr/bin/python3'
  sys.prefix = '/opt/freeware'
  sys.exec_prefix = '/opt/freeware'
  sys.path = [
    '/opt/freeware/lib64/python39.zip',
    '/opt/freeware/lib64/python3.9',
    '/opt/freeware/lib64/python3.9/lib-dynload',
  ]
Fatal Python error: init_fs_encoding: failed to get the Python codec of the filesystem encoding
Python runtime state: core initialized
LookupError: unknown encoding: IBM-943

Current thread 0x0000000000000001 (most recent call first):
<no Python frame>
[root:/]# 
[root:/]# 
```


### CPython versions tested on:

3.9

### Operating systems tested on:

Other

### Output from running 'python -VV' on the command line:

Python 3.9.6 (default, Sep 30 2021, 15:30:58)  [GCC 8.3.0]","['[root:/]# uname -a \nAIX testhost 2 7 00FA9C234B00\n[root:/]# oslevel -s\n7200-05-06-2320\n[root:/]# echo $LANG\nJa_JP\n[root:/]# locale\nLANG=Ja_JP\nLC_COLLATE=""Ja_JP""\nLC_CTYPE=""Ja_JP""\nLC_MONETARY=""Ja_JP""\nLC_NUMERIC=""Ja_JP""\nLC_TIME=""Ja_JP""\nLC_MESSAGES=""Ja_JP""\nLC_ALL=\n[root:/]# which python3\n/usr/bin/python3\n[root:/]# /usr/bin/python3 -VV \nPython 3.9.6 (default, Sep 30 2021, 15:30:58) \n[GCC 8.3.0]\n[root:/]# /usr/bin/python3 \nPython path configuration:\n  PYTHONHOME = (not set)\n  PYTHONPATH = (not set)\n  program name = \'/usr/bin/python3\'\n  isolated = 0\n  environment = 1\n  user site = 1\n  import site = 1\n  sys._base_executable = \'/usr/bin/python3\'\n  sys.base_prefix = \'/opt/freeware\'\n  sys.base_exec_prefix = \'/opt/freeware\'\n  sys.platlibdir = \'lib64\'\n  sys.executable = \'/usr/bin/python3\'\n  sys.prefix = \'/opt/freeware\'\n  sys.exec_prefix = \'/opt/freeware\'\n  sys.path = [\n    \'/opt/freeware/lib64/python39.zip\',\n    \'/opt/freeware/lib64/python3.9\',\n    \'/opt/freeware/lib64/python3.9/lib-dynload\',\n  ]\nFatal Python error: init_fs_encoding: failed to get the Python codec of the filesystem encoding\nPython runtime state: core initialized\nLookupError: unknown encoding: IBM-943\n\nCurrent thread 0x0000000000000001 (most recent call first):\n<no Python frame>\n[root:/]# \n[root:/]# /usr/bin/python3 -vvv \nimport _frozen_importlib # frozen\nimport _imp # builtin\nimport \'_thread\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'_warnings\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'_weakref\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'_io\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'marshal\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'posix\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'_frozen_importlib_external\' # <class \'_frozen_importlib.FrozenImporter\'>\n# installing zipimport hook\nimport \'time\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'zipimport\' # <class \'_frozen_importlib.FrozenImporter\'>\n# installed zipimport hook\n# /opt/freeware/lib64/python3.9/encodings/__pycache__/__init__.cpython-39.pyc matches /opt/freeware/lib64/python3.9/encodings/__init__.py\n# code object from \'/opt/freeware/lib64/python3.9/encodings/__pycache__/__init__.cpython-39.pyc\'\n# trying /opt/freeware/lib64/python3.9/codecs.cpython-39.so\n# trying /opt/freeware/lib64/python3.9/codecs.abi3.so\n# trying /opt/freeware/lib64/python3.9/codecs.so\n# trying /opt/freeware/lib64/python3.9/codecs.py\n# /opt/freeware/lib64/python3.9/__pycache__/codecs.cpython-39.pyc matches /opt/freeware/lib64/python3.9/codecs.py\n# code object from \'/opt/freeware/lib64/python3.9/__pycache__/codecs.cpython-39.pyc\'\nimport \'_codecs\' # <class \'_frozen_importlib.BuiltinImporter\'>\nimport \'codecs\' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000aff40>\n# trying /opt/freeware/lib64/python3.9/encodings/aliases.cpython-39.so\n# trying /opt/freeware/lib64/python3.9/encodings/aliases.abi3.so\n# trying /opt/freeware/lib64/python3.9/encodings/aliases.so\n# trying /opt/freeware/lib64/python3.9/encodings/aliases.py\n# /opt/freeware/lib64/python3.9/encodings/__pycache__/aliases.cpython-39.pyc matches /opt/freeware/lib64/python3.9/encodings/aliases.py\n# code object from \'/opt/freeware/lib64/python3.9/encodings/__pycache__/aliases.cpython-39.pyc\'\nimport \'encodings.aliases\' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000d3610>\nimport \'encodings\' # <_frozen_importlib_external.SourceFileLoader object at 0xa000000000afe50>\n# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.cpython-39.so\n# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.abi3.so\n# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.so\n# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.py\n# trying /opt/freeware/lib64/python3.9/encodings/ibm_943.pyc\nPython path configuration:\n  PYTHONHOME = (not set)\n  PYTHONPATH = (not set)\n  program name = \'/usr/bin/python3\'\n  isolated = 0\n  environment = 1\n  user site = 1\n  import site = 1\n  sys._base_executable = \'/usr/bin/python3\'\n  sys.base_prefix = \'/opt/freeware\'\n  sys.base_exec_prefix = \'/opt/freeware\'\n  sys.platlibdir = \'lib64\'\n  sys.executable = \'/usr/bin/python3\'\n  sys.prefix = \'/opt/freeware\'\n  sys.exec_prefix = \'/opt/freeware\'\n  sys.path = [\n    \'/opt/freeware/lib64/python39.zip\',\n    \'/opt/freeware/lib64/python3.9\',\n    \'/opt/freeware/lib64/python3.9/lib-dynload\',\n  ]\nFatal Python error: init_fs_encoding: failed to get the Python codec of the filesystem encoding\nPython runtime state: core initialized\nLookupError: unknown encoding: IBM-943\n\nCurrent thread 0x0000000000000001 (most recent call first):\n<no Python frame>\n[root:/]# \n[root:/]#']",This is duplicate of #91992,[],['python'],github,https://github.com/python/cpython/issues/130228,{'repo': 'python/cpython'}
"Remove unnecessary usages of `.. index::` directives in `Doc/library/uuid.rst`

See https://github.com/python/cpython/pull/120650#discussion_r1966531036.

We use `.. index:: single: uuidN` and other `.. index::` directives in the UUID documentation. However, the anchor is *after* the actual function, meaning that https://docs.python.org/3/library/uuid.html#index-6 jumps to uuid3 instead of uuid1 for instance (compare with https://docs.python.org/3/library/uuid.html#uuid.uuid1).

OTOH, we could simply remove the `.. index` usages but I don't remember whether they are intersphinxed or not.

cc @AA-Turner @hugovk 

<!-- gh-linked-prs -->
### Linked PRs
* gh-130468
* gh-130526
* gh-130546
* gh-130548
<!-- /gh-linked-prs -->
",[],"Also, the plain rendering of those indices is not really good. I think it's better to just keep the entry with `(in module uuid)` (this is the entry associated with `.. function:: uuidX()`).

![Image](https://github.com/user-attachments/assets/1ddf45cf-5735-47d3-8470-ccbf818b5c0d)",[],['python'],github,https://github.com/python/cpython/issues/130461,{'repo': 'python/cpython'}
"`enum.Flag.__contains__` changed behavior since python 3.12

# Bug report

### Bug description:

I noticed some strange behavior with `enum.Flag` an the `__contains__` method in Python 3.12/3.13, as shown in the following examples.

**Problem 1: Behavior changes at runtime**
In the following code snippet the first print statement returns `False`, which is expected, since `3` is not a member of `Weekday`.  However, the second print statement returns `True`, which is unexpected, since `3` is still not a member of `Weekday`.

```python
import enum

class Weekday(enum.Flag):
    MONDAY = 1
    TUESDAY = 2
    WEDNESDAY = 4
    THURSDAY = 8
    FRIDAY = 16
    SATURDAY = 32
    SUNDAY = 64

print(f""{3 in Weekday}"") # => False (expected)
_ = Weekday.MONDAY | Weekday.TUESDAY
print(f""{3 in Weekday}"") # => True (not expected)
```



**Problem 2: Behavior is not comparable to Python 3.11**
Since Python 3.12 the behavior of `Enum.__contains__` has changed, so that it is possible to compare not only with an enum-member, but also with non-enum-members (see [here](https://github.com/python/cpython/pull/93298) or [here](https://docs.python.org/3/library/enum.html#enum.EnumType.__contains__)). So with Python 3.11 the code above will raise an `TypeError: unsupported operand type(s) for 'in': 'int' and 'EnumType'`. There you have to change the code to the following. But this in turn always produces unexpected behavior in Python 3.12/3.13.

```python
import enum

class Weekday(enum.Flag):
    MONDAY = 1
    TUESDAY = 2
    WEDNESDAY = 4
    THURSDAY = 8
    FRIDAY = 16
    SATURDAY = 32
    SUNDAY = 64

print(f""{Weekday(3) in Weekday}"") # => Python 3.11: False (expected)    Python 3.12/3.13: True (not expected)
_ = Weekday.MONDAY | Weekday.TUESDAY
print(f""{Weekday(3) in Weekday}"") # => Python 3.11: False (expected)    Python 3.12/3.13: True (not expected)
```

**Conclusion**
I would have expected that in all cases the result is `False`, but since Python 3.12 it gets very strange...

### CPython versions tested on:

3.12, 3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-131053
* gh-131167
<!-- /gh-linked-prs -->
","['import enum\n\nclass Weekday(enum.Flag):\n    MONDAY = 1\n    TUESDAY = 2\n    WEDNESDAY = 4\n    THURSDAY = 8\n    FRIDAY = 16\n    SATURDAY = 32\n    SUNDAY = 64\n\nprint(f""{3 in Weekday}"") # => False (expected)\n_ = Weekday.MONDAY | Weekday.TUESDAY\nprint(f""{3 in Weekday}"") # => True (not expected)', 'import enum\n\nclass Weekday(enum.Flag):\n    MONDAY = 1\n    TUESDAY = 2\n    WEDNESDAY = 4\n    THURSDAY = 8\n    FRIDAY = 16\n    SATURDAY = 32\n    SUNDAY = 64\n\nprint(f""{Weekday(3) in Weekday}"") # => Python 3.11: False (expected)    Python 3.12/3.13: True (not expected)\n_ = Weekday.MONDAY | Weekday.TUESDAY\nprint(f""{Weekday(3) in Weekday}"") # => Python 3.11: False (expected)    Python 3.12/3.13: True (not expected)']","1 | 2 becomes 3 and I think your surprise comes from the fact that a new member is automatically created. I think you can avoid this starting from 3.12 by specifying the boundary (namely a new member is not automatically created). I haven't checked but this should also have been documented somehow maybe indirectly. 

I believe that the reason is because the result of the OR of two enum flag members should remain an enum flag member by default (3.12+) and thus we create that additional member on the fly.

With a different boundary the result would be a pure int and not an enum member. To check if this diagnosis is correct, print the type of the `_` in your code.

I can check on Wednesday as I'm unavailable until then (and I'm only answering from memory)",[],['python'],github,https://github.com/python/cpython/issues/131045,{'repo': 'python/cpython'}
"csv.Sniffer().has_header() Returns False for a CSV with a Header

# Bug report

### Bug description:

I encountered an issue while using csv.Sniffer().has_header() in Python's built-in csv module. Despite providing a CSV file with a clear header, the function returns False, whereas the expected result is True.
```python
import csv

with open('1.csv', mode='r', encoding='utf-8') as file:
    sample = file.read(1024)
    has_header = csv.Sniffer().has_header(sample)  
    print(f""Has header: {has_header}"")
```
1.csv
```
filename,path
c.txt,/tmp/c.txt
python.txt,/tmp/python.txt
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_","['import csv\n\nwith open(\'1.csv\', mode=\'r\', encoding=\'utf-8\') as file:\n    sample = file.read(1024)\n    has_header = csv.Sniffer().has_header(sample)  \n    print(f""Has header: {has_header}"")', 'filename,path\nc.txt,/tmp/c.txt\npython.txt,/tmp/python.txt']","This is what's written in the `has_header` method:
https://github.com/python/cpython/blob/2bef8ea8ea045d20394f0daec7a5c5b1046a4e22/Lib/csv.py#L452-L460

In the case of string values, it wants the strings in each column to have the same lengths which is not the case with the CSV file you gave (not saying this cannot be improved, just wanted to explain why the heuristic fails in this case)

",[],['python'],github,https://github.com/python/cpython/issues/131043,{'repo': 'python/cpython'}
"strxfrm fails on macOS 15 with OSError: [Errno 22] Invalid argument

# Bug report

### Bug description:

It appears that macOS 15 broke `locale.strxfrm` for letters outside the latin-1 set:

```python
import locale
locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
locale.strxfrm('Français') # works
locale.strxfrm('zkouška') # crashes with OSError
locale.strxfrm('中文') # crashes with OSError
```

This works on Linux and macOS 14 and crashes on macOS 15, tested with Python 3.9–3.14: https://github.com/nijel/python-strxfrm/actions/runs/13541306384/job/37842825809

There are several projects which run into this already:

* https://github.com/WeblateOrg/weblate/issues/14019
* https://github.com/nicotine-plus/nicotine-plus/issues/3063
* https://github.com/zim-desktop-wiki/zim-desktop-wiki/issues/2665

In most cases, this is being addressed by completely removing locale-aware sorting.

### CPython versions tested on:

3.14

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130619
<!-- /gh-linked-prs -->
","[""import locale\nlocale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\nlocale.strxfrm('Français') # works\nlocale.strxfrm('zkouška') # crashes with OSError\nlocale.strxfrm('中文') # crashes with OSError""]","Looking more into that I've found https://swi-prolog.discourse.group/t/compiling-swi-prolog-from-git-source-on-next-macos-15-beta/7590/1. They figured out that `wcsxfrm` does not actually return desired string size in case of the failure, so they ended up allocating double space in that case, see https://github.com/SWI-Prolog/swipl-devel/commit/f0bbfb082985382d777c3cfb84fc85e7e0ae345f.

The following code would have to be changed:

https://github.com/python/cpython/blob/263d56e1e23c711e3abafcae6707cbeb66d15e93/Modules/_localemodule.c#L426",[],['python'],github,https://github.com/python/cpython/issues/130567,{'repo': 'python/cpython'}
"Matplotlib savefig and close break multiprocessing and numpy thread allocation

# Bug report

### Bug description:

I recently updated my python environment and discovered a weird bug that occurs between matplotlib, numpy, and multiprocessing. 

Code to demonstrate the bug below. In the code I am running a multiprocessing pool, with a function that multiplies small matrices a large number of times. If run on its own this fully utilizes the expected number of threads/processes (num_threads). However if a plot is generated and saved before the multiprocessing loop begins, then all of the processing seems to be forced onto only 2 threads. 

Time is used only to demonstrate that the code runs much slower when the bug is occurring, on my machine (48 cores/96 threads) it runs about 30 times slower when the bug occurs. The try/except is used just so the pool is closed properly if you keyboard interrupt.


```python
import numpy as np
import multiprocessing as mp
from matplotlib import pyplot as plt
import time

def test_function(var):
    test_mat=np.zeros((3,3))
    for i in range(10**6):
        np.matmul(test_mat,test_mat)
    return()
    
def main():
    print('starting')
    
    test_array=np.arange(10)
    fig=plt.figure()
    plt.plot(test_array,test_array,'.')
    plt.savefig('test_fig.png')
    #plt.close('all')
    #plt.close(fig)
   # plt.close()

    num_threads=mp.cpu_count()//2
    pool=mp.Pool(num_threads)
    
 
    try:
        completed=0
        tic=time.time()
        for item in pool.imap(test_function,range(num_threads*2)):
            completed+=1
            print('%i completed'%(completed))
        
        toc=time.time()-tic
        print('Elapsed time %f seconds'%toc)
        pool.close()
        pool.join()
    except:
        pool.terminate()
        pool.join()
    
if __name__=='__main__':
    main()
```


This bug also occurs when using plt.close, although I tested a few different versions of matplotlib, and the behavior changes. With python 12 and matplotlib 3.10.0 the bug occurs with plt.close(fig) and plt.close('all'). With matplotlib 3.9.2 and 3.8.0 the bug does not occur with plt.close('all') but still occurs with plt.close(fig). The bug does not occur with a plain plt.close() in my testing.

This bug occurs in an important piece of code I am using at work so I am trying to find a working python environment where it does not occur. It seems like the bug does not occur in python 10, even running the same matplotlib versions listed above, so it seems to be a python bug, not a matplotlib bug. (I was previously working in Python 8, but had to update). Bug appears to be independent of matplotlib backend. 

OS RHEL9. 

 



### CPython versions tested on:

3.12

### Operating systems tested on:

Linux","[""import numpy as np\nimport multiprocessing as mp\nfrom matplotlib import pyplot as plt\nimport time\n\ndef test_function(var):\n    test_mat=np.zeros((3,3))\n    for i in range(10**6):\n        np.matmul(test_mat,test_mat)\n    return()\n    \ndef main():\n    print('starting')\n    \n    test_array=np.arange(10)\n    fig=plt.figure()\n    plt.plot(test_array,test_array,'.')\n    plt.savefig('test_fig.png')\n    #plt.close('all')\n    #plt.close(fig)\n   # plt.close()\n\n    num_threads=mp.cpu_count()//2\n    pool=mp.Pool(num_threads)\n    \n \n    try:\n        completed=0\n        tic=time.time()\n        for item in pool.imap(test_function,range(num_threads*2)):\n            completed+=1\n            print('%i completed'%(completed))\n        \n        toc=time.time()-tic\n        print('Elapsed time %f seconds'%toc)\n        pool.close()\n        pool.join()\n    except:\n        pool.terminate()\n        pool.join()\n    \nif __name__=='__main__':\n    main()""]","Not able to reproduce this on Python 3.12 + matplotlib == 3.10.0. The elapsed time is stable. The fact that changing matplotlib version affects the result might suggest this is related to matplotlib. To submit an issue with CPython, you should be able to give an example that is independent of 3rd party libraries.",[],['python'],github,https://github.com/python/cpython/issues/131066,{'repo': 'python/cpython'}
"gzip raising exception when closing with buffer backed by BytesIO

# Bug report

### Bug description:

Hello,

the following snippet raises an exception in Python 3.13.2 while it's fine with Python 3.12.

```python
import io
import gzip

def foo():
    buffer = gzip.GzipFile(fileobj=io.BytesIO(), mode=""w"")

foo()
```

Running this with python3.12 is silent, with Python 3.13.2 instead:

```
Exception ignored in: <gzip on 0x7fa4fd99c550>
Traceback (most recent call last):
  File ""/usr/lib/python3.13/gzip.py"", line 359, in close
    fileobj.write(self.compress.flush())

```


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130055
* gh-130669
* gh-130670
<!-- /gh-linked-prs -->
","['import io\nimport gzip\n\ndef foo():\n    buffer = gzip.GzipFile(fileobj=io.BytesIO(), mode=""w"")\n\nfoo()', 'Exception ignored in: <gzip on 0x7fa4fd99c550>\nTraceback (most recent call last):\n  File ""/usr/lib/python3.13/gzip.py"", line 359, in close\n    fileobj.write(self.compress.flush())']",Bisected this issue to https://github.com/python/cpython/pull/105104,[],['python'],github,https://github.com/python/cpython/issues/129726,{'repo': 'python/cpython'}
"`glob.translate` does not correctly handle `]` as first character in character class

# Bug report

### Bug description:

```python
> import glob
> glob.translate('[][!]')
(?s:[][!])\Z
```

This specific example is explicitly mentioned in `man glob`:

> The string enclosed by the
       brackets cannot be empty; therefore ']' can be allowed between the
       brackets, provided that it is the first character.  (Thus, ""[][!]""
       matches the three characters '[', ']', and '!'.)

Therefore, the expected regex would be `(?s:[\[\]!])\Z`, while the actual one simplifies to just `(?s:!)\Z`, only matching literal `'!'`.

Related to #130942 , where character classes do not correctly handle path separator. 

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","[""> import glob\n> glob.translate('[][!]')\n(?s:[][!])\\Z""]","Mmh I think the regex is actually correct. If you do re.match(p, s) with s being [, ] or !, the match is correct or am I missing something?",[],['python'],github,https://github.com/python/cpython/issues/130985,{'repo': 'python/cpython'}
"`KeyboardInterrupt` not handled while evaluating a tight `while` loop condition on Python 3.13

# Bug report

### Bug description:

Consider the following infinite loop:

```python
# test.py

class A:
    def __init__(self):
        self.shutdown_requested = False

    def start(self):
        pass

    def stop(self):
        self.shutdown_requested = True


def loop_1(a: A):
    try:
        while not a.shutdown_requested:
            pass

    except KeyboardInterrupt:
        print(""in except block"")

    finally:
        print(""in finally block"")
        a.stop()

def loop_2(a: A):
    try:
        while True:
            if a.shutdown_requested:
                break
    except KeyboardInterrupt:
        print(""in except block"")

    finally:
        print(""in finally block"")
        a.stop()


if __name__ == ""__main__"":
    a = A()
    a.start()
    loop_1(a)
    # loop_2(a)
```


```
^CTraceback (most recent call last):
  File ""/home/harshil/test.py"", line 40, in <module>
    loop_1(a)
    ~~~~~~^^^
  File ""/home/harshil/test.py"", line 14, in loop_1
    while not a.shutdown_requested:
              ^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
```

If you run this program on Python 3.13 (3.13.1, and 3.13.2), pressing Ctrl+C does not execute the except and finally blocks in the case of `loop_1()`, but it works for `loop_2()`.

If you run the same program on 3.14a5, or below 3.13, the issue does not happen, and the print statements are visible too.





### CPython versions tested on:

3.12, 3.13, 3.13t, 3.14, 3.10

### Operating systems tested on:

Linux","['# test.py\n\nclass A:\n    def __init__(self):\n        self.shutdown_requested = False\n\n    def start(self):\n        pass\n\n    def stop(self):\n        self.shutdown_requested = True\n\n\ndef loop_1(a: A):\n    try:\n        while not a.shutdown_requested:\n            pass\n\n    except KeyboardInterrupt:\n        print(""in except block"")\n\n    finally:\n        print(""in finally block"")\n        a.stop()\n\ndef loop_2(a: A):\n    try:\n        while True:\n            if a.shutdown_requested:\n                break\n    except KeyboardInterrupt:\n        print(""in except block"")\n\n    finally:\n        print(""in finally block"")\n        a.stop()\n\n\nif __name__ == ""__main__"":\n    a = A()\n    a.start()\n    loop_1(a)\n    # loop_2(a)', '^CTraceback (most recent call last):\n  File ""/home/harshil/test.py"", line 40, in <module>\n    loop_1(a)\n    ~~~~~~^^^\n  File ""/home/harshil/test.py"", line 14, in loop_1\n    while not a.shutdown_requested:\n              ^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt']","Interestingly, if you add `time.sleep(0.1)` inside the `while` loop in `loop_1`, this strange phenomenon will not occur. (My environment is Windows 11, Python 3.13.1)",[],['python'],github,https://github.com/python/cpython/issues/130279,{'repo': 'python/cpython'}
"Unittest.mock.patch - record result of wrapped function call

# Feature or enhancement

### Proposal:

I would like to access the return value of a function call wrapped with `unittest.mock.patch`, that I don't call myself directly.

# Motivation
Let's say I have a framework that supports some ""before"" hooks to allow users to customize some data flowing through the framework.
One could write hook functions for such a framework and publish them.
When doing so, it would make integration tests easier if one could access the return value of a function wrapped with a `MagicMock`.

```python
# framework.py
def init(before_hook):
    ... # register the update hook that is later used before doing some action to allow customization of the action

# my_plugin.py
def my_before_hook(some_data: dict) -> dict:
    ... #do something with some_data eg adding a key
    some_data[""foo""] = ""bar""
    return some_data # return the altered data


# test_my_plugin.py
import my_plugin
import framework

def test_my_before_hook():
    with unittest.mock.patch(""my_plugin.my_before_hook"",  wraps=my_plugin.my_before_hook) as m:
        framework.init(before_hook=m)
        ... #do something that runs the framework
        assert m.called
        assert ... # assert m's return value has the key ""foo"" with the value ""bar""
```

Unfortunately, currently the second assert statement is not really possible - at least I couldn't find anything in the docs, debugger, and LLMs just hallucinated on this one 😅.

## Alternatives
There are two alternatives I have considered:
1. Digging into the framework and finding a mock target - while this would work, it can be quite tedious, especially when the framework is big
2. Wrapping the function in question manually - Definitely possible, but seems to introduce an extra step every time this is necessary and moves the assertion to a an odd place:

```py
# test_my_plugin.py
import my_plugin
import framework

def foo(*args, **kwargs)
    result = my_plug.my_before_hook(*args, **kwargs)
    assert result[""foo""] == ""bar"" # this only works if the framework doesn't handle AssertionErrors
    return result


def test_my_before_hook():
    with unittest.mock.patch(""my_plugin.my_before_hook"",  wraps=foo) as m:
        framework.init(before_hook=m)
        ... #do something that runs the framework
        assert m.called
```


## Proposed Solution
Record the return value of a ""wraps"" call and make it available on the `call` tuple.

I know this could be somewhat problematic due to backwards compatibility, but I'm not entirely sure.

---

I dove a little bit into the source code and don't think it will be too big of a change both in terms of code and functionality - please correct me if I'm wrong.

I'd be happy to contribute if this is enhancement is desired 🙂 
  


### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_","['# framework.py\ndef init(before_hook):\n    ... # register the update hook that is later used before doing some action to allow customization of the action\n\n# my_plugin.py\ndef my_before_hook(some_data: dict) -> dict:\n    ... #do something with some_data eg adding a key\n    some_data[""foo""] = ""bar""\n    return some_data # return the altered data\n\n\n# test_my_plugin.py\nimport my_plugin\nimport framework\n\ndef test_my_before_hook():\n    with unittest.mock.patch(""my_plugin.my_before_hook"",  wraps=my_plugin.my_before_hook) as m:\n        framework.init(before_hook=m)\n        ... #do something that runs the framework\n        assert m.called\n        assert ... # assert m\'s return value has the key ""foo"" with the value ""bar""', '# test_my_plugin.py\nimport my_plugin\nimport framework\n\ndef foo(*args, **kwargs)\n    result = my_plug.my_before_hook(*args, **kwargs)\n    assert result[""foo""] == ""bar"" # this only works if the framework doesn\'t handle AssertionErrors\n    return result\n\n\ndef test_my_before_hook():\n    with unittest.mock.patch(""my_plugin.my_before_hook"",  wraps=foo) as m:\n        framework.init(before_hook=m)\n        ... #do something that runs the framework\n        assert m.called']","I am not sure `wraps` should record calls. Perhaps this might be achieved with a `side_effect` ? I also see you are patching `my_plugin.my_before_hook` and wrapping it again with `my_plugin.my_before_hook` which feels counter intuitive. 


```python
from unittest.mock import patch, MagicMock


def init():
    my_func()


def wrapper():
    some_data = {""foo"": ""bar""}
    return some_data


def my_func():
    some_data = {""foo"": ""my_func""}
    return some_data


with patch(""__main__.my_func"", side_effect=wrapper) as m:
    init()
    assert m.called
    assert my_func() == {""foo"": ""bar""}
    assert m() == {""foo"": ""bar""}
```","['from unittest.mock import patch, MagicMock\n\n\ndef init():\n    my_func()\n\n\ndef wrapper():\n    some_data = {""foo"": ""bar""}\n    return some_data\n\n\ndef my_func():\n    some_data = {""foo"": ""my_func""}\n    return some_data\n\n\nwith patch(""__main__.my_func"", side_effect=wrapper) as m:\n    init()\n    assert m.called\n    assert my_func() == {""foo"": ""bar""}\n    assert m() == {""foo"": ""bar""}']",['python'],github,https://github.com/python/cpython/issues/130368,{'repo': 'python/cpython'}
"We are running out of space for specialized opcodes

The opcode space is laid out as follows:

* Normal instructions
* Gap (>30 instructions)
* RESUME (opcode 149) 
* Specialized instructions
* Gap (3 instructions)
* Instrumented instruments

If we need to add four more specializations and/or instrumented instructions we will run out of space.
The fix is obvious: Renumber RESUME to something like 128. 

<!-- gh-linked-prs -->
### Linked PRs
* gh-130685
<!-- /gh-linked-prs -->
",[],"This may be a stupid question, but we would still run out of space in like.. 25 more instructions right (why actually RESUME=128 and not something else?)? what happens at this point?",[],['python'],github,https://github.com/python/cpython/issues/130574,{'repo': 'python/cpython'}
"i mapped the whole C standard library to python

might be a bit buggy right now, but here's a quick example:
```py
from pointers import fopen, fclose, fprintf # this is all type safe and cross platform as well

file = fopen('/dev/null', 'w')
fprintf(file, ""hello"")
fclose(file)
```

repo: https://github.com/ZeroIntensity/pointers.py","['from pointers import fopen, fclose, fprintf # this is all type safe and cross platform as well\n\nfile = fopen(\'/dev/null\', \'w\')\nfprintf(file, ""hello"")\nfclose(file)']",See comments on Reddit,[],['Python'],reddit,https://www.reddit.com/r/Python/comments/vd6yt2/i_mapped_the_whole_c_standard_library_to_python/,{'subreddit': 'Python'}
"glob.translate incorrectly matches path separator in character ranges

# Bug report

### Bug description:

## Description
The `glob.translate` function in Python 3.13 doesn't properly handle path separators when they're included in character ranges. According to the documentation, ""wildcards do not match path separators,"" but this isn't enforced for character ranges that include the path separator.

## Expected behavior
Character ranges in glob patterns should not match path separators, consistent with the behavior of single character wildcards (`?`) and the documented behavior of the module.

## Actual behavior
Character ranges that include the path separator (e.g., `[%-0]` which includes the `/` character) will match the path separator, contradicting the documented behavior.

## Code to reproduce

```python
import glob
import re

# Proper behavior with ? wildcard
r1 = re.compile(glob.translate('a?c', seps=['/']))
print(r1)  # (?s:a[^/]c)\Z
print(r1.match('abc'))  # match object
print(r1.match('a/c'))  # None, correctly doesn't match path separator

# Incorrect behavior with character range
r2 = re.compile(glob.translate('a[%-0]c', seps=['/']))
print(r2)  # (?s:a[%-0]c)\Z
print(r2.match('a0c'))  # match object
print(r2.match('a/c'))  # match object, incorrectly matches path separator

### CPython versions tested on:

3.13

### Operating systems tested on:

_No response_
```
---
Link to original find: https://stackoverflow.com/questions/79492274/glob-translate-incorrectly-matches-path-separator-when-using-ranges

<!-- gh-linked-prs -->
### Linked PRs
* gh-130989
<!-- /gh-linked-prs -->
","[""import glob\nimport re\n\n# Proper behavior with ? wildcard\nr1 = re.compile(glob.translate('a?c', seps=['/']))\nprint(r1)  # (?s:a[^/]c)\\Z\nprint(r1.match('abc'))  # match object\nprint(r1.match('a/c'))  # None, correctly doesn't match path separator\n\n# Incorrect behavior with character range\nr2 = re.compile(glob.translate('a[%-0]c', seps=['/']))\nprint(r2)  # (?s:a[%-0]c)\\Z\nprint(r2.match('a0c'))  # match object\nprint(r2.match('a/c'))  # match object, incorrectly matches path separator\n\n### CPython versions tested on:\n\n3.13\n\n### Operating systems tested on:\n\n_No response_""]","I will, I'm adding the unit test for it and will open one after I finish with that in a few minutes. ",[],['python'],github,https://github.com/python/cpython/issues/130942,{'repo': 'python/cpython'}
"Unexpected nested exception with b64decode

# Bug report

### Bug description:

The b64decode function of the base64 standard library module can behave in unexpected ways with invalid inputs.

Take this example:
```python
#!/usr/bin/python3
import base64
base64.b64decode('a\xd6==')
```

According to the docs, I would expect that invalid characters in the input cause a binascii.Error exception. However, this example gives me the following:
```pytb
Traceback (most recent call last):
  File ""/usr/lib/python3.12/base64.py"", line 37, in _bytes_from_decode_data
    return s.encode('ascii')
           ^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'ascii' codec can't encode character '\xd6' in position 1: ordinal not in range(128)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/tmp/./test"", line 3, in <module>
    base64.b64decode('a\xd6==')
  File ""/usr/lib/python3.12/base64.py"", line 83, in b64decode
    s = _bytes_from_decode_data(s)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.12/base64.py"", line 39, in _bytes_from_decode_data
    raise ValueError('string argument should contain only ASCII characters')
ValueError: string argument should contain only ASCII characters
```

So not only do I get an exception that I don't expect according to the docs, it appears there is a bug in the internal exception handling causing an exception (ValueError) during another exception (UnicodeEncodeError).

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","[""#!/usr/bin/python3\nimport base64\nbase64.b64decode('a\\xd6==')"", 'Traceback (most recent call last):\n  File ""/usr/lib/python3.12/base64.py"", line 37, in _bytes_from_decode_data\n    return s.encode(\'ascii\')\n           ^^^^^^^^^^^^^^^^^\nUnicodeEncodeError: \'ascii\' codec can\'t encode character \'\\xd6\' in position 1: ordinal not in range(128)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/tmp/./test"", line 3, in <module>\n    base64.b64decode(\'a\\xd6==\')\n  File ""/usr/lib/python3.12/base64.py"", line 83, in b64decode\n    s = _bytes_from_decode_data(s)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/lib/python3.12/base64.py"", line 39, in _bytes_from_decode_data\n    raise ValueError(\'string argument should contain only ASCII characters\')\nValueError: string argument should contain only ASCII characters']","I don't think the validate section is the issue (note this happens with validate=False).

If this is intended behavior, I'd add something to the last sentence, like this:

""May assert or raise a [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) if the length of altchars is not 2 *or the input is a string and contains non-ascii characters*.""

Shall I send a PR for that?",[],['python'],github,https://github.com/python/cpython/issues/129505,{'repo': 'python/cpython'}
"Some tests are skipped in `test_gettext`

# Bug report

### Bug description:

`PluralFormsInternalTestCase` does not inherit from `unittest.TestCase` so the test is not picked up:

https://github.com/python/cpython/blob/9837c2a21457e4eacabf606c44ec42d1962f11f1/Lib/test/test_gettext.py#L405-L407

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130178
* gh-130183
* gh-130184
<!-- /gh-linked-prs -->
",[],Thanks @tomasr8 for noticing and fixing this.,[],['python'],github,https://github.com/python/cpython/issues/130177,{'repo': 'python/cpython'}
"Update installers to use SQLite 3.49

### Proposal:

We'e been skipping some SQLite versions lately; currently we're shipping the macOS and Windows installers with SQLite 3.45.3 (released 300 days ago, 2024-04-15). SQLite 3.49.0 recently came out, so we should probably hold off upgrading for a couple of weeks to see if patch releases appear.

See also #129870.

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-131025
<!-- /gh-linked-prs -->
",[],@erlend-aasland I'll update the macOS installer builds.,[],['python'],github,https://github.com/python/cpython/issues/129917,{'repo': 'python/cpython'}
"segmentfault when pip installing setuptools

# Crash report

### What happened?

(test) ➜  build git:(development) gdb --args /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target '' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- 'setuptools>=40.8.0'
GNU gdb (GDB) Red Hat Enterprise Linux 8.2-20.el8
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-redhat-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...

warning: /workspace/git/ezennin/peda/peda.py: No such file or directory
Reading symbols from /workspace/git/ezennin/mbedtls/build/test/bin/python3...done.
(gdb) r
Starting program: /workspace/git/ezennin/mbedtls/build/test/bin/python3 /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip/__pip-runner__.py install --ignore-installed --no-user --prefix /tmp/pip-build-env-fmnjkpz1/overlay --no-warn-script-location --disable-pip-version-check --target '' -v --no-binary :none: --only-binary :none: -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple -- setuptools\>=40.8.0
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib64/libthread_db.so.1"".
Using pip 25.0.1 from /workspace/git/ezennin/mbedtls/build/test/lib/python3.12/site-packages/pip (python 3.12)
[Detaching after vfork from child process 728053]
[Detaching after vfork from child process 728078]
[Detaching after vfork from child process 728079]
Looking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
Collecting setuptools>=40.8.0
  Using cached https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/69/8a/b9dc7678803429e4a3bc9ba462fa3dd9066824d3c607490235c6a796be5a/setuptools-75.8.0-py3-none-any.whl (1.2 MB)
Installing collected packages: setuptools

Program received signal SIGSEGV, Segmentation fault.
0x00007fffe4c0e70f in _getcode (self=0x0, 
    name=0x1484b58 ""SNOWMAN}\"",\n"", ' ' <repeats 16 times>, ""extras_require={\""voting\"": [\""beaglevote\""]},\n"", ' ' <repeats 12 times>, "")\n"", ' ' <repeats 12 times>, ""@A\254"", namelen=7, 
    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275
1275        v = code_hash[i];
Missing separate debuginfos, use: yum debuginfo-install bzip2-libs-1.0.6-27.el8_10.x86_64 glibc-2.28-251.el8_10.5.x86_64 libuuid-2.32.1-46.el8.x86_64 openssl-libs-1.1.1k-14.el8_6.x86_64 xz-libs-5.2.4-4.el8_6.x86_64
(gdb) bt
#0  0x00007fffe4c0e70f in _getcode (self=0x0, 
    name=0x1484b58 ""SNOWMAN}\"",\n"", ' ' <repeats 16 times>, ""extras_require={\""voting\"": [\""beaglevote\""]},\n"", ' ' <repeats 12 times>, "")\n"", ' ' <repeats 12 times>, ""@A\254"", namelen=7, 
    code=0x7fffffffa48c, with_named_seq=0) at ./Modules/unicodedata.c:1275
#1  0x0000000000584e89 in _PyUnicode_DecodeUnicodeEscapeInternal (s=<optimized out>, size=<optimized out>, errors=errors@entry=0x0, consumed=consumed@entry=0x0, 
    first_invalid_escape=first_invalid_escape@entry=0x7fffffffa588) at Objects/unicodeobject.c:6239
#2  0x00000000005b9e6d in decode_unicode_with_escapes (parser=0x7fffe3add110, s=<optimized out>, len=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, t=0x7fffe389d970)
    at Parser/string_parser.c:146
#3  0x0000000000544f30 in _PyPegen_constant_from_string (p=p@entry=0x7fffe3add110, tok=0x7fffe389d970) at Parser/action_helpers.c:1331
#4  0x0000000000549faa in string_rule (p=0x7fffe3add110) at Parser/parser.c:16242
#5  _tmp_259_rule (p=0x7fffe3add110) at Parser/parser.c:40700
#6  _loop1_115_rule (p=0x7fffe3add110) at Parser/parser.c:32163
#7  strings_rule (p=0x7fffe3add110) at Parser/parser.c:16294
#8  0x0000000000549370 in atom_rule (p=0x7fffe3add110) at Parser/parser.c:14819
#9  0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327
#10 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#11 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#12 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#13 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#14 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#15 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#16 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#17 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#18 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
#19 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#20 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#21 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#22 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#23 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#24 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#25 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#26 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#27 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#28 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#29 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#30 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#31 0x000000000054b99e in _tmp_122_rule (p=0x7fffe3add110) at Parser/parser.c:32616
#32 genexp_rule (p=0x7fffe3add110) at Parser/parser.c:17168
#33 0x0000000000550ec6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14115
#34 0x0000000000550cd8 in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#35 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#36 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#37 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#38 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#39 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#40 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#41 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#42 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
--Type <RET> for more, q to quit, c to continue without paging--
#43 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#44 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#45 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#46 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#47 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#48 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#49 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#50 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#51 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#52 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#53 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#54 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#55 0x00000000005b601f in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16753
#56 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714
#57 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32352
#58 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641
#59 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561
#60 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838
#61 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772
#62 0x0000000000550fd6 in primary_raw (p=0x7fffe3add110) at Parser/parser.c:14327
#63 0x0000000000550c8b in primary_rule (p=0x7fffe3add110) at Parser/parser.c:14126
#64 0x00000000005506b9 in await_primary_rule (p=0x7fffe3add110) at Parser/parser.c:14079
#65 power_rule (p=0x7fffe3add110) at Parser/parser.c:13956
#66 factor_rule (p=0x7fffe3add110) at Parser/parser.c:13906
#67 0x000000000054fbab in term_raw (p=0x7fffe3add110) at Parser/parser.c:13746
#68 0x000000000054f853 in term_rule (p=0x7fffe3add110) at Parser/parser.c:13509
#69 0x000000000054f616 in sum_raw (p=0x7fffe3add110) at Parser/parser.c:13462
#70 sum_rule (p=0x7fffe3add110) at Parser/parser.c:13342
#71 0x000000000054f342 in shift_expr_raw (p=0x7fffe3add110) at Parser/parser.c:13301
#72 shift_expr_rule (p=0x7fffe3add110) at Parser/parser.c:13181
#73 0x000000000054e8e1 in bitwise_and_raw (p=0x7fffe3add110) at Parser/parser.c:13140
#74 bitwise_and_rule (p=0x7fffe3add110) at Parser/parser.c:13059
#75 bitwise_xor_raw (p=0x7fffe3add110) at Parser/parser.c:13019
#76 bitwise_xor_rule (p=0x7fffe3add110) at Parser/parser.c:12937
#77 0x000000000054cef5 in bitwise_or_raw (p=0x7fffe3add110) at Parser/parser.c:12896
#78 bitwise_or_rule (p=0x7fffe3add110) at Parser/parser.c:12815
#79 comparison_rule (p=0x7fffe3add110) at Parser/parser.c:12055
#80 inversion_rule (p=0x7fffe3add110) at Parser/parser.c:12006
#81 0x000000000054c25f in conjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11882
#82 0x000000000054bf8f in disjunction_rule (p=0x7fffe3add110) at Parser/parser.c:11794
#83 0x000000000054bdbf in expression_rule (p=0x7fffe3add110) at Parser/parser.c:11082
#84 0x00000000005b60be in kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:32277
#85 double_starred_kvpair_rule (p=0x7fffe3add110) at Parser/parser.c:16714
#86 _loop0_118_rule (p=0x7fffe3add110) at Parser/parser.c:32287
#87 _gather_117_rule (p=0x7fffe3add110) at Parser/parser.c:32354
#88 0x000000000054966a in double_starred_kvpairs_rule (p=0x7fffe3add110) at Parser/parser.c:16641
#89 dict_rule (p=0x7fffe3add110) at Parser/parser.c:16561
--Type <RET> for more, q to quit, c to continue without paging--
#90 _tmp_96_rule (p=0x7fffe3add110) at Parser/parser.c:30838
#91 atom_rule (p=0x7fffe3add110) at Parser/parser.c:14772
#92 0x0000000000548aa5 in t_primary_raw (p=0x7fffe3add110) at Parser/parser.c:18966
#93 0x000000000054afa7 in t_primary_rule (p=0x7fffe3add110) at Parser/parser.c:18757
#94 target_with_star_atom_rule (p=0x7fffe3add110) at Parser/parser.c:18257
#95 0x000000000054a541 in star_target_rule (p=0x7fffe3add110) at Parser/parser.c:18199
#96 star_targets_rule (p=0x7fffe3add110) at Parser/parser.c:17942
#97 0x00000000005478e9 in _tmp_250_rule (p=0x7fffe3add110) at Parser/parser.c:40231
#98 _loop1_14_rule (p=0x7fffe3add110) at Parser/parser.c:25810
#99 assignment_rule (p=0x7fffe3add110) at Parser/parser.c:2360
#100 simple_stmt_rule (p=0x7fffe3add110) at Parser/parser.c:1707
#101 0x0000000000546fa1 in simple_stmts_rule (p=0x7fffe3add110) at Parser/parser.c:1601
#102 0x00000000005b2722 in statement_rule (p=0x7fffe3add110) at Parser/parser.c:1426
#103 _loop1_3_rule (p=0x7fffe3add110) at Parser/parser.c:25157
#104 statements_rule (p=0x7fffe3add110) at Parser/parser.c:1360
#105 file_rule (p=0x7fffe3add110) at Parser/parser.c:1162
#106 _PyPegen_parse (p=p@entry=0x7fffe3add110) at Parser/parser.c:41920
#107 0x00000000005b142d in _PyPegen_run_parser (p=0x7fffe3add110) at Parser/pegen.c:926
#108 0x00000000005b1263 in _PyPegen_run_parser_from_string (
    str=str@entry=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., start_rule=start_rule@entry=257, filename_ob=filename_ob@entry=0x7fffe3c84c90, flags=flags@entry=0x7fffffffbab8, arena=0x7fffe3c26710, 
    arena@entry=0x5b1263 <_PyPegen_run_parser_from_string+147>) at Parser/pegen.c:1039
#109 0x00000000005b9f2a in _PyParser_ASTFromString (
    str=str@entry=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., filename=filename@entry=0x7fffe3c84c90, mode=mode@entry=257, flags=flags@entry=0x7fffffffbab8, arena=0x5b1263 <_PyPegen_run_parser_from_string+147>, 
    arena@entry=0x7fffe3c26710) at Parser/peg_api.c:14
#110 0x00000000005fcec4 in Py_CompileStringObject (
    str=0x14925c0 ""from __future__ import annotations\n\nimport builtins\nimport importlib\nimport os.path\nimport platform\nimport shutil\nimport stat\nimport struct\nimport sys\nimport sysconfig\nfrom contextlib import suppress\n""..., filename=filename@entry=0x7fffe3c84c90, start=start@entry=257, flags=flags@entry=0x7fffffffbab8, optimize=optimize@entry=-1) at Python/pythonrun.c:1801
#111 0x00000000005e28e3 in builtin_compile_impl (module=<optimized out>, source=0x14925a0, filename=0x7fffe3c84c90, mode=0xace568 <const_str_exec+40> ""exec"", flags=0, dont_inherit=1, optimize=-1, 
    feature_version=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:831
#112 builtin_compile (module=<optimized out>, args=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargs=<optimized out>, kwnames=<optimized out>)
    at Python/clinic/bltinmodule.c.h:383
#113 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50
#114 0x00000000005bd795 in _PyVectorcall_Call (tstate=0xb53070 <_PyRuntime+458992>, func=0x56c220 <cfunction_vectorcall_FASTCALL_KEYWORDS>, callable=0x7ffff7f745e0, tuple=<optimized out>, 
    kwargs=<optimized out>) at Objects/call.c:283
#115 0x000000000059602a in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:3263
#116 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xc33ec0, globals=globals@entry=0x7fffe9fd0a00, locals=locals@entry=0x7fffe9fd0a00) at Python/ceval.c:578
#117 0x00000000005e2573 in builtin_exec_impl (module=<optimized out>, source=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, globals=0x7fffe9fd0a00, 
    locals=0x7fffe9fd0a00, closure=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Python/bltinmodule.c:1096
#118 builtin_exec (module=<optimized out>, args=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Python/clinic/bltinmodule.c.h:586
#119 0x000000000056c272 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=<optimized out>, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ./Include/cpython/methodobject.h:50
#120 0x000000000055a0e4 in _PyObject_VectorcallTstate (tstate=0xb53070 <_PyRuntime+458992>, callable=0x7ffff7f74770, 
    callable@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, args=<optimized out>, 
    args@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, nargsf=<optimized out>, 
    nargsf@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>, kwnames=<optimized out>, 
    kwnames@entry=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at ./Include/internal/pycore_call.h:92
--Type <RET> for more, q to quit, c to continue without paging--
#121 PyObject_Vectorcall (callable=0x7ffff7f74770, args=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at Objects/call.c:325
#122 0x000000000058eca9 in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at Python/bytecodes.c:2715
#123 0x00000000005e33ae in PyEval_EvalCode (co=co@entry=0xbf72b0, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0) at Python/ceval.c:578
#124 0x00000000005fd0e7 in run_eval_code_obj (tstate=0xb53070 <_PyRuntime+458992>, co=0xbf72b0, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0) at Python/pythonrun.c:1722
#125 0x00000000005fd073 in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7ffff7fd23c0, locals=0x7ffff7fd23c0, flags=<optimized out>, arena=<optimized out>) at Python/pythonrun.c:1743
#126 0x00000000005fd4e2 in pyrun_file (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, start=start@entry=257, globals=globals@entry=0x7ffff7fd23c0, locals=locals@entry=0x7ffff7fd23c0, 
    closeit=closeit@entry=1, flags=0x7fffffffc208) at Python/pythonrun.c:1643
#127 0x00000000005fd395 in _PyRun_SimpleFileObject (fp=0xb96840, filename=0x7ffff7f30810, closeit=1, flags=0x7fffffffc208) at Python/pythonrun.c:433
#128 0x00000000005fd1ca in _PyRun_AnyFileObject (fp=fp@entry=0xb96840, filename=filename@entry=0x7ffff7f30810, closeit=closeit@entry=1, flags=flags@entry=0x7fffffffc208) at Python/pythonrun.c:78
#129 0x0000000000602e41 in pymain_run_file_obj (program_name=0x7ffff7f07150, filename=0x7ffff7f30810, skip_source_first_line=0) at Modules/main.c:360
#130 pymain_run_file (config=0xaf5c50 <_PyRuntime+77008>) at Modules/main.c:379
#131 pymain_run_python (exitcode=<error reading variable: dwarf2_find_location_expression: Corrupted DWARF expression.>) at Modules/main.c:633
#132 Py_RunMain () at Modules/main.c:713
#133 0x0000000000602a95 in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at Modules/main.c:767
#134 0x00007ffff70877e5 in __libc_start_main () from /lib64/libc.so.6
#135 0x00000000005b102e in _start () at Modules/main.c:478
(gdb) 
(gdb) 
(gdb) p code_hash
value requires 262144 bytes, which is more than max-value-size
(gdb) info locals
h = 9443209
v = <optimized out>
i = 9496694
incr = <optimized out>
(gdb) 

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.12.8 (main, Jan 21 2025, 03:13:20) [GCC 15.0.0 20241111 (experimental)]",[],Please close as is a duplicate of your previous issue.,[],['python'],github,https://github.com/python/cpython/issues/129993,{'repo': 'python/cpython'}
"test_math.test_sumprod_stress: ""_PyEval_EvalFrameDefault: Assertion `oparg & 1' failed""

# Crash report

Seen in:

https://buildbot.python.org/#/builders/345/builds/10459/steps/6/logs/stdio

Commit: b6769e94046

```
test_sumprod_stress (test.test_math.MathTests.test_sumprod_stress) ... python: Python/generated_cases.c.h:8149: _PyEval_EvalFrameDefault: Assertion `oparg & 1' failed.
Fatal Python error: Aborted

Current thread 0x00007f44956e7740 (most recent call first):
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 1133 in assertTupleEqual
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 916 in assertEqual
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/test_math.py"", line 1462 in test_sumprod_stress
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 606 in _callTestMethod
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 660 in run
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 716 in __call__
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 122 in run
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 84 in __call__
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 122 in run
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 84 in __call__
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/runner.py"", line 259 in run
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 84 in _run_suite
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 42 in run_unittest
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 162 in test_func
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 118 in regrtest_runner
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 165 in _load_run_test
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 210 in _runtest_env_changed_exc
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 319 in _runtest
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 348 in run_single_test
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 92 in worker_process
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 127 in main
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 131 in <module>
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/runpy.py"", line 88 in _run_code
  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/runpy.py"", line 198 in _run_module_as_main

Extension modules: _testinternalcapi (total: 1)
```

The test passed when retried.

https://github.com/python/cpython/blob/b6769e9404646e38d9c786984ef308c8e9747b91/Python/generated_cases.c.h#L8146-L8156","['test_sumprod_stress (test.test_math.MathTests.test_sumprod_stress) ... python: Python/generated_cases.c.h:8149: _PyEval_EvalFrameDefault: Assertion `oparg & 1\' failed.\nFatal Python error: Aborted\n\nCurrent thread 0x00007f44956e7740 (most recent call first):\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 1133 in assertTupleEqual\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 916 in assertEqual\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/test_math.py"", line 1462 in test_sumprod_stress\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 606 in _callTestMethod\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 660 in run\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/case.py"", line 716 in __call__\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 122 in run\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 84 in __call__\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 122 in run\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/suite.py"", line 84 in __call__\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/unittest/runner.py"", line 259 in run\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 84 in _run_suite\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 42 in run_unittest\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 162 in test_func\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 118 in regrtest_runner\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 165 in _load_run_test\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 210 in _runtest_env_changed_exc\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 319 in _runtest\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/single.py"", line 348 in run_single_test\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 92 in worker_process\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 127 in main\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/test/libregrtest/worker.py"", line 131 in <module>\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/runpy.py"", line 88 in _run_code\n  File ""/root/buildarea/3.x.angelico-debian-amd64/build/Lib/runpy.py"", line 198 in _run_module_as_main\n\nExtension modules: _testinternalcapi (total: 1)']","I've actually been doing some thermal stress-testing on that machine recently. I hadn't been aware of buildbot failures, but it is entirely possible that these happened during those tests. (It's an Intel 14700KF and they have proven to be, uhh, one of Intel's more notable releases.) The upshot of the testing is that now I have a sensors config that reduces the temperature cutoff before the system reduces CPU frequency, which seems to have improved things.

Apologies for not noticing that there were builds caught by this, but I was initially under the impression that the failure mode was a full system wedge and consequent restart, and it seems there may possibly have been less critical results. Will be monitoring the buildbot waterfall during future testing. Thanks for pinging me.",[],['python'],github,https://github.com/python/cpython/issues/130896,{'repo': 'python/cpython'}
"Why does Python 3.14 use ob_ref_local and ob_ref_shared for reference counts when GIL is absent

According to `Include/object.h` in Python's source code:

```c
struct _object {
    // ob_tid stores the thread id (or zero). It is also used by the GC and the
    // trashcan mechanism as a linked list pointer and by the GC to store the
    // computed ""gc_refs"" refcount.
    uintptr_t ob_tid;
    uint16_t ob_flags;
    PyMutex ob_mutex;           // per-object lock
    uint8_t ob_gc_bits;         // gc-related state
    uint32_t ob_ref_local;      // local reference count
    Py_ssize_t ob_ref_shared;   // shared (atomic) reference count
    PyTypeObject *ob_type;
};
```

When I managed to use an external tool, [pyobject](https://github.com/qfcy/pyobject) (`pip install pyobject`), to inspect them:

```python
C:\Users\admin>py314t
Python 3.14.0a5 experimental free-threading build (tags/v3.14.0a5:3ae9101, Feb 11 2025, 17:44:01) [MSC v.1942 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from pyobject import getrefcount_nogil,setrefcount_nogil
>>> class A:pass
...
>>> a=A()
>>> getrefcount_nogil(a)
(1, 0) # the first is ob_ref_local and the second is ob_ref_shared
>>> def another_thread():
...     b=a
...     while True:pass
...
>>> from _thread import start_new_thread
>>> start_new_thread(another_thread,())
10824
>>> getrefcount_nogil(a)
(1, 5)
>>>
```
Snippet of `getrefcount_nogil` from the source code of `pyobject`:
```c
PyObject *getrefcount_nogil(PyObject *self, PyObject *args){
    PyObject *obj;
    if (!PyArg_ParseTuple(args,""O"",&obj)) return NULL;
    PyObject *result = PyTuple_New(2); // Simply returns a tuple
    PyTuple_SetItem(result, 0, PyLong_FromUnsignedLong(obj->ob_ref_local));
    PyTuple_SetItem(result, 1, PyLong_FromSize_t(obj->ob_ref_shared));
    return result;
}
```
So, what is the function and implication of `ob_ref_local` and `ob_ref_shared` values that replace `ob_refcnt`?","['struct _object {\n    // ob_tid stores the thread id (or zero). It is also used by the GC and the\n    // trashcan mechanism as a linked list pointer and by the GC to store the\n    // computed ""gc_refs"" refcount.\n    uintptr_t ob_tid;\n    uint16_t ob_flags;\n    PyMutex ob_mutex;           // per-object lock\n    uint8_t ob_gc_bits;         // gc-related state\n    uint32_t ob_ref_local;      // local reference count\n    Py_ssize_t ob_ref_shared;   // shared (atomic) reference count\n    PyTypeObject *ob_type;\n};', 'C:\\Users\\admin>py314t\nPython 3.14.0a5 experimental free-threading build (tags/v3.14.0a5:3ae9101, Feb 11 2025, 17:44:01) [MSC v.1942 64 bit (AMD64)] on win32\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> from pyobject import getrefcount_nogil,setrefcount_nogil\n>>> class A:pass\n...\n>>> a=A()\n>>> getrefcount_nogil(a)\n(1, 0) # the first is ob_ref_local and the second is ob_ref_shared\n>>> def another_thread():\n...     b=a\n...     while True:pass\n...\n>>> from _thread import start_new_thread\n>>> start_new_thread(another_thread,())\n10824\n>>> getrefcount_nogil(a)\n(1, 5)\n>>>', 'PyObject *getrefcount_nogil(PyObject *self, PyObject *args){\n    PyObject *obj;\n    if (!PyArg_ParseTuple(args,""O"",&obj)) return NULL;\n    PyObject *result = PyTuple_New(2); // Simply returns a tuple\n    PyTuple_SetItem(result, 0, PyLong_FromUnsignedLong(obj->ob_ref_local));\n    PyTuple_SetItem(result, 1, PyLong_FromSize_t(obj->ob_ref_shared));\n    return result;\n}']",Take a look at https://peps.python.org/pep-0703/#reference-counting,[],['python'],github,https://github.com/python/cpython/issues/130173,{'repo': 'python/cpython'}
"Add information about IDLE to online contents

Clicking [Complete table of contents](https://docs.python.org/3/contents.html) on docs.python.org shows, in part,

![Image](https://github.com/user-attachments/assets/335641e6-b8a4-43f9-a5f0-415d3f628491)

A short line like:

> Python's Integrated Development Environment

Maybe the remainder can be omitted?

@terryjreedy 

<!-- gh-linked-prs -->
### Linked PRs
* gh-129727
* gh-129864
* gh-129865
<!-- /gh-linked-prs -->
",[],"This master html content index [file](https://docs.python.org/3/contents.html) is generated from the individual files when the doc set is created by Sphinx.  The entries are derived from the header lines.  Omitting other markup, tkinter.rst begins with ""tkinter --- Python interface to Tcl/Tk"", the same as above with `---` converted to the continuous line.  I suggest we add ` --- Python editor and shell` to the title of `Doc/library/idle.rst`.  Near the bottom of the file, we could expand the subsubsection 'idlelib' to `idlelib --- implementation of IDLE application`.  Either suggest other additions to add or go ahead with a PR if you want.

For the module index py-modindex.html, accessed by clicking the top right button on the online pages, the extra explanation is the module synopsis.  tkinter.rst has `:synopsis: Interface to Tcl/Tk for graphical user interfaces`.  This seems only to be applicable to modules.  Since IDLE is not a module, 'IDLE' does not belong there, which is why I added the idlelib section, with a synopsis.

",[],['python'],github,https://github.com/python/cpython/issues/129699,{'repo': 'python/cpython'}
"TIL you can use else with a while loop

Not sure why I’ve never heard about this, but apparently you can use else with a while loop. I’ve always used a separate flag variable 

This will execute when the while condition is false but not if you break out of the loop early.

For example:

**Using flag**

```
nums = [1, 3, 5, 7, 9]
target = 4
found = False
i = 0

while i &lt; len(nums):
    if nums[i] == target:
        found = True
        print(""Found:"", target)
        break
    i += 1

if not found:
    print(""Not found"")
```

**Using else**

```
nums = [1, 3, 5, 7, 9]
target = 4
i = 0

while i &lt; len(nums):
    if nums[i] == target:
        print(""Found:"", target)
        break
    i += 1
else:
    print(""Not found"")
```","['nums = [1, 3, 5, 7, 9]\ntarget = 4\nfound = False\ni = 0\n\nwhile i &lt; len(nums):\n    if nums[i] == target:\n        found = True\n        print(""Found:"", target)\n        break\n    i += 1\n\nif not found:\n    print(""Not found"")', 'nums = [1, 3, 5, 7, 9]\ntarget = 4\ni = 0\n\nwhile i &lt; len(nums):\n    if nums[i] == target:\n        print(""Found:"", target)\n        break\n    i += 1\nelse:\n    print(""Not found"")']",See comments on Reddit,[],['Python'],reddit,https://www.reddit.com/r/Python/comments/1j1axht/til_you_can_use_else_with_a_while_loop/,{'subreddit': 'Python'}
"tkinter missing -nolinestop on tk.Text

# Bug report

### Bug description:

```python
# current tkinter/__init__.py

class Text(...):
[...]
    def search(self, pattern, index, stopindex=None,
           forwards=None, backwards=None, exact=None,
           regexp=None, nocase=None, count=None, elide=None):
[...]
```

The current tkinter implementation of the `tkinter.Text.search` method misses use of <a href=""https://www.tcl-lang.org/man/tcl8.6/TkCmd/text.htm#M147"">tcl options</a>:
-nolinestop
-all
-overlap
-strictlimits

Is there any reason on why it is not inside the CPython implementation?

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130848
<!-- /gh-linked-prs -->
","['# current tkinter/__init__.py\n\nclass Text(...):\n[...]\n    def search(self, pattern, index, stopindex=None,\n           forwards=None, backwards=None, exact=None,\n           regexp=None, nocase=None, count=None, elide=None):\n[...]']",I'll see if I can make a pr,[],['python'],github,https://github.com/python/cpython/issues/130693,{'repo': 'python/cpython'}
"Improve speed of stdlib functions by replacing `re` uses

We can often find the module `re` in the standard library modules but it can be replaced (if it is possible). I don't suggest removing it everywhere, there are places where its use is appropriate, but there are also places where it is an unnecessary solution and leads to unpleasant consequences (they can be found below)

**Cons** of regular expressions and reasons to replace regular expressions with functions and methods:
1. We spend time to compile re pattern (one time, but anyway we spend it)
2. In most cases simple string methods are faster (according to my benchmarks about 2x)
3. We can remove `import re` which will affect import time
4. *Additionally*: I think for those who don't know regular expressions, the code is more difficult to read and therefore difficult to maintain.

> [!IMPORTANT]
> For those who want to work on the issue, please:
>
> - Read https://devguide.python.org/getting-started/pull-request-lifecycle/ before anything else.
> - Select **one** function to improve. It's easier to review and possibly backport.
> - Always report benchmarks using `pyperf`, `hyperfine`, and `tuna` together with `-X importtime` to compare import times and execution time. 
> - Open a pull request with the following title: <code>gh-130167: Improve speed of \`module.function\` by replacing \`re\`</code>

<!-- gh-linked-prs -->
### Linked PRs
* gh-130170
* gh-130242
* gh-130243
<!-- /gh-linked-prs -->
",[],"If you can *remove* `re` with simpler alternatives, then I'm fine. What I don't want to see is essentially PRs that would move lots of `re` imports to local ones if they hurt readability and don't improve start up time by much.

Note that it's also important to possibly plan for future extensions of the regex usage. Like getting the matched substring could be useful later. Now, I'm not against improving the various `re` usages whenever possible but benchmarks must always be given (with sufficient coverage).",[],['python'],github,https://github.com/python/cpython/issues/130167,{'repo': 'python/cpython'}
"New warning on `main`: `writing 1 byte into a region of size 0 [-Wstringop-overflow=]`

# Bug report

### Bug description:

This happens in Modules/_decimal/libmpdec/io.c 
Here: https://github.com/python/cpython/blob/a4722449caccc42ad644611d02fbdb5005f601eb/Modules/_decimal/libmpdec/io.c#L348-L349

<img width=""635"" alt=""Image"" src=""https://github.com/user-attachments/assets/b66e774d-cc81-4a27-b435-6fd12fc911ac"" />

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-116346
<!-- /gh-linked-prs -->
",[],"I doubt it's a new one, see https://github.com/python/cpython/issues/108562.  See patch: https://github.com/python/cpython/pull/116346.

Probably someone (me?:)) should just post that to the mpdecimal maillist.",[],['python'],github,https://github.com/python/cpython/issues/129467,{'repo': 'python/cpython'}
"threading: Exception at shutdown on musllinux_1_2_i686

# Bug report

### Bug description:

When `cibuildwheel` runs the `musllinux_1_2_i686` configuration, I often see exceptions logged when the end-of-process GC runs:

```
Exception ignored in: <function _DeleteDummyThreadOnDel.__del__ at 0xf2be5578>
  Traceback (most recent call last):
    File ""/opt/_internal/cpython-3.13.0/lib/python3.13/threading.py"", line 1383, in __del__
  TypeError: 'NoneType' object does not support the context manager protocol
  .Traceback (most recent call last):
    File ""<string>"", line 1, in <module>
      from tornado.ioloop import IOLoop; classname = lambda x: x.__class__.__name__; from tornado.platform.asyncio import AsyncIOMainLoop; AsyncIOMainLoop().install(); print(classname(IOLoop.current()))
```

It looks like something about musl libc is causing `_active_limbo_lock` to get GC'd before `_thread_local_info._track_dummy_thread_ref`. This happens on musllinux (1.2) on i686 builds. 64-bit builds (of x86 and arm) and manylinux builds are not affected. Older versions of python are not affected; I have not tested with 3.14 alphas but I think they are likely affected since the relevant code doesn't appear to have changed. 

A complete log with this failure can be found at https://github.com/bdarnell/tornado/actions/runs/13459578244/job/37733273132

This issue is not a priority for me. I'm just going to skip this configuration in my CI and I'm filing an issue so I have something to point to. 

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['Exception ignored in: <function _DeleteDummyThreadOnDel.__del__ at 0xf2be5578>\n  Traceback (most recent call last):\n    File ""/opt/_internal/cpython-3.13.0/lib/python3.13/threading.py"", line 1383, in __del__\n  TypeError: \'NoneType\' object does not support the context manager protocol\n  .Traceback (most recent call last):\n    File ""<string>"", line 1, in <module>\n      from tornado.ioloop import IOLoop; classname = lambda x: x.__class__.__name__; from tornado.platform.asyncio import AsyncIOMainLoop; AsyncIOMainLoop().install(); print(classname(IOLoop.current()))']","> It seems that relying on __del__ that refers to an external lock can't be fundamentally sound, since the ""rules of __del__"" seems to allow for that lock to be gone when the __del__ finally runs.

The reference to the lock in the global namespace is gone, but if you save a reference to the lock on the `_DeleteDummyThreadOnDel` object you can still have a reference to it during `__del__`. I've used this before as a workaround for destructor-time issues. (The main thing to watch out for is the possibility that some thread was abruptly shut down while holding the lock).

> When the problem reproduces (not always, sorry)

My one-liner repro appears to reproduce every time, FWIW. It brings in Tornado but just uses a small part of it. I haven't tried to dig into this because I don't have a good way to test in a musllinux environment. 

```
python -c ""from tornado.ioloop import IOLoop; classname = lambda x: x.__class__.__name__; from tornado.platform.asyncio import AsyncIOMainLoop; AsyncIOMainLoop().install(); print(classname(IOLoop.current()))""
```


","['python -c ""from tornado.ioloop import IOLoop; classname = lambda x: x.__class__.__name__; from tornado.platform.asyncio import AsyncIOMainLoop; AsyncIOMainLoop().install(); print(classname(IOLoop.current()))""']",['python'],github,https://github.com/python/cpython/issues/130522,{'repo': 'python/cpython'}
"build failed on DragonFlyBSD-6.4

# Bug report

### Bug description:

```
2025-02-27T04:16:40.9317730Z /usr/bin/cc -pthread  -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -I/root/.xbuilder/run/1051/auxroot/include -fPIC -fno-common -Os    -I/root/.xbuilder/run/1051/auxroot/include -fPIC -fno-common -Os     -g -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include -I/root/.xbuilder/run/1051/auxroot/include   -I/root/.xbuilder/run/1051/auxroot/include/tirpc -I/root/.xbuilder/run/1051/auxroot/include   -I/root/.xbuilder/run/1051/auxroot/include/tirpc  -DPy_BUILD_CORE_BUILTIN -c ./Modules/timemodule.c -o Modules/timemodule.o
2025-02-27T04:16:41.0793065Z In file included from ./Include/Python.h:64,
2025-02-27T04:16:41.0798014Z                  from ./Modules/timemodule.c:3:
2025-02-27T04:16:41.0798662Z ./Modules/timemodule.c: In function 'time_clockid_converter':
2025-02-27T04:16:41.0799495Z ./Include/pymacro.h:23:25: error: static assertion failed: ""sizeof(clk_id) == sizeof(*p)""
2025-02-27T04:16:41.0800210Z  #  define static_assert _Static_assert
2025-02-27T04:16:41.0800628Z                          ^~~~~~~~~~~~~~
2025-02-27T04:16:41.0801204Z ./Include/pymacro.h:77:13: note: in expansion of macro 'static_assert'
2025-02-27T04:16:41.0801791Z              static_assert((cond), #cond); \
2025-02-27T04:16:41.0802179Z              ^~~~~~~~~~~~~
2025-02-27T04:16:41.0802658Z ./Modules/timemodule.c:201:5: note: in expansion of macro 'Py_BUILD_ASSERT'
2025-02-27T04:16:41.0803366Z      Py_BUILD_ASSERT(sizeof(clk_id) == sizeof(*p));
2025-02-27T04:16:41.0803764Z      ^~~~~~~~~~~~~~~
2025-02-27T04:16:41.1033318Z gmake: *** [Makefile:3534: Modules/timemodule.o] Error 1
2025-02-27T04:16:41.1037795Z gmake: *** Waiting for unfinished jobs....
```

fulllogs:
https://github.com/leleliu008/python-distribution/actions/runs/13558699714/job/37897846484

### CPython versions tested on:

3.13

https://www.python.org/ftp/python/3.13.2/Python-3.13.2.tgz

### Operating systems tested on:

DragonFlyBSD-6.4

<!-- gh-linked-prs -->
### Linked PRs
* gh-130634
* gh-130666
<!-- /gh-linked-prs -->
","['2025-02-27T04:16:40.9317730Z /usr/bin/cc -pthread  -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -I/root/.xbuilder/run/1051/auxroot/include -fPIC -fno-common -Os    -I/root/.xbuilder/run/1051/auxroot/include -fPIC -fno-common -Os     -g -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include -I/root/.xbuilder/run/1051/auxroot/include   -I/root/.xbuilder/run/1051/auxroot/include/tirpc -I/root/.xbuilder/run/1051/auxroot/include   -I/root/.xbuilder/run/1051/auxroot/include/tirpc  -DPy_BUILD_CORE_BUILTIN -c ./Modules/timemodule.c -o Modules/timemodule.o\n2025-02-27T04:16:41.0793065Z In file included from ./Include/Python.h:64,\n2025-02-27T04:16:41.0798014Z                  from ./Modules/timemodule.c:3:\n2025-02-27T04:16:41.0798662Z ./Modules/timemodule.c: In function \'time_clockid_converter\':\n2025-02-27T04:16:41.0799495Z ./Include/pymacro.h:23:25: error: static assertion failed: ""sizeof(clk_id) == sizeof(*p)""\n2025-02-27T04:16:41.0800210Z  #  define static_assert _Static_assert\n2025-02-27T04:16:41.0800628Z                          ^~~~~~~~~~~~~~\n2025-02-27T04:16:41.0801204Z ./Include/pymacro.h:77:13: note: in expansion of macro \'static_assert\'\n2025-02-27T04:16:41.0801791Z              static_assert((cond), #cond); \\\n2025-02-27T04:16:41.0802179Z              ^~~~~~~~~~~~~\n2025-02-27T04:16:41.0802658Z ./Modules/timemodule.c:201:5: note: in expansion of macro \'Py_BUILD_ASSERT\'\n2025-02-27T04:16:41.0803366Z      Py_BUILD_ASSERT(sizeof(clk_id) == sizeof(*p));\n2025-02-27T04:16:41.0803764Z      ^~~~~~~~~~~~~~~\n2025-02-27T04:16:41.1033318Z gmake: *** [Makefile:3534: Modules/timemodule.o] Error 1\n2025-02-27T04:16:41.1037795Z gmake: *** Waiting for unfinished jobs....']",What is the size of the `clockid_t` type on DragonFlyBSD?,[],['python'],github,https://github.com/python/cpython/issues/130617,{'repo': 'python/cpython'}
"New REPL exits when there are non-string candidates for suggestions

# Crash report

### What happened?

The new REPL in main will exit if a suggestion would be offered, but there are non-string candidates like below:

```python
>>> import runpy
... runpy._run_module_code(""blech"", {0: """", ""bluch"": """"}, """")
...
Exception ignored in the internal traceback machinery:
Traceback (most recent call last):
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 139, in _print_exception_bltin
    return print_exception(exc, limit=BUILTIN_EXCEPTION_LIMIT, file=file, colorize=colorize)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 129, in print_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1138, in __init__
    context = TracebackException(
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__
    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error
    return _suggestions._generate_suggestions(d, wrong_name)
TypeError: all elements in 'candidates' must be strings
Traceback (most recent call last):
  File ""<python-input-0>"", line 2, in <module>
  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 98, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 88, in _run_code
    exec(code, run_globals)
  File ""<string>"", line 1, in <module>
NameError: name 'blech' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 173, in _excepthook
    lines = traceback.format_exception(
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 154, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__
    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error
    return _suggestions._generate_suggestions(d, wrong_name)
TypeError: all elements in 'candidates' must be strings

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 198, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 88, in _run_code
    exec(code, run_globals)
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/__main__.py"", line 6, in <module>
    __pyrepl_interactive_console()
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/main.py"", line 59, in interactive_console
    run_multiline_interactive_console(console)
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/simple_interact.py"", line 152, in run_multiline_interactive_console
    more = console.push(_strip_final_indent(statement), filename=input_name, _symbol=""single"")  # type: ignore[call-arg]
  File ""/home/danzin/projects/cpython/Lib/code.py"", line 324, in push
    more = self.runsource(source, filename, symbol=_symbol)
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 231, in runsource
    result = self.runcode(code)
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 191, in runcode
    self.showtraceback()
  File ""/home/danzin/projects/cpython/Lib/code.py"", line 128, in showtraceback
    self._showtraceback(typ, value, tb.tb_next, """")
  File ""/home/danzin/projects/cpython/Lib/code.py"", line 144, in _showtraceback
    self._excepthook(typ, value, tb)
  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 179, in _excepthook
    lines = traceback.format_exception(
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 154, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1138, in __init__
    context = TracebackException(
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__
    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)
  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error
    return _suggestions._generate_suggestions(d, wrong_name)
TypeError: all elements in 'candidates' must be strings
```

This is an offshoot of #129573, where code like above would abort in 3.12.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.14.0a5+ (heads/main:a3990df6121, Mar  9 2025, 00:02:58) [GCC 13.3.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-131001
<!-- /gh-linked-prs -->
","['>>> import runpy\n... runpy._run_module_code(""blech"", {0: """", ""bluch"": """"}, """")\n...\nException ignored in the internal traceback machinery:\nTraceback (most recent call last):\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 139, in _print_exception_bltin\n    return print_exception(exc, limit=BUILTIN_EXCEPTION_LIMIT, file=file, colorize=colorize)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 129, in print_exception\n    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1138, in __init__\n    context = TracebackException(\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__\n    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error\n    return _suggestions._generate_suggestions(d, wrong_name)\nTypeError: all elements in \'candidates\' must be strings\nTraceback (most recent call last):\n  File ""<python-input-0>"", line 2, in <module>\n  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 98, in _run_module_code\n    _run_code(code, mod_globals, init_globals,\n  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 88, in _run_code\n    exec(code, run_globals)\n  File ""<string>"", line 1, in <module>\nNameError: name \'blech\' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 173, in _excepthook\n    lines = traceback.format_exception(\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 154, in format_exception\n    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__\n    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error\n    return _suggestions._generate_suggestions(d, wrong_name)\nTypeError: all elements in \'candidates\' must be strings\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 198, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File ""/home/danzin/projects/cpython/Lib/runpy.py"", line 88, in _run_code\n    exec(code, run_globals)\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/__main__.py"", line 6, in <module>\n    __pyrepl_interactive_console()\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/main.py"", line 59, in interactive_console\n    run_multiline_interactive_console(console)\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/simple_interact.py"", line 152, in run_multiline_interactive_console\n    more = console.push(_strip_final_indent(statement), filename=input_name, _symbol=""single"")  # type: ignore[call-arg]\n  File ""/home/danzin/projects/cpython/Lib/code.py"", line 324, in push\n    more = self.runsource(source, filename, symbol=_symbol)\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 231, in runsource\n    result = self.runcode(code)\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 191, in runcode\n    self.showtraceback()\n  File ""/home/danzin/projects/cpython/Lib/code.py"", line 128, in showtraceback\n    self._showtraceback(typ, value, tb.tb_next, """")\n  File ""/home/danzin/projects/cpython/Lib/code.py"", line 144, in _showtraceback\n    self._excepthook(typ, value, tb)\n  File ""/home/danzin/projects/cpython/Lib/_pyrepl/console.py"", line 179, in _excepthook\n    lines = traceback.format_exception(\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 154, in format_exception\n    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1138, in __init__\n    context = TracebackException(\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1094, in __init__\n    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)\n  File ""/home/danzin/projects/cpython/Lib/traceback.py"", line 1535, in _compute_suggestion_error\n    return _suggestions._generate_suggestions(d, wrong_name)\nTypeError: all elements in \'candidates\' must be strings']","Ok, I'll say it's a bug for 3.13/3.14 and a crash for 3.12 but the crash issue is tracked elsewhere ",[],['python'],github,https://github.com/python/cpython/issues/130999,{'repo': 'python/cpython'}
"test_peepholers leaks references (main branch)

# Bug report

### Bug description:

Example:

```
$ ./python -m test -R 3:3 test_peepholer
(...)
test_peepholer leaked [46, 46, 46] references, sum=138
test_peepholer leaked [41, 41, 41] memory blocks, sum=123
(...)
```

Regression introduced by the change 0664c1af9b29a5af2404e04a522f8e9e175ba05a of https://github.com/python/cpython/pull/129568:

```
commit 0664c1af9b29a5af2404e04a522f8e9e175ba05a
Author: Yan Yanchii <yyanchiy@gmail.com>
Date:   Tue Feb 4 09:10:55 2025 +0100

    gh-126835: Move constant subscript folding to CFG (#129568)
    
    Move folding of constant subscription from AST optimizer to CFG.
    
    Co-authored-by: Irit Katriel <1055913+iritkatriel@users.noreply.github.com>
```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux","['$ ./python -m test -R 3:3 test_peepholer\n(...)\ntest_peepholer leaked [46, 46, 46] references, sum=138\ntest_peepholer leaked [41, 41, 41] memory blocks, sum=123\n(...)', 'commit 0664c1af9b29a5af2404e04a522f8e9e175ba05a\nAuthor: Yan Yanchii <yyanchiy@gmail.com>\nDate:   Tue Feb 4 09:10:55 2025 +0100\n\n    gh-126835: Move constant subscript folding to CFG (#129568)\n    \n    Move folding of constant subscription from AST optimizer to CFG.\n    \n    Co-authored-by: Irit Katriel <1055913+iritkatriel@users.noreply.github.com>']",I think it's solved by #129634,[],['python'],github,https://github.com/python/cpython/issues/129635,{'repo': 'python/cpython'}
"[TIL] Python silently concatenates strings next to each other ""abc""""def"" = ""abcdef""

```
&gt;&gt;&gt; ""adkl"" ""asldjk""
'adklasldjk'
```
and this:
```
&gt;&gt;&gt; [""asldkj"", ""asdld"", ""lasjd""]
['asldkj', 'asdld', 'lasjd']
&gt;&gt;&gt; [""asldkj"", ""asdld"" ""lasjd""]
['asldkj', 'asdldlasjd']
```

Why though?","['&gt;&gt;&gt; ""adkl"" ""asldjk""\n\'adklasldjk\'', '&gt;&gt;&gt; [""asldkj"", ""asdld"", ""lasjd""]\n[\'asldkj\', \'asdld\', \'lasjd\']\n&gt;&gt;&gt; [""asldkj"", ""asdld"" ""lasjd""]\n[\'asldkj\', \'asdldlasjd\']']",See comments on Reddit,[],['Python'],reddit,https://www.reddit.com/r/Python/comments/jgj206/til_python_silently_concatenates_strings_next_to/,{'subreddit': 'Python'}
"Allow Manual Control Over resource_tracker in shared_memory

# Feature or enhancement

### Proposal:

### **Proposal: Allow Manual Control Over `resource_tracker` in `shared_memory`**

#### **Context and Problem Statement**
I am working on a system where a **main module** is responsible for **creating and deleting shared memory segments**, while **sub-modules** only connect to these segments and write data. However, when a sub-module stops, `resource_tracker` **incorrectly deletes the shared memory segment**, even though it should persist.

This is a critical issue because `resource_tracker` assumes it has full control over shared memory cleanup, while in complex architectures like mine, only the main module should be responsible for managing these resources.

#### **Proposed Solution**
I propose adding a mechanism to **control whether `resource_tracker` tracks a shared memory segment**. There are several possible approaches:

1. **Add a flag** (e.g., `track=False`) when creating a `SharedMemory` object:
   ```python
   shm = SharedMemory(name=""my_shared_segment"", create=True, track=False)
   ```
   This would allow developers to specify that they do not want `resource_tracker` to track this object.

2. **Allow replacing `resource_tracker` with a custom implementation**, so developers can define their own resource management logic.

3. **Provide an API to disable `resource_tracker` entirely** for advanced users who manage shared memory explicitly:
   ```python
   from multiprocessing import resource_tracker
   resource_tracker.disable()
   ```

#### **Why This is Needed**
- In systems with complex shared memory architectures, `resource_tracker` does **not** have enough context to decide which segments should be deleted.
- Allowing manual control would prevent unintended resource deletion, reducing potential **data loss** or **race conditions** in multi-process applications.
- Manually patching `resource_tracker` or modifying the Python standard library is not an ideal solution.

#### **Current Workaround**
For now, I have resorted to **commenting out `resource_tracker` code** in the standard library, which I acknowledge is not a proper solution.

Would the Python maintainers consider adding such an option in `multiprocessing.shared_memory`?

**Thank you!**

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_","['shm = SharedMemory(name=""my_shared_segment"", create=True, track=False)', 'from multiprocessing import resource_tracker\n   resource_tracker.disable()']",Maybe the last part of this [link](https://forums.raspberrypi.com/viewtopic.php?t=340441) will be useful as workaround,[],['python'],github,https://github.com/python/cpython/issues/129999,{'repo': 'python/cpython'}
"Wrong output of sympy. Integrate with Rational

# Bug report

### Bug description:

```python
# sympy.integrate((3*x)/(x**2+smp.Rational(7/4)),x)
System response: 3/2*log(4x**2+7)
```
When I put the expression to integrate, it turns out that the answer is different than integrating without considering Rational.
#
sympy.integrate((3*x)/(x**2+7/4),x)
System response: 1.5*log(1.0x**2+1.75)

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['# sympy.integrate((3*x)/(x**2+smp.Rational(7/4)),x)\nSystem response: 3/2*log(4x**2+7)']","This is the issue tracker for the Python programming language itself. Please report SymPy bugs directly to them, or you can ask questions at https://discuss.python.org/c/help/7. Thank you.",[],['python'],github,https://github.com/python/cpython/issues/130765,{'repo': 'python/cpython'}
"`_overlapped` module cannot be imported without socket support

# Bug report

### Bug description:

To reproduce, boot Windows 11 into minimal safe mode and run this

```python
import asyncio
```

It causes this error

```
Traceback (most recent call last):
  File ""C:\projects\asyncio_test_safe_mode.py"", line 1, in <module>
    import asyncio
  File ""c:\python\Lib\asyncio\__init__.py"", line 42, in <module>
    from .windows_events import *
  File ""c:\python\Lib\asyncio\windows_events.py"", line 8, in <module>
    import _overlapped
OSError: [WinError 10050] A socket operation encountered a dead network
```

System information:
* Python 3.11.10 (main, Feb 17 2025, 07:07:12) [MSC v.1942 32 bit (Intel)] on win32
* Microsoft Windows 11 64-bit 23H2 22631.4890

The greater context is that it [breaks PyGObject](https://gitlab.gnome.org/GNOME/pygobject/-/issues/679) and [BleachBit](https://github.com/bleachbit/bleachbit/issues/1785#issuecomment-2715950534).

### CPython versions tested on:

3.11

### Operating systems tested on:

Windows","['import asyncio', 'Traceback (most recent call last):\n  File ""C:\\projects\\asyncio_test_safe_mode.py"", line 1, in <module>\n    import asyncio\n  File ""c:\\python\\Lib\\asyncio\\__init__.py"", line 42, in <module>\n    from .windows_events import *\n  File ""c:\\python\\Lib\\asyncio\\windows_events.py"", line 8, in <module>\n    import _overlapped\nOSError: [WinError 10050] A socket operation encountered a dead network']","I suggest to close the issue as ""won't fix"" (not planned). You cannot use asyncio in Windows Safe Mode when all network functions are disabled. For example, bleachbit fails on socket.socketpair(): https://github.com/bleachbit/bleachbit/issues/1785#issue-2888367131

If you want to support Windows Safe Mode, you should avoid asyncio and socket modules in your code.",[],['python'],github,https://github.com/python/cpython/issues/131131,{'repo': 'python/cpython'}
"Simple extension module in C sets `errno=2` somewhere

# Bug report

Reproduction:

```c
// asm_builtins/mod.c
#include <Python.h>

static PyObject *
print(PyObject *self, PyObject *args)
{
    Py_RETURN_NONE;
}

PyDoc_STRVAR(print__doc__,
""print($module, /, *args)\n""
""--\n""
""\n""
""Print passed args as strings."");


static PyMethodDef module_methods[] = {
    {""print"", (PyCFunction)print, METH_VARARGS, print__doc__},
    {NULL}  // sentinel
};


static struct PyModuleDef asm_builtins_spec = {
    PyModuleDef_HEAD_INIT,
    ""asm_builtins"",
    PyDoc_STR(""Builtins re-implemented in ASM""),
    -1,
    module_methods
};


PyMODINIT_FUNC PyInit_asm_builtins(void) {
    printf(""errno = %d\n"", errno);  // this will print `errno=2`
    return PyModule_Create(&asm_builtins_spec);
}
```
I created a repro here: https://github.com/sobolevn/errno-2-repro

You can see that all actions with Python versions from 3.9 to 3.13 print the same `errno` on Linux (tested on macos as well - the same).

But, other than that - there are no exceptions / failures / bugs / etc. Everything works.

Is it a bug? Or am I missing something obvious?","['// asm_builtins/mod.c\n#include <Python.h>\n\nstatic PyObject *\nprint(PyObject *self, PyObject *args)\n{\n    Py_RETURN_NONE;\n}\n\nPyDoc_STRVAR(print__doc__,\n""print($module, /, *args)\\n""\n""--\\n""\n""\\n""\n""Print passed args as strings."");\n\n\nstatic PyMethodDef module_methods[] = {\n    {""print"", (PyCFunction)print, METH_VARARGS, print__doc__},\n    {NULL}  // sentinel\n};\n\n\nstatic struct PyModuleDef asm_builtins_spec = {\n    PyModuleDef_HEAD_INIT,\n    ""asm_builtins"",\n    PyDoc_STR(""Builtins re-implemented in ASM""),\n    -1,\n    module_methods\n};\n\n\nPyMODINIT_FUNC PyInit_asm_builtins(void) {\n    printf(""errno = %d\\n"", errno);  // this will print `errno=2`\n    return PyModule_Create(&asm_builtins_spec);\n}']","quoting the `man`:

```
errno
       The value in errno is significant only when the return value of
       the call indicated an error (i.e., -1 from most system calls; -1
       or NULL from most library functions); a function that succeeds is
       allowed to change errno.  The value of errno is never set to zero
       by any system call or library function.

       For some system calls and library functions (e.g.,
       getpriority(2)), -1 is a valid return on success.  In such cases,
       a successful return can be distinguished from an error return by
       setting errno to zero before the call, and then, if the call
       returns a status that indicates that an error may have occurred,
       checking to see if errno has a nonzero value.
```

So, `errno` itself is not important.
I propose to close the issue.","['errno\n       The value in errno is significant only when the return value of\n       the call indicated an error (i.e., -1 from most system calls; -1\n       or NULL from most library functions); a function that succeeds is\n       allowed to change errno.  The value of errno is never set to zero\n       by any system call or library function.\n\n       For some system calls and library functions (e.g.,\n       getpriority(2)), -1 is a valid return on success.  In such cases,\n       a successful return can be distinguished from an error return by\n       setting errno to zero before the call, and then, if the call\n       returns a status that indicates that an error may have occurred,\n       checking to see if errno has a nonzero value.']",['python'],github,https://github.com/python/cpython/issues/129606,{'repo': 'python/cpython'}
"Python3.13t version venv    windows10

# Bug report

### Bug description:

```python
# Add a code block here, if required
```

```
python3.13t -m venv venv313t
cd venv313t
Scripts\activate
python.exe -m pip install --upgrade pip
pip install spyder-kernels

error

python -m venv venv313
cd venv313
Scripts\activate
python.exe -m pip install --upgrade pip
pip install spyder-kernels

no error!
```

```
pip install jupyter-core==5.7.2     error

(venv313t) C:\Users\BoSyA\venv313t>pip install jupyter-core==5.7.2
Collecting jupyter-core==5.7.2
  Using cached jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)
Collecting platformdirs>=2.5 (from jupyter-core==5.7.2)
  Using cached platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)
INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.
ERROR: Could not find a version that satisfies the requirement pywin32>=300; sys_platform == ""win32"" and platform_python_implementation != ""PyPy"" (from jupyter-core) (from versions: none)
ERROR: No matching distribution found for pywin32>=300; sys_platform == ""win32"" and platform_python_implementation != ""PyPy""
```



https://github.com/spyder-ide/spyder/issues/23635#issuecomment-2641866466



![Image](https://github.com/user-attachments/assets/eb90e018-4103-41b2-8d4f-b6124d72ac86)


![Image](https://github.com/user-attachments/assets/d71fa9c1-0293-4866-b06e-26f607e6fd41)







### CPython versions tested on:

3.13

### Operating systems tested on:

Windows","['# Add a code block here, if required', 'python3.13t -m venv venv313t\ncd venv313t\nScripts\\activate\npython.exe -m pip install --upgrade pip\npip install spyder-kernels\n\nerror\n\npython -m venv venv313\ncd venv313\nScripts\\activate\npython.exe -m pip install --upgrade pip\npip install spyder-kernels\n\nno error!', 'pip install jupyter-core==5.7.2     error\n\n(venv313t) C:\\Users\\BoSyA\\venv313t>pip install jupyter-core==5.7.2\nCollecting jupyter-core==5.7.2\n  Using cached jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\nCollecting platformdirs>=2.5 (from jupyter-core==5.7.2)\n  Using cached platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\nINFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\nERROR: Could not find a version that satisfies the requirement pywin32>=300; sys_platform == ""win32"" and platform_python_implementation != ""PyPy"" (from jupyter-core) (from versions: none)\nERROR: No matching distribution found for pywin32>=300; sys_platform == ""win32"" and platform_python_implementation != ""PyPy""']","Thanks for a bugreport, but this is issue tracker for the CPython, not for spyder-kernels or jupyter-core.  Please report this to an appropriate project.  From your issue in the spyder-ide repo, it seems that problem related with missing support for free-threading in PyZMQ on Windows.

BTW, please next time provide more information, i.e. include actual output, single ""error"" word is not enough to debug anything most time.",[],['python'],github,https://github.com/python/cpython/issues/129767,{'repo': 'python/cpython'}
"`typing._eval_type` is not preserving `GenericAlias` subclasses

# Bug report

### Bug description:

In `typing._eval_type`, generic aliases are reconstructed this way:

https://github.com/python/cpython/blob/e53d105872fafa77507ea33b7ecf0faddd4c3b60/Lib/typing.py#L488-L489

As `GenericAlias` is subclassable, we can loose the actual subclass in some cases:

```python
from typing import get_type_hints

from collections.abc import Callable

C = Callable[[str, 'int'], int]

C.__class__
#> <class 'collections.abc._CallableGenericAlias'>

C.__class__.__bases__
#> (<class 'types.GenericAlias'>,)

class A:
    c: C

hints = get_type_hints(A)
hints['c'].__class__
#> <class 'types.GenericAlias'>
```

I couldn't find a way to get actual bugs from it, but the repr is different:

```python
hints['c']
#> collections.abc.Callable[str, int, int]
C
#> collections.abc.Callable[[str, 'int'], int]
```

## Proposed fix

```diff
diff --git a/Lib/typing.py b/Lib/typing.py
index 4b3c63b25ae..25e0576839f 100644
--- a/Lib/typing.py
+++ b/Lib/typing.py
@@ -486,7 +486,9 @@ def _eval_type(t, globalns, localns, type_params=_sentinel, *, recursive_guard=f
         if ev_args == t.__args__:
             return t
         if isinstance(t, GenericAlias):
-            return GenericAlias(t.__origin__, ev_args)
+            if _should_unflatten_callable_args(t, ev_args):
+                return t.__class__(t.__origin__, (ev_args[:-1], ev_args[-1]))
+            return t.__class__(t.__origin__, ev_args)
         if isinstance(t, Union):
             return functools.reduce(operator.or_, ev_args)
         else:
```



### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130897
<!-- /gh-linked-prs -->
","[""from typing import get_type_hints\n\nfrom collections.abc import Callable\n\nC = Callable[[str, 'int'], int]\n\nC.__class__\n#> <class 'collections.abc._CallableGenericAlias'>\n\nC.__class__.__bases__\n#> (<class 'types.GenericAlias'>,)\n\nclass A:\n    c: C\n\nhints = get_type_hints(A)\nhints['c'].__class__\n#> <class 'types.GenericAlias'>"", ""hints['c']\n#> collections.abc.Callable[str, int, int]\nC\n#> collections.abc.Callable[[str, 'int'], int]"", 'diff --git a/Lib/typing.py b/Lib/typing.py\nindex 4b3c63b25ae..25e0576839f 100644\n--- a/Lib/typing.py\n+++ b/Lib/typing.py\n@@ -486,7 +486,9 @@ def _eval_type(t, globalns, localns, type_params=_sentinel, *, recursive_guard=f\n         if ev_args == t.__args__:\n             return t\n         if isinstance(t, GenericAlias):\n-            return GenericAlias(t.__origin__, ev_args)\n+            if _should_unflatten_callable_args(t, ev_args):\n+                return t.__class__(t.__origin__, (ev_args[:-1], ev_args[-1]))\n+            return t.__class__(t.__origin__, ev_args)\n         if isinstance(t, Union):\n             return functools.reduce(operator.or_, ev_args)\n         else:']",I'll make a pr on this [branch](https://github.com/sharktide/cpython/tree/patch-130870),[],['python'],github,https://github.com/python/cpython/issues/130870,{'repo': 'python/cpython'}
"Better constant narrowing in the JIT optimizer

**Please don't work on this. I'm planning on sprinting on this with new contributors at an event this weekend.**

Currently, the JIT optimizer uses the `_COMPARE_OP` family, `_CONTAINS_OP`, `_IS_OP`, and the `_TO_BOOL` family to narrow the *types* of the input values and the type of the output value.

However, by ""peeking ahead"" and seeing how a value will be used, we can narrow these types to constants as well. As a simple example, consider `_TO_BOOL_INT + _GUARD_IS_FALSE_CHECK` on an unknown value. After the `_TO_BOOL_INT`, it can be narrowed to a known class, `int` (we do this today). However, after the `_GUARD_IS_FALSE_CHECK`, we can actually narrow it to a constant value, `0`.

An example implementation of this idea for `_TO_BOOL_BOOL` is here: https://github.com/python/cpython/compare/main...brandtbucher:cpython:hack-night-to-bool-bool
 
I've divided this work into 3 ""waves"" of increasing complexity. Tasks in **bold** are probably a bit harder, tasks in *italics* are probably a bit easier.

## Narrow types to constants in branches involving truthiness:

- [x] **`_TO_BOOL + _GUARD_IS_*_POP`**
- [x] *`_TO_BOOL_BOOL + _GUARD_IS_*_POP`*
- [x] `_TO_BOOL_INT + _GUARD_IS_*_POP`
- [ ] ~**`_TO_BOOL_LIST + _GUARD_IS_*_POP`**~
- [x] `_TO_BOOL_STR + _GUARD_IS_*_POP`

## Narrow types to constants in branches involving comparisons with a constant:

- [ ] **`_COMPARE_OP + _GUARD_IS_*_POP` (`==`, `!=`)**
- [ ] `_COMPARE_OP_FLOAT + _GUARD_IS_*_POP` (`==`, `!=`)
- [ ] `_COMPARE_OP_INT + _GUARD_IS_*_POP` (`==`, `!=`)
- [ ] `_COMPARE_OP_STR + _GUARD_IS_*_POP` (`==`, `!=`)
- [ ] **`_CONTAINS_OP + _GUARD_IS_*_POP` (`in`, `not in`)**
- [ ] *`_IS_OP + _GUARD_IS_*_POP` (`is`, `is not`)*

## Evaluate comparisons involving two constants:

This is related, but a bit more involved, since we need a way to pop two values from the stack and push a constant (`_POP_TWO_LOAD_CONST_INLINE_BORROW`). We should also teach `remove_unneeded_uops` about this new instruction.

- [ ] **`_COMPARE_OP`** (`==`, `!=`, `<`, `>`, `<=`, `>=`)
- [ ] `_COMPARE_OP_FLOAT` (`==`, `!=`, `<`, `>`, `<=`, `>=`)
- [ ] `_COMPARE_OP_INT` (`==`, `!=`, `<`, `>`, `<=`, `>=`)
- [ ] `_COMPARE_OP_STR` (`==`, `!=`, `<`, `>`, `<=`, `>=`)
- [ ] **`_CONTAINS_OP` (`in`, `not in`)**
- [ ] *`_IS_OP` (`is`, `is not`)*

<!-- gh-linked-prs -->
### Linked PRs
* gh-130476
* gh-130477
* gh-130659
* gh-130772
<!-- /gh-linked-prs -->
",[],"Talked to Brandt in private. Sadly, have to agree here that we either need to peek or need a new symbol.",[],['python'],github,https://github.com/python/cpython/issues/130415,{'repo': 'python/cpython'}
"conditional blocks in class definitions seem to be evaluating types even when these conditionals are false

# Bug report

### Bug description:

using a conditional in a class definition like `if TYPE_CHECKING` where `TYPE_CHECKING` is False, or any kind of false conditional, seems to be ignored when types are evaluated under non-future annotations mode:

```python
class MyClass:
    somevalue: str

    if False:
        someothervalue: int

assert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""
```

this seems to be something that might have been done with [some intention](https://peps.python.org/pep-0749/), which is extremely troubling as this would be a huge showstopper for SQLAlchemy if these conditionals are no longer honored at runtime.  A similar example


```py
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    # is not evaluated under any python at runtime
    from some_module import SpecialType

class MyClass:
    somevalue: str

    if TYPE_CHECKING:
        # **is** evaluated under python 3.14.0a5, fails
        someothervalue: SpecialType

assert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""

```

calling upon `__annotations__` seems to be the trigger that makes the above fail:

```py
Traceback (most recent call last):
  File ""/home/classic/dev/sqlalchemy/test4.py"", line 14, in <module>
    assert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/classic/dev/sqlalchemy/test4.py"", line 12, in __annotate__
    someothervalue: SpecialType
                    ^^^^^^^^^^^
NameError: name 'SpecialType' is not defined

```

however this appears to be some very strange quantum-physics type of evaluation that isn't actually running Python fully; below, the ""someothervalue"" type is evaluted, but not the value function assigned!

```py
from typing import TYPE_CHECKING

def do_my_thing() -> int:
    print(""HEY!"")
    assert False
    return 3 + 4

class MyClass:
    somevalue: str

    if TYPE_CHECKING:
        someothervalue: int = do_my_thing()

assert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""
```


This is an enormous and strange behavioral change that is really going to make things extremely difficult for SQLAlchemy, starting with we will have to rewrite ~~thousands~~ (OK, it turned out to be ""dozens"") of lines of test suite code into a much bigger exploded form and also a lot of end-user use cases we've defined using TYPE_CHECKING blocks aren't going to work anymore, it's not clear how much further this change will go.

I suppose if the whole thing boils down to what `__annotations__` does, and we can call upon something like `__annotations_but_not_false_blocks__`, that could save us, but overall I'm really hoping this is just a bad dream that we can wake up from.



### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130935
<!-- /gh-linked-prs -->
","['class MyClass:\n    somevalue: str\n\n    if False:\n        someothervalue: int\n\nassert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""', 'from typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    # is not evaluated under any python at runtime\n    from some_module import SpecialType\n\nclass MyClass:\n    somevalue: str\n\n    if TYPE_CHECKING:\n        # **is** evaluated under python 3.14.0a5, fails\n        someothervalue: SpecialType\n\nassert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""', 'Traceback (most recent call last):\n  File ""/home/classic/dev/sqlalchemy/test4.py"", line 14, in <module>\n    assert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/classic/dev/sqlalchemy/test4.py"", line 12, in __annotate__\n    someothervalue: SpecialType\n                    ^^^^^^^^^^^\nNameError: name \'SpecialType\' is not defined', 'from typing import TYPE_CHECKING\n\ndef do_my_thing() -> int:\n    print(""HEY!"")\n    assert False\n    return 3 + 4\n\nclass MyClass:\n    somevalue: str\n\n    if TYPE_CHECKING:\n        someothervalue: int = do_my_thing()\n\nassert MyClass.__annotations__ == {""somevalue"": str}, f""MyClass.__annotations__ == {MyClass.__annotations__}""']","On the other hand, it seems to open new possibilities to interesting experiments that were not possible before 🤔 
```python
import enum
import random


class CatState(enum.Enum):
    alive = True
    dead = False


class SchrödingersCat:
    cat: CatState.alive = CatState.alive
    if random.choice((True, False)):
        cat: CatState.dead = CatState.dead


print(SchrödingersCat.__annotations__, SchrödingersCat.cat)
```","['import enum\nimport random\n\n\nclass CatState(enum.Enum):\n    alive = True\n    dead = False\n\n\nclass SchrödingersCat:\n    cat: CatState.alive = CatState.alive\n    if random.choice((True, False)):\n        cat: CatState.dead = CatState.dead\n\n\nprint(SchrödingersCat.__annotations__, SchrödingersCat.cat)']",['python'],github,https://github.com/python/cpython/issues/130881,{'repo': 'python/cpython'}
"richcompare suppresses all errors raised from descriptors of comparison special methods

# Bug report

### Bug description:

This is reporting possibly incorrect suppression of all errors generated by descriptors for the comparison special methods `__eq__`, `__lt__`, etc. (and possibly some other special methods). This only affects errors during the `__get__` stage, while errors from the actual call propagate as expected.

I say *possibly* incorrect because I can see this being one of those sensitive underbellies that could affect existing behavior for some libraries. However, this seems inconsistent relative to some other special methods like `__contains__`, `__bool__`, etc., and since it suppresses *all* errors like SystemExit, MemoryError, KeyboardInterrupt, etc. it can hide underlying problems or behaviors that are hard to diagnose.  

## Minimal example

Minimal demonstration of the issue below is a descriptor which always raises an exception during `__get__`. The result of comparison through `==` returns False instead of raising the error. The type of error raised from `__get__` is not important, it could have been from `exit()` or anything else down the stack. However, other special methods like `__bool__` *do* raise the exception, as does directly accessing `__eq__` as a method.

```python
class BadDescriptor:
  def __get__(self, obj, cls=None):
    assert False

class BadBase:
  __eq__ = BadDescriptor()
  __bool__ = BadDescriptor()

b = BadBase()

print(f""{b == 1=}"")
print(f""{b.__eq__(1)=}"")
```

```text
b == 1=False
Traceback (most recent call last):
  File ""bad_descriptor.py"", line 24, in <module>
    print(f""{b.__eq__(1)=}"")
             ^^^^^^^^
  File ""bad_descriptor.py"", line 14, in __get__
    assert False
           ^^^^^
AssertionError
```

## Suspected cause and proposed resolution

The source of this behavior appears to be in `Objects/typeobject.c`  function `slot_tp_richcompare`. Currently if an error occurs while *getting* the comparison method from a descriptor the error is cleared and `NotImplemented` is returned. Looking at some of the other special methods it seems like there is some inconsistency, some check for `PyErr_Occurred` and propagate the exception (EG `slot_nb_bool`), while others clear the error and default to some other action (E.G. `slot_tp_repr`).

```c
    if (func == NULL) {
        PyErr_Clear();
        Py_RETURN_NOTIMPLEMENTED;
    }
```

A couple experimental resolutions were attempted to look at the consequence. The first was to treat errors similar to `slot_nb_bool`,  propagating them instead of suppressing. 

```c
    if (func == NULL) {
        if(PyErr_Occurred()){
            return NULL;
        }

        Py_RETURN_NOTIMPLEMENTED;
    }
```

However, this caused a failed test which seems to be checking that raising `AttributeError` should lead to suppression and default comparison. It is not clear to me if that actually *should* be the expected behavior, and the comment in the test seems to indicate that it may actually be testing for some internal regression:

```text
======================================================================
ERROR: testForExceptionsRaisedInInstanceGetattr2 (test.test_class.ClassTests.testForExceptionsRaisedInInstanceGetattr2)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/cdodd/proj/contrib/cpython/Lib/test/test_class.py"", line 592, in testForExceptionsRaisedInInstanceGetattr2
    E() == E() # In debug mode, caused a C-level assert() to fail
    ^^^^^^^^^^
  File ""/home/cdodd/proj/contrib/cpython/Lib/test/test_class.py"", line 580, in booh
    raise AttributeError(""booh"")
AttributeError: booh

```

But, as a compromise the following alternative checking specifically for `AttributeError` passes all tests enabled for my current platform. Depending on feedback here I am willing to contribute a pull request once I have a better idea as to what is expected/desired in these cases.

```c
    if (func == NULL) {
        PyObject* exc = PyErr_Occurred();

        if (exc != NULL){
          if (PyErr_GivenExceptionMatches(exc, PyExc_AttributeError)){
            // NOTE: suppresses only ""attribute"" errors
            PyErr_Clear();
          }else{
            return NULL;
          }
        }

        Py_RETURN_NOTIMPLEMENTED;
    }
```

### CPython versions tested on:

3.14, CPython main branch

### Operating systems tested on:

Linux","['class BadDescriptor:\n  def __get__(self, obj, cls=None):\n    assert False\n\nclass BadBase:\n  __eq__ = BadDescriptor()\n  __bool__ = BadDescriptor()\n\nb = BadBase()\n\nprint(f""{b == 1=}"")\nprint(f""{b.__eq__(1)=}"")', 'b == 1=False\nTraceback (most recent call last):\n  File ""bad_descriptor.py"", line 24, in <module>\n    print(f""{b.__eq__(1)=}"")\n             ^^^^^^^^\n  File ""bad_descriptor.py"", line 14, in __get__\n    assert False\n           ^^^^^\nAssertionError', 'if (func == NULL) {\n        PyErr_Clear();\n        Py_RETURN_NOTIMPLEMENTED;\n    }', 'if (func == NULL) {\n        if(PyErr_Occurred()){\n            return NULL;\n        }\n\n        Py_RETURN_NOTIMPLEMENTED;\n    }', '======================================================================\nERROR: testForExceptionsRaisedInInstanceGetattr2 (test.test_class.ClassTests.testForExceptionsRaisedInInstanceGetattr2)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""/home/cdodd/proj/contrib/cpython/Lib/test/test_class.py"", line 592, in testForExceptionsRaisedInInstanceGetattr2\n    E() == E() # In debug mode, caused a C-level assert() to fail\n    ^^^^^^^^^^\n  File ""/home/cdodd/proj/contrib/cpython/Lib/test/test_class.py"", line 580, in booh\n    raise AttributeError(""booh"")\nAttributeError: booh', 'if (func == NULL) {\n        PyObject* exc = PyErr_Occurred();\n\n        if (exc != NULL){\n          if (PyErr_GivenExceptionMatches(exc, PyExc_AttributeError)){\n            // NOTE: suppresses only ""attribute"" errors\n            PyErr_Clear();\n          }else{\n            return NULL;\n          }\n        }\n\n        Py_RETURN_NOTIMPLEMENTED;\n    }']","Yes, it should probably suppress AttributeError only; I suspect it was simply written this way because it's easier. I think we can probably afford to change this, but in 3.14 only.

Also, we should make sure to do this consistently for all special methods with fallbacks.",[],['python'],github,https://github.com/python/cpython/issues/131151,{'repo': 'python/cpython'}
"Inconsistent `Popen.communicate()` behavior if stdin/stdout/stderr is closed `PIPE`

# Bug report

### Bug description:

The behavior with `Popen.communicate()` if stdin/stdout/stderr are `PIPE`s and they are closed before calling `communicate()` is rather strange.

If both stdout and stderr are `PIPE`s and one (or both) is closed,  `communicate()` succeeds. If only one of them is a `PIPE` and it is closed, the behavior changes and there's a `ValueError` instead:

```python
>>> from subprocess import Popen, PIPE
>>>
>>> p = Popen(['python', '-V'], stdout=PIPE, stderr=PIPE)
>>> p.stdout.close()
>>> p.communicate()
(b'', b'')
>>>
>>> p = Popen(['python', '-V'], stdout=PIPE)
>>> p.stdout.close()
>>> p.communicate()
Traceback (most recent call last):
  File ""<python-input-7>"", line 1, in <module>
    p.communicate()
    ~~~~~~~~~~~~~^^
  File ""/usr/lib/python3.14/subprocess.py"", line 1207, in communicate
    stdout = self.stdout.read()
ValueError: read of closed file
```

If stdin is a closed `PIPE`, the behavior is pretty much the opposite of the above. If other streams are not `PIPE`s, `communicate()` succeeds, but if the are other `PIPE`s, we get a `ValueError`:

```python
>>> from subprocess import Popen, PIPE
>>>
>>> p = Popen(['python', '-c', 'pass'], stdin=PIPE)
>>> p.stdin.close()
>>> p.communicate()
(None, None)
>>> 
>>> p = Popen(['python', '-c', 'pass'], stdin=PIPE, stdout=PIPE)
>>> p.stdin.close()
>>> p.communicate()
Traceback (most recent call last):
  File ""<python-input-14>"", line 1, in <module>
    p.communicate()
    ~~~~~~~~~~~~~^^
  File ""/usr/lib/python3.14/subprocess.py"", line 1220, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
                     ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.14/subprocess.py"", line 2081, in _communicate
    self.stdin.flush()
    ~~~~~~~~~~~~~~~~^^
ValueError: flush of closed file
```

This inconsistency seems to be caused by an [optimization](https://github.com/python/cpython/blob/8431b1fee88301b8cc04968546fc465f5e0b1ce6/Lib/subprocess.py#L1194) that leads to two different code paths depending on the number of `PIPE`s. I needed to spend some time to understand why our tests behaved seemingly inconsistently after code was refactored.

It would be easy to fix problems by changing code like `if self.stdout:` to `if self.stdout and not self.stdout.closed:`. I guess it could be argued that raising a `ValueError` is the correct way to handle these situations, but in that case it should be raised always.

Tested with Python 3.14 alpha 5. Occurs also with earlier ones.


### CPython versions tested on:

3.14

### Operating systems tested on:

Linux","['>>> from subprocess import Popen, PIPE\n>>>\n>>> p = Popen([\'python\', \'-V\'], stdout=PIPE, stderr=PIPE)\n>>> p.stdout.close()\n>>> p.communicate()\n(b\'\', b\'\')\n>>>\n>>> p = Popen([\'python\', \'-V\'], stdout=PIPE)\n>>> p.stdout.close()\n>>> p.communicate()\nTraceback (most recent call last):\n  File ""<python-input-7>"", line 1, in <module>\n    p.communicate()\n    ~~~~~~~~~~~~~^^\n  File ""/usr/lib/python3.14/subprocess.py"", line 1207, in communicate\n    stdout = self.stdout.read()\nValueError: read of closed file', '>>> from subprocess import Popen, PIPE\n>>>\n>>> p = Popen([\'python\', \'-c\', \'pass\'], stdin=PIPE)\n>>> p.stdin.close()\n>>> p.communicate()\n(None, None)\n>>> \n>>> p = Popen([\'python\', \'-c\', \'pass\'], stdin=PIPE, stdout=PIPE)\n>>> p.stdin.close()\n>>> p.communicate()\nTraceback (most recent call last):\n  File ""<python-input-14>"", line 1, in <module>\n    p.communicate()\n    ~~~~~~~~~~~~~^^\n  File ""/usr/lib/python3.14/subprocess.py"", line 1220, in communicate\n    stdout, stderr = self._communicate(input, endtime, timeout)\n                     ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/usr/lib/python3.14/subprocess.py"", line 2081, in _communicate\n    self.stdin.flush()\n    ~~~~~~~~~~~~~~~~^^\nValueError: flush of closed file']","If this is agreed to be a bug, I can provide a PR fixing these inconsistencies so that closed `PIPE`s are always handled gracefully. In that case we needed to decide should `None` or an empty string/bytes (depending on `self.text_mode`) be returned if `stdout` or `stderr` is a closed `PIPE`. A naïve fix would return `None`, but the current un-optimized code path returns an empty string/bytes and changing it could cause backwards compatibility problems.",[],['python'],github,https://github.com/python/cpython/issues/131064,{'repo': 'python/cpython'}
"Make `sys.dllhandle` available on non-Windows

# Feature or enhancement

### Proposal:

We currently expose the Python library path, if available, as [`sys.dllhandle`](https://docs.python.org/3/library/sys.html#sys.dllhandle) on Windows. This could also be helpful on other platforms.

My main worry are `hasattr(sys, 'dllhandle')` checks that assume its availability on Windows only. @zooba, do you have any concerns about this?

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_",[],"I don't think this attribute transfers well to other OS's - it would be the equivalent of returning `dlopen(sysconfig.get_config_var(""LIBRARY""))` (or something like that - I guessed the variable name).

It's most useful for ctypes, which I believe already has a way to get the current Python API?",[],['python'],github,https://github.com/python/cpython/issues/129457,{'repo': 'python/cpython'}
"building 3.14.0a5 with tail-call interpreter from source fails when using clang-19

# Bug report

### Bug description:

Building the 3.14.0a5 [tarball](https://www.python.org/ftp/python/3.14.0/Python-3.14.0a5.tar.xz) provided by python.org fails when enabling the following options:

```sh
CC=clang-19 ./configure --enable-optimizations --with-lto=yes --enable-experimental-jit --with-tail-call-interp
```

The result is the following compilation error:

```
In file included from Python/ceval.c:786:
Python/generated_cases.c.h:4934:13: error: use of undeclared label 'error'
 4934 |             GOTO_TIER_TWO(executor);
      |             ^
Python/ceval_macros.h:398:14: note: expanded from macro 'GOTO_TIER_TWO'
  398 |         goto error;                                    \
      |              ^
In file included from Python/ceval.c:786:
Python/generated_cases.c.h:6968:25: error: use of undeclared label 'error'
 6968 |                         GOTO_TIER_TWO(executor);
      |                         ^
Python/ceval_macros.h:398:14: note: expanded from macro 'GOTO_TIER_TWO'
  398 |         goto error;                                    \
      |              ^
2 errors generated.
make[2]: *** [Makefile:3116: Python/ceval.o] Fehler 1
```

~~Performing the build without the `--with-tail-call-interp` option results in the following error instead:~~
(the error was caused by me failing to configure the LLVM version properly)
```
/usr/bin/llvm-ar rcs libpython3.14.a Modules/getbuildinfo.o Parser/token.o  Parser/pegen.o Parser/pegen_errors.o Parser/action_helpers.o Parser/parser.o Parser/string_parser.o Parser/peg_api.o Parser/lexer/buffer.o Parser/lexer/lexer.o Parser/lexer/state.o Parser/tokenizer/file_tokenizer.o Parser/tokenizer/readline_tokenizer.o Parser/tokenizer/string_tokenizer.o Parser/tokenizer/utf8_tokenizer.o Parser/tokenizer/helpers.o Parser/myreadline.o Objects/abstract.o Objects/boolobject.o Objects/bytes_methods.o Objects/bytearrayobject.o Objects/bytesobject.o Objects/call.o Objects/capsule.o Objects/cellobject.o Objects/classobject.o Objects/codeobject.o Objects/complexobject.o Objects/descrobject.o Objects/enumobject.o Objects/exceptions.o Objects/genericaliasobject.o Objects/genobject.o Objects/fileobject.o Objects/floatobject.o Objects/frameobject.o Objects/funcobject.o Objects/iterobject.o Objects/listobject.o Objects/longobject.o Objects/dictobject.o Objects/odictobject.o Objects/memoryobject.o Objects/methodobject.o Objects/moduleobject.o Objects/namespaceobject.o Objects/object.o Objects/obmalloc.o Objects/picklebufobject.o Objects/rangeobject.o Objects/setobject.o Objects/sliceobject.o Objects/structseq.o Objects/tupleobject.o Objects/typeobject.o Objects/typevarobject.o Objects/unicodeobject.o Objects/unicodectype.o Objects/unionobject.o Objects/weakrefobject.o Python/asm_trampoline.o Python/_warnings.o Python/Python-ast.o Python/Python-tokenize.o Python/asdl.o Python/assemble.o Python/ast.o Python/ast_opt.o Python/ast_unparse.o Python/bltinmodule.o Python/brc.o Python/ceval.o Python/codecs.o Python/codegen.o Python/compile.o Python/context.o Python/critical_section.o Python/crossinterp.o Python/dynamic_annotations.o Python/errors.o Python/flowgraph.o Python/frame.o Python/frozenmain.o Python/future.o Python/gc.o Python/gc_free_threading.o Python/gc_gil.o Python/getargs.o Python/getcompiler.o Python/getcopyright.o Python/getplatform.o Python/getversion.o Python/ceval_gil.o Python/hamt.o Python/hashtable.o Python/import.o Python/importdl.o Python/index_pool.o Python/initconfig.o Python/interpconfig.o Python/instrumentation.o Python/instruction_sequence.o Python/intrinsics.o Python/jit.o Python/legacy_tracing.o Python/lock.o Python/marshal.o Python/modsupport.o Python/mysnprintf.o Python/mystrtoul.o Python/object_stack.o Python/optimizer.o Python/optimizer_analysis.o Python/optimizer_symbols.o Python/parking_lot.o Python/pathconfig.o Python/preconfig.o Python/pyarena.o Python/pyctype.o Python/pyfpe.o Python/pyhash.o Python/pylifecycle.o Python/pymath.o Python/pystate.o Python/pythonrun.o Python/pytime.o Python/qsbr.o Python/bootstrap_hash.o Python/specialize.o Python/stackrefs.o Python/structmember.o Python/symtable.o Python/sysmodule.o Python/thread.o Python/traceback.o Python/tracemalloc.o Python/uniqueid.o Python/getopt.o Python/pystrcmp.o Python/pystrtod.o Python/pystrhex.o Python/dtoa.o Python/formatter_unicode.o Python/fileutils.o Python/suggestions.o Python/perf_trampoline.o Python/perf_jit_trampoline.o Python/dynload_shlib.o     Modules/config.o Modules/main.o Modules/gcmodule.o Modules/atexitmodule.o  Modules/faulthandler.o  Modules/posixmodule.o  Modules/signalmodule.o  Modules/_tracemalloc.o  Modules/_suggestions.o  Modules/_codecsmodule.o  Modules/_collectionsmodule.o  Modules/errnomodule.o  Modules/_io/_iomodule.o Modules/_io/iobase.o Modules/_io/fileio.o Modules/_io/bytesio.o Modules/_io/bufferedio.o Modules/_io/textio.o Modules/_io/stringio.o  Modules/itertoolsmodule.o  Modules/_sre/sre.o  Modules/_sysconfig.o  Modules/_threadmodule.o  Modules/timemodule.o  Modules/_typingmodule.o  Modules/_weakref.o  Modules/_abc.o  Modules/_functoolsmodule.o  Modules/_localemodule.o  Modules/_opcode.o  Modules/_operator.o  Modules/_stat.o  Modules/symtablemodule.o  Modules/pwdmodule.o Modules/getpath.o Python/frozen.o
/usr/bin/llvm-ar: error: libpython3.14.a: Opaque pointers are only supported in -opaque-pointers mode (Producer: 'LLVM19.1.7' Reader: 'LLVM 14.0.6')
```

The system used is running MX Linux (based on Debian 12.9) with Clang 19 provided by the packages from LLVM and building succeeds with the following options (default compiler is gcc 12.2.0):

```sh
./configure --enable-optimizations --with-lto=yes --enable-experimental-jit
```

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux","['CC=clang-19 ./configure --enable-optimizations --with-lto=yes --enable-experimental-jit --with-tail-call-interp', ""In file included from Python/ceval.c:786:\nPython/generated_cases.c.h:4934:13: error: use of undeclared label 'error'\n 4934 |             GOTO_TIER_TWO(executor);\n      |             ^\nPython/ceval_macros.h:398:14: note: expanded from macro 'GOTO_TIER_TWO'\n  398 |         goto error;                                    \\\n      |              ^\nIn file included from Python/ceval.c:786:\nPython/generated_cases.c.h:6968:25: error: use of undeclared label 'error'\n 6968 |                         GOTO_TIER_TWO(executor);\n      |                         ^\nPython/ceval_macros.h:398:14: note: expanded from macro 'GOTO_TIER_TWO'\n  398 |         goto error;                                    \\\n      |              ^\n2 errors generated.\nmake[2]: *** [Makefile:3116: Python/ceval.o] Fehler 1"", ""/usr/bin/llvm-ar rcs libpython3.14.a Modules/getbuildinfo.o Parser/token.o  Parser/pegen.o Parser/pegen_errors.o Parser/action_helpers.o Parser/parser.o Parser/string_parser.o Parser/peg_api.o Parser/lexer/buffer.o Parser/lexer/lexer.o Parser/lexer/state.o Parser/tokenizer/file_tokenizer.o Parser/tokenizer/readline_tokenizer.o Parser/tokenizer/string_tokenizer.o Parser/tokenizer/utf8_tokenizer.o Parser/tokenizer/helpers.o Parser/myreadline.o Objects/abstract.o Objects/boolobject.o Objects/bytes_methods.o Objects/bytearrayobject.o Objects/bytesobject.o Objects/call.o Objects/capsule.o Objects/cellobject.o Objects/classobject.o Objects/codeobject.o Objects/complexobject.o Objects/descrobject.o Objects/enumobject.o Objects/exceptions.o Objects/genericaliasobject.o Objects/genobject.o Objects/fileobject.o Objects/floatobject.o Objects/frameobject.o Objects/funcobject.o Objects/iterobject.o Objects/listobject.o Objects/longobject.o Objects/dictobject.o Objects/odictobject.o Objects/memoryobject.o Objects/methodobject.o Objects/moduleobject.o Objects/namespaceobject.o Objects/object.o Objects/obmalloc.o Objects/picklebufobject.o Objects/rangeobject.o Objects/setobject.o Objects/sliceobject.o Objects/structseq.o Objects/tupleobject.o Objects/typeobject.o Objects/typevarobject.o Objects/unicodeobject.o Objects/unicodectype.o Objects/unionobject.o Objects/weakrefobject.o Python/asm_trampoline.o Python/_warnings.o Python/Python-ast.o Python/Python-tokenize.o Python/asdl.o Python/assemble.o Python/ast.o Python/ast_opt.o Python/ast_unparse.o Python/bltinmodule.o Python/brc.o Python/ceval.o Python/codecs.o Python/codegen.o Python/compile.o Python/context.o Python/critical_section.o Python/crossinterp.o Python/dynamic_annotations.o Python/errors.o Python/flowgraph.o Python/frame.o Python/frozenmain.o Python/future.o Python/gc.o Python/gc_free_threading.o Python/gc_gil.o Python/getargs.o Python/getcompiler.o Python/getcopyright.o Python/getplatform.o Python/getversion.o Python/ceval_gil.o Python/hamt.o Python/hashtable.o Python/import.o Python/importdl.o Python/index_pool.o Python/initconfig.o Python/interpconfig.o Python/instrumentation.o Python/instruction_sequence.o Python/intrinsics.o Python/jit.o Python/legacy_tracing.o Python/lock.o Python/marshal.o Python/modsupport.o Python/mysnprintf.o Python/mystrtoul.o Python/object_stack.o Python/optimizer.o Python/optimizer_analysis.o Python/optimizer_symbols.o Python/parking_lot.o Python/pathconfig.o Python/preconfig.o Python/pyarena.o Python/pyctype.o Python/pyfpe.o Python/pyhash.o Python/pylifecycle.o Python/pymath.o Python/pystate.o Python/pythonrun.o Python/pytime.o Python/qsbr.o Python/bootstrap_hash.o Python/specialize.o Python/stackrefs.o Python/structmember.o Python/symtable.o Python/sysmodule.o Python/thread.o Python/traceback.o Python/tracemalloc.o Python/uniqueid.o Python/getopt.o Python/pystrcmp.o Python/pystrtod.o Python/pystrhex.o Python/dtoa.o Python/formatter_unicode.o Python/fileutils.o Python/suggestions.o Python/perf_trampoline.o Python/perf_jit_trampoline.o Python/dynload_shlib.o     Modules/config.o Modules/main.o Modules/gcmodule.o Modules/atexitmodule.o  Modules/faulthandler.o  Modules/posixmodule.o  Modules/signalmodule.o  Modules/_tracemalloc.o  Modules/_suggestions.o  Modules/_codecsmodule.o  Modules/_collectionsmodule.o  Modules/errnomodule.o  Modules/_io/_iomodule.o Modules/_io/iobase.o Modules/_io/fileio.o Modules/_io/bytesio.o Modules/_io/bufferedio.o Modules/_io/textio.o Modules/_io/stringio.o  Modules/itertoolsmodule.o  Modules/_sre/sre.o  Modules/_sysconfig.o  Modules/_threadmodule.o  Modules/timemodule.o  Modules/_typingmodule.o  Modules/_weakref.o  Modules/_abc.o  Modules/_functoolsmodule.o  Modules/_localemodule.o  Modules/_opcode.o  Modules/_operator.o  Modules/_stat.o  Modules/symtablemodule.o  Modules/pwdmodule.o Modules/getpath.o Python/frozen.o\n/usr/bin/llvm-ar: error: libpython3.14.a: Opaque pointers are only supported in -opaque-pointers mode (Producer: 'LLVM19.1.7' Reader: 'LLVM 14.0.6')"", './configure --enable-optimizations --with-lto=yes --enable-experimental-jit']",This is expected. JIT doesn't build with tail call interpreter at the moment. I fixed this in https://github.com/python/cpython/pull/129820 but it needs approval before merging.,[],['python'],github,https://github.com/python/cpython/issues/130021,{'repo': 'python/cpython'}
"Make Source Code a directive for easier translation

# Documentation

Currently 

```**Source code:** :source:Lib/FILE```

Is the standard way of link source code, we should make this a directive `.. source-code:: Lib/FILE`

This will make it easier for translators as we would not have to translate the same string a hundred times.",['**Source code:** :source:Lib/FILE'],"This feels like a tooling problem with translations rather than something to fix upstream - as you say, identical strings should just be able to have identical translations. As such I'm rather hesitant to make this change.

A",[],['python'],github,https://github.com/python/cpython/issues/129720,{'repo': 'python/cpython'}
"Possibly data race in dict popitem vs do_lookup, dictobject.c

# Bug report

### Bug description:

I built cpython 3.13 from source with TSAN and running the following code:

```python

import concurrent.futures
import threading


if __name__ == ""__main__"":
    num_workers = 20
    num_runs = 100

    barrier = threading.Barrier(num_workers)

    shared_dict = {}
    for i in range(50):
        shared_dict[f""{i}""] = i

    def closure():
        barrier.wait()

        for _ in range(num_runs):
            for i in range(10):
                key = f""{i}""
                if key in shared_dict:
                    obj = shared_dict[key]
                if len(shared_dict) > 0:
                    another_obj = shared_dict.popitem()

    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for i in range(num_workers):
            futures.append(executor.submit(closure))
        assert len(list(f.result() for f in futures)) == num_workers

```
TSAN reports the following data race:
<details>
<summary>
data race report
</summary>

```
==================
WARNING: ThreadSanitizer: data race (pid=379167)
  Write of size 8 at 0x7fffb46b66b0 by thread T20:
    #0 __tsan_memset <null> (python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 dict_popitem_impl /project/cpython/Objects/dictobject.c:4469:25 (python3.13+0x2768db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 dict_popitem /project/cpython/Objects/clinic/dictobject.c.h:220:20 (python3.13+0x2768db)
    #3 method_vectorcall_NOARGS /project/cpython/Objects/descrobject.c:447:24 (python3.13+0x200b61) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1eafea) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #5 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eafea)
    #6 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e35db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)
    #9 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #10 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)
    #12 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #13 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #14 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Previous atomic read of size 8 at 0x7fffb46b66b0 by thread T3:
    #0 _Py_atomic_load_ptr_relaxed /project/cpython/./Include/cpython/pyatomic_gcc.h:359:18 (python3.13+0x25f09c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 compare_unicode_unicode_threadsafe /project/cpython/Objects/dictobject.c:1397:26 (python3.13+0x25f09c)
    #2 do_lookup /project/cpython/Objects/dictobject.c:1066:23 (python3.13+0x25f09c)
    #3 unicodekeys_lookup_unicode_threadsafe /project/cpython/Objects/dictobject.c:1423:12 (python3.13+0x25f09c)
    #4 _Py_dict_lookup_threadsafe /project/cpython/Objects/dictobject.c:1478:18 (python3.13+0x260c37) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #5 _PyDict_Contains_KnownHash /project/cpython/Objects/dictobject.c:4691:10 (python3.13+0x26b366) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 PyDict_Contains /project/cpython/Objects/dictobject.c:4667:12 (python3.13+0x26b366)
    #7 PySequence_Contains /project/cpython/Objects/abstract.c:2277:19 (python3.13+0x1c2cdd) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:2358:27 (python3.13+0x3e99c9) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #10 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)
    #11 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #13 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)
    #14 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #16 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #18 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Thread T20 (tid=379188, running) created by main thread at:
    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)
    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)
    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)
    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)
    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)
    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)
    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)
    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Thread T3 (tid=379171, running) created by main thread at:
    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)
    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)
    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)
    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)
    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)
    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)
    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)
    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

SUMMARY: ThreadSanitizer: data race (/tmp/output-python/bin/python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa) in __tsan_memset
==================
==================
WARNING: ThreadSanitizer: data race (pid=379167)
  Write of size 8 at 0x7fffb46b66a0 by thread T4:
    #0 __tsan_memset <null> (python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 dict_popitem_impl /project/cpython/Objects/dictobject.c:4469:25 (python3.13+0x2768db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 dict_popitem /project/cpython/Objects/clinic/dictobject.c.h:220:20 (python3.13+0x2768db)
    #3 method_vectorcall_NOARGS /project/cpython/Objects/descrobject.c:447:24 (python3.13+0x200b61) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1eafea) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #5 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eafea)
    #6 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e35db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)
    #9 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #10 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)
    #12 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #13 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #14 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Previous atomic read of size 8 at 0x7fffb46b66a0 by thread T1:
    #0 _Py_atomic_load_ptr_relaxed /project/cpython/./Include/cpython/pyatomic_gcc.h:359:18 (python3.13+0x25f09c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 compare_unicode_unicode_threadsafe /project/cpython/Objects/dictobject.c:1397:26 (python3.13+0x25f09c)
    #2 do_lookup /project/cpython/Objects/dictobject.c:1066:23 (python3.13+0x25f09c)
    #3 unicodekeys_lookup_unicode_threadsafe /project/cpython/Objects/dictobject.c:1423:12 (python3.13+0x25f09c)
    #4 _Py_dict_lookup_threadsafe /project/cpython/Objects/dictobject.c:1478:18 (python3.13+0x260c37) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #5 dict_subscript /project/cpython/Objects/dictobject.c:3311:10 (python3.13+0x275be6) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 PyObject_GetItem /project/cpython/Objects/abstract.c:158:26 (python3.13+0x1b8e3c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:446:23 (python3.13+0x3e1cdf) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)
    #10 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)
    #13 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #14 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #15 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Thread T4 (tid=379172, running) created by main thread at:
    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)
    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)
    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)
    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)
    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)
    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)
    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)
    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

  Thread T1 (tid=379169, running) created by main thread at:
    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)
    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)
    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)
    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)
    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)
    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)
    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)
    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)
    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)

SUMMARY: ThreadSanitizer: data race (/tmp/output-python/bin/python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa) in __tsan_memset
==================
Traceback (most recent call last):
  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 31, in <module>
    assert len(list(f.result() for f in futures)) == num_workers
               ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 31, in <genexpr>
    assert len(list(f.result() for f in futures)) == num_workers
                    ~~~~~~~~^^
  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/_base.py"", line 456, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/thread.py"", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 23, in closure
    obj = shared_dict[key]
          ~~~~~~~~~~~^^^^^
KeyError: '0'
ThreadSanitizer: reported 2 warnings

```
</details>

We believe that this should be a bug. An expected behaviour should be no race in c-level. 

cpython version:
```
Python 3.13.2+ experimental free-threading build (heads/3.13:aa2c4e4417d, Mar  5 2025, 16:21:25) [Clang 18.1.3 (1ubuntu1)]
```

cc @hawkinsp 


### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-131115
* gh-131119
<!-- /gh-linked-prs -->
","['import concurrent.futures\nimport threading\n\n\nif __name__ == ""__main__"":\n    num_workers = 20\n    num_runs = 100\n\n    barrier = threading.Barrier(num_workers)\n\n    shared_dict = {}\n    for i in range(50):\n        shared_dict[f""{i}""] = i\n\n    def closure():\n        barrier.wait()\n\n        for _ in range(num_runs):\n            for i in range(10):\n                key = f""{i}""\n                if key in shared_dict:\n                    obj = shared_dict[key]\n                if len(shared_dict) > 0:\n                    another_obj = shared_dict.popitem()\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for i in range(num_workers):\n            futures.append(executor.submit(closure))\n        assert len(list(f.result() for f in futures)) == num_workers', '==================\nWARNING: ThreadSanitizer: data race (pid=379167)\n  Write of size 8 at 0x7fffb46b66b0 by thread T20:\n    #0 __tsan_memset <null> (python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 dict_popitem_impl /project/cpython/Objects/dictobject.c:4469:25 (python3.13+0x2768db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 dict_popitem /project/cpython/Objects/clinic/dictobject.c.h:220:20 (python3.13+0x2768db)\n    #3 method_vectorcall_NOARGS /project/cpython/Objects/descrobject.c:447:24 (python3.13+0x200b61) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1eafea) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #5 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eafea)\n    #6 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e35db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)\n    #9 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #10 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)\n    #12 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #13 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)\n    #14 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Previous atomic read of size 8 at 0x7fffb46b66b0 by thread T3:\n    #0 _Py_atomic_load_ptr_relaxed /project/cpython/./Include/cpython/pyatomic_gcc.h:359:18 (python3.13+0x25f09c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 compare_unicode_unicode_threadsafe /project/cpython/Objects/dictobject.c:1397:26 (python3.13+0x25f09c)\n    #2 do_lookup /project/cpython/Objects/dictobject.c:1066:23 (python3.13+0x25f09c)\n    #3 unicodekeys_lookup_unicode_threadsafe /project/cpython/Objects/dictobject.c:1423:12 (python3.13+0x25f09c)\n    #4 _Py_dict_lookup_threadsafe /project/cpython/Objects/dictobject.c:1478:18 (python3.13+0x260c37) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #5 _PyDict_Contains_KnownHash /project/cpython/Objects/dictobject.c:4691:10 (python3.13+0x26b366) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 PyDict_Contains /project/cpython/Objects/dictobject.c:4667:12 (python3.13+0x26b366)\n    #7 PySequence_Contains /project/cpython/Objects/abstract.c:2277:19 (python3.13+0x1c2cdd) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:2358:27 (python3.13+0x3e99c9) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #10 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)\n    #11 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #13 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)\n    #14 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)\n    #16 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #18 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Thread T20 (tid=379188, running) created by main thread at:\n    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)\n    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)\n    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)\n    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)\n    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)\n    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)\n    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)\n    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Thread T3 (tid=379171, running) created by main thread at:\n    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)\n    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)\n    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)\n    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)\n    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)\n    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)\n    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)\n    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\nSUMMARY: ThreadSanitizer: data race (/tmp/output-python/bin/python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa) in __tsan_memset\n==================\n==================\nWARNING: ThreadSanitizer: data race (pid=379167)\n  Write of size 8 at 0x7fffb46b66a0 by thread T4:\n    #0 __tsan_memset <null> (python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 dict_popitem_impl /project/cpython/Objects/dictobject.c:4469:25 (python3.13+0x2768db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 dict_popitem /project/cpython/Objects/clinic/dictobject.c.h:220:20 (python3.13+0x2768db)\n    #3 method_vectorcall_NOARGS /project/cpython/Objects/descrobject.c:447:24 (python3.13+0x200b61) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1eafea) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #5 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eafea)\n    #6 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e35db) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)\n    #9 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #10 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)\n    #12 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #13 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)\n    #14 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Previous atomic read of size 8 at 0x7fffb46b66a0 by thread T1:\n    #0 _Py_atomic_load_ptr_relaxed /project/cpython/./Include/cpython/pyatomic_gcc.h:359:18 (python3.13+0x25f09c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 compare_unicode_unicode_threadsafe /project/cpython/Objects/dictobject.c:1397:26 (python3.13+0x25f09c)\n    #2 do_lookup /project/cpython/Objects/dictobject.c:1066:23 (python3.13+0x25f09c)\n    #3 unicodekeys_lookup_unicode_threadsafe /project/cpython/Objects/dictobject.c:1423:12 (python3.13+0x25f09c)\n    #4 _Py_dict_lookup_threadsafe /project/cpython/Objects/dictobject.c:1478:18 (python3.13+0x260c37) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #5 dict_subscript /project/cpython/Objects/dictobject.c:3311:10 (python3.13+0x275be6) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 PyObject_GetItem /project/cpython/Objects/abstract.c:158:26 (python3.13+0x1b8e3c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:446:23 (python3.13+0x3e1cdf) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df70a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df70a)\n    #10 _PyFunction_Vectorcall /project/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 method_vectorcall /project/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)\n    #13 _PyVectorcall_Call /project/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #14 _PyObject_Call /project/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)\n    #15 PyObject_Call /project/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 thread_run /project/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ef2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 pythread_wrapper /project/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0e67) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Thread T4 (tid=379172, running) created by main thread at:\n    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)\n    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)\n    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)\n    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)\n    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)\n    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)\n    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)\n    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\n  Thread T1 (tid=379169, running) created by main thread at:\n    #0 pthread_create <null> (python3.13+0xde1df) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #1 do_start_joinable_thread /project/cpython/Python/thread_pthread.h:290:14 (python3.13+0x4bfd18) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #2 PyThread_start_joinable_thread /project/cpython/Python/thread_pthread.h:314:9 (python3.13+0x4bfb3a) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #3 ThreadHandle_start /project/cpython/./Modules/_threadmodule.c:422:9 (python3.13+0x567a87) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #4 do_start_new_thread /project/cpython/./Modules/_threadmodule.c:1849:9 (python3.13+0x567a87)\n    #5 thread_PyThread_start_joinable_thread /project/cpython/./Modules/_threadmodule.c:1972:14 (python3.13+0x566b81) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #6 cfunction_call /project/cpython/Objects/methodobject.c:540:18 (python3.13+0x28afe7) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #7 _PyObject_MakeTpCall /project/cpython/Objects/call.c:242:18 (python3.13+0x1ea44c) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #8 _PyObject_VectorcallTstate /project/cpython/./Include/internal/pycore_call.h:166:16 (python3.13+0x1eb0a8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #9 PyObject_Vectorcall /project/cpython/Objects/call.c:327:12 (python3.13+0x1eb0a8)\n    #10 _PyEval_EvalFrameDefault /project/cpython/Python/generated_cases.c.h:1502:19 (python3.13+0x3e625d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #11 _PyEval_EvalFrame /project/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df3e2) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #12 _PyEval_Vector /project/cpython/Python/ceval.c:1813:12 (python3.13+0x3df3e2)\n    #13 PyEval_EvalCode /project/cpython/Python/ceval.c:603:21 (python3.13+0x3df3e2)\n    #14 run_eval_code_obj /project/cpython/Python/pythonrun.c:1381:9 (python3.13+0x4a2d0e) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #15 run_mod /project/cpython/Python/pythonrun.c:1466:19 (python3.13+0x4a2435) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #16 pyrun_file /project/cpython/Python/pythonrun.c:1295:15 (python3.13+0x49df45) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #17 _PyRun_SimpleFileObject /project/cpython/Python/pythonrun.c:517:13 (python3.13+0x49df45)\n    #18 _PyRun_AnyFileObject /project/cpython/Python/pythonrun.c:77:15 (python3.13+0x49d698) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #19 pymain_run_file_obj /project/cpython/Modules/main.c:410:15 (python3.13+0x4db15f) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #20 pymain_run_file /project/cpython/Modules/main.c:429:15 (python3.13+0x4db15f)\n    #21 pymain_run_python /project/cpython/Modules/main.c:697:21 (python3.13+0x4da3ac) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #22 Py_RunMain /project/cpython/Modules/main.c:776:5 (python3.13+0x4da3ac)\n    #23 pymain_main /project/cpython/Modules/main.c:806:12 (python3.13+0x4da7e8) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #24 Py_BytesMain /project/cpython/Modules/main.c:830:12 (python3.13+0x4da86b) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n    #25 main /project/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa)\n\nSUMMARY: ThreadSanitizer: data race (/tmp/output-python/bin/python3.13+0xda21d) (BuildId: 3ae84a424a863e898f8ae5899a1f37386e6a2faa) in __tsan_memset\n==================\nTraceback (most recent call last):\n  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 31, in <module>\n    assert len(list(f.result() for f in futures)) == num_workers\n               ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 31, in <genexpr>\n    assert len(list(f.result() for f in futures)) == num_workers\n                    ~~~~~~~~^^\n  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/_base.py"", line 456, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/_base.py"", line 401, in __get_result\n    raise self._exception\n  File ""/tmp/output-python/lib/python3.13t/concurrent/futures/thread.py"", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File ""/project/playground/cpython_checks/dict_popitem/repro.py"", line 23, in closure\n    obj = shared_dict[key]\n          ~~~~~~~~~~~^^^^^\nKeyError: \'0\'\nThreadSanitizer: reported 2 warnings', 'Python 3.13.2+ experimental free-threading build (heads/3.13:aa2c4e4417d, Mar  5 2025, 16:21:25) [Clang 18.1.3 (1ubuntu1)]']",This is fixed now in 3.13 and main.,[],['python'],github,https://github.com/python/cpython/issues/131113,{'repo': 'python/cpython'}
"Python allow multiple + or - after * and / operation without reporting exception ""Invalid argument to operation"" ?

# Bug report

### Bug description:

The plus and minus symbols can be regarded as numeric sign flag before an operands, but it seems Python can put multiple plus or minus after operators and before operands , and Python do not report any exception something like invalid argument to operation.  The operations results depends on the number of signs for minus symbols, that is quite wired.

For Java or other language, they do report syntax errors. Think about the following codes, they all work.
Should we report syntax error  for this situation?
 
```python
# 
a=3; b=4
c=a *+ b
print(c)

a=3; b=4
c=a *++++++ b
print(c)


a=3; b=4
c=a *- b
print(c)

a=3; b=4
c=a *-- b
print(c)

a=3; b=4
c=a *--- b
print(c)

a=3; b=4
c=a /+++--- b
print(c)

'''Output: 
12
12
-12
12
-12
-0.75
'''
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Windows","[""# \na=3; b=4\nc=a *+ b\nprint(c)\n\na=3; b=4\nc=a *++++++ b\nprint(c)\n\n\na=3; b=4\nc=a *- b\nprint(c)\n\na=3; b=4\nc=a *-- b\nprint(c)\n\na=3; b=4\nc=a *--- b\nprint(c)\n\na=3; b=4\nc=a /+++--- b\nprint(c)\n\n'''Output: \n12\n12\n-12\n12\n-12\n-0.75\n'''""]","This invokes the unary `+` and `-` operators a number of times. Somewhat confusing behavior but it follows logically from the grammar.

You can see this with the `ast` module:

```
>>> print(ast.dump(ast.parse('a+++b'), indent=True))
Module(
 body=[
  Expr(
   value=BinOp(
    left=Name(id='a', ctx=Load()),
    op=Add(),
    right=UnaryOp(
     op=UAdd(),
     operand=UnaryOp(
      op=UAdd(),
      operand=Name(id='b', ctx=Load())))))])
```

And in the bytecode:

```
>>> dis.dis('a+++b')
  0           RESUME                   0

  1           LOAD_NAME                0 (a)
              LOAD_NAME                1 (b)
              CALL_INTRINSIC_1         5 (INTRINSIC_UNARY_POSITIVE)
              CALL_INTRINSIC_1         5 (INTRINSIC_UNARY_POSITIVE)
              BINARY_OP                0 (+)
              RETURN_VALUE
```","["">>> print(ast.dump(ast.parse('a+++b'), indent=True))\nModule(\n body=[\n  Expr(\n   value=BinOp(\n    left=Name(id='a', ctx=Load()),\n    op=Add(),\n    right=UnaryOp(\n     op=UAdd(),\n     operand=UnaryOp(\n      op=UAdd(),\n      operand=Name(id='b', ctx=Load())))))])"", "">>> dis.dis('a+++b')\n  0           RESUME                   0\n\n  1           LOAD_NAME                0 (a)\n              LOAD_NAME                1 (b)\n              CALL_INTRINSIC_1         5 (INTRINSIC_UNARY_POSITIVE)\n              CALL_INTRINSIC_1         5 (INTRINSIC_UNARY_POSITIVE)\n              BINARY_OP                0 (+)\n              RETURN_VALUE""]",['python'],github,https://github.com/python/cpython/issues/130773,{'repo': 'python/cpython'}
"Nested virtual environment support in site/venv modules

# Feature or enhancement

### Proposal:

It's a bit of a niche use case, but it would be helpful if you could have one virtual environment be created that references another as its parent.  If you currently attempt to do this, the `pyvenv.cfg` of the child virtual environment only indirectly references the parent through the `command` variable (which doesn't appear to be used).  The code in [site.venv](https://github.com/python/cpython/blob/f26daa9470925120f6336ca508f7ea193b00a3f4/Lib/site.py#L634) could be enhanced to infer the prefix of the parent environment and add those site packages after the current virtual environment.  This would ensure that the order of `sys.path` entries would be appropriate.

This would allow you to create a group virtual environment with a lot of common packages and still allow users to have their own child environments with additional or newer packages.

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_",[],"> This is a minor feature, which does not need previous discussion elsewhere

Is it? Virtual environments are meant to be isolated.

I understand the benefit of reducing redundancy and storage but introducing hierarchical dependencies means
* child environment is no longer truly independent
* If the parent environment is updated, the child environment may break unexpectedly
* Users may assume their environment is self-contained, but it actually depends on the parent

for example, `pip freeze` would list the child libraries, or both parent and child libraries?

",[],['python'],github,https://github.com/python/cpython/issues/129445,{'repo': 'python/cpython'}
"Add more tests for `getpass`

This is something I thought of when working #130496, I noticed that some tests were missing.
Test `Lib/test/test_getpass.py` only has three classes: `GetpassGetuserTest`, `GetpassRawinputTest`, `UnixGetpassTest`.

This clearly doesn't cover all cases, I think we should add at least `WinGetpassTest` and check that both implementations (`unix_getpass` and `win_getpass`) work the same.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130529
<!-- /gh-linked-prs -->
",[],"Just an FYI, the devguide has some information on how to systematically measure and increase test coverage: https://devguide.python.org/testing/coverage/",[],['python'],github,https://github.com/python/cpython/issues/130524,{'repo': 'python/cpython'}
"An error occurred while uploading a package

# Bug report

### Bug description:

When uploading a software package using the twine library,a frequent error of 403 with __token__ is reported.
I use of the content in Help is still not valid.
command: twine upload dist/* --verbose
update the library is still not valid.

### CPython versions tested on:

3.10

### Operating systems tested on:

Windows",[],"Sorry, this is a bugtracker of the CPython, you should ask for help or report issues to an appropriate project (twine maybe).",[],['python'],github,https://github.com/python/cpython/issues/130867,{'repo': 'python/cpython'}
"Store and use the current task of asyncio on thread state for all threads

`asyncio` currently stores the current task in a global dict `_current_tasks` and on thread state. Storing it on dict in free-threading will cause significant contention under many threads and such I propose to remove it and always rely on the task stored on the thread state.

This has the added benefit that external introspection will always have the correct task and it will  be guaranteed by this implementation while also being performant. 

cc @asvetlov @ambv @pablogsal  


<!-- gh-linked-prs -->
### Linked PRs
* gh-129899
<!-- /gh-linked-prs -->
",[],"Hi everyone,

This is a great improvement for asyncio, especially considering the potential contention issues in a free-threading environment. Storing the current task directly in the thread state seems like a more scalable and efficient approach.

I see that PR #129899 is already in progress. Are there any specific areas where feedback or testing would be most helpful? I’d love to understand if there are edge cases or performance benchmarks that need validation before merging.

Looking forward to your thoughts! Thanks for all the hard work on this!

",[],['python'],github,https://github.com/python/cpython/issues/129898,{'repo': 'python/cpython'}
"list iterator and list reverse iterator are not thread safe

While reviewing https://github.com/python/cpython/pull/130096,  I checked the thread safety of list object and there at some places we are missing atomic stores of index.

Specifically the following: 
- https://github.com/python/cpython/blob/97d0011e7ec0c8222de46ce581b8bac3cc7dddda/Objects/listobject.c#L3994-L3997
- https://github.com/python/cpython/blob/97d0011e7ec0c8222de46ce581b8bac3cc7dddda/Objects/listobject.c#L4146-L4149

They should use atomic relaxed stores.



<!-- gh-linked-prs -->
### Linked PRs
* gh-130266
<!-- /gh-linked-prs -->
",[],Fixed by 388e1ca9f08ee5caefd1dd946dc6e236ce73d46f,[],['python'],github,https://github.com/python/cpython/issues/130263,{'repo': 'python/cpython'}
"Annotate test cases which are timing sensitive

# Feature or enhancement

### Proposal:

Many tests in the cpython test suite are sensitive to timing and assume an entirely unloaded system. For example, the `TimerfdTests` check for 1ms accuracy in expected durations.  Some people (eg people building and testing python) may be running the test suite on build machines which are potentially heavily loaded so this sort of expectation isn't feasible.

It seems like a good solution to this would be to annotate the tests which are timing sensitive in some way, so they can be skipped easily.

For reference, we're manually patching python to skip tests which are failing under load but we're now having to rebase these patches on upgrades:
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-Skip-failing-tests-due-to-load-variability-on-YP-AB.patch
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-skip-no_stdout_fileno-test-due-to-load-variability.patch
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-test_active_children-skip-problematic-test.patch
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-test_deadlock-skip-problematic-test.patch
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-test_shutdown-skip-problematic-test.patch
* https://git.yoctoproject.org/poky/tree/meta/recipes-devtools/python/python3/0001-test_storlines-skip-due-to-load-variability.patch


### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130508
<!-- /gh-linked-prs -->
",[],"> Let's open a separate issue for the flaky tests as it could be orthogonal to tests that require an idle system due to stats gathering.

Issue's here: https://github.com/python/cpython/issues/130474

> I suggested ""stats"" because I don't think we should have a test that doesn't check against a population that some hypothesis is verified. However, I'm not sure we have any test that would test something else than timings like this.

Yeah, I'm not sure if we assert anything else besides timings that is similarly stochastic.. maybe we can stick with some time-related name for now and adjust it if something else comes up?",[],['python'],github,https://github.com/python/cpython/issues/130363,{'repo': 'python/cpython'}
"Avoid using deprecated typing aliases in `importlib`

# Feature or enhancement

### Proposal:

In the documentation it is written:
https://docs.python.org/3.14/library/typing.html#deprecated-aliases

The redundant types are deprecated as of Python 3.9. However, while the aliases may be removed at some point, removal of these aliases is not currently planned. As such, no deprecation warnings are currently issued by the interpreter for these aliases.

If at some point it is decided to remove these deprecated aliases, a deprecation warning will be issued by the interpreter for at least two releases prior to removal. The aliases are guaranteed to remain in the typing module without deprecation warnings until at least Python 3.14.

---

For importlib, there are already type annotations, and in the previous discussion it was felt that type annotations should be kept
See https://discuss.python.org/t/static-type-annotations-in-cpython/65068

> Where we are now, though, is that we have several bits and pieces of CPython that do use type annotations, and to good effect...

I'd like to clean up typing aliases that have been deprecated since python 3.9, although they won't have warnings at the moment. However, in the long run, for example, if a deprecation warning is prompted after 5 years, it will be a burden on the maintenance of stdlib.

For example, `from typing import List`
It can be replaced with a `list` of `_builtin`

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-129491
<!-- /gh-linked-prs -->
",[],"I answered in https://github.com/python/cpython/pull/129491#issuecomment-2629513349. Short answer is that for this kind of change, contribution to the third-party packages would be preferred. Thanks for understanding.",[],['python'],github,https://github.com/python/cpython/issues/129490,{'repo': 'python/cpython'}
"Crashing ""pyrepl"" with ""__getattr__""

# Bug report

### Bug description:

This is a regression introduced in 3.13 because the new pyrepl. 3.14 is also affected.

Type this in an interactive 3.13/3.14 session:

```python
>>> class a:
...     def __getattr__(self, x):
...         print(x)
...         print(qq)
...         
>>> b=a()
>>> b.pepe
pepe
qq
qq
Traceback (most recent call last):
  File ""<python-input-5>"", line 1, in <module>
  File ""<python-input-3>"", line 4, in __getattr__
NameError: name 'qq' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""/usr/local/lib/python3.13/_pyrepl/__main__.py"", line 6, in <module>
    __pyrepl_interactive_console()
  File ""/usr/local/lib/python3.13/_pyrepl/main.py"", line 59, in interactive_console
    run_multiline_interactive_console(console)
  File ""/usr/local/lib/python3.13/_pyrepl/simple_interact.py"", line 160, in run_multiline_interactive_console
    more = console.push(_strip_final_indent(statement), filename=input_name, _symbol=""single"")  # type: ignore[call-arg]
  File ""/usr/local/lib/python3.13/code.py"", line 314, in push
    more = self.runsource(source, filename, symbol=_symbol)
  File ""/usr/local/lib/python3.13/_pyrepl/console.py"", line 211, in runsource
    self.runcode(code)
  File ""/usr/local/lib/python3.13/code.py"", line 96, in runcode
    self.showtraceback()
  File ""/usr/local/lib/python3.13/code.py"", line 129, in showtraceback
    self._showtraceback(typ, value, tb.tb_next, '')
  File ""/usr/local/lib/python3.13/code.py"", line 145, in _showtraceback
    self._excepthook(typ, value, tb)
  File ""/usr/local/lib/python3.13/_pyrepl/console.py"", line 169, in _excepthook
    lines = traceback.format_exception(
  File ""/usr/local/lib/python3.13/traceback.py"", line 154, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File ""/usr/local/lib/python3.13/traceback.py"", line 1090, in __init__
    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)
  File ""/usr/local/lib/python3.13/traceback.py"", line 1516, in _compute_suggestion_error
    if hasattr(self, wrong_name):
  File ""<python-input-3>"", line 4, in __getattr__
NameError: name 'qq' is not defined
```
And the interactive python session is terminated.

Under previous Python releases, with no pyrepl, the right exception is raised and the repl keeps going:

```python
Python 3.9.21 (main, Dec  9 2024, 19:43:35) 
[GCC 10.5.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> class a:
...   def __getattr__(self, x):
...     print(x)
...     print(qq)
... 
>>> b=a()
>>> b.pepe
pepe
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 4, in __getattr__
NameError: name 'qq' is not defined
>>> 
```

Notice that this problem raises SPECIFICALLY if ```__getattr__``` raises a NameError exception. Other exceptions, like division by zero, don't break pyrepl.


### CPython versions tested on:

3.13, 3.12, 3.11, 3.10, 3.9, 3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129615
* gh-129632
<!-- /gh-linked-prs -->
","['>>> class a:\n...     def __getattr__(self, x):\n...         print(x)\n...         print(qq)\n...         \n>>> b=a()\n>>> b.pepe\npepe\nqq\nqq\nTraceback (most recent call last):\n  File ""<python-input-5>"", line 1, in <module>\n  File ""<python-input-3>"", line 4, in __getattr__\nNameError: name \'qq\' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""<frozen runpy>"", line 198, in _run_module_as_main\n  File ""<frozen runpy>"", line 88, in _run_code\n  File ""/usr/local/lib/python3.13/_pyrepl/__main__.py"", line 6, in <module>\n    __pyrepl_interactive_console()\n  File ""/usr/local/lib/python3.13/_pyrepl/main.py"", line 59, in interactive_console\n    run_multiline_interactive_console(console)\n  File ""/usr/local/lib/python3.13/_pyrepl/simple_interact.py"", line 160, in run_multiline_interactive_console\n    more = console.push(_strip_final_indent(statement), filename=input_name, _symbol=""single"")  # type: ignore[call-arg]\n  File ""/usr/local/lib/python3.13/code.py"", line 314, in push\n    more = self.runsource(source, filename, symbol=_symbol)\n  File ""/usr/local/lib/python3.13/_pyrepl/console.py"", line 211, in runsource\n    self.runcode(code)\n  File ""/usr/local/lib/python3.13/code.py"", line 96, in runcode\n    self.showtraceback()\n  File ""/usr/local/lib/python3.13/code.py"", line 129, in showtraceback\n    self._showtraceback(typ, value, tb.tb_next, \'\')\n  File ""/usr/local/lib/python3.13/code.py"", line 145, in _showtraceback\n    self._excepthook(typ, value, tb)\n  File ""/usr/local/lib/python3.13/_pyrepl/console.py"", line 169, in _excepthook\n    lines = traceback.format_exception(\n  File ""/usr/local/lib/python3.13/traceback.py"", line 154, in format_exception\n    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n  File ""/usr/local/lib/python3.13/traceback.py"", line 1090, in __init__\n    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)\n  File ""/usr/local/lib/python3.13/traceback.py"", line 1516, in _compute_suggestion_error\n    if hasattr(self, wrong_name):\n  File ""<python-input-3>"", line 4, in __getattr__\nNameError: name \'qq\' is not defined', 'Python 3.9.21 (main, Dec  9 2024, 19:43:35) \n[GCC 10.5.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> class a:\n...   def __getattr__(self, x):\n...     print(x)\n...     print(qq)\n... \n>>> b=a()\n>>> b.pepe\npepe\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\n  File ""<stdin>"", line 4, in __getattr__\nNameError: name \'qq\' is not defined\n>>>']","A quick fix (I'm not sure it's a right way):
```diff
diff --git a/Lib/traceback.py b/Lib/traceback.py
index 31c73efcef..abcc099c29 100644
--- a/Lib/traceback.py
+++ b/Lib/traceback.py
@@ -1520,8 +1520,11 @@ def _compute_suggestion_error(exc_value, tb, wrong_name):
         # has the wrong name as attribute
         if 'self' in frame.f_locals:
             self = frame.f_locals['self']
-            if hasattr(self, wrong_name):
-                return f""self.{wrong_name}""
+            try:
+                if hasattr(self, wrong_name):
+                    return f""self.{wrong_name}""
+            except NameError:
+                pass
 
     try:
         import _suggestions
```

```pycon
>>> b.pepe
pepe
qq
Traceback (most recent call last):
  File ""<python-input-2>"", line 1, in <module>
    b.pepe
  File ""<python-input-0>"", line 4, in __getattr__
    print(qq)
          ^^
NameError: name 'qq' is not defined
```","['diff --git a/Lib/traceback.py b/Lib/traceback.py\nindex 31c73efcef..abcc099c29 100644\n--- a/Lib/traceback.py\n+++ b/Lib/traceback.py\n@@ -1520,8 +1520,11 @@ def _compute_suggestion_error(exc_value, tb, wrong_name):\n         # has the wrong name as attribute\n         if \'self\' in frame.f_locals:\n             self = frame.f_locals[\'self\']\n-            if hasattr(self, wrong_name):\n-                return f""self.{wrong_name}""\n+            try:\n+                if hasattr(self, wrong_name):\n+                    return f""self.{wrong_name}""\n+            except NameError:\n+                pass\n \n     try:\n         import _suggestions', '>>> b.pepe\npepe\nqq\nTraceback (most recent call last):\n  File ""<python-input-2>"", line 1, in <module>\n    b.pepe\n  File ""<python-input-0>"", line 4, in __getattr__\n    print(qq)\n          ^^\nNameError: name \'qq\' is not defined']",['python'],github,https://github.com/python/cpython/issues/129605,{'repo': 'python/cpython'}
"Thousands separators in fractional part are ignored in width computation

# Bug report

### Bug description:

Examples:
```pycon
>>> f""{0.1234567891:010.6,f}""  # should be '00.123,457'
'000.123,457'
>>> len(_)
11
>>> f""{0.1234567891:010.7,f}""  # should be '0.123,456,8'
'00.123,456,8'
>>> len(_)
12
```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130865
<!-- /gh-linked-prs -->
","['>>> f""{0.1234567891:010.6,f}""  # should be \'00.123,457\'\n\'000.123,457\'\n>>> len(_)\n11\n>>> f""{0.1234567891:010.7,f}""  # should be \'0.123,456,8\'\n\'00.123,456,8\'\n>>> len(_)\n12']",fixed by [2352bd4](https://github.com/python/cpython/commit/2352bd418a7a0c38f8ea135bd1879937d90ecce1),[],['python'],github,https://github.com/python/cpython/issues/130860,{'repo': 'python/cpython'}
"The function unicodedata.normalize() should always return an instance of the built-in str type.

# Bug report

### Bug description:

The current implementation of unicodedata.normalize() returns a new reference to the input string when the data is already normalized. It is fine for instances of the built-in str type. However, if the function receives an instance of a subclass of str, the return type becomes inconsistent.

```
import unicodedata

class MyStr(str):
	pass

s1 = unicodedata.normalize('NFKC', MyStr('Å')) # U+00C5 (already normalized)
s2 = unicodedata.normalize('NFKC', MyStr('Å')) # U+0041 U+030A (not normalized)

print(type(s1), type(s2))		# <class '__main__.MyStr'> <class 'str'>
```

In addition, passing instances of user-defined str subclasses can lead to unexpected sharing of modifiable attributes:

```
import unicodedata

class MyStr(str):
	pass


original = MyStr('ascii string')
original.is_original = True

verified = unicodedata.normalize('NFKC', original)
verified.is_original = False

print(original.is_original)		# False
```

The solution would be to use the PyUnicode_FromObject() API for early returns in the normalize() function implementation instead of Py_NewRef() to make sure that the function always returns an instance of the built-in str type.



### CPython versions tested on:

3.11, 3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-129570
* gh-130403
* gh-130404
<!-- /gh-linked-prs -->
","[""import unicodedata\n\nclass MyStr(str):\n\tpass\n\ns1 = unicodedata.normalize('NFKC', MyStr('Å')) # U+00C5 (already normalized)\ns2 = unicodedata.normalize('NFKC', MyStr('Å')) # U+0041 U+030A (not normalized)\n\nprint(type(s1), type(s2))\t\t# <class '__main__.MyStr'> <class 'str'>"", ""import unicodedata\n\nclass MyStr(str):\n\tpass\n\n\noriginal = MyStr('ascii string')\noriginal.is_original = True\n\nverified = unicodedata.normalize('NFKC', original)\nverified.is_original = False\n\nprint(original.is_original)\t\t# False""]","If @serhiy-storchaka considers this a bug, then we can backport it. I was confused between this as behavior changes or a bug :)",[],['python'],github,https://github.com/python/cpython/issues/129569,{'repo': 'python/cpython'}
"Auto comment indented blocks when first line is commented

# Feature or enhancement

### Proposal:

Currently: Python does this
```python
class A:
    def B():
        print(""Whatever"")
```
When we comment out `class A:` (line 1), executing it will cause an indentation error (at line 2)

But if we want to comment out a whole class / def / with block, we have to manually comment out EVERY LINE.
Hence, i propose that:
When we comments out the first line of class / def / with block, Python interpreter auto-ignores the blocks in it.
So:
```python
class A:
    # Do something
# class B:
    def func(a):
        print(a)
```
In the code above, python auto ignores the B class. This could be useful for a big function that errors out but we don't know which line is the problem (and its hard to debug)

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_","['class A:\n    def B():\n        print(""Whatever"")', 'class A:\n    # Do something\n# class B:\n    def func(a):\n        print(a)']","Hi there! Thanks for the feature request, but unfortunately, I think you have a better chance of getting struck by lightning than this getting implemented :)

This would break *a lot* of code; commented-out function/class definitions in existing codebases could royaly screw things up, because the rest of the definition no longer becomes valid. For example:

```py
class Foo:
    # def a():
         def b():
             pass
```

The extra indentation on `b` is allowed in Python--so, was `b` supposed to be a nested function in `a`, or was it just a comment that was never removed, and then someone used a different tab-width?

Presumably, it would also be quite difficult to implement, because our compiler and interpreter both ignore comments--we would have to refactor the compiler to emit comments as AST nodes, and then the interpreter would have to be able to handle Python statements (or expressions too?) in said comments. 

> This could be useful for a big function that errors out but we don't know which line is the problem (and its hard to debug)

Or, you could look at the big Python traceback that comes out telling you exactly where things went wrong :smile:

I highly suggest looking into IDEs that come with an ""automatically comment-out all selected lines"" feature instead. (In fact, I'm not sure I know of an editor that *doesn't* provide this out of the box!)",['class Foo:\n    # def a():\n         def b():\n             pass'],['python'],github,https://github.com/python/cpython/issues/130681,{'repo': 'python/cpython'}
"Support comments as part of multiline values in configparser

# Feature or enhancement

### Proposal:

Today's configparser module does not consider lines being properly indented and starting with a comment_prefixes to be part of a multiline value. This can lead to unintended data loss during reading an INI file as:
**config.ini**
```ini
# I am a comment
    # I am also a comment
[dummy]
# I am a comment
key = I am a multiline
# I am a comment
    # multiline part which is not considered but should be
    being again part
# I am a comment
````

**test.py**
```python
import configparser
config = configparser.ConfigParser(comment_prefixes='#', interpolation=None, inline_comment_prefixes=None)
config.read('config.ini')
print(config['dummy']['key'])
# output: 'I am a multiline\nbeing again part'
# expected output:  'I am a multiline\n# multiline part which is not considered but should be\nbeing again part''
```

Therefore, I would propose to add a new parameter allow_comment_in_value (default False) in the ConfigParser class to support such scenarios. **Please note that in this scenario the comment_prefixes is set to '#' and any interpolation is disabled!**

Thanks and best regards! 

### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_","['# I am a comment\n    # I am also a comment\n[dummy]\n# I am a comment\nkey = I am a multiline\n# I am a comment\n    # multiline part which is not considered but should be\n    being again part\n# I am a comment', ""import configparser\nconfig = configparser.ConfigParser(comment_prefixes='#', interpolation=None, inline_comment_prefixes=None)\nconfig.read('config.ini')\nprint(config['dummy']['key'])\n# output: 'I am a multiline\\nbeing again part'\n# expected output:  'I am a multiline\\n# multiline part which is not considered but should be\\nbeing again part''""]",Hi @donBarbos have updated the description accordingly.,[],['python'],github,https://github.com/python/cpython/issues/130927,{'repo': 'python/cpython'}
"use -flto=thin for clang-cl on Windows

This started off as a build time analysis (https://github.com/python/cpython/issues/130090#issuecomment-2709951815), but since I now have the infrastructure, I tried `-flto=thin`, too:

- faster in building 520.6 vs 651.2 seconds
- is neutral on the pyperformance benchmarks
- would bring us in sync with Linux, because there  `CONFIGURE_CFLAGS_NODIST` and `CONFIGURE_LDFLAGS_NOLTO` both use `-flto=thin` when I configure for clang in WSL Ubuntu-24.04. See also the discussion why not to use full `-flto` in https://github.com/python/cpython/issues/130048

| Benchmark                       | clang.pgo.20.1.0-rc2 | clang.pgo.thin.20.1.0-rc2 |
|---------------------------------|:--------------------:|:-------------------------:|
| Geometric mean                  | (ref)                | 1.00x faster              |

<details><summary>Detailed pybenchmark results</summary>
<p>

| Benchmark                       | clang.pgo.20.1.0-rc2 | clang.pgo.thin.20.1.0-rc2 |
|---------------------------------|:--------------------:|:-------------------------:|
| float                           | 95.0 ms              | 89.7 ms: 1.06x faster     |
| json_loads                      | 29.8 us              | 28.6 us: 1.04x faster     |
| mdp                             | 2.86 sec             | 2.77 sec: 1.03x faster    |
| html5lib                        | 68.3 ms              | 66.2 ms: 1.03x faster     |
| async_tree_none_tg              | 330 ms               | 320 ms: 1.03x faster      |
| pyflate                         | 518 ms               | 505 ms: 1.03x faster      |
| sqlite_synth                    | 3.21 us              | 3.13 us: 1.03x faster     |
| pidigits                        | 228 ms               | 223 ms: 1.02x faster      |
| bench_mp_pool                   | 168 ms               | 165 ms: 1.02x faster      |
| async_tree_eager_io             | 742 ms               | 727 ms: 1.02x faster      |
| generators                      | 34.5 ms              | 33.8 ms: 1.02x faster     |
| comprehensions                  | 18.3 us              | 17.9 us: 1.02x faster     |
| async_tree_cpu_io_mixed         | 641 ms               | 629 ms: 1.02x faster      |
| scimark_sparse_mat_mult         | 4.51 ms              | 4.43 ms: 1.02x faster     |
| async_tree_memoization          | 425 ms               | 417 ms: 1.02x faster      |
| sympy_expand                    | 538 ms               | 529 ms: 1.02x faster      |
| unpack_sequence                 | 57.0 ns              | 56.0 ns: 1.02x faster     |
| regex_dna                       | 209 ms               | 205 ms: 1.02x faster      |
| async_generators                | 465 ms               | 458 ms: 1.02x faster      |
| scimark_sor                     | 140 ms               | 137 ms: 1.02x faster      |
| sympy_str                       | 319 ms               | 314 ms: 1.02x faster      |
| async_tree_io_tg                | 751 ms               | 740 ms: 1.01x faster      |
| regex_effbot                    | 3.14 ms              | 3.10 ms: 1.01x faster     |
| async_tree_eager_tg             | 272 ms               | 268 ms: 1.01x faster      |
| pickle_dict                     | 27.3 us              | 27.0 us: 1.01x faster     |
| async_tree_eager_memoization_tg | 363 ms               | 359 ms: 1.01x faster      |
| sympy_integrate                 | 22.5 ms              | 22.2 ms: 1.01x faster     |
| sympy_sum                       | 181 ms               | 179 ms: 1.01x faster      |
| 2to3                            | 390 ms               | 386 ms: 1.01x faster      |
| hexiom                          | 6.68 ms              | 6.61 ms: 1.01x faster     |
| docutils                        | 3.03 sec             | 3.00 sec: 1.01x faster    |
| sqlglot_normalize               | 121 ms               | 120 ms: 1.01x faster      |
| async_tree_memoization_tg       | 392 ms               | 389 ms: 1.01x faster      |
| async_tree_cpu_io_mixed_tg      | 614 ms               | 609 ms: 1.01x faster      |
| tomli_loads                     | 2.20 sec             | 2.18 sec: 1.01x faster    |
| spectral_norm                   | 102 ms               | 101 ms: 1.01x faster      |
| python_startup_no_site          | 34.4 ms              | 34.2 ms: 1.01x faster     |
| genshi_text                     | 24.6 ms              | 24.5 ms: 1.01x faster     |
| dulwich_log                     | 119 ms               | 118 ms: 1.00x faster      |
| go                              | 128 ms               | 128 ms: 1.00x faster      |
| deltablue                       | 3.62 ms              | 3.63 ms: 1.00x slower     |
| unpickle_pure_python            | 247 us               | 248 us: 1.00x slower      |
| xml_etree_generate              | 107 ms               | 107 ms: 1.01x slower      |
| django_template                 | 39.2 ms              | 39.4 ms: 1.01x slower     |
| coroutines                      | 24.8 ms              | 25.0 ms: 1.01x slower     |
| mako                            | 13.3 ms              | 13.5 ms: 1.01x slower     |
| unpickle                        | 15.9 us              | 16.1 us: 1.01x slower     |
| nbody                           | 119 ms               | 121 ms: 1.01x slower      |
| fannkuch                        | 465 ms               | 472 ms: 1.01x slower      |
| crypto_pyaes                    | 81.3 ms              | 82.6 ms: 1.02x slower     |
| json_dumps                      | 11.5 ms              | 11.7 ms: 1.02x slower     |
| deepcopy                        | 285 us               | 291 us: 1.02x slower      |
| pprint_safe_repr                | 858 ms               | 876 ms: 1.02x slower      |
| xml_etree_iterparse             | 136 ms               | 139 ms: 1.02x slower      |
| gc_traversal                    | 5.03 ms              | 5.14 ms: 1.02x slower     |
| meteor_contest                  | 115 ms               | 117 ms: 1.02x slower      |
| deepcopy_memo                   | 33.8 us              | 34.7 us: 1.03x slower     |
| richards_super                  | 51.1 ms              | 52.6 ms: 1.03x slower     |
| scimark_fft                     | 327 ms               | 337 ms: 1.03x slower      |
| richards                        | 44.9 ms              | 46.3 ms: 1.03x slower     |
| pickle_list                     | 4.83 us              | 4.99 us: 1.03x slower     |
| deepcopy_reduce                 | 2.93 us              | 3.03 us: 1.03x slower     |
| pprint_pformat                  | 1.74 sec             | 1.80 sec: 1.03x slower    |
| logging_simple                  | 10.9 us              | 11.4 us: 1.05x slower     |
| logging_format                  | 12.1 us              | 12.6 us: 1.05x slower     |
| xml_etree_parse                 | 197 ms               | 208 ms: 1.05x slower      |
| Geometric mean                  | (ref)                | 1.00x faster              |


</p>
</details> 

|            | pgo_clang_20.1.0-rc2 | pgo_clang_thin_20.1.0-rc2 |
|------------|:--------------------:|:-------------------------:|
| pginstr    |  297.2               |  219.3                    |
| pgo        |   70.0               |   69.0                    |
| kill       |    1.2               |    0.5                    |
| pgupd      |  282.8               |  231.7                    |
| total time |  651.2               |  520.6                    |



<details><summary>Details pginstrument</summary>
<p>

|                     | pgo_clang_20.1.0-rc2 | pgo_clang_thin_20.1.0-rc2 |
|---------------------|:--------------------:|:-------------------------:|
| _freeze_module      |   38.5               |   40.0                    |
| python314           |  141.5               |   81.3                    |
| pyexpat             |   52.7               |    3.9                    |
| _elementtree        |   51.8               |    5.3                    |
| sqlite3             |   46.0               |   42.4                    |
| liblzma             |   18.2               |   16.5                    |
| _decimal            |   12.4               |    7.7                    |
| _testcapi           |    8.3               |    7.1                    |
| _bz2                |    7.0               |    4.9                    |
| _ctypes             |    6.9               |    7.5                    |
| _testlimitedcapi    |    4.9               |    4.3                    |
| _wmi                |    4.5               |    3.0                    |
| _overlapped         |    4.5               |    3.2                    |
| _asyncio            |    4.0               |    5.2                    |
| _lzma               |    3.8               |    1.8                    |
| _ssl                |    3.7               |    5.5                    |
| _ctypes_test        |    3.7               |    3.4                    |
| _multiprocessing    |    3.5               |    2.7                    |
| _sqlite3            |    3.4               |    2.8                    |
| venvwlauncher       |    3.3               |    2.7                    |
| _zoneinfo           |    3.1               |    3.4                    |
| unicodedata         |    2.7               |    3.0                    |
| pyshellext          |    2.7               |    2.6                    |
| pyw                 |    2.7               |    2.7                    |
| py                  |    2.6               |    2.5                    |
| _socket             |    2.4               |    3.7                    |
| _testinternalcapi   |    2.4               |    2.2                    |
| _tkinter            |    2.2               |    4.1                    |
| _testclinic         |    2.0               |    1.9                    |
| _hashlib            |    1.8               |    3.1                    |
| select              |    1.8               |    2.2                    |
| venvlauncher        |    1.8               |    1.7                    |
| winsound            |    1.7               |    3.3                    |
| _uuid               |    1.6               |    3.2                    |
| _queue              |    1.6               |    2.3                    |
| _testembed          |    1.5               |    1.5                    |
| _testbuffer         |    1.4               |    1.3                    |
| pythonw             |    1.1               |    1.1                    |
| _testconsole        |    1.1               |    1.1                    |
| _testmultiphase     |    1.0               |    1.0                    |
| _testsinglephase    |    1.0               |    1.0                    |
| python              |    1.0               |    0.9                    |
| _testclinic_limited |    0.9               |    0.9                    |
| _testimportmultiple |    0.9               |    0.9                    |
| python3             |    0.5               |    0.5                    |
| total               |  465.8               |  303.3                    |

</p>
</details> 

<details><summary>Details pgupdate</summary>
<p>

|                     | pgo_clang_20.1.0-rc2 | pgo_clang_thin_20.1.0-rc2 |
|---------------------|:--------------------:|:-------------------------:|
| _freeze_module      |   38.0               |   39.5                    |
| python314           |  141.9               |   95.4                    |
| sqlite3             |   44.4               |   42.9                    |
| liblzma             |   17.3               |   16.5                    |
| _decimal            |   11.2               |    8.7                    |
| _testcapi           |    8.6               |    7.3                    |
| _ctypes             |    8.0               |    7.2                    |
| _bz2                |    7.8               |    5.5                    |
| _ssl                |    5.2               |    5.6                    |
| _testlimitedcapi    |    5.0               |    4.2                    |
| pyexpat             |    4.6               |    3.6                    |
| _asyncio            |    4.5               |    4.6                    |
| _socket             |    4.3               |    3.5                    |
| _tkinter            |    4.0               |    4.2                    |
| _ctypes_test        |    3.7               |    3.4                    |
| _overlapped         |    3.5               |    3.7                    |
| _elementtree        |    3.5               |    4.5                    |
| _wmi                |    3.5               |    3.1                    |
| _zoneinfo           |    3.2               |    3.2                    |
| _lzma               |    3.2               |    1.9                    |
| unicodedata         |    3.2               |    3.0                    |
| _sqlite3            |    3.1               |    2.7                    |
| _hashlib            |    3.1               |    3.3                    |
| venvwlauncher       |    3.1               |    3.0                    |
| _multiprocessing    |    2.8               |    2.6                    |
| pyshellext          |    2.7               |    2.6                    |
| pyw                 |    2.6               |    2.6                    |
| _uuid               |    2.6               |    2.8                    |
| py                  |    2.6               |    2.7                    |
| _testinternalcapi   |    2.4               |    2.2                    |
| _testclinic         |    2.0               |    1.9                    |
| _queue              |    1.9               |    2.2                    |
| winsound            |    1.8               |    3.0                    |
| venvlauncher        |    1.7               |    1.5                    |
| select              |    1.6               |    2.0                    |
| _testembed          |    1.5               |    1.4                    |
| _testbuffer         |    1.4               |    1.3                    |
| _testconsole        |    1.1               |    1.0                    |
| pythonw             |    1.1               |    1.1                    |
| _testmultiphase     |    1.0               |    1.1                    |
| _testsinglephase    |    1.0               |    1.0                    |
| python              |    1.0               |    0.9                    |
| _testclinic_limited |    0.9               |    0.9                    |
| _testimportmultiple |    0.9               |    0.9                    |
| python3             |    0.5               |    0.5                    |
| total               |  372.9               |  316.8                    |

</p>
</details> 

<!-- gh-linked-prs -->
### Linked PRs
* gh-131036
<!-- /gh-linked-prs -->
",[],"@zooba: yippie, that was a fast one :rocket:

PR is merged. Shall I close the issue (or is this a core-dev task)? I see, I get the option to ""close as completed"".",[],['python'],github,https://github.com/python/cpython/issues/131035,{'repo': 'python/cpython'}
"Incorrect details for `os.path.abspath()` documentation

# Documentation

https://github.com/python/cpython/blob/3a555f09f387a0212e5961535ae4e31178b26c11/Doc/library/os.path.rst?plain=1#L59-L61

claim is wrong, because `normpath(join(os.getcwd(), path))` is **only** called when the pathname is not absolute.<br>
If the claim would be true, every absolute pathname would get the cwd prepended.

Cheers,
Chris.",[],"~~AFAICT, we could amend the docs by adding ""For non-absolute paths, on most platforms, [...]"".~~

EDIT: See https://github.com/python/cpython/issues/130527#issuecomment-2680048584

cc @barneygale ",[],['python'],github,https://github.com/python/cpython/issues/130527,{'repo': 'python/cpython'}
"Inconsistent name mangling in `TypedDict` in function and class forms

# Bug report

Let's say that you have a dict like `{""__key"": 1}` and you want to type it.

You can write:

```python
>>> import typing
>>> class A(typing.TypedDict):
...     __key: int

>>> A.__mutable_keys__
frozenset({'_A__key'})
```

and:

```python
>>> B = typing.TypedDict(""B"", [(""__key"", int)])
>>> B.__mutable_keys__
frozenset({'__key'})
```

Note that `A` mangles `__key` as a regular name. While `B` does not.

I guess that it is expected, but!
Docs (https://docs.python.org/3/library/typing.html#typing.TypedDict) does not say anything about this behavior. We only mention that functional form should be used for invalid identifiers. But, `__key` is a valid indentifier.
We don't have explicit tests for this either.
And Typing Spec does not mention this as well: https://typing.readthedocs.io/en/latest/spec/typeddict.html


So, what we can do:
- Do not mangle names in this case (hard and problematic: it can break existing stuff)
- Document and test current behavior (my vote)

Please, share your thoughts on this. And I willing to send a PR with the fix.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130233
* gh-130841
* gh-130842
<!-- /gh-linked-prs -->
","["">>> import typing\n>>> class A(typing.TypedDict):\n...     __key: int\n\n>>> A.__mutable_keys__\nfrozenset({'_A__key'})"", '>>> B = typing.TypedDict(""B"", [(""__key"", int)])\n>>> B.__mutable_keys__\nfrozenset({\'__key\'})']",I'm +1 for documenting this and linking to the section about mangling so that users know how to write a mangling/demangling helper if needs arise (if they don't want to use the functional syntax),[],['python'],github,https://github.com/python/cpython/issues/129567,{'repo': 'python/cpython'}
"`test_active_children` multiprocessing test is flaky

# Bug report

Seen in https://github.com/python/cpython/actions/runs/13606431591/job/38038447198?pr=130724

```
FAIL: test_active_children (test.test_multiprocessing_spawn.test_threads.WithThreadsTestProcess.test_active_children)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\a\cpython\cpython\Lib\test\_test_multiprocessing.py"", line 597, in test_active_children
    self.assertIn(p, self.active_children())
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: <DummyProcess(Thread-120 (sleep), stopped daemon 6440)> not found in []
```

Test succeeded when retried.

Also see the old issue:

* https://github.com/python/cpython/issues/50910

<!-- gh-linked-prs -->
### Linked PRs
* gh-130731
* gh-130837
* gh-130845
* gh-130846
<!-- /gh-linked-prs -->
","['FAIL: test_active_children (test.test_multiprocessing_spawn.test_threads.WithThreadsTestProcess.test_active_children)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""D:\\a\\cpython\\cpython\\Lib\\test\\_test_multiprocessing.py"", line 597, in test_active_children\n    self.assertIn(p, self.active_children())\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: <DummyProcess(Thread-120 (sleep), stopped daemon 6440)> not found in []']","The test uses a sleep as a synchronization method: it's not reliable. If the process completes before `self.assertIn(p, self.active_children())`, the test fails.

I wrote https://github.com/python/cpython/pull/130837 to replace the sleep with an event.",[],['python'],github,https://github.com/python/cpython/issues/130730,{'repo': 'python/cpython'}
"Subclasses are GC'ed even though it changes `__subclasses__()` results

# Bug report

### Bug description:

Let's say I have an abstract class / protocol.

However, some of them are automatically generated in anonymous scopes as syntax sugar (in below's example, `function` is easier to write than `ExtendBaseClass`).

I would have to access it through `__subclasses__()`.

Since `__subclasses__` behavior changes just by calling `gc.collect()`, I believe this to be a bug.

See code below:

```python
class SomeBaseClass:
    def compute(self) -> int:
        return 1


def adapt_function(f):
    class ExtendBaseClass(SomeBaseClass):
        def compute(self):
            return f()

    return f


@adapt_function
def function():
    return 2


def find_all_subclass(cls: type, result: set):
    result.add(cls)

    for subcls in cls.__subclasses__():
        find_all_subclass(subcls, result)


def main():
    result = set()
    find_all_subclass(SomeBaseClass, result)
    print(result)


if __name__ == ""__main__"":
    print(""Before GC"")
    main()
    import gc

    gc.collect()
    print(""After GC"")
    main()
  ```

Output:
```
(venv) ➜  ~ python main.py
Before GC
{<class '__main__.adapt_function.<locals>.ExtendBaseClass'>, <class '__main__.SomeBaseClass'>}
After GC
{<class '__main__.SomeBaseClass'>}
```

### CPython versions tested on:

3.11

### Operating systems tested on:

Linux","['class SomeBaseClass:\n    def compute(self) -> int:\n        return 1\n\n\ndef adapt_function(f):\n    class ExtendBaseClass(SomeBaseClass):\n        def compute(self):\n            return f()\n\n    return f\n\n\n@adapt_function\ndef function():\n    return 2\n\n\ndef find_all_subclass(cls: type, result: set):\n    result.add(cls)\n\n    for subcls in cls.__subclasses__():\n        find_all_subclass(subcls, result)\n\n\ndef main():\n    result = set()\n    find_all_subclass(SomeBaseClass, result)\n    print(result)\n\n\nif __name__ == ""__main__"":\n    print(""Before GC"")\n    main()\n    import gc\n\n    gc.collect()\n    print(""After GC"")\n    main()', ""(venv) ➜  ~ python main.py\nBefore GC\n{<class '__main__.adapt_function.<locals>.ExtendBaseClass'>, <class '__main__.SomeBaseClass'>}\nAfter GC\n{<class '__main__.SomeBaseClass'>}""]",I'm not sure it changes the _behavior_ of `__subclasses__()`; it changes the result.,[],['python'],github,https://github.com/python/cpython/issues/130072,{'repo': 'python/cpython'}
"Failed assertion in `_PyUnicode_Equal` from `calculate_suggestions` with non-string candidate

# Crash report

### What happened?

The interpreter will abort if `runpy._run_module_code` is called with invalid values:
```python
import runpy
runpy._run_module_code(""A"", {0: """"}, """")
```

Another way to trigger:
```python
class Parent:
    def __dir__(self):
        return [0]

class WithNonStringAttrs(Parent):
    blech = None

WithNonStringAttrs().bluch
```

Abort message:
```
python: Objects/unicodeobject.c:10799: _PyUnicode_Equal: Assertion `PyUnicode_Check(str2)' failed.
Aborted (core dumped)
```

The suggestions machinery is the source of the issue, with `calculate_suggestions` calling `_PyUnicode_Equal(name, item)` for an item that might not be unicode.

Only aborts in 3.12. In 3.13 and main it results in an error in the traceback machinery:
```
Exception ignored in the internal traceback machinery:
Traceback (most recent call last):
  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 139, in _print_exception_bltin
    return print_exception(exc, limit=BUILTIN_EXCEPTION_LIMIT, file=file, colorize=colorize)
  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 129, in print_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 1090, in __init__
    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)
  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 1531, in _compute_suggestion_error
    return _suggestions._generate_suggestions(d, wrong_name)
TypeError: all elements in 'candidates' must be strings
[...]
```

Will submit a PR shortly.

Found using [fusil](https://github.com/devdanzin/fusil) by @vstinner.

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.12.8+ (heads/3.12:580d7810946, Feb  2 2025, 01:56:47) [GCC 13.3.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-129574
* gh-130997
<!-- /gh-linked-prs -->
","['import runpy\nrunpy._run_module_code(""A"", {0: """"}, """")', 'class Parent:\n    def __dir__(self):\n        return [0]\n\nclass WithNonStringAttrs(Parent):\n    blech = None\n\nWithNonStringAttrs().bluch', ""python: Objects/unicodeobject.c:10799: _PyUnicode_Equal: Assertion `PyUnicode_Check(str2)' failed.\nAborted (core dumped)"", 'Exception ignored in the internal traceback machinery:\nTraceback (most recent call last):\n  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 139, in _print_exception_bltin\n    return print_exception(exc, limit=BUILTIN_EXCEPTION_LIMIT, file=file, colorize=colorize)\n  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 129, in print_exception\n    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 1090, in __init__\n    suggestion = _compute_suggestion_error(exc_value, exc_traceback, wrong_name)\n  File ""/home/danzin/projects/upstream_cpython/Lib/traceback.py"", line 1531, in _compute_suggestion_error\n    return _suggestions._generate_suggestions(d, wrong_name)\nTypeError: all elements in \'candidates\' must be strings\n[...]']","In Rust parlance we'd say that this code is ""unsound"" -- there's not a vulnerability to be directly exploited, but depending on the code written by the user, it may be possible to produce a vulnerability.

The question here is whether there is non-pathological Python code that might make this exploitable by a user? I'm not sure if there is.",[],['python'],github,https://github.com/python/cpython/issues/129573,{'repo': 'python/cpython'}
"turtle

# Documentation

(A clear and concise description of the issue.)

From documentation, to color change it is ('color'), but in actual coding, it is (""color"")",[],Using single or double quotes is identical in Python. Both produce the same strings.,[],['python'],github,https://github.com/python/cpython/issues/130868,{'repo': 'python/cpython'}
"Clarify the meaning `dataclasses.field(..., hash=False)`

See https://discuss.python.org/t/unclear-docs-for-dataclasses-field/80716. Currently the docs are:

> hash: This can be a bool or None. If true, this field is included in the generated [\_\_hash\_\_()](https://docs.python.org/3/reference/datamodel.html#object.__hash__) method. If None (the default), use the value of compare: this would normally be the expected behavior. A field should be considered in the hash if it’s used for comparisons. Setting this value to anything other than None is discouraged.

We can change it to

```diff
 hash: This can be a bool or None. If true, this field is included in the generated :meth:`~object.__hash__` method.
+If false, this field is excluded from the generated :meth:`~object.__hash__` method.
 If :const:`None` (the default), use the value of compare: this would normally be the expected behavior.
```

<!-- gh-linked-prs -->
### Linked PRs
* gh-130324
* gh-130336
* gh-130337
<!-- /gh-linked-prs -->
","['hash: This can be a bool or None. If true, this field is included in the generated :meth:`~object.__hash__` method.\n+If false, this field is excluded from the generated :meth:`~object.__hash__` method.\n If :const:`None` (the default), use the value of compare: this would normally be the expected behavior.']","I also think it should be changed from:

`If None (the default), use the value of compare: this would normally be the expected behavior. A field should be considered in the hash if it’s used for comparisons. `

to

`If None (the default), use the value of compare: this would normally be the expected behavior, since a field should be included in the hash if it’s used for comparisons. `
",[],['python'],github,https://github.com/python/cpython/issues/130130,{'repo': 'python/cpython'}
"Flaky `test.test_concurrent_futures.test_wait` on free-threaded build

# Bug report

### Bug description:

See https://github.com/python/cpython/actions/runs/13604468612/job/38034332952?pr=121185. Not sure if it's a flaky or a real bug. But I'll start reporting issues on free-threading builds from now on, just in case.

cc @colesbury 

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_",[],Please just file the issue if you don't see an existing one. It's not a big deal if there's an occasional duplicate issue.,[],['python'],github,https://github.com/python/cpython/issues/130723,{'repo': 'python/cpython'}
"Minimal build support when using LibreSSL

# Bug report

### Bug description:

On systems using LibreSSL, using OpenBSD 7.6 in this example, you see the following:

```shell
$ ./configure
$ gmake
[...]
cc -pthread  -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall    -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ssl.c -o Modules/_ssl.o
./Modules/_ssl.c:4800:18: error: call to undeclared function 'X509_OBJECT_set1_X509'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]
            ok = X509_OBJECT_set1_X509(ret, X509_OBJECT_get0_X509(obj));
                 ^
./Modules/_ssl.c:4800:18: note: did you mean 'X509_OBJECT_get0_X509'?
/usr/include/openssl/x509_vfy.h:285:7: note: 'X509_OBJECT_get0_X509' declared here
X509 *X509_OBJECT_get0_X509(const X509_OBJECT *xo);
      ^
./Modules/_ssl.c:4804:18: error: call to undeclared function 'X509_OBJECT_set1_X509_CRL'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]
            ok = X509_OBJECT_set1_X509_CRL(
                 ^
./Modules/_ssl.c:4804:18: note: did you mean 'X509_OBJECT_get0_X509_CRL'?
/usr/include/openssl/x509_vfy.h:286:11: note: 'X509_OBJECT_get0_X509_CRL' declared here
X509_CRL *X509_OBJECT_get0_X509_CRL(X509_OBJECT *xo);
          ^
./Modules/_ssl.c:4821:1: error: static declaration of 'X509_STORE_get1_objects' follows non-static declaration
X509_STORE_get1_objects(X509_STORE *store)
^
/usr/include/openssl/x509_vfy.h:296:24: note: previous declaration is here
STACK_OF(X509_OBJECT) *X509_STORE_get1_objects(X509_STORE *xs);
                       ^
./Modules/_ssl.c:4824:10: error: call to undeclared function 'X509_STORE_lock'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]
    if (!X509_STORE_lock(store)) {
         ^
./Modules/_ssl.c:4827:11: error: call to undeclared function 'sk_X509_OBJECT_deep_copy'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]
    ret = sk_X509_OBJECT_deep_copy(X509_STORE_get0_objects(store),
          ^
./Modules/_ssl.c:4827:9: warning: incompatible integer to pointer conversion assigning to 'struct stack_st_X509_OBJECT *' from 'int' [-Wint-conversion]
    ret = sk_X509_OBJECT_deep_copy(X509_STORE_get0_objects(store),
        ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
./Modules/_ssl.c:4829:5: error: call to undeclared function 'X509_STORE_unlock'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]
    X509_STORE_unlock(store);
    ^
1 warning and 6 errors generated.
gmake: *** [Makefile:3505: Modules/_ssl.o] Error 1
```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Other

<!-- gh-linked-prs -->
### Linked PRs
* gh-131128
<!-- /gh-linked-prs -->
","[""$ ./configure\n$ gmake\n[...]\ncc -pthread  -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall    -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -fPIC -c ./Modules/_ssl.c -o Modules/_ssl.o\n./Modules/_ssl.c:4800:18: error: call to undeclared function 'X509_OBJECT_set1_X509'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]\n            ok = X509_OBJECT_set1_X509(ret, X509_OBJECT_get0_X509(obj));\n                 ^\n./Modules/_ssl.c:4800:18: note: did you mean 'X509_OBJECT_get0_X509'?\n/usr/include/openssl/x509_vfy.h:285:7: note: 'X509_OBJECT_get0_X509' declared here\nX509 *X509_OBJECT_get0_X509(const X509_OBJECT *xo);\n      ^\n./Modules/_ssl.c:4804:18: error: call to undeclared function 'X509_OBJECT_set1_X509_CRL'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]\n            ok = X509_OBJECT_set1_X509_CRL(\n                 ^\n./Modules/_ssl.c:4804:18: note: did you mean 'X509_OBJECT_get0_X509_CRL'?\n/usr/include/openssl/x509_vfy.h:286:11: note: 'X509_OBJECT_get0_X509_CRL' declared here\nX509_CRL *X509_OBJECT_get0_X509_CRL(X509_OBJECT *xo);\n          ^\n./Modules/_ssl.c:4821:1: error: static declaration of 'X509_STORE_get1_objects' follows non-static declaration\nX509_STORE_get1_objects(X509_STORE *store)\n^\n/usr/include/openssl/x509_vfy.h:296:24: note: previous declaration is here\nSTACK_OF(X509_OBJECT) *X509_STORE_get1_objects(X509_STORE *xs);\n                       ^\n./Modules/_ssl.c:4824:10: error: call to undeclared function 'X509_STORE_lock'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]\n    if (!X509_STORE_lock(store)) {\n         ^\n./Modules/_ssl.c:4827:11: error: call to undeclared function 'sk_X509_OBJECT_deep_copy'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]\n    ret = sk_X509_OBJECT_deep_copy(X509_STORE_get0_objects(store),\n          ^\n./Modules/_ssl.c:4827:9: warning: incompatible integer to pointer conversion assigning to 'struct stack_st_X509_OBJECT *' from 'int' [-Wint-conversion]\n    ret = sk_X509_OBJECT_deep_copy(X509_STORE_get0_objects(store),\n        ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./Modules/_ssl.c:4829:5: error: call to undeclared function 'X509_STORE_unlock'; ISO C99 and later do not support implicit function declarations [-Werror,-Wimplicit-function-declaration]\n    X509_STORE_unlock(store);\n    ^\n1 warning and 6 errors generated.\ngmake: *** [Makefile:3505: Modules/_ssl.o] Error 1""]","In build requirements we have OpenSSL 1.1.1:
https://docs.python.org/3/using/configure.html#build-requirements
See also [PEP 644](https://peps.python.org/pep-0644/).

This definitely not a bug.",[],['python'],github,https://github.com/python/cpython/issues/131127,{'repo': 'python/cpython'}
"Build failure with -fsanitize=undefined

# Bug report

### Bug description:

```
export LDFLAGS=""-fsanitize=undefined""
export CFLAGS=""-fsanitize=undefined -fno-sanitize-recover=all -g""
./configure --enable-shared --with-pydebug
make -j8
```

Please see the part of the output where error occured,

```
gcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/sha2module.o  Modules/_hacl/libHacl_Hash_SHA2.a  -o Modules/_sha2.cpython-314d-darwin.so
gcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/blake2module.o  Modules/_hacl/libHacl_Hash_Blake2.a  -o Modules/_blake2.cpython-314d-darwin.so
gcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/pyexpat.o -lm Modules/expat/libexpat.a  -o Modules/pyexpat.cpython-314d-darwin.so
gcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/_elementtree.o   -o Modules/_elementtree.cpython-314d-darwin.so
gcc -c -fno-strict-overflow -Wsign-compare -g -Og -Wall -fsanitize=undefined -fno-sanitize-recover=all -g -fsanitize=undefined -fno-sanitize-recover=all -g  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden -Werror=unguarded-availability  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -DPy_BUILD_CORE \
	      -DGITVERSION=""\""`LC_ALL=C git --git-dir ./.git rev-parse --short HEAD`\"""" \
	      -DGITTAG=""\""`LC_ALL=C git --git-dir ./.git describe --all --always --dirty`\"""" \
	      -DGITBRANCH=""\""`LC_ALL=C git --git-dir ./.git name-rev --name-only HEAD`\"""" \
	      -o Modules/getbuildinfo.o ./Modules/getbuildinfo.c
gcc -fsanitize=undefined -fsanitize=undefined   -o Programs/_freeze_module Programs/_freeze_module.o Modules/getpath_noop.o Modules/getbuildinfo.o Parser/token.o  Parser/pegen.o Parser/pegen_errors.o Parser/action_helpers.o Parser/parser.o Parser/string_parser.o Parser/peg_api.o Parser/lexer/buffer.o Parser/lexer/lexer.o Parser/lexer/state.o Parser/tokenizer/file_tokenizer.o Parser/tokenizer/readline_tokenizer.o Parser/tokenizer/string_tokenizer.o Parser/tokenizer/utf8_tokenizer.o Parser/tokenizer/helpers.o Parser/myreadline.o Objects/abstract.o Objects/boolobject.o Objects/bytes_methods.o Objects/bytearrayobject.o Objects/bytesobject.o Objects/call.o Objects/capsule.o Objects/cellobject.o Objects/classobject.o Objects/codeobject.o Objects/complexobject.o Objects/descrobject.o Objects/enumobject.o Objects/exceptions.o Objects/genericaliasobject.o Objects/genobject.o Objects/fileobject.o Objects/floatobject.o Objects/frameobject.o Objects/funcobject.o Objects/iterobject.o Objects/listobject.o Objects/longobject.o Objects/dictobject.o Objects/odictobject.o Objects/memoryobject.o Objects/methodobject.o Objects/moduleobject.o Objects/namespaceobject.o Objects/object.o Objects/obmalloc.o Objects/picklebufobject.o Objects/rangeobject.o Objects/setobject.o Objects/sliceobject.o Objects/structseq.o Objects/tupleobject.o Objects/typeobject.o Objects/typevarobject.o Objects/unicodeobject.o Objects/unicodectype.o Objects/unionobject.o Objects/weakrefobject.o  Python/_warnings.o Python/Python-ast.o Python/Python-tokenize.o Python/asdl.o Python/assemble.o Python/ast.o Python/ast_opt.o Python/ast_unparse.o Python/bltinmodule.o Python/brc.o Python/ceval.o Python/codecs.o Python/codegen.o Python/compile.o Python/context.o Python/critical_section.o Python/crossinterp.o Python/dynamic_annotations.o Python/errors.o Python/flowgraph.o Python/frame.o Python/frozenmain.o Python/future.o Python/gc.o Python/gc_free_threading.o Python/gc_gil.o Python/getargs.o Python/getcompiler.o Python/getcopyright.o Python/getplatform.o Python/getversion.o Python/ceval_gil.o Python/hamt.o Python/hashtable.o Python/import.o Python/importdl.o Python/index_pool.o Python/initconfig.o Python/interpconfig.o Python/instrumentation.o Python/instruction_sequence.o Python/intrinsics.o Python/jit.o Python/legacy_tracing.o Python/lock.o Python/marshal.o Python/modsupport.o Python/mysnprintf.o Python/mystrtoul.o Python/object_stack.o Python/optimizer.o Python/optimizer_analysis.o Python/optimizer_symbols.o Python/parking_lot.o Python/pathconfig.o Python/preconfig.o Python/pyarena.o Python/pyctype.o Python/pyfpe.o Python/pyhash.o Python/pylifecycle.o Python/pymath.o Python/pystate.o Python/pythonrun.o Python/pytime.o Python/qsbr.o Python/bootstrap_hash.o Python/specialize.o Python/stackrefs.o Python/structmember.o Python/symtable.o Python/sysmodule.o Python/thread.o Python/traceback.o Python/tracemalloc.o Python/uniqueid.o Python/getopt.o Python/pystrcmp.o Python/pystrtod.o Python/pystrhex.o Python/dtoa.o Python/formatter_unicode.o Python/fileutils.o Python/suggestions.o Python/perf_trampoline.o Python/perf_jit_trampoline.o Python/dynload_shlib.o     Modules/config.o Modules/main.o Modules/gcmodule.o Modules/atexitmodule.o  Modules/faulthandler.o  Modules/posixmodule.o  Modules/signalmodule.o  Modules/_tracemalloc.o  Modules/_suggestions.o  Modules/_codecsmodule.o  Modules/_collectionsmodule.o  Modules/errnomodule.o  Modules/_io/_iomodule.o Modules/_io/iobase.o Modules/_io/fileio.o Modules/_io/bytesio.o Modules/_io/bufferedio.o Modules/_io/textio.o Modules/_io/stringio.o  Modules/itertoolsmodule.o  Modules/_sre/sre.o  Modules/_sysconfig.o  Modules/_threadmodule.o  Modules/timemodule.o  Modules/_typingmodule.o  Modules/_weakref.o  Modules/_abc.o  Modules/_functoolsmodule.o  Modules/_localemodule.o  Modules/_opcode.o  Modules/_operator.o  Modules/_stat.o  Modules/symtablemodule.o  Modules/pwdmodule.o -lintl -ldl  -framework CoreFoundation
./Programs/_freeze_module getpath ./Modules/getpath.py Python/frozen_modules/getpath.h
./Programs/_freeze_module importlib._bootstrap ./Lib/importlib/_bootstrap.py Python/frozen_modules/importlib._bootstrap.h
./Programs/_freeze_module importlib._bootstrap_external ./Lib/importlib/_bootstrap_external.py Python/frozen_modules/importlib._bootstrap_external.h
./Programs/_freeze_module zipimport ./Lib/zipimport.py Python/frozen_modules/zipimport.h
Python/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
namespaceobject.c:173: note: namespace_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in
make: *** [Python/frozen_modules/importlib._bootstrap.h] Abort trap: 6
make: *** Waiting for unfinished jobs....
Python/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
namespaceobject.c:173: note: namespace_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in
make: *** [Python/frozen_modules/importlib._bootstrap_external.h] Abort trap: 6
Python/gc.c:2189:11: runtime error: call to function inst_seq_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
instruction_sequence.c:402: note: inst_seq_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:2189:11 in
make: *** [Python/frozen_modules/getpath.h] Abort trap: 6
Python/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
namespaceobject.c:173: note: namespace_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in
make: *** [Python/frozen_modules/zipimport.h] Abort trap: 6

```

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

macOS","['export LDFLAGS=""-fsanitize=undefined""\nexport CFLAGS=""-fsanitize=undefined -fno-sanitize-recover=all -g""\n./configure --enable-shared --with-pydebug\nmake -j8', 'gcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/sha2module.o  Modules/_hacl/libHacl_Hash_SHA2.a  -o Modules/_sha2.cpython-314d-darwin.so\ngcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/blake2module.o  Modules/_hacl/libHacl_Hash_Blake2.a  -o Modules/_blake2.cpython-314d-darwin.so\ngcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/pyexpat.o -lm Modules/expat/libexpat.a  -o Modules/pyexpat.cpython-314d-darwin.so\ngcc -bundle -undefined dynamic_lookup -fsanitize=undefined -fsanitize=undefined    Modules/_elementtree.o   -o Modules/_elementtree.cpython-314d-darwin.so\ngcc -c -fno-strict-overflow -Wsign-compare -g -Og -Wall -fsanitize=undefined -fno-sanitize-recover=all -g -fsanitize=undefined -fno-sanitize-recover=all -g  -std=c11 -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wstrict-prototypes -Werror=implicit-function-declaration -fvisibility=hidden -Werror=unguarded-availability  -I./Include/internal -I./Include/internal/mimalloc  -I. -I./Include    -DPy_BUILD_CORE \\\n\t      -DGITVERSION=""\\""`LC_ALL=C git --git-dir ./.git rev-parse --short HEAD`\\"""" \\\n\t      -DGITTAG=""\\""`LC_ALL=C git --git-dir ./.git describe --all --always --dirty`\\"""" \\\n\t      -DGITBRANCH=""\\""`LC_ALL=C git --git-dir ./.git name-rev --name-only HEAD`\\"""" \\\n\t      -o Modules/getbuildinfo.o ./Modules/getbuildinfo.c\ngcc -fsanitize=undefined -fsanitize=undefined   -o Programs/_freeze_module Programs/_freeze_module.o Modules/getpath_noop.o Modules/getbuildinfo.o Parser/token.o  Parser/pegen.o Parser/pegen_errors.o Parser/action_helpers.o Parser/parser.o Parser/string_parser.o Parser/peg_api.o Parser/lexer/buffer.o Parser/lexer/lexer.o Parser/lexer/state.o Parser/tokenizer/file_tokenizer.o Parser/tokenizer/readline_tokenizer.o Parser/tokenizer/string_tokenizer.o Parser/tokenizer/utf8_tokenizer.o Parser/tokenizer/helpers.o Parser/myreadline.o Objects/abstract.o Objects/boolobject.o Objects/bytes_methods.o Objects/bytearrayobject.o Objects/bytesobject.o Objects/call.o Objects/capsule.o Objects/cellobject.o Objects/classobject.o Objects/codeobject.o Objects/complexobject.o Objects/descrobject.o Objects/enumobject.o Objects/exceptions.o Objects/genericaliasobject.o Objects/genobject.o Objects/fileobject.o Objects/floatobject.o Objects/frameobject.o Objects/funcobject.o Objects/iterobject.o Objects/listobject.o Objects/longobject.o Objects/dictobject.o Objects/odictobject.o Objects/memoryobject.o Objects/methodobject.o Objects/moduleobject.o Objects/namespaceobject.o Objects/object.o Objects/obmalloc.o Objects/picklebufobject.o Objects/rangeobject.o Objects/setobject.o Objects/sliceobject.o Objects/structseq.o Objects/tupleobject.o Objects/typeobject.o Objects/typevarobject.o Objects/unicodeobject.o Objects/unicodectype.o Objects/unionobject.o Objects/weakrefobject.o  Python/_warnings.o Python/Python-ast.o Python/Python-tokenize.o Python/asdl.o Python/assemble.o Python/ast.o Python/ast_opt.o Python/ast_unparse.o Python/bltinmodule.o Python/brc.o Python/ceval.o Python/codecs.o Python/codegen.o Python/compile.o Python/context.o Python/critical_section.o Python/crossinterp.o Python/dynamic_annotations.o Python/errors.o Python/flowgraph.o Python/frame.o Python/frozenmain.o Python/future.o Python/gc.o Python/gc_free_threading.o Python/gc_gil.o Python/getargs.o Python/getcompiler.o Python/getcopyright.o Python/getplatform.o Python/getversion.o Python/ceval_gil.o Python/hamt.o Python/hashtable.o Python/import.o Python/importdl.o Python/index_pool.o Python/initconfig.o Python/interpconfig.o Python/instrumentation.o Python/instruction_sequence.o Python/intrinsics.o Python/jit.o Python/legacy_tracing.o Python/lock.o Python/marshal.o Python/modsupport.o Python/mysnprintf.o Python/mystrtoul.o Python/object_stack.o Python/optimizer.o Python/optimizer_analysis.o Python/optimizer_symbols.o Python/parking_lot.o Python/pathconfig.o Python/preconfig.o Python/pyarena.o Python/pyctype.o Python/pyfpe.o Python/pyhash.o Python/pylifecycle.o Python/pymath.o Python/pystate.o Python/pythonrun.o Python/pytime.o Python/qsbr.o Python/bootstrap_hash.o Python/specialize.o Python/stackrefs.o Python/structmember.o Python/symtable.o Python/sysmodule.o Python/thread.o Python/traceback.o Python/tracemalloc.o Python/uniqueid.o Python/getopt.o Python/pystrcmp.o Python/pystrtod.o Python/pystrhex.o Python/dtoa.o Python/formatter_unicode.o Python/fileutils.o Python/suggestions.o Python/perf_trampoline.o Python/perf_jit_trampoline.o Python/dynload_shlib.o     Modules/config.o Modules/main.o Modules/gcmodule.o Modules/atexitmodule.o  Modules/faulthandler.o  Modules/posixmodule.o  Modules/signalmodule.o  Modules/_tracemalloc.o  Modules/_suggestions.o  Modules/_codecsmodule.o  Modules/_collectionsmodule.o  Modules/errnomodule.o  Modules/_io/_iomodule.o Modules/_io/iobase.o Modules/_io/fileio.o Modules/_io/bytesio.o Modules/_io/bufferedio.o Modules/_io/textio.o Modules/_io/stringio.o  Modules/itertoolsmodule.o  Modules/_sre/sre.o  Modules/_sysconfig.o  Modules/_threadmodule.o  Modules/timemodule.o  Modules/_typingmodule.o  Modules/_weakref.o  Modules/_abc.o  Modules/_functoolsmodule.o  Modules/_localemodule.o  Modules/_opcode.o  Modules/_operator.o  Modules/_stat.o  Modules/symtablemodule.o  Modules/pwdmodule.o -lintl -ldl  -framework CoreFoundation\n./Programs/_freeze_module getpath ./Modules/getpath.py Python/frozen_modules/getpath.h\n./Programs/_freeze_module importlib._bootstrap ./Lib/importlib/_bootstrap.py Python/frozen_modules/importlib._bootstrap.h\n./Programs/_freeze_module importlib._bootstrap_external ./Lib/importlib/_bootstrap_external.py Python/frozen_modules/importlib._bootstrap_external.h\n./Programs/_freeze_module zipimport ./Lib/zipimport.py Python/frozen_modules/zipimport.h\nPython/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type \'int (*)(struct _object *, int (*)(struct _object *, void *), void *)\'\nnamespaceobject.c:173: note: namespace_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in\nmake: *** [Python/frozen_modules/importlib._bootstrap.h] Abort trap: 6\nmake: *** Waiting for unfinished jobs....\nPython/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type \'int (*)(struct _object *, int (*)(struct _object *, void *), void *)\'\nnamespaceobject.c:173: note: namespace_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in\nmake: *** [Python/frozen_modules/importlib._bootstrap_external.h] Abort trap: 6\nPython/gc.c:2189:11: runtime error: call to function inst_seq_traverse through pointer to incorrect function type \'int (*)(struct _object *, int (*)(struct _object *, void *), void *)\'\ninstruction_sequence.c:402: note: inst_seq_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:2189:11 in\nmake: *** [Python/frozen_modules/getpath.h] Abort trap: 6\nPython/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type \'int (*)(struct _object *, int (*)(struct _object *, void *), void *)\'\nnamespaceobject.c:173: note: namespace_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in\nmake: *** [Python/frozen_modules/zipimport.h] Abort trap: 6']","Especially the part,
```
Python/gc.c:2189:11: runtime error: call to function inst_seq_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
instruction_sequence.c:402: note: inst_seq_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:2189:11 in
make: *** [Python/frozen_modules/getpath.h] Abort trap: 6
Python/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'
namespaceobject.c:173: note: namespace_traverse defined here
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in
make: *** [Python/frozen_modules/zipimport.h] Abort trap: 6
```","[""Python/gc.c:2189:11: runtime error: call to function inst_seq_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'\ninstruction_sequence.c:402: note: inst_seq_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:2189:11 in\nmake: *** [Python/frozen_modules/getpath.h] Abort trap: 6\nPython/gc.c:1458:16: runtime error: call to function namespace_traverse through pointer to incorrect function type 'int (*)(struct _object *, int (*)(struct _object *, void *), void *)'\nnamespaceobject.c:173: note: namespace_traverse defined here\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior Python/gc.c:1458:16 in\nmake: *** [Python/frozen_modules/zipimport.h] Abort trap: 6""]",['python'],github,https://github.com/python/cpython/issues/130411,{'repo': 'python/cpython'}
"Fatal Python error from `warnings._release_lock()`

# Crash report

### What happened?

Exposing the mutex  used by the `_warnings` module in https://github.com/python/cpython/pull/128386 has made it possible to abort the interpreter by calling `warnings._release_lock()`:

```python
import warnings
warnings._release_lock()
```

Error message:
```
Fatal Python error: _PyRecursiveMutex_Unlock: unlocking a recursive mutex that is not owned by the current thread
Python runtime state: initialized

Current thread 0x0000718eb9295740 (most recent call first):
  File ""<string>"", line 1 in <module>
Aborted (core dumped)
```

Found using [fusil](https://github.com/devdanzin/fusil) by @vstinner.

### CPython versions tested on:

CPython main branch, 3.14

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.14.0a4+ (heads/main:e1006ce1de, Feb  6 2025, 17:22:01) [GCC 13.3.0]

<!-- gh-linked-prs -->
### Linked PRs
* gh-129771
<!-- /gh-linked-prs -->
","['import warnings\nwarnings._release_lock()', 'Fatal Python error: _PyRecursiveMutex_Unlock: unlocking a recursive mutex that is not owned by the current thread\nPython runtime state: initialized\n\nCurrent thread 0x0000718eb9295740 (most recent call first):\n  File ""<string>"", line 1 in <module>\nAborted (core dumped)']",cc @nascheme and @kumaraditya303 ,[],['python'],github,https://github.com/python/cpython/issues/129766,{'repo': 'python/cpython'}
"`Tools/jit` has several `bytes` and `bytearray` mixups

# Bug report

`Stensil` defines `body` as `bytearray` https://github.com/python/cpython/blob/175844713af383c9e4dd60166d1d7407c80a1949/Tools/jit/_stencils.py#L189-L197

But, it is passed to functions that expect `bytes`, this now works for historic reasons. But, since mypy@2.0 or mypy@1.5 with `--strict-bytes` turned on - it won't. See https://github.com/python/mypy/blob/master/CHANGELOG.md#--strict-bytes

Examples:

```diff
diff --git Tools/jit/_stencils.py Tools/jit/_stencils.py
index ee761a73fa8..8b6957f8bdb 100644
--- Tools/jit/_stencils.py
+++ Tools/jit/_stencils.py
@@ -141,7 +141,11 @@ class Hole:
     def __post_init__(self) -> None:
         self.func = _PATCH_FUNCS[self.kind]
 
-    def fold(self, other: typing.Self, body: bytes) -> typing.Self | None:
+    def fold(
+        self,
+        other: typing.Self,
+        body: bytes | bytearray,
+    ) -> typing.Self | None:
         """"""Combine two holes into a single hole, if possible.""""""
         instruction_a = int.from_bytes(
             body[self.offset : self.offset + 4], byteorder=sys.byteorder
diff --git Tools/jit/_targets.py Tools/jit/_targets.py
index d23ced19842..4015fc564ad 100644
--- Tools/jit/_targets.py
+++ Tools/jit/_targets.py
@@ -97,7 +97,7 @@ def _handle_section(self, section: _S, group: _stencils.StencilGroup) -> None:
         raise NotImplementedError(type(self))
 
     def _handle_relocation(
-        self, base: int, relocation: _R, raw: bytes
+        self, base: int, relocation: _R, raw: bytes | bytearray
     ) -> _stencils.Hole:
         raise NotImplementedError(type(self))
 
@@ -257,7 +257,7 @@ def _unwrap_dllimport(self, name: str) -> tuple[_stencils.HoleValue, str | None]
         return _stencils.symbol_to_value(name)
 
     def _handle_relocation(
-        self, base: int, relocation: _schema.COFFRelocation, raw: bytes
+        self, base: int, relocation: _schema.COFFRelocation, raw: bytes | bytearray
     ) -> _stencils.Hole:
         match relocation:
             case {
@@ -348,7 +348,10 @@ def _handle_section(
             }, section_type
 
     def _handle_relocation(
-        self, base: int, relocation: _schema.ELFRelocation, raw: bytes
+        self,
+        base: int,
+        relocation: _schema.ELFRelocation,
+        raw: bytes | bytearray,
     ) -> _stencils.Hole:
         symbol: str | None
         match relocation:
@@ -424,7 +427,10 @@ def _handle_section(
             stencil.holes.append(hole)
 
     def _handle_relocation(
-        self, base: int, relocation: _schema.MachORelocation, raw: bytes
+        self,
+        base: int,
+        relocation: _schema.MachORelocation,
+        raw: bytes | bytearray,
     ) -> _stencils.Hole:
         symbol: str | None
         match relocation:
```

I propose to proactively fix this by using `bytes | bytearray`. Why? Because this union won't allow to mutate `byte` objects. Why not `collections.abc.Buffer`? `jit` requires `python3.11+`, and `Buffer` is available since 3.12, we also don't want to add `typing_extensions` package as a single dependency. We also don't want to do some cool `TYPE_CHECKING` hacks, when we can just use a union.

<!-- gh-linked-prs -->
### Linked PRs
* gh-129806
* gh-130216
<!-- /gh-linked-prs -->
","['diff --git Tools/jit/_stencils.py Tools/jit/_stencils.py\nindex ee761a73fa8..8b6957f8bdb 100644\n--- Tools/jit/_stencils.py\n+++ Tools/jit/_stencils.py\n@@ -141,7 +141,11 @@ class Hole:\n     def __post_init__(self) -> None:\n         self.func = _PATCH_FUNCS[self.kind]\n \n-    def fold(self, other: typing.Self, body: bytes) -> typing.Self | None:\n+    def fold(\n+        self,\n+        other: typing.Self,\n+        body: bytes | bytearray,\n+    ) -> typing.Self | None:\n         """"""Combine two holes into a single hole, if possible.""""""\n         instruction_a = int.from_bytes(\n             body[self.offset : self.offset + 4], byteorder=sys.byteorder\ndiff --git Tools/jit/_targets.py Tools/jit/_targets.py\nindex d23ced19842..4015fc564ad 100644\n--- Tools/jit/_targets.py\n+++ Tools/jit/_targets.py\n@@ -97,7 +97,7 @@ def _handle_section(self, section: _S, group: _stencils.StencilGroup) -> None:\n         raise NotImplementedError(type(self))\n \n     def _handle_relocation(\n-        self, base: int, relocation: _R, raw: bytes\n+        self, base: int, relocation: _R, raw: bytes | bytearray\n     ) -> _stencils.Hole:\n         raise NotImplementedError(type(self))\n \n@@ -257,7 +257,7 @@ def _unwrap_dllimport(self, name: str) -> tuple[_stencils.HoleValue, str | None]\n         return _stencils.symbol_to_value(name)\n \n     def _handle_relocation(\n-        self, base: int, relocation: _schema.COFFRelocation, raw: bytes\n+        self, base: int, relocation: _schema.COFFRelocation, raw: bytes | bytearray\n     ) -> _stencils.Hole:\n         match relocation:\n             case {\n@@ -348,7 +348,10 @@ def _handle_section(\n             }, section_type\n \n     def _handle_relocation(\n-        self, base: int, relocation: _schema.ELFRelocation, raw: bytes\n+        self,\n+        base: int,\n+        relocation: _schema.ELFRelocation,\n+        raw: bytes | bytearray,\n     ) -> _stencils.Hole:\n         symbol: str | None\n         match relocation:\n@@ -424,7 +427,10 @@ def _handle_section(\n             stencil.holes.append(hole)\n \n     def _handle_relocation(\n-        self, base: int, relocation: _schema.MachORelocation, raw: bytes\n+        self,\n+        base: int,\n+        relocation: _schema.MachORelocation,\n+        raw: bytes | bytearray,\n     ) -> _stencils.Hole:\n         symbol: str | None\n         match relocation:']",I've taken the liberty of closing it since it seemed that everything was addressed. Feel free to re-open if you had more in mind.,[],['python'],github,https://github.com/python/cpython/issues/129805,{'repo': 'python/cpython'}
"nogil set `clear` causes concurrent `__str__` to print as empty dict

# Bug report

### Bug description:

Hi,

We're a research group focused on testing concurrent runtimes. Our work-in-progress prototype found that the current nogil build `__str__` can return `""{}""` (empty dict) instead of the expected `""set()""` when there is a concurrent `clear()` operation. The program below shows the wrong behavior:

```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    s.clear()

def t1(b1,s,res):
    b1.wait()
    res.append(s.__str__())

def Test():
  s =  {17, 18, 'a', 'b', 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] == ""{}"":
      print(""found bug: "" + res[0])

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```
Sample output:
```
test begin...
0
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
```

This behavior can be observed quite readily.  We tested it on a number of x86_64 and one ARM machine.

@flypoodles and @overlorde are part of the team, adding them so they get notified about further discussion.


```

### CPython versions tested on:

3.14, CPython main branch

### Operating systems tested on:

Linux","['import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    s.clear()\n\ndef t1(b1,s,res):\n    b1.wait()\n    res.append(s.__str__())\n\ndef Test():\n  s =  {17, 18, \'a\', \'b\', \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] == ""{}"":\n      print(""found bug: "" + res[0])\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}']","Oops, my browser created this duplicate.  Sorry about that, can you please delete it?",[],['python'],github,https://github.com/python/cpython/issues/129968,{'repo': 'python/cpython'}
"`inspect.getdoc()` failing to return docstring for cached_property for subclass that overrides code but not docstring

# Bug report

### Bug description:

When a child/sub-class inherits a method from its parent/base-class, `inspect.getdoc(...)` returns the parent's method's docstring when the child's method does not have its own docstring. This is true even if the child overwrites the method but doesn't have a docstring as part of that.

However, this is failing when the method has the `functools.cached_property` decorator on it and the method is overwritten in the child. The below code errors on the assertion.

```python
from functools import cached_property
import inspect

class Parent:
    @cached_property
    def foo(self):
        ""this is the docstring for foo""
        return 1

class Child(Parent):
    @cached_property
    def foo(self): ...

assert inspect.getdoc(Child.foo) == inspect.getdoc(Parent.foo) # fails but we want this to be True
```

I did my best to test this across a variety of similar things and this was the only case where I found the docstring to not be inherited. I tested across methods, properties (with the `@property` decorator), cached_properties, static_methods, and class_methods; and having the child explicitly overwrite the code (but not the docstring) of the method or not.

The below test code shows passes for all those other scenarios but only fails on `test_cached_property_defined_in_parent_and_child`.

```python
from functools import cached_property
import inspect

import unittest


class TestMatchingDocstrings(unittest.TestCase):
    def setUp(self):
        self.parent_class = ParentClass
        self.child_class = ChildClass

    def compare_docstrings(self, attrname):
        parent_attr = getattr(self.parent_class, attrname)
        parent_docstring = inspect.getdoc(parent_attr)
        child_attr = getattr(self.child_class, attrname)
        child_docstring = inspect.getdoc(child_attr)
        self.assertEqual(parent_docstring, child_docstring)

    def test_method_defined_in_parent_only(self):
        self.compare_docstrings(""method_defined_in_parent_only"")

    def test_method_defined_in_parent_and_child(self):
        self.compare_docstrings(""method_defined_in_parent_and_child"")

    def test_property_defined_in_parent_only(self):
        self.compare_docstrings(""property_defined_in_parent_only"")

    def test_property_defined_in_parent_and_child(self):
        self.compare_docstrings(""property_defined_in_parent_and_child"")

    def test_cached_property_defined_in_parent_only(self):
        self.compare_docstrings(""cached_property_defined_in_parent_only"")

    def test_cached_property_defined_in_parent_and_child(self):
        self.compare_docstrings(""cached_property_defined_in_parent_and_child"")

    def test_static_method_defined_in_parent_only(self):
        self.compare_docstrings(""static_method_defined_in_parent_only"")

    def test_static_method_defined_in_parent_and_child(self):
        self.compare_docstrings(""static_method_defined_in_parent_and_child"")

    def test_class_method_defined_in_parent_only(self):
        self.compare_docstrings(""class_method_defined_in_parent_only"")

    def test_class_method_defined_in_parent_and_child(self):
        self.compare_docstrings(""class_method_defined_in_parent_and_child"")


class ParentClass:
    def method_defined_in_parent_only(self):
        ""This is a method in the parent only""

    def method_defined_in_parent_and_child(self):
        ""This is a method in the parent and child""

    @property
    def property_defined_in_parent_only(self):
        ""This is a property with the decorator in the parent only""

    @property
    def property_defined_in_parent_and_child(self):
        ""This is a property with the decorator in the parent and child""

    @cached_property
    def cached_property_defined_in_parent_only(self):
        ""This is a cached property with the decorator in the parent only""

    @cached_property
    def cached_property_defined_in_parent_and_child(self):
        ""This is a cached property with the decorator in the parent and child""

    @staticmethod
    def static_method_defined_in_parent_only():
        ""This is a static method with the decorator in the parent only""

    @staticmethod
    def static_method_defined_in_parent_and_child():
        ""This is a static method with the decorator in the parent and child""

    @classmethod
    def class_method_defined_in_parent_only(cls):
        ""This is a class method with the decorator in the parent only""

    @classmethod
    def class_method_defined_in_parent_and_child(cls):
        ""This is a class method with the decorator in the parent and child""


class ChildClass(ParentClass):
    def method_defined_in_parent_and_child(self): ...

    @property
    def property_defined_in_parent_and_child(self): ...

    @cached_property
    def cached_property_defined_in_parent_and_child(self): ...

    @staticmethod
    def static_method_defined_in_parent_and_child(): ...

    @classmethod
    def class_method_defined_in_parent_and_child(cls): ...


if __name__ == ""__main__"":
    unittest.main()
```



### CPython versions tested on:

3.9, 3.10, 3.11, 3.12, 3.13, 3.14

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-131165
<!-- /gh-linked-prs -->
","['from functools import cached_property\nimport inspect\n\nclass Parent:\n    @cached_property\n    def foo(self):\n        ""this is the docstring for foo""\n        return 1\n\nclass Child(Parent):\n    @cached_property\n    def foo(self): ...\n\nassert inspect.getdoc(Child.foo) == inspect.getdoc(Parent.foo) # fails but we want this to be True', 'from functools import cached_property\nimport inspect\n\nimport unittest\n\n\nclass TestMatchingDocstrings(unittest.TestCase):\n    def setUp(self):\n        self.parent_class = ParentClass\n        self.child_class = ChildClass\n\n    def compare_docstrings(self, attrname):\n        parent_attr = getattr(self.parent_class, attrname)\n        parent_docstring = inspect.getdoc(parent_attr)\n        child_attr = getattr(self.child_class, attrname)\n        child_docstring = inspect.getdoc(child_attr)\n        self.assertEqual(parent_docstring, child_docstring)\n\n    def test_method_defined_in_parent_only(self):\n        self.compare_docstrings(""method_defined_in_parent_only"")\n\n    def test_method_defined_in_parent_and_child(self):\n        self.compare_docstrings(""method_defined_in_parent_and_child"")\n\n    def test_property_defined_in_parent_only(self):\n        self.compare_docstrings(""property_defined_in_parent_only"")\n\n    def test_property_defined_in_parent_and_child(self):\n        self.compare_docstrings(""property_defined_in_parent_and_child"")\n\n    def test_cached_property_defined_in_parent_only(self):\n        self.compare_docstrings(""cached_property_defined_in_parent_only"")\n\n    def test_cached_property_defined_in_parent_and_child(self):\n        self.compare_docstrings(""cached_property_defined_in_parent_and_child"")\n\n    def test_static_method_defined_in_parent_only(self):\n        self.compare_docstrings(""static_method_defined_in_parent_only"")\n\n    def test_static_method_defined_in_parent_and_child(self):\n        self.compare_docstrings(""static_method_defined_in_parent_and_child"")\n\n    def test_class_method_defined_in_parent_only(self):\n        self.compare_docstrings(""class_method_defined_in_parent_only"")\n\n    def test_class_method_defined_in_parent_and_child(self):\n        self.compare_docstrings(""class_method_defined_in_parent_and_child"")\n\n\nclass ParentClass:\n    def method_defined_in_parent_only(self):\n        ""This is a method in the parent only""\n\n    def method_defined_in_parent_and_child(self):\n        ""This is a method in the parent and child""\n\n    @property\n    def property_defined_in_parent_only(self):\n        ""This is a property with the decorator in the parent only""\n\n    @property\n    def property_defined_in_parent_and_child(self):\n        ""This is a property with the decorator in the parent and child""\n\n    @cached_property\n    def cached_property_defined_in_parent_only(self):\n        ""This is a cached property with the decorator in the parent only""\n\n    @cached_property\n    def cached_property_defined_in_parent_and_child(self):\n        ""This is a cached property with the decorator in the parent and child""\n\n    @staticmethod\n    def static_method_defined_in_parent_only():\n        ""This is a static method with the decorator in the parent only""\n\n    @staticmethod\n    def static_method_defined_in_parent_and_child():\n        ""This is a static method with the decorator in the parent and child""\n\n    @classmethod\n    def class_method_defined_in_parent_only(cls):\n        ""This is a class method with the decorator in the parent only""\n\n    @classmethod\n    def class_method_defined_in_parent_and_child(cls):\n        ""This is a class method with the decorator in the parent and child""\n\n\nclass ChildClass(ParentClass):\n    def method_defined_in_parent_and_child(self): ...\n\n    @property\n    def property_defined_in_parent_and_child(self): ...\n\n    @cached_property\n    def cached_property_defined_in_parent_and_child(self): ...\n\n    @staticmethod\n    def static_method_defined_in_parent_and_child(): ...\n\n    @classmethod\n    def class_method_defined_in_parent_and_child(cls): ...\n\n\nif __name__ == ""__main__"":\n    unittest.main()']",I'd like to work on this if no one else is. Not sure how to assign these.,[],['python'],github,https://github.com/python/cpython/issues/131116,{'repo': 'python/cpython'}
"docs: fix deprecated or broken examples in urllib.request documentation.

# Documentation

ref. https://docs.python.org/3/library/urllib.request.html#examples

There are many example in `urllib.request` documentation that need to be updated as they no longer works as expected.

> In the following example, we are sending a data-stream to the stdin of a CGI and reading the data it returns to us. Note that this example will only work when the Python installation supports SSL.

> Use of Basic HTTP Authentication:
",[],One issue is fine for all examples on one page. Please choose one.,[],['python'],github,https://github.com/python/cpython/issues/130374,{'repo': 'python/cpython'}
"Race between `_PyObject_GetMethod` and `ensure_nonmanaged_dict`

# Bug report

### Bug description:

Using CPython 3.13 built at commit 2ab7e1135a2d5ca45b60881ece27729e4fc0ee8b with TSAN enabled:

Repro:
```python
import concurrent.futures
import functools
import threading

num_threads = 100


def closure(b, o):
  b.wait()
  o.__call__()
  o.foo = 42

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
  for _ in range(100):
    b = threading.Barrier(num_threads)
    o = functools.partial(lambda x: x, 42)
    for _ in range(num_threads):
      executor.submit(functools.partial(closure, b, o))
```

TSAN report:
```
WARNING: ThreadSanitizer: data race (pid=124621)
  Read of size 8 at 0x7f942a59fda8 by thread T86:
    #0 _PyObject_GetMethod /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1587:20 (python3.13+0x2974ea) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #1 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:3744:25 (python3.13+0x3eeed3) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #2 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #3 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)
    #4 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #5 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x575642) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #6 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x575642)
    #7 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #8 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)
    #9 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #10 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e5572) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #11 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #12 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)
    #13 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #14 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5cf) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #15 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5cf)
    #16 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #17 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)
    #18 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #19 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ca2) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #20 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0c17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)

  Previous atomic write of size 8 at 0x7f942a59fda8 by thread T89:
    #0 _Py_atomic_store_ptr_release /usr/local/google/home/phawkins/p/cpython/./Include/cpython/pyatomic_gcc.h:501:3 (python3.13+0x272d27) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #1 ensure_nonmanaged_dict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7275:9 (python3.13+0x272d27)
    #2 _PyObjectDict_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7311:12 (python3.13+0x272dfe) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #3 _PyObject_GenericSetAttrWithDict /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1825:19 (python3.13+0x29813e) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #4 PyObject_GenericSetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1853:12 (python3.13+0x298b17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #5 PyObject_SetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1415:15 (python3.13+0x29543a) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #6 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5488:27 (python3.13+0x3f4f9d) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #7 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #8 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)
    #9 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #10 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x575642) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #11 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x575642)
    #12 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #13 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)
    #14 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #15 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e5572) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #16 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #17 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)
    #18 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #19 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5cf) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #20 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5cf)
    #21 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #22 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)
    #23 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #24 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ca2) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
    #25 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0c17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)
```

This is quite similar to https://github.com/python/cpython/issues/128100

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux","['import concurrent.futures\nimport functools\nimport threading\n\nnum_threads = 100\n\n\ndef closure(b, o):\n  b.wait()\n  o.__call__()\n  o.foo = 42\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n  for _ in range(100):\n    b = threading.Barrier(num_threads)\n    o = functools.partial(lambda x: x, 42)\n    for _ in range(num_threads):\n      executor.submit(functools.partial(closure, b, o))', 'WARNING: ThreadSanitizer: data race (pid=124621)\n  Read of size 8 at 0x7f942a59fda8 by thread T86:\n    #0 _PyObject_GetMethod /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1587:20 (python3.13+0x2974ea) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #1 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:3744:25 (python3.13+0x3eeed3) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #2 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #3 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)\n    #4 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #5 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x575642) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #6 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x575642)\n    #7 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #8 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)\n    #9 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #10 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e5572) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #11 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #12 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)\n    #13 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #14 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5cf) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #15 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5cf)\n    #16 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #17 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)\n    #18 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #19 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ca2) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #20 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0c17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n\n  Previous atomic write of size 8 at 0x7f942a59fda8 by thread T89:\n    #0 _Py_atomic_store_ptr_release /usr/local/google/home/phawkins/p/cpython/./Include/cpython/pyatomic_gcc.h:501:3 (python3.13+0x272d27) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #1 ensure_nonmanaged_dict /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7275:9 (python3.13+0x272d27)\n    #2 _PyObjectDict_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/dictobject.c:7311:12 (python3.13+0x272dfe) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #3 _PyObject_GenericSetAttrWithDict /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1825:19 (python3.13+0x29813e) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #4 PyObject_GenericSetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1853:12 (python3.13+0x298b17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #5 PyObject_SetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1415:15 (python3.13+0x29543a) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #6 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5488:27 (python3.13+0x3f4f9d) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #7 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #8 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)\n    #9 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #10 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x575642) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #11 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x575642)\n    #12 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #13 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)\n    #14 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #15 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e5572) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #16 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3df4ba) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #17 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1813:12 (python3.13+0x3df4ba)\n    #18 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb5ff) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #19 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5cf) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #20 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5cf)\n    #21 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb273) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #22 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb273)\n    #23 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb2f5) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #24 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x567ca2) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)\n    #25 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4c0c17) (BuildId: 7813a82c043bc03d6031bcfa367627f3fee4c283)']",Thanks for tracking this down. Let's backport the PR.,[],['python'],github,https://github.com/python/cpython/issues/130571,{'repo': 'python/cpython'}
"Backport of `PyConfig.use_system_logger` has changed ABI in a patch 3.13.1 -> 3.13.2

# Bug report

### Bug description:

In https://github.com/python/cpython/pull/127592 a new `PyConfig` flag was added for apple platforms to allow use of the system logger.

This PR looks like it was backported to all branches from 3.9 through to 3.13, and has been released in 3.13.2 ~~and 3.12.9~~. 

Unfortunately, this has changed the public ABI (layout of the `PyConfig` struct) on a patch release. This means that binaries using the `PyConfig` API and built using 3.13.1 or 3.13.0 ~~(or 3.12.8)~~ will potentially misbehave if running against a newer interpreter.

I picked this up after getting a PyO3 ""FFI check"" failure on 3.13.2, reporting that our FFI bindings were no longer compatible with CPython.

In PEP 741 it was previously noted that backporting a flag to break the public ABI was decided against, so I believe this to be a bug.

Do I wait for CPython to revert this? Or do I make PyO3 adjust to the new ABI (and break compatibility with all existing interpreters)?

ping @vstinner as I know you have been very active on this API.

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-131129
<!-- /gh-linked-prs -->
",[],"I believe it to be for all apple platforms, including macOS.

https://developer.apple.com/library/archive/documentation/Porting/Conceptual/PortingUnix/compiling/compiling.html#//apple_ref/doc/uid/TP40002850-SW13 indicates `__APPLE__` is for any apple system.",[],['python'],github,https://github.com/python/cpython/issues/130940,{'repo': 'python/cpython'}
"Zipapp archives are always empty

# Bug report

### Bug description:

Good evening,

I have recently installed Python 3.13 (Windows x64) over 3.12.
Now `zipapp.create_archive(..)` is creating just empty archives.

After some fiddling around I found there might be an issue in these lines:

(from zipapp.py, lines 113 ff)
```
    with _maybe_open(target, 'wb') as fd:
        _write_file_prefix(fd, interpreter)
        compression = (zipfile.ZIP_DEFLATED if compressed else
                       zipfile.ZIP_STORED)
        with zipfile.ZipFile(fd, 'w', compression=compression) as z:
            for child in sorted(source.rglob('*')):
                arcname = child.relative_to(source)
                if filter is None or filter(arcname) and child.resolve() != arcname.resolve():   # ██ LOOK HERE ! ██
                    z.write(child, arcname.as_posix())
            if main_py:
                z.writestr('__main__.py', main_py.encode('utf-8'))
```

This change was introduced in Python 3.13 (have verified against 3.12 sources) and seemingly causes the trouble.

My guess is, as `child` is pointing to the same file as `arcname`, and naturally, they both resolve to the same file, no file gets added due to the `!=` check, ever, to the archive-to-be-created.

Maybe it was intended to check against `target`, not `arcname`?

Once I monkeypatched the `and child.resolve() != arcname.resolve()` part away, the archive got written again.

Or am I just not doing it right?
Any help much appreciated!

Sebastian.

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-130509
* gh-130791
<!-- /gh-linked-prs -->
","[""with _maybe_open(target, 'wb') as fd:\n        _write_file_prefix(fd, interpreter)\n        compression = (zipfile.ZIP_DEFLATED if compressed else\n                       zipfile.ZIP_STORED)\n        with zipfile.ZipFile(fd, 'w', compression=compression) as z:\n            for child in sorted(source.rglob('*')):\n                arcname = child.relative_to(source)\n                if filter is None or filter(arcname) and child.resolve() != arcname.resolve():   # ██ LOOK HERE ! ██\n                    z.write(child, arcname.as_posix())\n            if main_py:\n                z.writestr('__main__.py', main_py.encode('utf-8'))""]","IMO, that's correct behaviour. You have given `zipapp.create_archive` a source directory containing a file called `out`, and you didn't specify a filter that excluded that file. So in that case, zipapp *should* include the file in the archive.

#104527 would improve the behaviour in this area, by giving an error message rather than simply creating an ever-growing file, but that's an issue for the zipfile module, not for zipapp. I'd also be willing to accept a PR adding some form of `--filter` argument to the zipapp CLI, although the details of how that would work would need to be sorted out.

Generally, though, I would strongly advise *not* creating the target in the source directory.",[],['python'],github,https://github.com/python/cpython/issues/130379,{'repo': 'python/cpython'}
"Controls in Tkinter ttk under MacOS show a white border

我的运行环境
Python 3.8.9
MacOS 14.7.4 (23H420)
Tkinter > 8.6

我的代码
import tkinter.ttk as ttk
from tkinter import *
root = Tk()

label = ttk.Button(root, text=""Hello, macOS!"",)
label.pack(pady=20)

root.geometry('400x400')
root.mainloop()

我遇到的问题

我是一个Python新手，我在MacOS想要构建一个应用程序，我是用了tkinter中的ttk模块来创建一些控件，但是在运行后，发现空间在macos环境下显示有异常，控件的周围有白色边框，而且点击按钮时，按钮聚焦也跟原声的macos ui差距很大，我在网络上找到了一些方法，升级最新版的python，这样确实可以，但是由于我的项目，需要用到一个库，它只能使用3.8以内或者更低的版本，这导致我无法通过更新版本解决，我尝试下载新版本的python tkinter源代码发现不起作用，但是我是一个新手，不知道如何分析原理，所以我希望有人可以给我提供一些代码实例，感谢



我运行时的图片

![Image](https://github.com/user-attachments/assets/636e320d-2d3d-4d4f-9c02-8240dc329a34)


",[],"Python 3.8 is very old and no longer receives updates.  The latest binary release on our end also contains an older version of Tk.   More recent releases (such as Python 3.12 or 3.13) contain much newer versions of Tk which fix numerous issues with that library.

One way to check the detailed Tk version:

``sh
$ python3.12 -m test.pythoninfo | grep tkinter
tkinter.TCL_VERSION: 8.6
tkinter.TK_VERSION: 8.6
tkinter.info_patchlevel: 8.6.15
```

This shows that Tk version 8.6.15 is used on my laptop. This version does not have the problem in your screenshot.

",[],['python'],github,https://github.com/python/cpython/issues/130570,{'repo': 'python/cpython'}
"Indentation changes itself when copying the code from the Editor into Python 3.13.1 results in IndentationError

Hi,

I am a kind of beginner with Python and the following issue happened:

I have a code to extract information from a search engine and when I try to copy my code into Python 3.13.1 it destroy the intendation and I get the IndentationError.

import pandas as pd
import requests
import os

# Load the input file
input_file = 'companies.csv'
df = pd.read_csv(input_file)

# Your SerpAPI key
SERPAPI_KEY = 'PUT YOUR SERPAPI_KEY HERE'
base_url = 'https://serpapi.com/search'

# Create a list to hold results
results = []

# Loop through each company name and fetch website
for company in df['Company Name']:
params = {
'api_key': SERPAPI_KEY,
'engine': 'google',
'q': company, 
'hl': 'en',
'gl': 'us'
    }
    
response = requests.get(base_url, params=params)
data = response.json()
    
    # Get the first organic result link
if 'organic_results' in data and len(data['organic_results']) > 0:
    website = data['organic_results'][0].get('link')
    results.append({'Company Name': company, 'Website': website})
**else:
   results.append({'Company Name': company, 'Website': None})**

# Create a DataFrame and save to CSV
results_df = pd.DataFrame(results)
results_df.to_csv('company_websites.csv', index=False)

**And when I copy it into Python somehow the intendation will be destroyed and I got the IndentationError**, because the 
else:
results.append({'Company Name': company, 'Website': None})** 
**2 lines have more blank space then it should have to have.** 

So the code will look like this:
Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import pandas as pd
>>> import requests
>>> import os
>>>
>>> # Load the input file
>>> input_file = 'companies.csv'
>>> df = pd.read_csv(input_file)
>>>
>>> # Your SerpAPI key
>>> SERPAPI_KEY = 'PUT YOUR SERPAPI_KEY HERE'
>>> base_url = 'https://serpapi.com/search'
>>>
>>> # Create a list to hold results
>>> results = []
>>>
>>> # Loop through each company name and fetch website
>>> for company in df['Company Name']:
...     params = {
...     'api_key': SERPAPI_KEY,
...     'engine': 'google',
...     'q': company,
...     'hl': 'en',
...     'gl': 'us'
...         }
...
>>> response = requests.get(base_url, params=params)
>>> data = response.json()
>>>
>>>     # Get the first organic result link
>>> if 'organic_results' in data and len(data['organic_results']) > 0:
...         website = data['organic_results'][0].get('link')
...             results.append({'Company Name': company, 'Website': website})
...             else:
...                         results.append({'Company Name': company, 'Website': None})
...
  **File ""<python-input-21>"", line 3
    results.append({'Company Name': company, 'Website': website})
IndentationError: unexpected indent**
>>> # Create a DataFrame and save to CSV
>>> results_df = pd.DataFrame(results)
>>> results_df.to_csv('company_websites.csv', index=False)

**I tried to write the code with Notepad, Notepad++ and VisualBasic and it happened everytime I copied the code into Python 3.13.** 
Next to it I have been trying to write the code directly into Python 3.13. and it started to run without letting me to finish the code. 

Op. system: Windows

",[],"Hi, and thanks for asking your question! Can you format your code in between sets of three backticks like this:

````
```
print(“Hello, world”)
# a comment that doesn’t get huge
print(“neat!”)
```
````

It will make this much easier for others to read.",['`'],['python'],github,https://github.com/python/cpython/issues/129489,{'repo': 'python/cpython'}
"Proposal: OOP Interface Support in Python

# Feature or enhancement

### Proposal:

**Abstract**

This proposal suggests introducing an official way to define and enforce interfaces in Python. The proposed solution utilizes metaclasses to ensure that derived classes implement interface methods with identical signatures, improving code robustness and maintainability.

**Motivation**

Python currently lacks a built-in mechanism to enforce method signatures in interfaces. While the abc module allows for abstract base classes (ABCs), it does not verify method signatures, leading to potential runtime errors when method signatures do not match expectations.

This proposal introduces an InterfaceMeta metaclass that ensures derived classes implement all required interface methods with the correct signatures. This helps developers detect signature mismatches early, enhancing code reliability.

**Specification**

A new Interface class will be introduced, using the InterfaceMeta metaclass. Any class inheriting from Interface must implement all defined methods with the same signature.

from abc import ABCMeta
import inspect

```
class InterfaceMeta(ABCMeta):
    """"""Metaclass to force implementation of methods in derived classes with the same signature.""""""
    
    def __new__(mcs, name, bases, namespace):
        if bases:  # Ensure we are checking derived classes, not the base interface
            for base in bases:
                if isinstance(base, InterfaceMeta):
                    for attr_name, attr_value in base.__dict__.items():
                        if callable(attr_value) and not attr_name.startswith('__'):
                            if attr_name not in namespace:
                                raise TypeError(
                                    f""Class '{name}' must implement method '{attr_name}' of interface '{base.__name__}'""
                                )
                            
                            base_signature = inspect.signature(attr_value)
                            derived_signature = inspect.signature(namespace[attr_name])
                            
                            if base_signature != derived_signature:
                                raise TypeError(
                                    f""Method '{attr_name}' in class '{name}' does not match the interface signature.\n""
                                    f""Expected: {base_signature}\n""
                                    f""Got: {derived_signature}""
                                )
        return super().__new__(mcs, name, bases, namespace)

class Interface(metaclass=InterfaceMeta):
    """"""Base class for all interfaces.""""""
    pass
```

**Example Usage**

```
class MyInterface(Interface):
    def method(self, x: int) -> str:
        pass

class ValidImplementation(MyInterface):
    def method(self, x: int) -> str:
        return str(x)

class InvalidImplementation(MyInterface):
    def method(self, x):  # Missing return annotation
        return str(x)

# Raises TypeError: ""Method 'method' in class 'InvalidImplementation' does not match the interface signature.""
# Expected: (self, x: int) -> str
# Got: (self, x)
```

**Backward Compatibility**

This proposal introduces a new interface enforcement mechanism and does not affect existing ABCs or classes. It is fully backward-compatible with current Python functionality.

**Alternatives Considered**

1. Using Abstract Base Classes (ABCs): While ABCs enforce method existence, they do not verify method signatures, making them less strict than this approach.
 
2. Type Hints & Static Analysis (e.g., mypy): While static analysis tools can detect type mismatches, they do not enforce runtime constraints, which this proposal aims to achieve.4. 


**Open Questions**

- Should this functionality be integrated into the abc module or remain as a standalone implementation?

- Should additional enforcement (e.g., return type enforcement) be included?

**Conclusion**

This proposal enhances Python's object-oriented capabilities by introducing runtime-verified interfaces. By enforcing method signatures, it reduces bugs and improves maintainability in large-scale applications.


### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130993
<!-- /gh-linked-prs -->
","['class InterfaceMeta(ABCMeta):\n    """"""Metaclass to force implementation of methods in derived classes with the same signature.""""""\n    \n    def __new__(mcs, name, bases, namespace):\n        if bases:  # Ensure we are checking derived classes, not the base interface\n            for base in bases:\n                if isinstance(base, InterfaceMeta):\n                    for attr_name, attr_value in base.__dict__.items():\n                        if callable(attr_value) and not attr_name.startswith(\'__\'):\n                            if attr_name not in namespace:\n                                raise TypeError(\n                                    f""Class \'{name}\' must implement method \'{attr_name}\' of interface \'{base.__name__}\'""\n                                )\n                            \n                            base_signature = inspect.signature(attr_value)\n                            derived_signature = inspect.signature(namespace[attr_name])\n                            \n                            if base_signature != derived_signature:\n                                raise TypeError(\n                                    f""Method \'{attr_name}\' in class \'{name}\' does not match the interface signature.\\n""\n                                    f""Expected: {base_signature}\\n""\n                                    f""Got: {derived_signature}""\n                                )\n        return super().__new__(mcs, name, bases, namespace)\n\nclass Interface(metaclass=InterfaceMeta):\n    """"""Base class for all interfaces.""""""\n    pass', 'class MyInterface(Interface):\n    def method(self, x: int) -> str:\n        pass\n\nclass ValidImplementation(MyInterface):\n    def method(self, x: int) -> str:\n        return str(x)\n\nclass InvalidImplementation(MyInterface):\n    def method(self, x):  # Missing return annotation\n        return str(x)\n\n# Raises TypeError: ""Method \'method\' in class \'InvalidImplementation\' does not match the interface signature.""\n# Expected: (self, x: int) -> str\n# Got: (self, x)']","This needs to be discussed this on [DPO](https://discuss.python.org/) first, but please don't use ChatGPT to generate feature proposals.",[],['python'],github,https://github.com/python/cpython/issues/130992,{'repo': 'python/cpython'}
"pure-Python warn_explicit() passes wrong arg to WarningMessage

The pure-Python implementation of the `warnings.warn_explicit()` function does this:
```python
msg = WarningMessage(message, category, filename, lineno, source)
```
But the 5th argument of `WarningMessage` is `file` (the file the message is supposed to be printed into), not `source` (""the destroyed object which emitted a `ResourceWarning`"").

Here's how to reproduce the bug:

```pycon
>>> import sys, importlib, warnings
>>> warnings.warn_explicit('eggs', UserWarning, 'eggs.py', 42, source=object())
eggs.py:42: UserWarning: eggs
Object allocated at (most recent call last):
  File ""<stdin>"", lineno 1
>>> # so far so good; now let's try the same with pure-Python implementation
>>> sys.modules['_warnings'] = None
>>> importlib.reload(warnings)
<module 'warnings' from '/usr/lib/python3.12/warnings.py'>
>>> warnings.warn_explicit('eggs', UserWarning, 'eggs.py', 42, source=object())
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python3.12/warnings.py"", line 413, in warn_explicit
    _showwarnmsg(msg)
  File ""/usr/lib/python3.12/warnings.py"", line 115, in _showwarnmsg
    _showwarnmsg_impl(msg)
  File ""/usr/lib/python3.12/warnings.py"", line 30, in _showwarnmsg_impl
    file.write(text)
    ^^^^^^^^^^
AttributeError: 'object' object has no attribute 'write'
```

<!-- gh-linked-prs -->
### Linked PRs
* gh-129848
<!-- /gh-linked-prs -->
","['msg = WarningMessage(message, category, filename, lineno, source)', '>>> import sys, importlib, warnings\n>>> warnings.warn_explicit(\'eggs\', UserWarning, \'eggs.py\', 42, source=object())\neggs.py:42: UserWarning: eggs\nObject allocated at (most recent call last):\n  File ""<stdin>"", lineno 1\n>>> # so far so good; now let\'s try the same with pure-Python implementation\n>>> sys.modules[\'_warnings\'] = None\n>>> importlib.reload(warnings)\n<module \'warnings\' from \'/usr/lib/python3.12/warnings.py\'>\n>>> warnings.warn_explicit(\'eggs\', UserWarning, \'eggs.py\', 42, source=object())\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\n  File ""/usr/lib/python3.12/warnings.py"", line 413, in warn_explicit\n    _showwarnmsg(msg)\n  File ""/usr/lib/python3.12/warnings.py"", line 115, in _showwarnmsg\n    _showwarnmsg_impl(msg)\n  File ""/usr/lib/python3.12/warnings.py"", line 30, in _showwarnmsg_impl\n    file.write(text)\n    ^^^^^^^^^^\nAttributeError: \'object\' object has no attribute \'write\'']","> Do you want to send a PR fixing this?

No.",[],['python'],github,https://github.com/python/cpython/issues/129843,{'repo': 'python/cpython'}
"Adding default value as None for tk.OptionMenu and ttk.OptionMenu positional arguments in order to follow standards and get default non-parameterized widget

# Feature or enhancement

### Proposal:

In current implementation of `.__init__` of `tk.OptionMenu`, tkinter raise's error if we use

    tk.OptionMenu() # Argument missing error

while other widgets like `tk.Button` work without arguments

     tk.Button() # No Error

Therefore by making the below change, tkinter can follow its standard among other widget as well as let user get a non-parameterized OptionMenu widget.

**Change:**
```python
def __init__(self, master, variable, value, *values, **kwargs): #Line 4020 in cpython/Lib/tkinter /__init__.py
```

**To:**

```python
def __init__(self, master=None, variable=None, value=None, *values, **kwargs): #Line 4020 in cpython/Lib/tkinter /__init__.py
```


### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130479
<!-- /gh-linked-prs -->
","['def __init__(self, master, variable, value, *values, **kwargs): #Line 4020 in cpython/Lib/tkinter /__init__.py', 'def __init__(self, master=None, variable=None, value=None, *values, **kwargs): #Line 4020 in cpython/Lib/tkinter /__init__.py']","@kurawlefaraaz I agree with you!

I took a look and saw that it looks like only the widget `OptionMenu` doesn't have default parameters, which is really inconvenient for some situations (e.g. when I just want to quickly create widgets to see the layout, and don't want to specify the exact parameters)

So I created a PR to implement this feature and linked it to this issue.

But using `None` as the default for some parameters causes some problems, and I changed it to an empty string in the PR.",[],['python'],github,https://github.com/python/cpython/issues/130356,{'repo': 'python/cpython'}
"Syntax error on '{z} if z is not None else pass'

# Bug report

### Bug description:

```python
My question is in the title.

In the tutorial, I read: Use 'pass' in places, where code is required syntactically, but none is needed.
In order to save indentations, I used the conditional assignement in some segment of code. But I only want to include z in the set x, if it is not None, because later, the None disturbs.

So my thesis is: The code in the title is syntactically correct, but still, I get a syntax error.

Thank you for your kind consideration
```


### CPython versions tested on:

3.10

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-129880
<!-- /gh-linked-prs -->
","[""My question is in the title.\n\nIn the tutorial, I read: Use 'pass' in places, where code is required syntactically, but none is needed.\nIn order to save indentations, I used the conditional assignement in some segment of code. But I only want to include z in the set x, if it is not None, because later, the None disturbs.\n\nSo my thesis is: The code in the title is syntactically correct, but still, I get a syntax error.\n\nThank you for your kind consideration""]","Yeah would be fantastic if the `SyntaxError` here said something like ""statement given where expression required"".",[],['python'],github,https://github.com/python/cpython/issues/129515,{'repo': 'python/cpython'}
"AttributeError 'did you mean' suggestions don't appear for properties without a setter

# Bug report

### Bug description:

```python
class A:
    @property
    def computed_a(self):
        return 2

    @property
    def computed_b(self):
        return 3
    @computed_b.setter
    def computed_b(self, val):
        print('set!')

a = A()
a.computed_a = 12 # typo
```

When running this, I would expect to get `AttributeError: ... Did you mean: 'computed_b'`, but I'm not getting a suggestion. I think it's because the `AttributeError` that `property.__set__` raises doesn't have `.obj` and `.name` set.

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux","[""class A:\n    @property\n    def computed_a(self):\n        return 2\n\n    @property\n    def computed_b(self):\n        return 3\n    @computed_b.setter\n    def computed_b(self, val):\n        print('set!')\n\na = A()\na.computed_a = 12 # typo""]","Also no suggestion for:

```python
class A:
    pass

a = A()
a.abcde = 1
del a.abcdf # typo
```",['class A:\n    pass\n\na = A()\na.abcde = 1\ndel a.abcdf # typo'],['python'],github,https://github.com/python/cpython/issues/130399,{'repo': 'python/cpython'}
"`@typing.overload` doesn't preserve function attributes (like `__annotations__`)

# Bug report

### Bug description:

Somewhat of a corner-case, but something like this

```python
import typing

class Foo:
    @typing.overload
    def foo(): ...

    print(foo.__qualname__)
```

prints `_overload_dummy` which, yeah OK I think I'm the real dummy here, but also did it need to call me that 😝 ?

(In all seriousness I'm just doing weird things, and hit this and even though I'm doing weird things, Python never stopped me before)

### CPython versions tested on:

3.11

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-129932
<!-- /gh-linked-prs -->
",['import typing\n\nclass Foo:\n    @typing.overload\n    def foo(): ...\n\n    print(foo.__qualname__)'],"Sorry, but this is not how this function should be used :(

I don't think that we should support this.",[],['python'],github,https://github.com/python/cpython/issues/129931,{'repo': 'python/cpython'}
"Exit code in case of an error is always 1 since Python 3.13

# Bug report

### Bug description:

We noticed a failure of our Vim test suite on the Github Windows runners, when it was updated from python3.12 to python3.13.

Vim basically does run in a terminal `exit(123)` and expects the return code to be 123, however, since python3.13 the return code seems to be 1.

Note this works find on the linux jobs, just on Windows this does not work correctly. Also note, python3 -c 'exit(123)' seems to work correctly, only when using an interactive session it doesn't seem to work right.

related: 
- vim/vim#16546 (see in particular this [comment](https://github.com/vim/vim/issues/16546#issuecomment-2646133046))
- actions/runner-images#11512

```python
exit(123)
```


### CPython versions tested on:

3.13

### Operating systems tested on:

Windows

<!-- gh-linked-prs -->
### Linked PRs
* gh-129901
<!-- /gh-linked-prs -->
",['exit(123)'],"I was able to reproduce this on Linux as well. Looking into it. (Note that this is specific to the REPL, this doesn't happen when running normal files.)",[],['python'],github,https://github.com/python/cpython/issues/129900,{'repo': 'python/cpython'}
"Socketpair authentication fails while Proxifier is enabled

# Bug report

### Bug description:

In the fallback socketpair implementation for Windows, socket authentication fails while Proxifier (and likely similar tools) are enabled. The following exception is always raised:
https://github.com/python/cpython/blob/e41ec8e18b078024b02a742272e675ae39778536/Lib/socket.py#L644-L648

Originally spotted in: https://github.com/nicotine-plus/nicotine-plus/issues/3265

Relevant discussion on curl's issue tracker: https://github.com/curl/curl/issues/10144

### CPython versions tested on:

3.12

### Operating systems tested on:

Windows",[],"This is working as intended. You're running software that interferes with expected functionality. https://github.com/python/cpython/pull/122134 to fix [CVE-2024-3219](https://osv.dev/vulnerability/CVE-2024-3219) caused it to show up, before this your man-in-the-middle software was snooping the localhost connections being used to build a socket pair work-alike for inter process communication on Windows without being noticed.

If you wanted to propose a workaround PR for this to go back to not caring about sockets being intercepted and snooped on, it would wind up requiring doing authentication handshake through both ends of the socket to ensure they were communicating with one another.  _(and only doing the existing `raise` if that handshake fails)_

I do not consider that a good idea... This smells like a Proxifier bug, it should not be intercepting localhost sockets.",[],['python'],github,https://github.com/python/cpython/issues/129676,{'repo': 'python/cpython'}
"Alignment fault in PyMember_SetOne under freethreading on aarch64

# Bug report

### Bug description:

I saw a SIGBUS crash with the following backtrace immediately on startup when running a free-threaded build of https://github.com/jax-ml/jax on Python 3.13t:

```
#0  PyMember_SetOne (addr=0x20006fa48bc """", addr@entry=0x20006fa4890 ""`\367N~"", <incomplete sequence \346>, l=<optimized out>,
    v=v@entry='Context manager for `jax2tf_associative_scan_reductions` config option.\n\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.') at Python/structmember.c:308
#1  0x0000b1fea968e908 in member_set (self=<member_descriptor at remote 0x20006384210>, obj=<State at remote 0x20006fa4890>,
    value='Context manager for `jax2tf_associative_scan_reductions` config option.\n\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.') at Objects/descrobject.c:238
#2  0x0000b1fea96e9928 in _PyObject_GenericSetAttrWithDict (obj=<State at remote 0x20006fa4890>, name='__doc__',
    value='Context manager for `jax2tf_associative_scan_reductions` config option.\n\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.', dict=dict@entry=0x0) at Objects/object.c:1778
```

What we're doing here is running this code:
```
obj.__doc__ = ""...""
```
and crashing.

We're at this line of code:
https://github.com/python/cpython/blob/4f0261561a247919b0733075c4436d97919b08a4/Python/structmember.c#L308

Digging a little deeper, the relevant disassembly is:

```
(gdb) display /10i $pc-20
10: x/10i $pc-20
   0xb1fea9860094 <PyMember_SetOne+1596>:       bl      0xb1fea985f690 <_PyCriticalSection_BeginMutex>
   0xb1fea9860098 <PyMember_SetOne+1600>:       ldr     x19, [x19, x21]
   0xb1fea986009c <PyMember_SetOne+1604>:       cbz     x20, 0xb1fea98600a8 <PyMember_SetOne+1616>
   0xb1fea98600a0 <PyMember_SetOne+1608>:       mov     x0, x20
   0xb1fea98600a4 <PyMember_SetOne+1612>:       bl      0xb1fea985f42c <Py_INCREF>
=> 0xb1fea98600a8 <PyMember_SetOne+1616>:       stlr    x20, [x24]
   0xb1fea98600ac <PyMember_SetOne+1620>:       add     x0, sp, #0x8
   0xb1fea98600b0 <PyMember_SetOne+1624>:       bl      0xb1fea985f774 <_PyCriticalSection_End>
   0xb1fea98600b4 <PyMember_SetOne+1628>:       mov     x0, x19
   0xb1fea98600b8 <PyMember_SetOne+1632>:       bl      0xb1fea985f664 <Py_XDECREF>

(gdb) info registers
...
x20            0x200064f9610       2199129134608
x21            0x2c                44
x22            0x10                16
x23            0x0                 0
x24            0x20006fa48bc       2199140321468
x25            0x0                 0
...
```

What's going on here is that `stlr`'s target address must be 8-byte aligned on aarch64: https://developer.arm.com/documentation/102336/0100/Load-Acquire-and-Store-Release-instructions

but the `__doc__` field of this object  is only 4-byte aligned, with `offset = 44`.

```
(gdb) up
(gdb) print *descr->d_member
$38 = {name = 0xb1fea9bdc950 <_PyRuntime+63952> ""__doc__"", type = 16, offset = 44, flags = 0, doc = 0x0}
```

We've placed an object field at an unaligned address, and used it in an atomic access that requires alignment, which is an error.

How should we fix this?

This seems like it's a CPython bug: CPython shouldn't choose underaligned slot offsets for object fields.

However, in this particular case it comes from a Python subclass of a C extension base class that has `tp_basicsize=44`; I'm also not aware of any rule that says `tp_basicsize` has to be a multiple of the word size. Perhaps CPython should either enforce that or round up the size of base classes to ensure alignment.

Or we can argue that CPython shouldn't be using an aligned atomic in this case.

What do you think?



### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129850
* gh-131078
* gh-131079
<!-- /gh-linked-prs -->
","['#0  PyMember_SetOne (addr=0x20006fa48bc """", addr@entry=0x20006fa4890 ""`\\367N~"", <incomplete sequence \\346>, l=<optimized out>,\n    v=v@entry=\'Context manager for `jax2tf_associative_scan_reductions` config option.\\n\\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.\') at Python/structmember.c:308\n#1  0x0000b1fea968e908 in member_set (self=<member_descriptor at remote 0x20006384210>, obj=<State at remote 0x20006fa4890>,\n    value=\'Context manager for `jax2tf_associative_scan_reductions` config option.\\n\\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.\') at Objects/descrobject.c:238\n#2  0x0000b1fea96e9928 in _PyObject_GenericSetAttrWithDict (obj=<State at remote 0x20006fa4890>, name=\'__doc__\',\n    value=\'Context manager for `jax2tf_associative_scan_reductions` config option.\\n\\nJAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.\', dict=dict@entry=0x0) at Objects/object.c:1778', 'obj.__doc__ = ""...""', '(gdb) display /10i $pc-20\n10: x/10i $pc-20\n   0xb1fea9860094 <PyMember_SetOne+1596>:       bl      0xb1fea985f690 <_PyCriticalSection_BeginMutex>\n   0xb1fea9860098 <PyMember_SetOne+1600>:       ldr     x19, [x19, x21]\n   0xb1fea986009c <PyMember_SetOne+1604>:       cbz     x20, 0xb1fea98600a8 <PyMember_SetOne+1616>\n   0xb1fea98600a0 <PyMember_SetOne+1608>:       mov     x0, x20\n   0xb1fea98600a4 <PyMember_SetOne+1612>:       bl      0xb1fea985f42c <Py_INCREF>\n=> 0xb1fea98600a8 <PyMember_SetOne+1616>:       stlr    x20, [x24]\n   0xb1fea98600ac <PyMember_SetOne+1620>:       add     x0, sp, #0x8\n   0xb1fea98600b0 <PyMember_SetOne+1624>:       bl      0xb1fea985f774 <_PyCriticalSection_End>\n   0xb1fea98600b4 <PyMember_SetOne+1628>:       mov     x0, x19\n   0xb1fea98600b8 <PyMember_SetOne+1632>:       bl      0xb1fea985f664 <Py_XDECREF>\n\n(gdb) info registers\n...\nx20            0x200064f9610       2199129134608\nx21            0x2c                44\nx22            0x10                16\nx23            0x0                 0\nx24            0x20006fa48bc       2199140321468\nx25            0x0                 0\n...', '(gdb) up\n(gdb) print *descr->d_member\n$38 = {name = 0xb1fea9bdc950 <_PyRuntime+63952> ""__doc__"", type = 16, offset = 44, flags = 0, doc = 0x0}']","This is now fixed in nanobind, but I think there's still a couple of action items here for CPython to document and enforce this.",[],['python'],github,https://github.com/python/cpython/issues/129675,{'repo': 'python/cpython'}
"random.sample raises ""IndexError: pop from empty list"" when both ""population"" and ""counts"" are empty

# Bug report

### Bug description:

I just encountered the situation where I used `random.sample` but both the `population` and `counts` arguments were empty (my algorithm had nothing left to choose from). So, basically this situation:
```python
>>> random.sample([], 1, counts=[])
Traceback (most recent call last):
  File ""<python-input-1>"", line 1, in <module>
    random.sample([], 1, counts=[])
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File ""/path/to/lib/python3.14/random.py"", line 424, in sample
    total = cum_counts.pop()
IndexError: pop from empty list
```

Instead of the `IndexError`, I expected a `ValueError`, similar to the following situations:
```python
>>> random.sample([], 1)
Traceback (most recent call last):
  File ""<python-input-2>"", line 1, in <module>
    random.sample([], 1)
    ~~~~~~~~~~~~~^^^^^^^
  File ""/path/to/lib/python3.14/random.py"", line 434, in sample
    raise ValueError(""Sample larger than population or is negative"")
ValueError: Sample larger than population or is negative
>>> 
>>> random.sample([1], 2, counts=[1])
Traceback (most recent call last):
  File ""<python-input-3>"", line 1, in <module>
    random.sample([1], 2, counts=[1])
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File ""/path/to/lib/python3.14/random.py"", line 429, in sample
    selections = self.sample(range(total), k=k)
  File ""/path/to/lib/python3.14/random.py"", line 434, in sample
    raise ValueError(""Sample larger than population or is negative"")
ValueError: Sample larger than population or is negative
```

[The docs](https://docs.python.org/3/library/random.html#random.sample) mention that
> If the sample size is larger than the population size, a [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) is raised.

In addition, I would expect the following to work:
```python
>>> random.sample([], 0, counts=[])
Traceback (most recent call last):
  File ""<python-input-4>"", line 1, in <module>
    random.sample([], 0, counts=[])
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File ""/path/to/lib/python3.14/random.py"", line 424, in sample
    total = cum_counts.pop()
IndexError: pop from empty list
```
similar to how it works when `counts` is not specified:
```python
>>> random.sample([], 0)
[]
```

Not sure though what CPython's backwards-compatibility policy has to say here, since changing the exception type – or, in the second case, removing the exception altogether – might actually break someone's code...

---

Tested with:
```lang-none
Python 3.14.0a5 (main, Feb 12 2025, 14:51:40) [Clang 19.1.6 ] on linux
cpython-3.14.0a5-linux-x86_64-gnu
```

### CPython versions tested on:

3.14

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130291
* gh-130416
* gh-130417
<!-- /gh-linked-prs -->
","['>>> random.sample([], 1, counts=[])\nTraceback (most recent call last):\n  File ""<python-input-1>"", line 1, in <module>\n    random.sample([], 1, counts=[])\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File ""/path/to/lib/python3.14/random.py"", line 424, in sample\n    total = cum_counts.pop()\nIndexError: pop from empty list', '>>> random.sample([], 1)\nTraceback (most recent call last):\n  File ""<python-input-2>"", line 1, in <module>\n    random.sample([], 1)\n    ~~~~~~~~~~~~~^^^^^^^\n  File ""/path/to/lib/python3.14/random.py"", line 434, in sample\n    raise ValueError(""Sample larger than population or is negative"")\nValueError: Sample larger than population or is negative\n>>> \n>>> random.sample([1], 2, counts=[1])\nTraceback (most recent call last):\n  File ""<python-input-3>"", line 1, in <module>\n    random.sample([1], 2, counts=[1])\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File ""/path/to/lib/python3.14/random.py"", line 429, in sample\n    selections = self.sample(range(total), k=k)\n  File ""/path/to/lib/python3.14/random.py"", line 434, in sample\n    raise ValueError(""Sample larger than population or is negative"")\nValueError: Sample larger than population or is negative', '>>> random.sample([], 0, counts=[])\nTraceback (most recent call last):\n  File ""<python-input-4>"", line 1, in <module>\n    random.sample([], 0, counts=[])\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File ""/path/to/lib/python3.14/random.py"", line 424, in sample\n    total = cum_counts.pop()\nIndexError: pop from empty list', '>>> random.sample([], 0)\n[]', '-none\nPython 3.14.0a5 (main, Feb 12 2025, 14:51:40) [Clang 19.1.6 ] on linux\ncpython-3.14.0a5-linux-x86_64-gnu']","Neither of these cases was tested or intended behavior, so it would be reasonable to fix them both.  I'll work on a PR soonish.  Thanks for the report.

Because of the possibility of breaking code, I'm -0 on backporting the edit.",[],['python'],github,https://github.com/python/cpython/issues/130285,{'repo': 'python/cpython'}
"pygettext: Add `--omit-header` option

# Feature or enhancement

### Proposal:

From gettext:

> ‘--omit-header’
> 
>     Don’t write header with ‘msgid """"’ entry. Note: Using this option may lead to an error in subsequent operations if the output contains non-ASCII characters.
> 
>     This is useful for testing purposes because it eliminates a source of variance for generated .gmo files. With --omit-header, two invocations of xgettext on the same files with the same options at different times are guaranteed to produce the same results.
> 
>     Note that using this option will lead to an error if the resulting file would not entirely be in ASCII.

Will be useful for our tests. PR soon



### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130650
<!-- /gh-linked-prs -->
",[],"This flag is universally useful but to expand on this:

> Will be useful for our tests. PR soon

We currently have i18n tests for argparse, optparse and getopt. The snapshots are in `Lib/test/translationdata`.
The current format of the snapshots is just a list of msgids, which is not great because it doesn't include for example `msgid_plural` or `msgctxt`.

With `--omit-header` (and `--no-location`) we can use .po files for the snapshots instead. With the header removed, the snapshots will not change unless the source strings change.
",[],['python'],github,https://github.com/python/cpython/issues/130647,{'repo': 'python/cpython'}
"`epoll_ctl` returns `EBADF` and crashes with `SIGABRT`

# Crash report

### What happened?

Program was running in docker container using `nikolaik/python-nodejs:python3.13-nodejs23` image.
Container has been removed with it's volume as soon as process exited so I can't provide core dump.

I can't provide exact code which caused the issue because it has thousands of lines and is private.
Code heavily uses asyncio and has ~20k tasks running which are sleeping most of the time, ~20 tasks running simultaneously.

Code has many dependencies but only 2 of them might be interesting: `uvloop` and `curl_cffi` (used in async mode).

The most mysterious part is that 1-2 hours before crash program started behave very very strange. Logs started to be printed in spurts, network connections started being disconnected because of timeouts. I looked into htop and discovered that process had 0.0% CPU usage in time when no logs have been printed, then wave of text printed and all over again. Looks very like program sleeps or waits for some IO synchronously, but nothing in program does it. Also it's the second or third time this happens, most of the time program works normally.
Machine and process had enough free CPU and RAM available to use so it's not resource problem. SSD and network also wasn't busy so it's definitely not resource problem.

I've been lucky to catch this using strace in htop. I didn't find a way to dump to file but here are screenshots of last lines and last lines filtered with `119` (fd that caused the issue).

<img width=""1249"" alt=""Image"" src=""https://github.com/user-attachments/assets/b103e7f8-c847-4512-89b2-5e95e6b1e77e"" />
<img width=""1244"" alt=""Image"" src=""https://github.com/user-attachments/assets/9f2b7198-eff8-4251-a60d-91fbb809a814"" />

### CPython versions tested on:

3.13

### Operating systems tested on:

Linux

### Output from running 'python -VV' on the command line:

Python 3.13.2 (main, Feb 25 2025, 05:25:21) [GCC 12.2.0]",[],"Can you reproduce this, or was it a one-off? If a one-off, we're not going to be able to help -- not enough information, and chances are that it was either a container hiccup or 3rd party software. If you *can* reproduce, could you narrow it down to something that doesn't depend on 3rd party software, or on proprietary code? Without that there's little hope that we can help even if you *can* reproduce it at will -- we've seen other cases (unrelated to your symptoms) where there was too much not under our control and we've never made any progress with those, so we'd probably end up closing the issue in that case. Sorry!",[],['python'],github,https://github.com/python/cpython/issues/131111,{'repo': 'python/cpython'}
"Add tests for delattr and setattr suggestions

# Feature or enhancement

### Proposal:

Add tests for currently untested delattr and setattr suggestions

### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130455
<!-- /gh-linked-prs -->
",[],"Calling setattr on a new attribute name doesn’t raise an AttributeError, so I’m a bit confused on how to extend our suggestion testing to cover it. Thoughts?
Also, any further suggestions on the delattr tests are welcome:)",[],['python'],github,https://github.com/python/cpython/issues/130428,{'repo': 'python/cpython'}
"Vague behavior when single quoted f-string format_spec contains line break

# Bug report

### Bug description:

```python
>>> value = 123
>>> f""{value:.{'2'}f}"" # '123.00'
>>> f""{value:.
{'2f'}}"" # '123.00'
# but, shouldn't this one below also be valid?
>>> f""{value:.
... {'2'}f}"" # invalid
>>> f""{value:
... {'.2f'}}"" # '123.00'
```

I am checking the code of CPython's lexer and am confused why the lexer resets to normal mode when it encounters line break in format spec
https://github.com/python/cpython/blob/d7672e5d5a7b9580a72dbe75d3a9e8840bcc604c/Parser/lexer/lexer.c#L1338-L1348

Go back to the original PR: https://github.com/python/cpython/pull/110271
Seems this case is not covered by the test cases

The case above could be recognized by tokenizer, so maybe pegen should be modified.
However, since it goes back to normal mode, some corner cases cannot be handled by tokenizer:
```python
>>> value = 123
>>> f""{value:#{'x'}}"" # '0x7b'
>>> f""{value:
... #{'x'}}"" # breaks the tokenizer
```

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130063
<!-- /gh-linked-prs -->
","['>>> value = 123\n>>> f""{value:.{\'2\'}f}"" # \'123.00\'\n>>> f""{value:.\n{\'2f\'}}"" # \'123.00\'\n# but, shouldn\'t this one below also be valid?\n>>> f""{value:.\n... {\'2\'}f}"" # invalid\n>>> f""{value:\n... {\'.2f\'}}"" # \'123.00\'', '>>> value = 123\n>>> f""{value:#{\'x\'}}"" # \'0x7b\'\n>>> f""{value:\n... #{\'x\'}}"" # breaks the tokenizer']",Seems to me that newlines should perhaps not be allowed in single-quoted f-strings at all? Allowing this violates my original design for strings.,[],['python'],github,https://github.com/python/cpython/issues/129958,{'repo': 'python/cpython'}
"Various data races in subinterpreter tests under TSAN

# Bug report

Thread sanitizer reports a number of data races when running subinterpreter tests

### `InterpreterPoolMixin` (`test_concurrent_futures`)

* `run_eval_code_obj`: see https://github.com/python/cpython/issues/128130
* [`posixmodule_exec`](https://github.com/python/cpython/blob/49bd47d5f14993d37b97aa2bbf257f5df16b96a9/Modules/posixmodule.c#L18014) modifies globals `waitid_result_desc` and `stat_result_desc`
* `_PyBuiltins_AddExceptions`: modifies globals `PyExc_EnvironmentError`, etc. https://github.com/python/cpython/blob/49bd47d5f14993d37b97aa2bbf257f5df16b96a9/Objects/exceptions.c#L4354-L4355
* `_PyInterpreterState_FinalizeAllocatedBlocks`: modifies _PyRuntime variable _PyInterpreterState_FinalizeAllocatedBlocks
* `_globals_fini` + [`clear_interpreter`](https://github.com/python/cpython/blob/49bd47d5f14993d37b97aa2bbf257f5df16b96a9/Modules/_interpqueuesmodule.c#L1454-L1456): data race on `_globals.module_count` (the read in `clear_interpreter` happens outside of a lock)
* `init_static_exctypes`: modifies globals `_PyExc_InterpreterError`, etc.
* `_structmodule_exec`: data race reported on [`ptr->unpack = native->unpack`](https://github.com/python/cpython/blob/49bd47d5f14993d37b97aa2bbf257f5df16b96a9/Modules/_struct.c#L2815)

I think for now it would make sense to skip the `InterpreterPoolMixin` tests when running with TSAN.

### `test__interpchannels`

* [`find_name_in_mro`](https://github.com/python/cpython/blob/7b2e01bb555359913939d7ff168363f1760d3f8e/Objects/typeobject.c#L5415) and [`_waiting_release`](https://github.com/python/cpython/blob/7b2e01bb555359913939d7ff168363f1760d3f8e/Modules/_interpchannelsmodule.c#L497): I don't understand this one, but it happens during `test_send_recv_different_interpreters_and_threads`

### `test__interpreters` and `test_interpreters`

* `type_ready_set_new`: https://github.com/python/cpython/blob/7b2e01bb555359913939d7ff168363f1760d3f8e/Objects/typeobject.c#L8509
* `type_ready`: (see https://github.com/python/cpython/issues/129817)
* File descriptor race in `test_api.LowLevelTests.test_is_running` and `test_running`: `close()` concurrent with `read()` on the same file descriptor.
* `managed_static_type_state_init` in `test.test_interpreters.test_stress.StressTests.test_create_many_threaded`: data race on the non-atomic read of `interp_count`.
* pegen [`memo_statistics`](https://github.com/python/cpython/blob/5fa7e1b7fd57e8c6297e9eb79d79cede42e5ce0f/Parser/pegen.c#L367) mutex is currently only used in free threading build (seen in test_create_many_threaded) 
* version tags on static types: `NEXT_GLOBAL_VERSION_TAG`, `type->tp_versions_used`, and `tp->tp_version_tag` modifications are not thread-safe (seen in test_create_many_threaded)

### `test_capi.test_misc.assign_version_tag`

* race on `NEXT_GLOBAL_VERSION_TAG` in `assign_version_tag` (see above)

<!-- gh-linked-prs -->
### Linked PRs
* gh-129826
* gh-129829
<!-- /gh-linked-prs -->
",[],"No, I'm not actively working on them. Go for it.",[],['python'],github,https://github.com/python/cpython/issues/129824,{'repo': 'python/cpython'}
"`test_free_threading.test_dict` on TSAN/free-threading is flaky

# Bug report

### Bug description:

We have:

```
0:04:15 load avg: 7.63 [20/23/2] test_free_threading worker non-zero exit code (Exit code -6 (SIGABRT)) -- running (2): test_socket (1 min 38 sec), test_threading (38.8 sec)
python: Objects/obmalloc.c:1219: void process_queue(struct llist_node *, struct _qsbr_thread_state *, _Bool, delayed_dealloc_cb, void *): Assertion `buf->rd_idx == buf->wr_idx' failed.
Fatal Python error: Aborted

<Cannot show all threads while the GIL is disabled>
Stack (most recent call first):
  File ""/home/runner/work/cpython/cpython/Lib/test/test_free_threading/test_dict.py"", line 184 in writer_func
  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 996 in run
  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 1054 in _bootstrap_inner
  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 1016 in _bootstrap

Extension modules: _testinternalcapi, _testcapi (total: 2)
```

I'm not sure if it's a real bug or not. Victor suggested me to open an issue for this one. Maybe there's already one that exists though.

See https://github.com/python/cpython/actions/runs/13225352402/job/36915529351?pr=129175#step:12:44 for the log (hopefully it will stay).

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130553
<!-- /gh-linked-prs -->
","['0:04:15 load avg: 7.63 [20/23/2] test_free_threading worker non-zero exit code (Exit code -6 (SIGABRT)) -- running (2): test_socket (1 min 38 sec), test_threading (38.8 sec)\npython: Objects/obmalloc.c:1219: void process_queue(struct llist_node *, struct _qsbr_thread_state *, _Bool, delayed_dealloc_cb, void *): Assertion `buf->rd_idx == buf->wr_idx\' failed.\nFatal Python error: Aborted\n\n<Cannot show all threads while the GIL is disabled>\nStack (most recent call first):\n  File ""/home/runner/work/cpython/cpython/Lib/test/test_free_threading/test_dict.py"", line 184 in writer_func\n  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 996 in run\n  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 1054 in _bootstrap_inner\n  File ""/home/runner/work/cpython/cpython/Lib/threading.py"", line 1016 in _bootstrap\n\nExtension modules: _testinternalcapi, _testcapi (total: 2)']",This should be fixed now.,[],['python'],github,https://github.com/python/cpython/issues/130519,{'repo': 'python/cpython'}
"iOS testbed clone breaks on some symlinks

# Bug report

### Bug description:

The iOS testbed project is able to use symlinks when referring to the XCframework (or simulator Framework slice of an XCframework). This saves significant disk space and startup time as the need to copy the full framework is eliminated.

The `clone` subcommand of the testbed will duplicate this symlink; or, if a path to an XCframework (or simulator slice) is provided, that framework will be used instead.

However:
1. If the testbed is cloned and *no* new framework is provided, and the symlink is specified as a relative link, the symlink will not work in the new location
2. If the existing framework symlink is invalid, any attempt to replace it fails because the existing link won't resolve.

To replicate, generate an arm64 simulator build, then:
1. `python iOS/testbed clone testbed-1 --framework cross-build/arm64-apple-ios-simulator/iOS/Frameworks/arm64-iphonesimulator`  (substitute path to simulator framework as appropriate)
2. `python testbed-1 clone tmp/testbed-2`
3. Inspect `tmp/testbed-2/Python.xcframework/ios-arm64_x86_64-simulator` - it will be an invalid symlink.
4. `python tmp/testbed-2 clone tmp/testbed-3` - this will fail because testbed-2 doesn't contain a simulator framework.
5. `python tmp/testbed-2 clone tmp/testbed-3 --framework cross-build/arm64-apple-ios-simulator/iOS/Frameworks/arm64-iphonesimulator` - this will fail with a FileNotFoundError looking for `.../cpython/tmp/cross-build/arm64-apple-ios-simulator/iOS/Frameworks/arm64-iphonesimulator`, which is what the testbed-2 framework symlink would resolve to (but doesn't exist).

### CPython versions tested on:

3.14

### Operating systems tested on:

Other

<!-- gh-linked-prs -->
### Linked PRs
* gh-130026
* gh-130073
<!-- /gh-linked-prs -->
",[],"(Note: we use the plain X.Y labels on issues and the ""needs backport to X.Y"" labels on PRs)",[],['python'],github,https://github.com/python/cpython/issues/130025,{'repo': 'python/cpython'}
"PyLong_AsLongAndOverflow does not guarantee overflow is -1 when value is -1

# Bug report

### Bug description:

In the function `pylong_aslongandoverflow`
https://github.com/python/cpython/blob/3929af5e3a203291dc07b40c9c3515492e3ba7b4/Modules/_testlimitedcapi/long.c#L621-L632

there is an assertion `overflow == -1` when `value == -1`. But this is not always true, like if `arg` is `NULL`.

Reproduce:
```python
from test.support import import_helper

_testlimitedcapi = import_helper.import_module('_testlimitedcapi')

aslonglongandoverflow = _testlimitedcapi.pylong_aslonglongandoverflow
aslonglongandoverflow(None)
```

Result:
```
python: ../Modules/_testlimitedcapi/long.c:674: pylong_aslonglongandoverflow: Assertion `overflow == -1' failed.
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-130828
* gh-130869
* gh-130871
* gh-130876
<!-- /gh-linked-prs -->
","[""from test.support import import_helper\n\n_testlimitedcapi = import_helper.import_module('_testlimitedcapi')\n\naslonglongandoverflow = _testlimitedcapi.pylong_aslonglongandoverflow\naslonglongandoverflow(None)"", ""python: ../Modules/_testlimitedcapi/long.c:674: pylong_aslonglongandoverflow: Assertion `overflow == -1' failed.""]","That would be because passing `None` to `pylong_aslongandoverflow` changes the argument to `NULL`, so a `SystemError` is raised by `PyLong_AsLongAndOverflow`, which the test function wasn't expecting.

This is [documented](https://docs.python.org/3/c-api/long.html#c.PyLong_AsLongAndOverflow):

> If any other exception occurs set *overflow to 0 and return -1 as usual.

`overflow` is indeed getting set to `0` here, not `-1`, so the assertion is wrong. It's fine to fix this specific case since we're already here, but I'm assuming you're doing some fuzzing. That's fine--we're happy to fix edge cases--but please try to keep the fuzzing in the *standard library*, not our test suite (so no more fuzzing on the `test` module, please!)",[],['python'],github,https://github.com/python/cpython/issues/130824,{'repo': 'python/cpython'}
"Crash with locals() used in list comprehension 

# Crash report

### What happened?

```python
def f():
    lambda: k
    k = 1
    print([locals() for k in [0]])

f()
```

Was reported on https://discuss.python.org/t/segfault-in-calling-locals-within-list-comprehension/81681
Tested on macOS and Fedora 41.

### CPython versions tested on:

3.13

### Operating systems tested on:

macOS

### Output from running 'python -VV' on the command line:

Python 3.13.0 (v3.13.0:60403a5409f, Oct  7 2024, 00:37:40) [Clang 15.0.0 (clang-1500.3.9.4)]",['def f():\n    lambda: k\n    k = 1\n    print([locals() for k in [0]])\n\nf()'],cc @carljm (not sure if it wasn't already a known issue),[],['python'],github,https://github.com/python/cpython/issues/130451,{'repo': 'python/cpython'}
"Question with peg_generator grammar

as per `metagrammar.gram` item can be optional
```
item[Item]:
    | '[' ~ alts ']' {Opt(alts)}
```
by this it can be concluded that `alt` can be optional and so on. As understood by me is that it is possible to write a rule like `rulename: ` with no `alts`. pls clerify.","[""item[Item]:\n    | '[' ~ alts ']' {Opt(alts)}""]","Since this isn't a bug, I'm going to close this.",[],['python'],github,https://github.com/python/cpython/issues/131103,{'repo': 'python/cpython'}
"Refactor tests for HMAC

The tests for HMAC are organized in such a way that makes the adoption of HACL* HMAC harder. More precisely, it'll be a bit harder to test the OpenSSL *and* the HACL* implementation of HMAC (for instance, some tests may or may not work with HACL* as they only support a subset of the hash functions supported by OpenSSL).

I am suggesting a way to make the test interface more generic using mixin classes. For instance, we have multiple ways of creating a HMAC object. It can be through `hmac.HMAC` or through `hmac.new` or through `_hashlib.hmac_new`. While `hmac.new` and `hmac.HMAC` are identical, `_hashlib.hmac_new` is different in the sense that the signature is different as well (and that the objects being returned are also different; they are not instances of `hmac.HMAC` but instances of `_hashlib.HMAC`, though they implement the same interface).

Now, once we add HACL* implementation, the interface will be similar to the Python implementation of HMAC and thus we need to test them both. Currently, it's hard to switch from the Python module implementation to the C implementation.

<!-- gh-linked-prs -->
### Linked PRs
* gh-130150
* gh-130788
<!-- /gh-linked-prs -->
",[],"I won't backport this one because there will be too many conflicts. In addition, since we won't have multiple implementations of HMAC on 3.12 and 3.13, there is no need for the mixins.",[],['python'],github,https://github.com/python/cpython/issues/130149,{'repo': 'python/cpython'}
"`ast.parse(..., mode='single')` parses of multiple statements which are then not unparsed

# Bug report

### Bug description:

```python
$ ./python
Python 3.14.0a4+ (heads/test:d906bde250, Feb  2 2025, 11:08:38) [GCC 11.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import ast
>>> a = ast.parse('i = 1; j = 2', mode='single')
>>> print(ast.dump(a, indent=2))
Interactive(
  body=[
    Assign(
      targets=[
        Name(id='i', ctx=Store())],
      value=Constant(value=1)),
    Assign(
      targets=[
        Name(id='j', ctx=Store())],
      value=Constant(value=2))])
>>> ast.unparse(a)
'j = 2'
```
My guess the `ast.parse()` should probably error?

### CPython versions tested on:

3.14, 3.12, 3.13, 3.11, 3.10

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129620
<!-- /gh-linked-prs -->
","['$ ./python\nPython 3.14.0a4+ (heads/test:d906bde250, Feb  2 2025, 11:08:38) [GCC 11.4.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import ast\n>>> a = ast.parse(\'i = 1; j = 2\', mode=\'single\')\n>>> print(ast.dump(a, indent=2))\nInteractive(\n  body=[\n    Assign(\n      targets=[\n        Name(id=\'i\', ctx=Store())],\n      value=Constant(value=1)),\n    Assign(\n      targets=[\n        Name(id=\'j\', ctx=Store())],\n      value=Constant(value=2))])\n>>> ast.unparse(a)\n\'j = 2\'']","Sure, will send something up later.",[],['python'],github,https://github.com/python/cpython/issues/129598,{'repo': 'python/cpython'}
"nogil set `clear` causes concurrent `__str__` to print as empty dict

# Bug report

### Bug description:

Hi,

We're a research group focused on testing concurrent runtimes. Our work-in-progress prototype found that the current nogil build `__str__` can return `""{}""` (empty dict) instead of the expected `""set()""` when there is a concurrent `clear()` operation. The program below shows the wrong behavior:

```python
import threading
import sys
def t0(b1,s,res):
    b1.wait()
    s.clear()

def t1(b1,s,res):
    b1.wait()
    res.append(s.__str__())

def Test():
  s =  {17, 18, 'a', 'b', 'c', 'd', 'e'}
  threads=[]
  barrier = threading.Barrier(2)
  res = []
  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))
  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))
  for i in range(0, len(threads)):
      threads[i].start()
  for i in range(0, len(threads)):
      threads[i].join()
  if res[0] == ""{}"":
      print(""found bug: "" + res[0])

print(""test begin..."")
for i in range(0,50000):
  threads = []
  if i % 1000 == 0:
      print(i)
  for i in range(0,100):
      threads.append(threading.Thread(target= Test))
  for t in threads:
      t.start()
  for t in threads:
      t.join()
print(""test Done"")
```
Sample output:
```
test begin...
0
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
found bug: {}
```

This behavior can be observed quite readily.  We tested it on a number of x86_64 and one ARM machine.

@flypoodles and @overlorde are part of the team, adding them so they get notified about further discussion.

### CPython versions tested on:

3.14, CPython main branch

### Operating systems tested on:

Linux

<!-- gh-linked-prs -->
### Linked PRs
* gh-129978
* gh-130020
<!-- /gh-linked-prs -->
","['import threading\nimport sys\ndef t0(b1,s,res):\n    b1.wait()\n    s.clear()\n\ndef t1(b1,s,res):\n    b1.wait()\n    res.append(s.__str__())\n\ndef Test():\n  s =  {17, 18, \'a\', \'b\', \'c\', \'d\', \'e\'}\n  threads=[]\n  barrier = threading.Barrier(2)\n  res = []\n  threads.append(threading.Thread(target= t0, args=(barrier, s,res)))\n  threads.append(threading.Thread(target= t1, args=(barrier, s,res)))\n  for i in range(0, len(threads)):\n      threads[i].start()\n  for i in range(0, len(threads)):\n      threads[i].join()\n  if res[0] == ""{}"":\n      print(""found bug: "" + res[0])\n\nprint(""test begin..."")\nfor i in range(0,50000):\n  threads = []\n  if i % 1000 == 0:\n      print(i)\n  for i in range(0,100):\n      threads.append(threading.Thread(target= Test))\n  for t in threads:\n      t.start()\n  for t in threads:\n      t.join()\nprint(""test Done"")', 'test begin...\n0\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}\nfound bug: {}']",Thanks @luisggpina - this is fixed now in the main and 3.13 branches.,[],['python'],github,https://github.com/python/cpython/issues/129967,{'repo': 'python/cpython'}
"The tp_dictoffset and Py_TPFLAGS_MANAGED_WEAKREF flag

From the `tp_dictoffset` slot documentation:
>""It is an error to set both the **`Py_TPFLAGS_MANAGED_WEAKREF`** bit and `tp_dictoffset`.""

I think the `Py_TPFLAGS_MANAGED_WEAKREF` flag is being used **incorrectly** in this context. Do you mean the `Py_TPFLAGS_MANAGED_DICT` flag?

https://docs.python.org/3/c-api/typeobj.html#c.PyTypeObject.tp_dictoffset

<!-- gh-linked-prs -->
### Linked PRs
* gh-130044
* gh-130059
* gh-130060
<!-- /gh-linked-prs -->
",[],I agree that it looks like a typo (cc @vstinner),[],['python'],github,https://github.com/python/cpython/issues/129912,{'repo': 'python/cpython'}
"Document that public headers target C11 and C++11

Our public documentation should say that you need C11 or C++11 to `#include <Python.h>`.

Internally, we need to be more lenient & careful (though we won’t promise upfront how much). It's not OK to just break C99 support or slightly out-of-spec compilers.
We should test as much as we can; the devguide should be updated with details.

API WG discussion/vote: https://github.com/capi-workgroup/decisions/issues/30#issuecomment-2610090581
Discourse topic: https://discuss.python.org/t/python-3-14-headers-will-require-c11-and-c-11/79481

<!-- gh-linked-prs -->
### Linked PRs
* gh-130686
* gh-130688
* gh-130692
<!-- /gh-linked-prs -->

### Devguide PR
* https://github.com/python/devguide/pull/1524",[],"I have something to say:

It would be better if this could be managed through some switch macros to toggle between different C versions, This would make the migration process less abrupt, at least giving developers some options to choose from. I believe it's not just about migrating to C11. As far as I know, many are still using C99, and even though this has no impact on the migration results, C99 already fully meets the needs of some CPython developers. Although static assertions are really great, their absence can be compensated for by using a scanner.
(Although this will keep pace with the times.)",[],['python'],github,https://github.com/python/cpython/issues/129666,{'repo': 'python/cpython'}
"contextlib.redirect_stdout/stderr does not work with `pytest-run-parallel`

# Bug report

### Bug description:

redirect_stdout/stderr does not work if freethreading is enabled. 

The following example shows the problem:

```python
# /// script
# dependencies = [
#   ""pytest"",
#   ""pytest-run-parallel""
# ]
# ///


from contextlib import redirect_stdout
from io import StringIO
import time


def test_redirect():
    text=StringIO()
    with redirect_stdout(text):
        print(""hello"")
        time.sleep(1)
        print(""hello"")

    assert text.getvalue()==""hello\nhello\n""


if __name__ == ""__main__"":
    import pytest
    pytest.main([""--parallel-threads=5"",__file__])
```

output:
```
❯ uv run -p 3.13t bug.py
================================== test session starts ==================================
platform linux -- Python 3.13.1, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/frank/projects/bugs/pytest_redirect
plugins: run-parallel-0.3.1
collected 1 item                                                                        

bug.py F                                                                          [100%]

======================================= FAILURES ========================================
_____________________________________ test_redirect _____________________________________

    def test_redirect():
        text=StringIO()
        with redirect_stdout(text):
            print(""hello"")
            time.sleep(1)
            print(""hello"")
    
>       assert text.getvalue()==""hello\nhello\n""
E       AssertionError: assert 'hello\n' == 'hello\nhello\n'
E         
E           hello
E         - hello

bug.py:22: AssertionError
================================ short test summary info ================================
FAILED bug.py::test_redirect - AssertionError: assert 'hello\n' == 'hello\nhello\n'
=================================== 1 failed in 1.04s ===================================
```


The underlying problem is probably the global sys.stdout/stderr state which is shared between threads.
Is it possible to make these thread local?


### CPython versions tested on:

3.13

### Operating systems tested on:

_No response_","['# /// script\n# dependencies = [\n#   ""pytest"",\n#   ""pytest-run-parallel""\n# ]\n# ///\n\n\nfrom contextlib import redirect_stdout\nfrom io import StringIO\nimport time\n\n\ndef test_redirect():\n    text=StringIO()\n    with redirect_stdout(text):\n        print(""hello"")\n        time.sleep(1)\n        print(""hello"")\n\n    assert text.getvalue()==""hello\\nhello\\n""\n\n\nif __name__ == ""__main__"":\n    import pytest\n    pytest.main([""--parallel-threads=5"",__file__])', '❯ uv run -p 3.13t bug.py\n================================== test session starts ==================================\nplatform linux -- Python 3.13.1, pytest-8.3.4, pluggy-1.5.0\nrootdir: /home/frank/projects/bugs/pytest_redirect\nplugins: run-parallel-0.3.1\ncollected 1 item                                                                        \n\nbug.py F                                                                          [100%]\n\n======================================= FAILURES ========================================\n_____________________________________ test_redirect _____________________________________\n\n    def test_redirect():\n        text=StringIO()\n        with redirect_stdout(text):\n            print(""hello"")\n            time.sleep(1)\n            print(""hello"")\n    \n>       assert text.getvalue()==""hello\\nhello\\n""\nE       AssertionError: assert \'hello\\n\' == \'hello\\nhello\\n\'\nE         \nE           hello\nE         - hello\n\nbug.py:22: AssertionError\n================================ short test summary info ================================\nFAILED bug.py::test_redirect - AssertionError: assert \'hello\\n\' == \'hello\\nhello\\n\'\n=================================== 1 failed in 1.04s ===================================']","Changing `sys.stdout` behavior, such as making it thread-local, doesn't seem like a good idea to me either, but I think we can add functionality to `contextlib.redirect_stdout` to make it work better with `pytest-run-parallel` and the similar functionality (gh-127933) we're using to test CPython.

I think it's probably best implemented in an external library, possibly `pytest-run-parallel`, at least at first.

Here's a rough sketch of the idea:

* `contextlib.redirect_stdout` gains an optional argument `per_thread=False`
* When called with `per_thread=True`, `contextlib.redirect_stdout` wraps the passed stream with a `PerThreadStream`, and sets `sys.stdout` to the instance of `PerThreadStream`
* `PerThreadStream` has a slot per-thread, along with a default stream. The `PerThreadStream` delegates file operations (like `write()`) the appropriate stream, or to the default stream if no stream is set for the current thread.
* `contextlib.redirect_stdout` calls are synchronized with each other, but not necessarily with `print()` or `sys.stdout.write()` calls.
* Calls to `contextlib.redirect_stdout(..., per_thread=True)` will set the current thread's stream slot, if `sys.stdout` is already a `PerThreadStream`
* The last `__exit__` from `contextlib.redirect_stdout()` removes the `PerThreadStream` from `sys.stdout` if all per-thread slots are empty, and restores `sys.stdout` to the default stream.
",[],['python'],github,https://github.com/python/cpython/issues/130148,{'repo': 'python/cpython'}
"Float Addition Issue

# Bug report

### Bug description:

This is an issue that python fail sometime to do float Addition

![Image](https://github.com/user-attachments/assets/dfe6c566-b920-41ad-9ac2-960ee1233a62)
Do fix this

### CPython versions tested on:

3.13

### Operating systems tested on:

Windows",[],"@Rudra2701, please take look on the Tutorial: https://docs.python.org/3/tutorial/floatingpoint.html#tut-fp-issues",[],['python'],github,https://github.com/python/cpython/issues/129857,{'repo': 'python/cpython'}
"Logs are getting auto deleted after the date is changed.

# Bug report

### Bug description:

I have written a code that would rotate logs on midnight maintaing backup of 1 day. But the next day, the previous logs are getting deleted.

For example :
While I am checking logs on 14th Feb, I noticed that all the logs generated on 13th Feb, got deleted from instancelogs.log.2025-02-13. The first log generated on 14th Feb is getting stored in instancelogs.log.2025-02-13 file instead of instancelogs.log file , the remaining logs for 14th Feb are correctly stored in instancelogs.log file.

Please look into the issue as we are losing all the logs for 13th of Feb.


I am using below code to handle logs:


```python


import logging
from logging.handlers import TimedRotatingFileHandler


#logger instances for PPT creator
LOG_FILE_PATH = ""../STORE_LOGS/instancelogs.log""

instance_logger = logging.getLogger('instance_logger')

instance_logger_file_handler = None


instance_logger_file_handler = TimedRotatingFileHandler(LOG_FILE_PATH, when='midnight', interval=1, backupCount=1)
instance_logger_file_formatter = logging.Formatter(
    fmt=""[%(asctime)s] - [%(levelname)s]  - [%(filename)s] - [%(funcName)s] - %(message)s"",
    datefmt=""%d-%m-%y %H:%M:%S"")
instance_logger_file_handler.setFormatter(instance_logger_file_formatter)

instance_logger.setLevel(logging.DEBUG)
instance_logger.addHandler(instance_logger_file_handler)

```


### CPython versions tested on:

3.9

### Operating systems tested on:

Linux","['import logging\nfrom logging.handlers import TimedRotatingFileHandler\n\n\n#logger instances for PPT creator\nLOG_FILE_PATH = ""../STORE_LOGS/instancelogs.log""\n\ninstance_logger = logging.getLogger(\'instance_logger\')\n\ninstance_logger_file_handler = None\n\n\ninstance_logger_file_handler = TimedRotatingFileHandler(LOG_FILE_PATH, when=\'midnight\', interval=1, backupCount=1)\ninstance_logger_file_formatter = logging.Formatter(\n    fmt=""[%(asctime)s] - [%(levelname)s]  - [%(filename)s] - [%(funcName)s] - %(message)s"",\n    datefmt=""%d-%m-%y %H:%M:%S"")\ninstance_logger_file_handler.setFormatter(instance_logger_file_formatter)\n\ninstance_logger.setLevel(logging.DEBUG)\ninstance_logger.addHandler(instance_logger_file_handler)']","Hello, this issue tracker is for bugs and feature requests in CPython itself.

Please post in the help forum for questions about your own code:

https://discuss.python.org/c/help/7",[],['python'],github,https://github.com/python/cpython/issues/130108,{'repo': 'python/cpython'}
"`test_notify` multiprocessing test is flaky

# Bug report

Seen in https://github.com/python/cpython/actions/runs/13606907022/job/38039459160?pr=130732

```
FAIL: test_notify (test.test_multiprocessing_spawn.test_threads.WithThreadsTestCondition.test_notify)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\a\cpython\cpython\Lib\test\_test_multiprocessing.py"", line 1691, in test_notify
    self.assertReturnsIfImplemented(2, get_value, woken)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File ""D:\a\cpython\cpython\Lib\test\_test_multiprocessing.py"", line 275, in assertReturnsIfImplemented
    return self.assertEqual(value, res)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
AssertionError: 2 != 1
```

<!-- gh-linked-prs -->
### Linked PRs
* gh-130797
* gh-130802
* gh-130803
<!-- /gh-linked-prs -->
","['FAIL: test_notify (test.test_multiprocessing_spawn.test_threads.WithThreadsTestCondition.test_notify)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File ""D:\\a\\cpython\\cpython\\Lib\\test\\_test_multiprocessing.py"", line 1691, in test_notify\n    self.assertReturnsIfImplemented(2, get_value, woken)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n  File ""D:\\a\\cpython\\cpython\\Lib\\test\\_test_multiprocessing.py"", line 275, in assertReturnsIfImplemented\n    return self.assertEqual(value, res)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nAssertionError: 2 != 1']","Well, the test uses a sleep of 100 ms as a synchronization method, it's not reliable. I wrote PR https://github.com/python/cpython/pull/130797 to wait until a condition is met using a loop.",[],['python'],github,https://github.com/python/cpython/issues/130737,{'repo': 'python/cpython'}
"pyrepl messed up terminal if a signal handler expects stdin

# Bug report

### Bug description:

This is related to #129614 but more straightforward and irrelevant to pdb. (pdb needs this to be fixed though)

Start REPL from a terminal and do
```
import signal
signal.signal(signal.SIGINT, lambda s, f: input(""test""))
<Ctrl+C>
```

Your terminal is messed up and newline won't work anymore. (Not the Python repl which will exit due to some run time error, the terminal itself is messed up)

### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux","['import signal\nsignal.signal(signal.SIGINT, lambda s, f: input(""test""))\n<Ctrl+C>']","I started looking into this but I'm just trying to better understand the issue first:

In general when using REPL, you would use exit() or Ctrl-D  to exit. 

I wasn't able to replicate the terminal being messed up, but just wanted to clarify: 
In this case bug isn't that Ctrl+C isn't working,  it's that trying to get user input from within a SIGINT handler while already in the REPL causes terminal corruption? What is the desired behaviour for when keyboard interrupt happens in this scenario?",[],['python'],github,https://github.com/python/cpython/issues/130168,{'repo': 'python/cpython'}
"tracemalloc regression: deadlocks in 3.12.9

# Bug report

### Bug description:

After recent changes, Polars debug builds, which integrate tracemalloc tracking, started experiencing deadlocks. Ripping out the tracemalloc integration fixed them (https://github.com/pola-rs/polars/pull/21231). This started happening specifically when GitHub Actions switched to 3.12.9. I imagine this is due to the recent tracemalloc bug fixes.

No reproducer yet, but as a starting point:

1. I am fairly certain this was _not_ after doing `tracemalloc.start()`, since it happened in e.g. doctest runs that don't do that at all.
2. Polars in this mode would trace Rust allocations using `PyTraceMalloc_Track()`: https://github.com/pola-rs/polars/blob/f378b24aeaaa14a8e7dacb6b35103424e8b97f1c/py-polars/src/memory.rs#L53
3. Polars is heavily multi-threaded, and tracemalloc memory tracking would happen both while holding GIL and not holding GIL.

So this suggests some mixture of GIL-holding and non-GIL holding threads calling `PyTraceMalloc_Track()` and friends can cause deadlocks.

### CPython versions tested on:

3.12

### Operating systems tested on:

Linux",[],"Here's a plausible theory: the way Polars works is there's a main thread that dispatches tasks to a Rust thread pool, and waits for results. When using Python version of Polars, it's important that main thread release the GIL before dispatching to the thread pool, for situations where operations running threads may acquire the GIL. So I went and did that in the relevant APIs. Many operations would never acquire the GIL so likely I missed some cases.

With latest version of tracemalloc, when tracemalloc is compiled into Polars, _any_ Rust memory allocation will acquire the GIL. So the scope for deadlocks is now much broader. _Any_ operation will acquire the GIL.

If this is the case, is it a bug in CPython? Maaaaybe? It's a change in behavior, certainly always acquiring GIL when allocations are tracked, even when `tracemalloc.start()` isn't called. But arguably if you're going to work with tracemalloc you need to handle GIL acquisition since that was always going to happen after `tracemalloc.start()` was called.

So maybe not a CPython bug. But probably worth at minimum documenting that `PyTraceMalloc_Track()` acquires the GIL.

I will try to validate this theory, and if it is correct I will close this issue.",[],['python'],github,https://github.com/python/cpython/issues/130093,{'repo': 'python/cpython'}
"Add ""Report an Issue"" to idle

# Feature or enhancement

### Proposal:

Add some sort of ""Report an Issue"" button.

Maybe under Help?


### Has this already been discussed elsewhere?

This is a minor feature, which does not need previous discussion elsewhere

### Links to previous discussion of this feature:

_No response_",[],"The first entry in Help=> About IDLE is ""Python Forums: https://discuss.python.org"", with the link being clickable.  This is where we want people with IDLE questions, bug claims, and most feature proposals to go to first.  (Questions can also go to Stackoverflow as long as I actively monitor the Python IDLE tag, and that is also a good place to search for answered questions.)  I do not want to direct people here as prior to discus.python.org, a majority of IDLE issues here on the tracker should not have been posted here.",[],['python'],github,https://github.com/python/cpython/issues/129592,{'repo': 'python/cpython'}
"Traceback colors are shifted when the line contains wide unicode characters

# Bug report

### Bug description:

<img width=""571"" alt=""Image"" src=""https://github.com/user-attachments/assets/ddf6eacc-8176-459e-88a3-39a8661386c1"" />

In #28150, the carets' positions are compatible with wide unicode characters. I believe the colors should also be compatible.

### CPython versions tested on:

3.13, CPython main branch

### Operating systems tested on:

Windows, macOS

<!-- gh-linked-prs -->
### Linked PRs
* gh-130277
<!-- /gh-linked-prs -->
",[],"Not sure if this borderline case `啊哈 = 1/0#######` is necessary. If use Unicode to replace Chinese characters, there is no color shift.

![Image](https://github.com/user-attachments/assets/bc5f3f32-d831-4f64-a821-d035f18b08ca)",[],['python'],github,https://github.com/python/cpython/issues/130273,{'repo': 'python/cpython'}
"GhostBSD 20.10.1 python3 build failed: ./Modules/posixmodule.c:8817:21: error: 'I_PUSH' undeclared

# Bug report

### Bug description:


I want to compile python on my **GhostBSD 20.10.1** OS based on **freeBSD 14.1 STABLE**
The bug is the same for python **3.11**, **3.12**, **3.13.** 
I have not tried with earlier versions.

Here is the bug:
ptmx is detected, but stropts.h does not exist. 

In the **./Modules/posixmodule.c** file, on lines 8814, 8815 and 8816, there is no test to see if **HAVE_STROPTS_H** is defined, even though the variable **I_PUSH** defined in **stropts.h** is used.

I've looked hard but in the current version of GhostBSD **stropts.h** is no longer included. 
While browsing the internet, I read here and there that stropts.h was no longer part of posix. 
EDIT: Removed in POSIX.1-2024.

To solve the problem I could install **openpty**, but this library doesn't seem to be available any more either. 

```
# checking for stropts.h... no
# checking for pty.h... no
# checking for _getpty... no
# checking for openpty... no
# checking for openpty in -lutil... no
# checking for openpty in -lbsd... no
# checking for library containing login_tty... no
# checking for forkpty... no
# checking for forkpty in -lutil... no
# checking for forkpty in -lbsd... no
# checking for /dev/ptmx... yes 
````

### CPython versions tested on:

3.13

### Operating systems tested on:

_No response_",['# checking for stropts.h... no\n# checking for pty.h... no\n# checking for _getpty... no\n# checking for openpty... no\n# checking for openpty in -lutil... no\n# checking for openpty in -lbsd... no\n# checking for library containing login_tty... no\n# checking for forkpty... no\n# checking for forkpty in -lutil... no\n# checking for forkpty in -lbsd... no\n# checking for /dev/ptmx... yes'],"The solution:
sudo pkg install -g 'GhostBSD*-dev'

The explication:
https://forums.ghostbsd.org/d/194-where-is-libutilh
",[],['python'],github,https://github.com/python/cpython/issues/130456,{'repo': 'python/cpython'}
"`configure` help for tail call interpreter is wrong

# Bug report

```
  --tail-call-interp      enable tail-calling interpreter in evaluation loop
                          and rest of CPython
```

But the flag is `--with-tail-call-interp`

cc @Fidget-Spinner 

<!-- gh-linked-prs -->
### Linked PRs
* gh-129754
<!-- /gh-linked-prs -->
",['--tail-call-interp      enable tail-calling interpreter in evaluation loop\n                          and rest of CPython'],@colesbury woops thanks for catching this!,[],['python'],github,https://github.com/python/cpython/issues/129737,{'repo': 'python/cpython'}
"--help doesn't return when argparse is called from inside a program acting on a passed-in string

# Bug report

### Bug description:

If I parse a command line and I use the option -h or --help, the program exits through a path not under my control, i.e. if in a try/except block, the program just exits, this is ok for the usual case, but if my program is modal, that is I have different parsings for different modes, I'd like to capture a bad option  (or simply handle a return from --help).  In the modal case, a bad parse or even --help will cause the program to lock up.
note: parse_known_args() locks up

```python

the parse routine:

def parse_afe_send(theLine):
    #
    err_f = False

    parser = argparse.ArgumentParser()

    parser.add_argument(""-i"", ""--iter"", type=int, 
                                      default=1, help=""iterations."")
                           
    parser.add_argument(""-d"", ""--delay"",type=int, default=0, 
                                       help=""seconds delay between iterations."")

    parser.add_argument(""-r"", ""--response"",action='store_true',
                        help=""response expected."")

    parser.add_argument(""-e"", ""--expect"",  
                              default="""", help=""expected response."")

    parser.add_argument(""-a"", ""--append"",  
                              default="""", help=""append response to file."")

    #
    # adding listen without wait argument
    # default delay determine stochastically
    #
    theWait = 3
    parser.add_argument(""-l"", ""--listen"",type = int, 
                                         default = theWait,
                                         const = theWait,
                                         nargs='?',
                                         help = ""listen seconds."")
    #
    # Note 1: bad option causes exit()
    #         which bypasses the exception handler and
    #         prevents cleanup, so vector elsewhere
    #
    # Note 2: argument parser doesn't handle no options, so 
    #         treats a no option parameter as an error, 
    #         Need to have a pass-through for this case
    #
    try:
      (args,unknowns) = parser.parse_known_args(theLine)
    except Exception as eobj:
      #
      # One would think that a bad option leads to unknowns,
      # however option -3 does not
      #
      err_str = ""options exception in parse_afe_send()""
      err_code = -1
      eobj_str = repr(eobj)
      errDict = {'err_code': err_code, 'err_str': err_str, 'eobj_str': eobj_str}
      raise UserDefinedException(errDict)     
    else:
        theLast = len(unknowns)
        ii = 0
        while (ii < theLast):
          if (unknowns[ii][0] == '-'):
            print(""unknown option="",unknowns[ii])
            err_f = True    # keep going, print all
          ii = ii + 1
        # end while

        if (err_f):
          err_str = ""other options exception in parse_afe_send()""
          err_code = -2
          eobj_str = None
          errDict = {'err_code': err_code, 'err_str': err_str, 'eobj_str': eobj_str}
          raise UserDefinedException(errDict)
    # end else

    return args
# end parse_afe_send

the invocation, trimmed:

      try:
        shlex_out = shlex.split(theCmdString)
      except Exception as eobj:        # likely no closing quotations
        print(""afe_send: shlex exception:"",eobj)
        status = -2
        err_f = True
        return status
      #                                  # still here? 
         
      try:
        args = parse_afe_send(shlex_out) # parse send options
      except Exception as eobj:
        err_f = True
        err_str = ""afe_send: other options exception in parse_afe_send()""
        err_code = -3
        eobj_str = repr(eobj)
        errDict = {'err_code': err_code, 'err_str': err_str, 'eobj_str': eobj_str}
        raise UserDefinedException(errDict)
```


### CPython versions tested on:

CPython main branch

### Operating systems tested on:

Linux","['the parse routine:\n\ndef parse_afe_send(theLine):\n    #\n    err_f = False\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""-i"", ""--iter"", type=int, \n                                      default=1, help=""iterations."")\n                           \n    parser.add_argument(""-d"", ""--delay"",type=int, default=0, \n                                       help=""seconds delay between iterations."")\n\n    parser.add_argument(""-r"", ""--response"",action=\'store_true\',\n                        help=""response expected."")\n\n    parser.add_argument(""-e"", ""--expect"",  \n                              default="""", help=""expected response."")\n\n    parser.add_argument(""-a"", ""--append"",  \n                              default="""", help=""append response to file."")\n\n    #\n    # adding listen without wait argument\n    # default delay determine stochastically\n    #\n    theWait = 3\n    parser.add_argument(""-l"", ""--listen"",type = int, \n                                         default = theWait,\n                                         const = theWait,\n                                         nargs=\'?\',\n                                         help = ""listen seconds."")\n    #\n    # Note 1: bad option causes exit()\n    #         which bypasses the exception handler and\n    #         prevents cleanup, so vector elsewhere\n    #\n    # Note 2: argument parser doesn\'t handle no options, so \n    #         treats a no option parameter as an error, \n    #         Need to have a pass-through for this case\n    #\n    try:\n      (args,unknowns) = parser.parse_known_args(theLine)\n    except Exception as eobj:\n      #\n      # One would think that a bad option leads to unknowns,\n      # however option -3 does not\n      #\n      err_str = ""options exception in parse_afe_send()""\n      err_code = -1\n      eobj_str = repr(eobj)\n      errDict = {\'err_code\': err_code, \'err_str\': err_str, \'eobj_str\': eobj_str}\n      raise UserDefinedException(errDict)     \n    else:\n        theLast = len(unknowns)\n        ii = 0\n        while (ii < theLast):\n          if (unknowns[ii][0] == \'-\'):\n            print(""unknown option="",unknowns[ii])\n            err_f = True    # keep going, print all\n          ii = ii + 1\n        # end while\n\n        if (err_f):\n          err_str = ""other options exception in parse_afe_send()""\n          err_code = -2\n          eobj_str = None\n          errDict = {\'err_code\': err_code, \'err_str\': err_str, \'eobj_str\': eobj_str}\n          raise UserDefinedException(errDict)\n    # end else\n\n    return args\n# end parse_afe_send\n\nthe invocation, trimmed:\n\n      try:\n        shlex_out = shlex.split(theCmdString)\n      except Exception as eobj:        # likely no closing quotations\n        print(""afe_send: shlex exception:"",eobj)\n        status = -2\n        err_f = True\n        return status\n      #                                  # still here? \n         \n      try:\n        args = parse_afe_send(shlex_out) # parse send options\n      except Exception as eobj:\n        err_f = True\n        err_str = ""afe_send: other options exception in parse_afe_send()""\n        err_code = -3\n        eobj_str = repr(eobj)\n        errDict = {\'err_code\': err_code, \'err_str\': err_str, \'eobj_str\': eobj_str}\n        raise UserDefinedException(errDict)']","Maybe this is helpful? https://docs.python.org/3/library/argparse.html#exiting-methods

I expect you could override `error()` too. Maybe this is juts a docs defect?",[],['python'],github,https://github.com/python/cpython/issues/130690,{'repo': 'python/cpython'}
"add ability to specify name for `tk.OptionMenu` and `ttk.OptionMenu`

# Feature or enhancement

### Proposal:

In current implementation of `tk.OptionMenu` and `ttk.OptionMenu`, we can not specify name to them since adding additional `kwargs` raises `unknown option` error

Since after initialization of widget `name` cannot be changed, hence we cannot specify custom name such as `games_option_menu` etc to the `OptionMenu`.

Ability to specify name to a widget is very handy, since it helps programmer to easily gain access to widget between diffrent scopes and this ability is lacking in `OptionMenu` widget.


### Has this already been discussed elsewhere?

No response given

### Links to previous discussion of this feature:

_No response_

<!-- gh-linked-prs -->
### Linked PRs
* gh-130502
<!-- /gh-linked-prs -->
",[],This is a worthy idea.,[],['python'],github,https://github.com/python/cpython/issues/130482,{'repo': 'python/cpython'}
